{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8d7adaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"   #(xxxx is your specific GPU ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f1adb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Activation, Dense, Flatten, GlobalAveragePooling2D\n",
    "from MyEarlyStopping import MyEarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.preprocessing import LabelEncoder  \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "354ae52c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 30000 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "All_data = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "All_data_generator = All_data.flow_from_directory('Mel_Audio_folder_digits',\n",
    "                                                batch_size=1,\n",
    "                                                target_size=(224,224),\n",
    "                                                class_mode='categorical',\n",
    "                                               shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7532b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_names = All_data_generator.filenames\n",
    "image_no = [i.split(\"/\")[1].split(\"_\")[2].split(\".\")[0] for i in image_names]\n",
    "image_no = np.array(list(map(int, image_no)))\n",
    "ALL_participant_class = [i.split(\"/\")[1].split(\"_\")[1] for i in image_names]\n",
    "ALL_participant_class = np.array(list(map(int, ALL_participant_class)))\n",
    "command_class = All_data_generator.classes\n",
    "All_participant_class = tf.keras.utils.to_categorical(ALL_participant_class-1, num_classes=60)\n",
    "All_command_class = tf.keras.utils.to_categorical(command_class, num_classes=10)\n",
    "All_command_uniform = All_command_class*0+1/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a7eb15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "All_Inputs = [next(All_data_generator)[0][0] for _ in range(len(All_data_generator))]\n",
    "All_Inputs = np.array(All_Inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d38377",
   "metadata": {},
   "source": [
    "# performance of initial model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d122d6ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Existing_Train_participant_class = np.load(\"Existing_Train_participant_class.npy\")\n",
    "Existing_Train_participant_uniform = np.load(\"Existing_Train_participant_uniform.npy\")\n",
    "Existing_Train_command_class = np.load(\"Existing_Train_command_class.npy\")\n",
    "Existing_Train_command_uniform = np.load(\"Existing_Train_command_uniform.npy\")\n",
    "Existing_Train_Inputs = np.load(\"Existing_Train_Inputs.npy\")\n",
    "Existing_Test_participant_class = np.load(\"Existing_Test_participant_class.npy\")\n",
    "Existing_Test_participant_uniform = np.load(\"Existing_Test_participant_uniform.npy\")\n",
    "Existing_Test_command_class = np.load(\"Existing_Test_command_class.npy\")\n",
    "Existing_Test_command_uniform = np.load(\"Existing_Test_command_uniform.npy\")\n",
    "Existing_Test_Inputs = np.load(\"Existing_Test_Inputs.npy\")\n",
    "\n",
    "\n",
    "speaker_number = Existing_Train_participant_class.shape[1]\n",
    "speaker_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "283822c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the initial model \n",
    "resnet_model_0 = tf.keras.models.load_model('resnet_model_0531_digit_refine_group_5->30_final_free&unfree.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "130e81c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# command_accuracy = []\n",
    "# subject_accuracy = []\n",
    "# for i in range(1,61):\n",
    "    \n",
    "#     select_indexs_test_i = (image_no>39)&(image_no<=49)&(ALL_participant_class==i)\n",
    "#     Test_Inputs_i = All_Inputs[select_indexs_test_i]\n",
    "#     Test_command_class_i = All_command_class[select_indexs_test_i]\n",
    "#     Test_command_uniform_i = Test_command_class_i*0+1/10\n",
    "    \n",
    "#     # subject prediction \n",
    "#     predictions = resnet_model_0.predict(Test_Inputs_i)[0]\n",
    "#     predicted_classes = np.argmax(predictions, axis=1)\n",
    "#     true_classes = np.array([j.split(\"/\")[1].split(\"_\")[1] for j in All_data_generator.filenames])\n",
    "#     true_classes = np.array(list(map(int, true_classes)))[select_indexs_test_i]-1\n",
    "    \n",
    "#     subject_accuracy.append(round(sum(x == y for x, y in zip(true_classes, predicted_classes)) / len(true_classes),4))\n",
    "    \n",
    "#     # command prediction \n",
    "#     predictions = resnet_model_0.predict(Test_Inputs_i)[1]\n",
    "#     predicted_classes = np.argmax(predictions, axis=1)\n",
    "#     true_classes = np.array([j.split(\"/\")[0] for j in All_data_generator.filenames])\n",
    "#     true_classes = np.array(list(map(int, true_classes)))[select_indexs_test_i]\n",
    "    \n",
    "#     command_accuracy.append(round(sum(x == y for x, y in zip(true_classes, predicted_classes)) / len(true_classes),4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db4be689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# performance_command = pd.DataFrame(columns=[\"Subject_No\",\"add_data\"] + list(range(1,61)))\n",
    "# performance_speaker = pd.DataFrame(columns=[\"Subject_No\",\"add_data\"] + list(range(1,61)))\n",
    "# performance_command = performance_command.append({\"Subject_No\":5,\"add_data\":\"40%\"}, ignore_index=True)\n",
    "# performance_speaker = performance_speaker.append({\"Subject_No\":5,\"add_data\":\"40%\"}, ignore_index=True)\n",
    "# performance_command.iloc[performance_command['Subject_No']==5,2:] = command_accuracy\n",
    "# performance_speaker.iloc[performance_speaker['Subject_No']==5,2:] = subject_accuracy\n",
    "\n",
    "performance_speaker = pd.read_csv(\"performance_speaker_0531_5->30_final_free&unfree.csv\")\n",
    "performance_command = pd.read_csv(\"performance_command_0531_5->30_final_free&unfree.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a95f74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "57ba2daa",
   "metadata": {},
   "source": [
    "# refine models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "446cf67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "actv_fun_1_1 = \"relu\" \n",
    "actv_fun_1_2 = \"sigmoid\"\n",
    "shape_1_1 = 128\n",
    "shape_1_2 = 256\n",
    "actv_fun_2_1 = \"sigmoid\" \n",
    "actv_fun_2_2 = \"sigmoid\"\n",
    "shape_2_1 = 512\n",
    "shape_2_2 = 512\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3fe9a99",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "27/27 [==============================] - 7s 270ms/step - loss: 0.4481 - participant_output_loss: 0.4375 - command_output_loss: 0.0031 - command_output_1_loss: 0.0067 - participant_output_1_loss: 8.3122e-04 - participant_output_accuracy: 0.9424 - command_output_accuracy: 0.9988 - command_output_1_accuracy: 0.0841 - participant_output_1_accuracy: 0.0853\n",
      "Epoch 2/10\n",
      "27/27 [==============================] - 6s 229ms/step - loss: 0.0911 - participant_output_loss: 0.0870 - command_output_loss: 0.0013 - command_output_1_loss: 0.0025 - participant_output_1_loss: 3.2583e-04 - participant_output_accuracy: 0.9988 - command_output_accuracy: 0.9994 - command_output_1_accuracy: 0.1518 - participant_output_1_accuracy: 0.0700\n",
      "Epoch 3/10\n",
      "27/27 [==============================] - 7s 250ms/step - loss: 0.0580 - participant_output_loss: 0.0544 - command_output_loss: 0.0012 - command_output_1_loss: 0.0022 - participant_output_1_loss: 2.0527e-04 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9994 - command_output_1_accuracy: 0.0229 - participant_output_1_accuracy: 0.0547\n",
      "Epoch 4/10\n",
      "27/27 [==============================] - 6s 233ms/step - loss: 0.0437 - participant_output_loss: 0.0413 - command_output_loss: 2.7104e-04 - command_output_1_loss: 0.0019 - participant_output_1_loss: 1.3435e-04 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0635 - participant_output_1_accuracy: 0.0606\n",
      "Epoch 5/10\n",
      "27/27 [==============================] - 6s 233ms/step - loss: 0.0362 - participant_output_loss: 0.0342 - command_output_loss: 1.7940e-04 - command_output_1_loss: 0.0017 - participant_output_1_loss: 9.2087e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0888 - participant_output_1_accuracy: 0.0759\n",
      "Epoch 6/10\n",
      "27/27 [==============================] - 6s 224ms/step - loss: 0.0310 - participant_output_loss: 0.0292 - command_output_loss: 1.4510e-04 - command_output_1_loss: 0.0016 - participant_output_1_loss: 7.0576e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.1129 - participant_output_1_accuracy: 0.0594\n",
      "Epoch 7/10\n",
      "27/27 [==============================] - 6s 222ms/step - loss: 0.0276 - participant_output_loss: 0.0260 - command_output_loss: 1.2661e-04 - command_output_1_loss: 0.0015 - participant_output_1_loss: 5.7799e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0371 - participant_output_1_accuracy: 0.0624\n",
      "Epoch 8/10\n",
      "27/27 [==============================] - 6s 222ms/step - loss: 0.0250 - participant_output_loss: 0.0234 - command_output_loss: 1.1059e-04 - command_output_1_loss: 0.0014 - participant_output_1_loss: 5.0329e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0559 - participant_output_1_accuracy: 0.0529\n",
      "Epoch 9/10\n",
      "27/27 [==============================] - 6s 215ms/step - loss: 0.0228 - participant_output_loss: 0.0213 - command_output_loss: 1.0327e-04 - command_output_1_loss: 0.0013 - participant_output_1_loss: 4.4791e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0824 - participant_output_1_accuracy: 0.0576\n",
      "Epoch 10/10\n",
      "27/27 [==============================] - 6s 214ms/step - loss: 0.0212 - participant_output_loss: 0.0197 - command_output_loss: 9.5118e-05 - command_output_1_loss: 0.0013 - participant_output_1_loss: 4.1388e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0700 - participant_output_1_accuracy: 0.0453\n",
      "Epoch 1/10\n",
      "27/27 [==============================] - 6s 231ms/step - loss: 0.0197 - participant_output_loss: 0.0183 - command_output_loss: 8.8353e-05 - command_output_1_loss: 0.0013 - participant_output_1_loss: 3.8910e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0706 - participant_output_1_accuracy: 0.0453\n",
      "Epoch 2/10\n",
      "27/27 [==============================] - 6s 216ms/step - loss: 0.0183 - participant_output_loss: 0.0169 - command_output_loss: 8.3152e-05 - command_output_1_loss: 0.0012 - participant_output_1_loss: 3.5675e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.1029 - participant_output_1_accuracy: 0.0476\n",
      "Epoch 3/10\n",
      "27/27 [==============================] - 6s 216ms/step - loss: 0.0170 - participant_output_loss: 0.0157 - command_output_loss: 7.7941e-05 - command_output_1_loss: 0.0012 - participant_output_1_loss: 3.4297e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0465 - participant_output_1_accuracy: 0.0382\n",
      "Epoch 4/10\n",
      "27/27 [==============================] - 6s 216ms/step - loss: 0.0159 - participant_output_loss: 0.0146 - command_output_loss: 7.5878e-05 - command_output_1_loss: 0.0011 - participant_output_1_loss: 3.2197e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0535 - participant_output_1_accuracy: 0.0488\n",
      "Epoch 5/10\n",
      "27/27 [==============================] - 6s 214ms/step - loss: 0.0149 - participant_output_loss: 0.0137 - command_output_loss: 7.2975e-05 - command_output_1_loss: 0.0011 - participant_output_1_loss: 3.0225e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0188 - participant_output_1_accuracy: 0.0453\n",
      "Epoch 6/10\n",
      "27/27 [==============================] - 6s 217ms/step - loss: 0.0141 - participant_output_loss: 0.0129 - command_output_loss: 6.9437e-05 - command_output_1_loss: 0.0011 - participant_output_1_loss: 2.8769e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0141 - participant_output_1_accuracy: 0.0500\n",
      "Epoch 7/10\n",
      "27/27 [==============================] - 6s 215ms/step - loss: 0.0134 - participant_output_loss: 0.0122 - command_output_loss: 6.7842e-05 - command_output_1_loss: 0.0010 - participant_output_1_loss: 2.7713e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0318 - participant_output_1_accuracy: 0.0371\n",
      "Epoch 8/10\n",
      "27/27 [==============================] - 6s 212ms/step - loss: 0.0127 - participant_output_loss: 0.0116 - command_output_loss: 6.5660e-05 - command_output_1_loss: 9.7162e-04 - participant_output_1_loss: 2.6664e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0271 - participant_output_1_accuracy: 0.0400\n",
      "Epoch 9/10\n",
      "27/27 [==============================] - 6s 213ms/step - loss: 0.0120 - participant_output_loss: 0.0110 - command_output_loss: 6.3640e-05 - command_output_1_loss: 9.0868e-04 - participant_output_1_loss: 2.5520e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0047 - participant_output_1_accuracy: 0.0371\n",
      "Epoch 10/10\n",
      "27/27 [==============================] - 6s 215ms/step - loss: 0.0114 - participant_output_loss: 0.0104 - command_output_loss: 6.2989e-05 - command_output_1_loss: 8.5633e-04 - participant_output_1_loss: 2.4241e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0259 - participant_output_1_accuracy: 0.0376\n",
      "Epoch 1/10\n",
      "28/28 [==============================] - 7s 258ms/step - loss: 0.4205 - participant_output_loss: 0.4123 - command_output_loss: 5.6118e-04 - command_output_1_loss: 0.0072 - participant_output_1_loss: 3.9027e-04 - participant_output_accuracy: 0.9474 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.1040 - participant_output_1_accuracy: 0.0086\n",
      "Epoch 2/10\n",
      "28/28 [==============================] - 7s 244ms/step - loss: 0.1008 - participant_output_loss: 0.0978 - command_output_loss: 4.0368e-04 - command_output_1_loss: 0.0024 - participant_output_1_loss: 1.1081e-04 - participant_output_accuracy: 0.9966 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0251 - participant_output_1_accuracy: 0.0560\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 7s 254ms/step - loss: 0.0653 - participant_output_loss: 0.0629 - command_output_loss: 3.5436e-04 - command_output_1_loss: 0.0021 - participant_output_1_loss: 7.3729e-05 - participant_output_accuracy: 0.9994 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.1434 - participant_output_1_accuracy: 0.0903\n",
      "Epoch 4/10\n",
      "28/28 [==============================] - 7s 252ms/step - loss: 0.0516 - participant_output_loss: 0.0494 - command_output_loss: 2.1744e-04 - command_output_1_loss: 0.0018 - participant_output_1_loss: 5.6991e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.1954 - participant_output_1_accuracy: 0.0954\n",
      "Epoch 5/10\n",
      "28/28 [==============================] - 7s 239ms/step - loss: 0.0427 - participant_output_loss: 0.0408 - command_output_loss: 1.6895e-04 - command_output_1_loss: 0.0017 - participant_output_1_loss: 5.0578e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.2103 - participant_output_1_accuracy: 0.0949\n",
      "Epoch 6/10\n",
      "28/28 [==============================] - 7s 237ms/step - loss: 0.0368 - participant_output_loss: 0.0350 - command_output_loss: 9.9127e-05 - command_output_1_loss: 0.0016 - participant_output_1_loss: 4.2816e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.3257 - participant_output_1_accuracy: 0.0920\n",
      "Epoch 7/10\n",
      "28/28 [==============================] - 7s 235ms/step - loss: 0.0325 - participant_output_loss: 0.0309 - command_output_loss: 9.4686e-05 - command_output_1_loss: 0.0015 - participant_output_1_loss: 3.8025e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.2434 - participant_output_1_accuracy: 0.1120\n",
      "Epoch 8/10\n",
      "28/28 [==============================] - 6s 231ms/step - loss: 0.0290 - participant_output_loss: 0.0274 - command_output_loss: 9.1107e-05 - command_output_1_loss: 0.0014 - participant_output_1_loss: 3.4231e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.3000 - participant_output_1_accuracy: 0.1023\n",
      "Epoch 9/10\n",
      "28/28 [==============================] - 6s 229ms/step - loss: 0.0264 - participant_output_loss: 0.0249 - command_output_loss: 8.7815e-05 - command_output_1_loss: 0.0013 - participant_output_1_loss: 3.0866e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.3217 - participant_output_1_accuracy: 0.1114\n",
      "Epoch 10/10\n",
      "28/28 [==============================] - 6s 228ms/step - loss: 0.0243 - participant_output_loss: 0.0230 - command_output_loss: 8.4884e-05 - command_output_1_loss: 0.0013 - participant_output_1_loss: 2.8601e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.3337 - participant_output_1_accuracy: 0.1137\n",
      "Epoch 1/10\n",
      "28/28 [==============================] - 7s 246ms/step - loss: 0.0225 - participant_output_loss: 0.0212 - command_output_loss: 7.8535e-05 - command_output_1_loss: 0.0012 - participant_output_1_loss: 2.6740e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.3400 - participant_output_1_accuracy: 0.1006\n",
      "Epoch 2/10\n",
      "28/28 [==============================] - 7s 238ms/step - loss: 0.0208 - participant_output_loss: 0.0195 - command_output_loss: 7.3241e-05 - command_output_1_loss: 0.0012 - participant_output_1_loss: 2.4116e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.4834 - participant_output_1_accuracy: 0.0966\n",
      "Epoch 3/10\n",
      "28/28 [==============================] - 7s 237ms/step - loss: 0.0194 - participant_output_loss: 0.0182 - command_output_loss: 6.9541e-05 - command_output_1_loss: 0.0012 - participant_output_1_loss: 2.2601e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.4903 - participant_output_1_accuracy: 0.0840\n",
      "Epoch 4/10\n",
      "28/28 [==============================] - 7s 236ms/step - loss: 0.0183 - participant_output_loss: 0.0170 - command_output_loss: 6.5936e-05 - command_output_1_loss: 0.0012 - participant_output_1_loss: 2.1814e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.5754 - participant_output_1_accuracy: 0.0794\n",
      "Epoch 5/10\n",
      "28/28 [==============================] - 6s 226ms/step - loss: 0.0172 - participant_output_loss: 0.0159 - command_output_loss: 6.2477e-05 - command_output_1_loss: 0.0011 - participant_output_1_loss: 2.0587e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.5749 - participant_output_1_accuracy: 0.0960\n",
      "Epoch 6/10\n",
      "28/28 [==============================] - 7s 233ms/step - loss: 0.0161 - participant_output_loss: 0.0149 - command_output_loss: 6.0386e-05 - command_output_1_loss: 0.0011 - participant_output_1_loss: 1.9476e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.5406 - participant_output_1_accuracy: 0.0737\n",
      "Epoch 7/10\n",
      "28/28 [==============================] - 7s 233ms/step - loss: 0.0152 - participant_output_loss: 0.0141 - command_output_loss: 5.9761e-05 - command_output_1_loss: 0.0010 - participant_output_1_loss: 1.8227e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.4583 - participant_output_1_accuracy: 0.0834\n",
      "Epoch 8/10\n",
      "28/28 [==============================] - 6s 224ms/step - loss: 0.0142 - participant_output_loss: 0.0132 - command_output_loss: 5.8478e-05 - command_output_1_loss: 9.7880e-04 - participant_output_1_loss: 1.7689e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.3331 - participant_output_1_accuracy: 0.0829\n",
      "Epoch 9/10\n",
      "28/28 [==============================] - 6s 218ms/step - loss: 0.0134 - participant_output_loss: 0.0124 - command_output_loss: 5.7525e-05 - command_output_1_loss: 9.2096e-04 - participant_output_1_loss: 1.6653e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.2326 - participant_output_1_accuracy: 0.0771\n",
      "Epoch 10/10\n",
      "28/28 [==============================] - 6s 228ms/step - loss: 0.0127 - participant_output_loss: 0.0118 - command_output_loss: 5.7444e-05 - command_output_1_loss: 8.6628e-04 - participant_output_1_loss: 1.5937e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.2394 - participant_output_1_accuracy: 0.0794\n",
      "Epoch 1/10\n",
      "29/29 [==============================] - 8s 259ms/step - loss: 0.4596 - participant_output_loss: 0.4507 - command_output_loss: 1.2584e-04 - command_output_1_loss: 0.0085 - participant_output_1_loss: 2.3982e-04 - participant_output_accuracy: 0.9500 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0900 - participant_output_1_accuracy: 0.0739\n",
      "Epoch 2/10\n",
      "29/29 [==============================] - 7s 236ms/step - loss: 0.1252 - participant_output_loss: 0.1227 - command_output_loss: 3.3255e-04 - command_output_1_loss: 0.0021 - participant_output_1_loss: 7.0886e-05 - participant_output_accuracy: 0.9967 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0744 - participant_output_1_accuracy: 0.0278\n",
      "Epoch 3/10\n",
      "29/29 [==============================] - 6s 224ms/step - loss: 0.0879 - participant_output_loss: 0.0857 - command_output_loss: 3.5806e-04 - command_output_1_loss: 0.0017 - participant_output_1_loss: 5.3281e-05 - participant_output_accuracy: 0.9994 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0622 - participant_output_1_accuracy: 0.0367\n",
      "Epoch 4/10\n",
      "29/29 [==============================] - 6s 219ms/step - loss: 0.0713 - participant_output_loss: 0.0689 - command_output_loss: 8.1896e-04 - command_output_1_loss: 0.0016 - participant_output_1_loss: 5.2133e-05 - participant_output_accuracy: 0.9994 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0628 - participant_output_1_accuracy: 0.0361\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 7s 228ms/step - loss: 0.0577 - participant_output_loss: 0.0560 - command_output_loss: 2.9391e-04 - command_output_1_loss: 0.0014 - participant_output_1_loss: 4.7420e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0328 - participant_output_1_accuracy: 0.0217\n",
      "Epoch 6/10\n",
      "29/29 [==============================] - 6s 219ms/step - loss: 0.0627 - participant_output_loss: 0.0540 - command_output_loss: 0.0072 - command_output_1_loss: 0.0014 - participant_output_1_loss: 6.0479e-05 - participant_output_accuracy: 0.9989 - command_output_accuracy: 0.9983 - command_output_1_accuracy: 0.0672 - participant_output_1_accuracy: 0.0167\n",
      "Epoch 7/10\n",
      "29/29 [==============================] - 7s 230ms/step - loss: 0.0712 - participant_output_loss: 0.0603 - command_output_loss: 0.0095 - command_output_1_loss: 0.0014 - participant_output_1_loss: 9.1396e-05 - participant_output_accuracy: 0.9972 - command_output_accuracy: 0.9972 - command_output_1_accuracy: 0.0867 - participant_output_1_accuracy: 0.0656\n",
      "Epoch 8/10\n",
      "29/29 [==============================] - 7s 229ms/step - loss: 0.0685 - participant_output_loss: 0.0591 - command_output_loss: 0.0079 - command_output_1_loss: 0.0014 - participant_output_1_loss: 1.0620e-04 - participant_output_accuracy: 0.9967 - command_output_accuracy: 0.9983 - command_output_1_accuracy: 0.0606 - participant_output_1_accuracy: 0.0594\n",
      "Epoch 9/10\n",
      "29/29 [==============================] - 6s 223ms/step - loss: 0.0477 - participant_output_loss: 0.0453 - command_output_loss: 0.0011 - command_output_1_loss: 0.0011 - participant_output_1_loss: 9.1924e-05 - participant_output_accuracy: 0.9972 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0417 - participant_output_1_accuracy: 0.0344\n",
      "Epoch 10/10\n",
      "29/29 [==============================] - 6s 216ms/step - loss: 0.0294 - participant_output_loss: 0.0279 - command_output_loss: 4.4303e-04 - command_output_1_loss: 9.5602e-04 - participant_output_1_loss: 7.1754e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0422 - participant_output_1_accuracy: 0.0356\n",
      "Epoch 1/10\n",
      "29/29 [==============================] - 7s 246ms/step - loss: 0.0263 - participant_output_loss: 0.0251 - command_output_loss: 2.9697e-04 - command_output_1_loss: 8.7162e-04 - participant_output_1_loss: 6.1308e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0556 - participant_output_1_accuracy: 0.0417\n",
      "Epoch 2/10\n",
      "29/29 [==============================] - 7s 238ms/step - loss: 0.0241 - participant_output_loss: 0.0230 - command_output_loss: 2.3572e-04 - command_output_1_loss: 8.0354e-04 - participant_output_1_loss: 5.6038e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0728 - participant_output_1_accuracy: 0.0506\n",
      "Epoch 3/10\n",
      "29/29 [==============================] - 7s 240ms/step - loss: 0.0212 - participant_output_loss: 0.0202 - command_output_loss: 2.0091e-04 - command_output_1_loss: 7.2762e-04 - participant_output_1_loss: 4.9050e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0989 - participant_output_1_accuracy: 0.0517\n",
      "Epoch 4/10\n",
      "29/29 [==============================] - 7s 237ms/step - loss: 0.0193 - participant_output_loss: 0.0184 - command_output_loss: 1.7930e-04 - command_output_1_loss: 6.6888e-04 - participant_output_1_loss: 4.6006e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0422 - participant_output_1_accuracy: 0.0561\n",
      "Epoch 5/10\n",
      "29/29 [==============================] - 7s 236ms/step - loss: 0.0177 - participant_output_loss: 0.0169 - command_output_loss: 1.6414e-04 - command_output_1_loss: 6.2059e-04 - participant_output_1_loss: 4.3599e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0306 - participant_output_1_accuracy: 0.0539\n",
      "Epoch 6/10\n",
      "29/29 [==============================] - 7s 242ms/step - loss: 0.0165 - participant_output_loss: 0.0157 - command_output_loss: 1.5041e-04 - command_output_1_loss: 5.7918e-04 - participant_output_1_loss: 4.0727e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0194 - participant_output_1_accuracy: 0.0600\n",
      "Epoch 7/10\n",
      "29/29 [==============================] - 7s 236ms/step - loss: 0.0155 - participant_output_loss: 0.0148 - command_output_loss: 1.4478e-04 - command_output_1_loss: 5.2727e-04 - participant_output_1_loss: 3.8671e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0150 - participant_output_1_accuracy: 0.0589\n",
      "Epoch 8/10\n",
      "29/29 [==============================] - 7s 230ms/step - loss: 0.0146 - participant_output_loss: 0.0139 - command_output_loss: 1.3500e-04 - command_output_1_loss: 4.9257e-04 - participant_output_1_loss: 3.6654e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0217 - participant_output_1_accuracy: 0.0600\n",
      "Epoch 9/10\n",
      "29/29 [==============================] - 7s 235ms/step - loss: 0.0138 - participant_output_loss: 0.0132 - command_output_loss: 1.2651e-04 - command_output_1_loss: 4.5739e-04 - participant_output_1_loss: 3.4090e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0811 - participant_output_1_accuracy: 0.0522\n",
      "Epoch 10/10\n",
      "29/29 [==============================] - 7s 233ms/step - loss: 0.0136 - participant_output_loss: 0.0131 - command_output_loss: 1.1848e-04 - command_output_1_loss: 4.2713e-04 - participant_output_1_loss: 3.3213e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0972 - participant_output_1_accuracy: 0.0561\n",
      "Epoch 1/10\n",
      "29/29 [==============================] - 7s 257ms/step - loss: 0.4409 - participant_output_loss: 0.4328 - command_output_loss: 6.6916e-04 - command_output_1_loss: 0.0070 - participant_output_1_loss: 4.4624e-04 - participant_output_accuracy: 0.9481 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.1168 - participant_output_1_accuracy: 0.0654\n",
      "Epoch 2/10\n",
      "29/29 [==============================] - 7s 238ms/step - loss: 0.0855 - participant_output_loss: 0.0833 - command_output_loss: 4.0070e-04 - command_output_1_loss: 0.0016 - participant_output_1_loss: 1.6537e-04 - participant_output_accuracy: 0.9995 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.2319 - participant_output_1_accuracy: 0.0368\n",
      "Epoch 3/10\n",
      "29/29 [==============================] - 7s 233ms/step - loss: 0.0575 - participant_output_loss: 0.0560 - command_output_loss: 2.4565e-04 - command_output_1_loss: 0.0011 - participant_output_1_loss: 8.5227e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.2162 - participant_output_1_accuracy: 0.0535\n",
      "Epoch 4/10\n",
      "29/29 [==============================] - 6s 222ms/step - loss: 0.0471 - participant_output_loss: 0.0460 - command_output_loss: 1.8880e-04 - command_output_1_loss: 9.1780e-04 - participant_output_1_loss: 5.7232e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0838 - participant_output_1_accuracy: 0.0616\n",
      "Epoch 5/10\n",
      "29/29 [==============================] - 6s 223ms/step - loss: 0.0403 - participant_output_loss: 0.0394 - command_output_loss: 1.5016e-04 - command_output_1_loss: 7.4406e-04 - participant_output_1_loss: 4.5681e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0605 - participant_output_1_accuracy: 0.0611\n",
      "Epoch 6/10\n",
      "29/29 [==============================] - 6s 219ms/step - loss: 0.0358 - participant_output_loss: 0.0350 - command_output_loss: 1.3159e-04 - command_output_1_loss: 6.2905e-04 - participant_output_1_loss: 3.9041e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0416 - participant_output_1_accuracy: 0.0659\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 7s 231ms/step - loss: 0.0323 - participant_output_loss: 0.0316 - command_output_loss: 1.1634e-04 - command_output_1_loss: 5.6269e-04 - participant_output_1_loss: 3.5158e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0222 - participant_output_1_accuracy: 0.0676\n",
      "Epoch 8/10\n",
      "29/29 [==============================] - 7s 241ms/step - loss: 0.0291 - participant_output_loss: 0.0285 - command_output_loss: 1.0273e-04 - command_output_1_loss: 5.1097e-04 - participant_output_1_loss: 3.0671e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0168 - participant_output_1_accuracy: 0.0627\n",
      "Epoch 9/10\n",
      "29/29 [==============================] - 7s 256ms/step - loss: 0.0263 - participant_output_loss: 0.0257 - command_output_loss: 9.3717e-05 - command_output_1_loss: 4.7114e-04 - participant_output_1_loss: 2.8100e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0043 - participant_output_1_accuracy: 0.0503\n",
      "Epoch 10/10\n",
      "29/29 [==============================] - 7s 231ms/step - loss: 0.0239 - participant_output_loss: 0.0234 - command_output_loss: 8.5322e-05 - command_output_1_loss: 4.3706e-04 - participant_output_1_loss: 2.5781e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0081 - participant_output_1_accuracy: 0.0508\n",
      "Epoch 1/10\n",
      "29/29 [==============================] - 8s 260ms/step - loss: 0.0220 - participant_output_loss: 0.0214 - command_output_loss: 7.9646e-05 - command_output_1_loss: 4.0593e-04 - participant_output_1_loss: 2.3844e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0103 - participant_output_1_accuracy: 0.0530\n",
      "Epoch 2/10\n",
      "29/29 [==============================] - 7s 249ms/step - loss: 0.0203 - participant_output_loss: 0.0199 - command_output_loss: 7.5146e-05 - command_output_1_loss: 3.6498e-04 - participant_output_1_loss: 2.1920e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0119 - participant_output_1_accuracy: 0.0541\n",
      "Epoch 3/10\n",
      "29/29 [==============================] - 7s 245ms/step - loss: 0.0189 - participant_output_loss: 0.0185 - command_output_loss: 6.9035e-05 - command_output_1_loss: 3.3099e-04 - participant_output_1_loss: 2.0917e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0373 - participant_output_1_accuracy: 0.0422\n",
      "Epoch 4/10\n",
      "29/29 [==============================] - 7s 233ms/step - loss: 0.0177 - participant_output_loss: 0.0173 - command_output_loss: 6.4986e-05 - command_output_1_loss: 3.1168e-04 - participant_output_1_loss: 1.9570e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0514 - participant_output_1_accuracy: 0.0416\n",
      "Epoch 5/10\n",
      "29/29 [==============================] - 6s 222ms/step - loss: 0.0166 - participant_output_loss: 0.0163 - command_output_loss: 6.1660e-05 - command_output_1_loss: 3.0106e-04 - participant_output_1_loss: 1.8406e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0665 - participant_output_1_accuracy: 0.0416\n",
      "Epoch 6/10\n",
      "29/29 [==============================] - 7s 237ms/step - loss: 0.0156 - participant_output_loss: 0.0152 - command_output_loss: 5.7961e-05 - command_output_1_loss: 2.9106e-04 - participant_output_1_loss: 1.7223e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0730 - participant_output_1_accuracy: 0.0378\n",
      "Epoch 7/10\n",
      "29/29 [==============================] - 7s 257ms/step - loss: 0.0146 - participant_output_loss: 0.0143 - command_output_loss: 5.4577e-05 - command_output_1_loss: 2.8048e-04 - participant_output_1_loss: 1.6313e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.1373 - participant_output_1_accuracy: 0.0432\n",
      "Epoch 8/10\n",
      "29/29 [==============================] - 7s 246ms/step - loss: 0.0138 - participant_output_loss: 0.0134 - command_output_loss: 5.2435e-05 - command_output_1_loss: 2.6878e-04 - participant_output_1_loss: 1.5687e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0876 - participant_output_1_accuracy: 0.0319\n",
      "Epoch 9/10\n",
      "29/29 [==============================] - 7s 235ms/step - loss: 0.0130 - participant_output_loss: 0.0127 - command_output_loss: 5.0108e-05 - command_output_1_loss: 2.5343e-04 - participant_output_1_loss: 1.4598e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.1654 - participant_output_1_accuracy: 0.0314\n",
      "Epoch 10/10\n",
      "29/29 [==============================] - 7s 236ms/step - loss: 0.0123 - participant_output_loss: 0.0120 - command_output_loss: 4.7978e-05 - command_output_1_loss: 2.3700e-04 - participant_output_1_loss: 1.3900e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.2541 - participant_output_1_accuracy: 0.0335\n",
      "Epoch 1/10\n",
      "30/30 [==============================] - 8s 251ms/step - loss: 0.4290 - participant_output_loss: 0.4193 - command_output_loss: 0.0044 - command_output_1_loss: 0.0050 - participant_output_1_loss: 2.9742e-04 - participant_output_accuracy: 0.9532 - command_output_accuracy: 0.9979 - command_output_1_accuracy: 0.0921 - participant_output_1_accuracy: 0.0674\n",
      "Epoch 2/10\n",
      "30/30 [==============================] - 7s 229ms/step - loss: 0.1079 - participant_output_loss: 0.1060 - command_output_loss: 5.5271e-04 - command_output_1_loss: 0.0012 - participant_output_1_loss: 1.4247e-04 - participant_output_accuracy: 0.9979 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0163 - participant_output_1_accuracy: 0.0600\n",
      "Epoch 3/10\n",
      "30/30 [==============================] - 7s 233ms/step - loss: 0.0729 - participant_output_loss: 0.0716 - command_output_loss: 1.8132e-04 - command_output_1_loss: 9.7550e-04 - participant_output_1_loss: 1.0012e-04 - participant_output_accuracy: 0.9995 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0384 - participant_output_1_accuracy: 0.0379\n",
      "Epoch 4/10\n",
      "30/30 [==============================] - 7s 221ms/step - loss: 0.0607 - participant_output_loss: 0.0596 - command_output_loss: 1.5969e-04 - command_output_1_loss: 8.2955e-04 - participant_output_1_loss: 7.9252e-05 - participant_output_accuracy: 0.9989 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0505 - participant_output_1_accuracy: 0.0389\n",
      "Epoch 5/10\n",
      "30/30 [==============================] - 7s 244ms/step - loss: 0.0458 - participant_output_loss: 0.0449 - command_output_loss: 1.2547e-04 - command_output_1_loss: 7.1584e-04 - participant_output_1_loss: 6.5005e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0568 - participant_output_1_accuracy: 0.0489\n",
      "Epoch 6/10\n",
      "30/30 [==============================] - 7s 248ms/step - loss: 0.0397 - participant_output_loss: 0.0389 - command_output_loss: 1.0651e-04 - command_output_1_loss: 6.2841e-04 - participant_output_1_loss: 5.6239e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0589 - participant_output_1_accuracy: 0.0463\n",
      "Epoch 7/10\n",
      "30/30 [==============================] - 8s 255ms/step - loss: 0.0353 - participant_output_loss: 0.0346 - command_output_loss: 9.3408e-05 - command_output_1_loss: 5.5104e-04 - participant_output_1_loss: 4.9827e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0774 - participant_output_1_accuracy: 0.0537\n",
      "Epoch 8/10\n",
      "30/30 [==============================] - 7s 235ms/step - loss: 0.0312 - participant_output_loss: 0.0306 - command_output_loss: 8.5195e-05 - command_output_1_loss: 4.7404e-04 - participant_output_1_loss: 4.4904e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0874 - participant_output_1_accuracy: 0.0463\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 7s 218ms/step - loss: 0.0281 - participant_output_loss: 0.0276 - command_output_loss: 8.0633e-05 - command_output_1_loss: 4.1245e-04 - participant_output_1_loss: 4.0755e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0711 - participant_output_1_accuracy: 0.0458\n",
      "Epoch 10/10\n",
      "30/30 [==============================] - 7s 221ms/step - loss: 0.0254 - participant_output_loss: 0.0250 - command_output_loss: 7.6171e-05 - command_output_1_loss: 3.4879e-04 - participant_output_1_loss: 3.8304e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0321 - participant_output_1_accuracy: 0.0421\n",
      "Epoch 1/10\n",
      "30/30 [==============================] - 7s 244ms/step - loss: 0.0232 - participant_output_loss: 0.0228 - command_output_loss: 7.2545e-05 - command_output_1_loss: 3.1075e-04 - participant_output_1_loss: 3.5529e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0653 - participant_output_1_accuracy: 0.0437\n",
      "Epoch 2/10\n",
      "30/30 [==============================] - 7s 220ms/step - loss: 0.0213 - participant_output_loss: 0.0209 - command_output_loss: 6.8392e-05 - command_output_1_loss: 2.7973e-04 - participant_output_1_loss: 3.2912e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0279 - participant_output_1_accuracy: 0.0463\n",
      "Epoch 3/10\n",
      "30/30 [==============================] - 7s 221ms/step - loss: 0.0196 - participant_output_loss: 0.0193 - command_output_loss: 6.5536e-05 - command_output_1_loss: 2.5418e-04 - participant_output_1_loss: 3.1537e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0637 - participant_output_1_accuracy: 0.0400\n",
      "Epoch 4/10\n",
      "30/30 [==============================] - 7s 220ms/step - loss: 0.0181 - participant_output_loss: 0.0178 - command_output_loss: 6.0799e-05 - command_output_1_loss: 2.3718e-04 - participant_output_1_loss: 3.0190e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0532 - participant_output_1_accuracy: 0.0411\n",
      "Epoch 5/10\n",
      "30/30 [==============================] - 7s 218ms/step - loss: 0.0169 - participant_output_loss: 0.0166 - command_output_loss: 5.8589e-05 - command_output_1_loss: 2.2107e-04 - participant_output_1_loss: 2.7626e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0732 - participant_output_1_accuracy: 0.0468\n",
      "Epoch 6/10\n",
      "30/30 [==============================] - 7s 224ms/step - loss: 0.0158 - participant_output_loss: 0.0155 - command_output_loss: 5.6625e-05 - command_output_1_loss: 2.0733e-04 - participant_output_1_loss: 2.6109e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0700 - participant_output_1_accuracy: 0.0389\n",
      "Epoch 7/10\n",
      "30/30 [==============================] - 7s 221ms/step - loss: 0.0149 - participant_output_loss: 0.0146 - command_output_loss: 5.4247e-05 - command_output_1_loss: 1.9790e-04 - participant_output_1_loss: 2.5325e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0484 - participant_output_1_accuracy: 0.0484\n",
      "Epoch 8/10\n",
      "30/30 [==============================] - 7s 243ms/step - loss: 0.0140 - participant_output_loss: 0.0138 - command_output_loss: 5.1896e-05 - command_output_1_loss: 1.9071e-04 - participant_output_1_loss: 2.4213e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0579 - participant_output_1_accuracy: 0.0395\n",
      "Epoch 9/10\n",
      "30/30 [==============================] - 8s 251ms/step - loss: 0.0132 - participant_output_loss: 0.0130 - command_output_loss: 4.9971e-05 - command_output_1_loss: 1.8513e-04 - participant_output_1_loss: 2.3323e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0505 - participant_output_1_accuracy: 0.0384\n",
      "Epoch 10/10\n",
      "30/30 [==============================] - 8s 251ms/step - loss: 0.0125 - participant_output_loss: 0.0122 - command_output_loss: 4.8122e-05 - command_output_1_loss: 1.8020e-04 - participant_output_1_loss: 2.2763e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0637 - participant_output_1_accuracy: 0.0437\n",
      "Epoch 1/10\n",
      "31/31 [==============================] - 8s 252ms/step - loss: 0.4417 - participant_output_loss: 0.4377 - command_output_loss: 1.2890e-04 - command_output_1_loss: 0.0037 - participant_output_1_loss: 2.0436e-04 - participant_output_accuracy: 0.9462 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.1241 - participant_output_1_accuracy: 0.0600\n",
      "Epoch 2/10\n",
      "31/31 [==============================] - 8s 243ms/step - loss: 0.1032 - participant_output_loss: 0.1020 - command_output_loss: 5.2138e-04 - command_output_1_loss: 5.9802e-04 - participant_output_1_loss: 7.3045e-05 - participant_output_accuracy: 0.9969 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.1046 - participant_output_1_accuracy: 0.0621\n",
      "Epoch 3/10\n",
      "31/31 [==============================] - 8s 259ms/step - loss: 0.0660 - participant_output_loss: 0.0650 - command_output_loss: 4.4782e-04 - command_output_1_loss: 4.5401e-04 - participant_output_1_loss: 5.9627e-05 - participant_output_accuracy: 0.9995 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0949 - participant_output_1_accuracy: 0.0662\n",
      "Epoch 4/10\n",
      "31/31 [==============================] - 8s 247ms/step - loss: 0.0580 - participant_output_loss: 0.0565 - command_output_loss: 0.0011 - command_output_1_loss: 3.9924e-04 - participant_output_1_loss: 6.1362e-05 - participant_output_accuracy: 0.9985 - command_output_accuracy: 0.9995 - command_output_1_accuracy: 0.1785 - participant_output_1_accuracy: 0.0364\n",
      "Epoch 5/10\n",
      "31/31 [==============================] - 7s 238ms/step - loss: 0.0464 - participant_output_loss: 0.0458 - command_output_loss: 1.6957e-04 - command_output_1_loss: 3.4547e-04 - participant_output_1_loss: 5.2652e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0851 - participant_output_1_accuracy: 0.0374\n",
      "Epoch 6/10\n",
      "31/31 [==============================] - 7s 222ms/step - loss: 0.0374 - participant_output_loss: 0.0370 - command_output_loss: 1.1706e-04 - command_output_1_loss: 3.0466e-04 - participant_output_1_loss: 4.3756e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0949 - participant_output_1_accuracy: 0.0369\n",
      "Epoch 7/10\n",
      "31/31 [==============================] - 7s 230ms/step - loss: 0.0327 - participant_output_loss: 0.0323 - command_output_loss: 8.8883e-05 - command_output_1_loss: 2.7393e-04 - participant_output_1_loss: 3.9114e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.1405 - participant_output_1_accuracy: 0.0277\n",
      "Epoch 8/10\n",
      "31/31 [==============================] - 7s 238ms/step - loss: 0.0291 - participant_output_loss: 0.0287 - command_output_loss: 7.9442e-05 - command_output_1_loss: 2.3988e-04 - participant_output_1_loss: 3.5861e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.1533 - participant_output_1_accuracy: 0.0256\n",
      "Epoch 9/10\n",
      "31/31 [==============================] - 8s 246ms/step - loss: 0.0265 - participant_output_loss: 0.0262 - command_output_loss: 7.4463e-05 - command_output_1_loss: 2.0285e-04 - participant_output_1_loss: 3.2832e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0508 - participant_output_1_accuracy: 0.0251\n",
      "Epoch 10/10\n",
      "31/31 [==============================] - 7s 226ms/step - loss: 0.0239 - participant_output_loss: 0.0236 - command_output_loss: 6.5702e-05 - command_output_1_loss: 1.7495e-04 - participant_output_1_loss: 3.0155e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.1015 - participant_output_1_accuracy: 0.0256\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 7s 241ms/step - loss: 0.0216 - participant_output_loss: 0.0214 - command_output_loss: 6.1222e-05 - command_output_1_loss: 1.5733e-04 - participant_output_1_loss: 2.7965e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0774 - participant_output_1_accuracy: 0.0287\n",
      "Epoch 2/10\n",
      "31/31 [==============================] - 8s 248ms/step - loss: 0.0200 - participant_output_loss: 0.0197 - command_output_loss: 5.7839e-05 - command_output_1_loss: 1.4316e-04 - participant_output_1_loss: 2.6132e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.1036 - participant_output_1_accuracy: 0.0267\n",
      "Epoch 3/10\n",
      "31/31 [==============================] - 8s 243ms/step - loss: 0.0185 - participant_output_loss: 0.0183 - command_output_loss: 5.4983e-05 - command_output_1_loss: 1.2880e-04 - participant_output_1_loss: 2.4899e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0713 - participant_output_1_accuracy: 0.0277\n",
      "Epoch 4/10\n",
      "31/31 [==============================] - 7s 241ms/step - loss: 0.0172 - participant_output_loss: 0.0170 - command_output_loss: 5.0646e-05 - command_output_1_loss: 1.1475e-04 - participant_output_1_loss: 2.3345e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.1138 - participant_output_1_accuracy: 0.0292\n",
      "Epoch 5/10\n",
      "31/31 [==============================] - 7s 218ms/step - loss: 0.0161 - participant_output_loss: 0.0159 - command_output_loss: 4.8453e-05 - command_output_1_loss: 1.0157e-04 - participant_output_1_loss: 2.2056e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.1272 - participant_output_1_accuracy: 0.0272\n",
      "Epoch 6/10\n",
      "31/31 [==============================] - 7s 216ms/step - loss: 0.0151 - participant_output_loss: 0.0149 - command_output_loss: 4.6718e-05 - command_output_1_loss: 9.0319e-05 - participant_output_1_loss: 2.1008e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.1579 - participant_output_1_accuracy: 0.0215\n",
      "Epoch 7/10\n",
      "31/31 [==============================] - 7s 216ms/step - loss: 0.0141 - participant_output_loss: 0.0140 - command_output_loss: 4.3897e-05 - command_output_1_loss: 8.0581e-05 - participant_output_1_loss: 2.0092e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.1677 - participant_output_1_accuracy: 0.0287\n",
      "Epoch 8/10\n",
      "31/31 [==============================] - 7s 215ms/step - loss: 0.0133 - participant_output_loss: 0.0131 - command_output_loss: 4.1188e-05 - command_output_1_loss: 7.4021e-05 - participant_output_1_loss: 1.8956e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.1805 - participant_output_1_accuracy: 0.0308\n",
      "Epoch 9/10\n",
      "31/31 [==============================] - 7s 224ms/step - loss: 0.0125 - participant_output_loss: 0.0124 - command_output_loss: 3.9092e-05 - command_output_1_loss: 6.9571e-05 - participant_output_1_loss: 1.8057e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.1862 - participant_output_1_accuracy: 0.0287\n",
      "Epoch 10/10\n",
      "31/31 [==============================] - 8s 251ms/step - loss: 0.0118 - participant_output_loss: 0.0117 - command_output_loss: 3.7286e-05 - command_output_1_loss: 6.6528e-05 - participant_output_1_loss: 1.7129e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.2021 - participant_output_1_accuracy: 0.0344\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 8s 241ms/step - loss: 0.4872 - participant_output_loss: 0.4831 - command_output_loss: 1.3281e-04 - command_output_1_loss: 0.0037 - participant_output_1_loss: 2.6312e-04 - participant_output_accuracy: 0.9525 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0665 - participant_output_1_accuracy: 0.0035\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 7s 225ms/step - loss: 0.1155 - participant_output_loss: 0.1142 - command_output_loss: 4.7044e-04 - command_output_1_loss: 7.0947e-04 - participant_output_1_loss: 8.0866e-05 - participant_output_accuracy: 0.9995 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0410 - participant_output_1_accuracy: 0.0210\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 7s 225ms/step - loss: 0.0816 - participant_output_loss: 0.0805 - command_output_loss: 4.9309e-04 - command_output_1_loss: 5.2537e-04 - participant_output_1_loss: 6.1297e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.2225 - participant_output_1_accuracy: 0.0370\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 7s 221ms/step - loss: 0.0758 - participant_output_loss: 0.0722 - command_output_loss: 0.0030 - command_output_1_loss: 5.0864e-04 - participant_output_1_loss: 7.2719e-05 - participant_output_accuracy: 0.9990 - command_output_accuracy: 0.9990 - command_output_1_accuracy: 0.2170 - participant_output_1_accuracy: 0.0285\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 8s 245ms/step - loss: 0.0639 - participant_output_loss: 0.0595 - command_output_loss: 0.0039 - command_output_1_loss: 4.5974e-04 - participant_output_1_loss: 9.1106e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9985 - command_output_1_accuracy: 0.0065 - participant_output_1_accuracy: 0.0235\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 8s 250ms/step - loss: 0.0791 - participant_output_loss: 0.0749 - command_output_loss: 0.0036 - command_output_1_loss: 5.0150e-04 - participant_output_1_loss: 1.0654e-04 - participant_output_accuracy: 0.9960 - command_output_accuracy: 0.9990 - command_output_1_accuracy: 0.0335 - participant_output_1_accuracy: 0.0135\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 8s 244ms/step - loss: 0.0662 - participant_output_loss: 0.0643 - command_output_loss: 0.0014 - command_output_1_loss: 3.9744e-04 - participant_output_1_loss: 9.6567e-05 - participant_output_accuracy: 0.9945 - command_output_accuracy: 0.9995 - command_output_1_accuracy: 0.0715 - participant_output_1_accuracy: 0.0135\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 7s 217ms/step - loss: 0.0540 - participant_output_loss: 0.0532 - command_output_loss: 3.9786e-04 - command_output_1_loss: 2.7920e-04 - participant_output_1_loss: 8.2550e-05 - participant_output_accuracy: 0.9965 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.1290 - participant_output_1_accuracy: 0.0265\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 7s 215ms/step - loss: 0.0335 - participant_output_loss: 0.0330 - command_output_loss: 2.2929e-04 - command_output_1_loss: 2.3336e-04 - participant_output_1_loss: 6.9862e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0535 - participant_output_1_accuracy: 0.0320\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 7s 215ms/step - loss: 0.0276 - participant_output_loss: 0.0272 - command_output_loss: 1.6321e-04 - command_output_1_loss: 1.9739e-04 - participant_output_1_loss: 5.8325e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0375 - participant_output_1_accuracy: 0.0360\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 8s 249ms/step - loss: 0.0248 - participant_output_loss: 0.0244 - command_output_loss: 1.2985e-04 - command_output_1_loss: 1.7679e-04 - participant_output_1_loss: 5.2056e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0280 - participant_output_1_accuracy: 0.0400\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 8s 243ms/step - loss: 0.0227 - participant_output_loss: 0.0224 - command_output_loss: 1.1101e-04 - command_output_1_loss: 1.5693e-04 - participant_output_1_loss: 4.7490e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0190 - participant_output_1_accuracy: 0.0565\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 8s 243ms/step - loss: 0.0211 - participant_output_loss: 0.0208 - command_output_loss: 1.0017e-04 - command_output_1_loss: 1.3657e-04 - participant_output_1_loss: 4.3470e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0375 - participant_output_1_accuracy: 0.0550\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 7s 230ms/step - loss: 0.0200 - participant_output_loss: 0.0197 - command_output_loss: 9.6419e-05 - command_output_1_loss: 1.2231e-04 - participant_output_1_loss: 4.1870e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0250 - participant_output_1_accuracy: 0.0525\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 7s 216ms/step - loss: 0.0184 - participant_output_loss: 0.0181 - command_output_loss: 8.4709e-05 - command_output_1_loss: 1.0600e-04 - participant_output_1_loss: 3.9150e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0310 - participant_output_1_accuracy: 0.0495\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 7s 233ms/step - loss: 0.0172 - participant_output_loss: 0.0170 - command_output_loss: 7.8146e-05 - command_output_1_loss: 9.6104e-05 - participant_output_1_loss: 3.7534e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0445 - participant_output_1_accuracy: 0.0635\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 8s 240ms/step - loss: 0.0161 - participant_output_loss: 0.0160 - command_output_loss: 7.1076e-05 - command_output_1_loss: 8.6711e-05 - participant_output_1_loss: 3.5161e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0345 - participant_output_1_accuracy: 0.0525\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 8s 251ms/step - loss: 0.0152 - participant_output_loss: 0.0150 - command_output_loss: 6.6734e-05 - command_output_1_loss: 8.0043e-05 - participant_output_1_loss: 3.3375e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0405 - participant_output_1_accuracy: 0.0585\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 7s 221ms/step - loss: 0.0143 - participant_output_loss: 0.0142 - command_output_loss: 6.1932e-05 - command_output_1_loss: 7.4388e-05 - participant_output_1_loss: 3.1722e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0400 - participant_output_1_accuracy: 0.0485\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 7s 224ms/step - loss: 0.0136 - participant_output_loss: 0.0134 - command_output_loss: 5.8737e-05 - command_output_1_loss: 7.0063e-05 - participant_output_1_loss: 3.0660e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0405 - participant_output_1_accuracy: 0.0470\n",
      "Epoch 1/10\n",
      "33/33 [==============================] - 8s 237ms/step - loss: 0.5323 - participant_output_loss: 0.5275 - command_output_loss: 0.0011 - command_output_1_loss: 0.0034 - participant_output_1_loss: 3.2888e-04 - participant_output_accuracy: 0.9429 - command_output_accuracy: 0.9995 - command_output_1_accuracy: 0.0727 - participant_output_1_accuracy: 0.0439\n",
      "Epoch 2/10\n",
      "33/33 [==============================] - 7s 222ms/step - loss: 0.1618 - participant_output_loss: 0.1603 - command_output_loss: 7.4215e-04 - command_output_1_loss: 5.8209e-04 - participant_output_1_loss: 1.7453e-04 - participant_output_accuracy: 0.9976 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0224 - participant_output_1_accuracy: 0.0844\n",
      "Epoch 3/10\n",
      "33/33 [==============================] - 8s 232ms/step - loss: 0.1162 - participant_output_loss: 0.1152 - command_output_loss: 3.8358e-04 - command_output_1_loss: 4.6695e-04 - participant_output_1_loss: 1.3872e-04 - participant_output_accuracy: 0.9971 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0873 - participant_output_1_accuracy: 0.1317\n",
      "Epoch 4/10\n",
      "33/33 [==============================] - 9s 261ms/step - loss: 0.0762 - participant_output_loss: 0.0755 - command_output_loss: 1.6709e-04 - command_output_1_loss: 4.1929e-04 - participant_output_1_loss: 1.1425e-04 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0571 - participant_output_1_accuracy: 0.1059\n",
      "Epoch 5/10\n",
      "33/33 [==============================] - 8s 239ms/step - loss: 0.0609 - participant_output_loss: 0.0603 - command_output_loss: 1.0672e-04 - command_output_1_loss: 3.9175e-04 - participant_output_1_loss: 9.6303e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.1200 - participant_output_1_accuracy: 0.1024\n",
      "Epoch 6/10\n",
      "33/33 [==============================] - 7s 220ms/step - loss: 0.0604 - participant_output_loss: 0.0598 - command_output_loss: 1.5968e-04 - command_output_1_loss: 3.7374e-04 - participant_output_1_loss: 8.8076e-05 - participant_output_accuracy: 0.9985 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0849 - participant_output_1_accuracy: 0.1039\n",
      "Epoch 7/10\n",
      "33/33 [==============================] - 7s 216ms/step - loss: 0.0505 - participant_output_loss: 0.0499 - command_output_loss: 1.9906e-04 - command_output_1_loss: 3.4244e-04 - participant_output_1_loss: 8.0193e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.1873 - participant_output_1_accuracy: 0.0590\n",
      "Epoch 8/10\n",
      "33/33 [==============================] - 7s 217ms/step - loss: 0.0511 - participant_output_loss: 0.0505 - command_output_loss: 2.5913e-04 - command_output_1_loss: 3.3796e-04 - participant_output_1_loss: 8.2763e-05 - participant_output_accuracy: 0.9995 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.1234 - participant_output_1_accuracy: 0.0420\n",
      "Epoch 9/10\n",
      "33/33 [==============================] - 7s 213ms/step - loss: 0.0415 - participant_output_loss: 0.0410 - command_output_loss: 8.6716e-05 - command_output_1_loss: 2.9843e-04 - participant_output_1_loss: 7.1171e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0415 - participant_output_1_accuracy: 0.0815\n",
      "Epoch 10/10\n",
      "33/33 [==============================] - 7s 214ms/step - loss: 0.0398 - participant_output_loss: 0.0394 - command_output_loss: 7.6931e-05 - command_output_1_loss: 2.7609e-04 - participant_output_1_loss: 5.8995e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0263 - participant_output_1_accuracy: 0.0790\n",
      "Epoch 1/10\n",
      "33/33 [==============================] - 8s 232ms/step - loss: 0.0331 - participant_output_loss: 0.0327 - command_output_loss: 6.4712e-05 - command_output_1_loss: 2.5441e-04 - participant_output_1_loss: 5.0886e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0278 - participant_output_1_accuracy: 0.0795\n",
      "Epoch 2/10\n",
      "33/33 [==============================] - 7s 215ms/step - loss: 0.0364 - participant_output_loss: 0.0361 - command_output_loss: 6.5479e-05 - command_output_1_loss: 2.4454e-04 - participant_output_1_loss: 4.9767e-05 - participant_output_accuracy: 0.9990 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0410 - participant_output_1_accuracy: 0.0507\n",
      "Epoch 3/10\n",
      "33/33 [==============================] - 7s 214ms/step - loss: 0.0280 - participant_output_loss: 0.0276 - command_output_loss: 5.7684e-05 - command_output_1_loss: 2.3221e-04 - participant_output_1_loss: 4.4090e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0459 - participant_output_1_accuracy: 0.0502\n",
      "Epoch 4/10\n",
      "33/33 [==============================] - 7s 215ms/step - loss: 0.0248 - participant_output_loss: 0.0245 - command_output_loss: 5.3234e-05 - command_output_1_loss: 2.1717e-04 - participant_output_1_loss: 3.9284e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0268 - participant_output_1_accuracy: 0.0327\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 8s 228ms/step - loss: 0.0435 - participant_output_loss: 0.0431 - command_output_loss: 8.5868e-05 - command_output_1_loss: 2.2329e-04 - participant_output_1_loss: 4.9754e-05 - participant_output_accuracy: 0.9976 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0498 - participant_output_1_accuracy: 0.0380\n",
      "Epoch 6/10\n",
      "33/33 [==============================] - 8s 257ms/step - loss: 0.0730 - participant_output_loss: 0.0389 - command_output_loss: 0.0338 - command_output_1_loss: 2.9544e-04 - participant_output_1_loss: 5.8489e-05 - participant_output_accuracy: 0.9976 - command_output_accuracy: 0.9961 - command_output_1_accuracy: 0.1668 - participant_output_1_accuracy: 0.0249\n",
      "Epoch 7/10\n",
      "33/33 [==============================] - 8s 254ms/step - loss: 0.0599 - participant_output_loss: 0.0451 - command_output_loss: 0.0137 - command_output_1_loss: 9.6412e-04 - participant_output_1_loss: 1.3378e-04 - participant_output_accuracy: 0.9980 - command_output_accuracy: 0.9966 - command_output_1_accuracy: 0.1205 - participant_output_1_accuracy: 0.0327\n",
      "Epoch 8/10\n",
      "33/33 [==============================] - 7s 227ms/step - loss: 0.1330 - participant_output_loss: 0.1285 - command_output_loss: 0.0039 - command_output_1_loss: 4.3622e-04 - participant_output_1_loss: 1.5278e-04 - participant_output_accuracy: 0.9810 - command_output_accuracy: 0.9995 - command_output_1_accuracy: 0.0961 - participant_output_1_accuracy: 0.0961\n",
      "Epoch 9/10\n",
      "33/33 [==============================] - 7s 215ms/step - loss: 0.0437 - participant_output_loss: 0.0391 - command_output_loss: 0.0042 - command_output_1_loss: 3.3138e-04 - participant_output_1_loss: 1.3836e-04 - participant_output_accuracy: 0.9985 - command_output_accuracy: 0.9990 - command_output_1_accuracy: 0.1883 - participant_output_1_accuracy: 0.0293\n",
      "Epoch 10/10\n",
      "33/33 [==============================] - 7s 216ms/step - loss: 0.0194 - participant_output_loss: 0.0186 - command_output_loss: 5.4256e-04 - command_output_1_loss: 1.8138e-04 - participant_output_1_loss: 1.0493e-04 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0376 - participant_output_1_accuracy: 0.0307\n",
      "Epoch 1/10\n",
      "33/33 [==============================] - 8s 250ms/step - loss: 0.5591 - participant_output_loss: 0.5536 - command_output_loss: 0.0020 - command_output_1_loss: 0.0031 - participant_output_1_loss: 3.6456e-04 - participant_output_accuracy: 0.9357 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0643 - participant_output_1_accuracy: 0.1100\n",
      "Epoch 2/10\n",
      "33/33 [==============================] - 8s 230ms/step - loss: 0.1360 - participant_output_loss: 0.1345 - command_output_loss: 5.5952e-04 - command_output_1_loss: 8.1431e-04 - participant_output_1_loss: 1.6909e-04 - participant_output_accuracy: 0.9981 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0686 - participant_output_1_accuracy: 0.0576\n",
      "Epoch 3/10\n",
      "33/33 [==============================] - 8s 232ms/step - loss: 0.0914 - participant_output_loss: 0.0904 - command_output_loss: 2.7711e-04 - command_output_1_loss: 6.0057e-04 - participant_output_1_loss: 1.1993e-04 - participant_output_accuracy: 0.9995 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0710 - participant_output_1_accuracy: 0.0657\n",
      "Epoch 4/10\n",
      "33/33 [==============================] - 8s 231ms/step - loss: 0.0672 - participant_output_loss: 0.0665 - command_output_loss: 1.5978e-04 - command_output_1_loss: 4.9376e-04 - participant_output_1_loss: 9.3668e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0229 - participant_output_1_accuracy: 0.0767\n",
      "Epoch 5/10\n",
      "33/33 [==============================] - 8s 233ms/step - loss: 0.0561 - participant_output_loss: 0.0555 - command_output_loss: 1.1163e-04 - command_output_1_loss: 4.2567e-04 - participant_output_1_loss: 7.6869e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0467 - participant_output_1_accuracy: 0.0467\n",
      "Epoch 6/10\n",
      "33/33 [==============================] - 8s 239ms/step - loss: 0.0490 - participant_output_loss: 0.0485 - command_output_loss: 8.8707e-05 - command_output_1_loss: 3.7382e-04 - participant_output_1_loss: 6.4079e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0933 - participant_output_1_accuracy: 0.0471\n",
      "Epoch 7/10\n",
      "33/33 [==============================] - 8s 250ms/step - loss: 0.0437 - participant_output_loss: 0.0432 - command_output_loss: 7.7621e-05 - command_output_1_loss: 3.3822e-04 - participant_output_1_loss: 5.5341e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.1267 - participant_output_1_accuracy: 0.0329\n",
      "Epoch 8/10\n",
      "33/33 [==============================] - 7s 223ms/step - loss: 0.0390 - participant_output_loss: 0.0386 - command_output_loss: 6.7538e-05 - command_output_1_loss: 3.0592e-04 - participant_output_1_loss: 4.8924e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.1233 - participant_output_1_accuracy: 0.0248\n",
      "Epoch 9/10\n",
      "33/33 [==============================] - 7s 220ms/step - loss: 0.0351 - participant_output_loss: 0.0347 - command_output_loss: 5.9892e-05 - command_output_1_loss: 2.7796e-04 - participant_output_1_loss: 4.3250e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0905 - participant_output_1_accuracy: 0.0214\n",
      "Epoch 10/10\n",
      "33/33 [==============================] - 7s 219ms/step - loss: 0.0321 - participant_output_loss: 0.0317 - command_output_loss: 5.5529e-05 - command_output_1_loss: 2.4969e-04 - participant_output_1_loss: 3.8884e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0548 - participant_output_1_accuracy: 0.0214\n",
      "Epoch 1/10\n",
      "33/33 [==============================] - 8s 256ms/step - loss: 0.0294 - participant_output_loss: 0.0291 - command_output_loss: 5.1358e-05 - command_output_1_loss: 2.2337e-04 - participant_output_1_loss: 3.4738e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0448 - participant_output_1_accuracy: 0.0257\n",
      "Epoch 2/10\n",
      "33/33 [==============================] - 7s 226ms/step - loss: 0.0270 - participant_output_loss: 0.0267 - command_output_loss: 4.7986e-05 - command_output_1_loss: 2.0091e-04 - participant_output_1_loss: 3.1678e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0962 - participant_output_1_accuracy: 0.0233\n",
      "Epoch 3/10\n",
      "33/33 [==============================] - 7s 227ms/step - loss: 0.0249 - participant_output_loss: 0.0246 - command_output_loss: 4.4790e-05 - command_output_1_loss: 1.8250e-04 - participant_output_1_loss: 2.9264e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0657 - participant_output_1_accuracy: 0.0205\n",
      "Epoch 4/10\n",
      "33/33 [==============================] - 7s 224ms/step - loss: 0.0229 - participant_output_loss: 0.0227 - command_output_loss: 4.1210e-05 - command_output_1_loss: 1.6739e-04 - participant_output_1_loss: 2.6986e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0824 - participant_output_1_accuracy: 0.0205\n",
      "Epoch 5/10\n",
      "33/33 [==============================] - 7s 219ms/step - loss: 0.0212 - participant_output_loss: 0.0210 - command_output_loss: 3.9665e-05 - command_output_1_loss: 1.5439e-04 - participant_output_1_loss: 2.5150e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0800 - participant_output_1_accuracy: 0.0190\n",
      "Epoch 6/10\n",
      "33/33 [==============================] - 7s 219ms/step - loss: 0.0198 - participant_output_loss: 0.0195 - command_output_loss: 3.7234e-05 - command_output_1_loss: 1.4292e-04 - participant_output_1_loss: 2.3732e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.1800 - participant_output_1_accuracy: 0.0171\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 7s 220ms/step - loss: 0.0184 - participant_output_loss: 0.0182 - command_output_loss: 3.5094e-05 - command_output_1_loss: 1.2822e-04 - participant_output_1_loss: 2.2173e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.1548 - participant_output_1_accuracy: 0.0176\n",
      "Epoch 8/10\n",
      "33/33 [==============================] - 7s 219ms/step - loss: 0.0173 - participant_output_loss: 0.0171 - command_output_loss: 3.3770e-05 - command_output_1_loss: 1.1352e-04 - participant_output_1_loss: 2.0990e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.1571 - participant_output_1_accuracy: 0.0205\n",
      "Epoch 9/10\n",
      "33/33 [==============================] - 7s 218ms/step - loss: 0.0163 - participant_output_loss: 0.0161 - command_output_loss: 3.2367e-05 - command_output_1_loss: 1.0009e-04 - participant_output_1_loss: 1.9933e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.2629 - participant_output_1_accuracy: 0.0200\n",
      "Epoch 10/10\n",
      "33/33 [==============================] - 7s 223ms/step - loss: 0.0153 - participant_output_loss: 0.0152 - command_output_loss: 3.0917e-05 - command_output_1_loss: 8.6843e-05 - participant_output_1_loss: 1.8978e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.2995 - participant_output_1_accuracy: 0.0157\n",
      "Epoch 1/10\n",
      "34/34 [==============================] - 9s 251ms/step - loss: 0.5584 - participant_output_loss: 0.5562 - command_output_loss: 1.2343e-04 - command_output_1_loss: 0.0017 - participant_output_1_loss: 2.8617e-04 - participant_output_accuracy: 0.9358 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.1098 - participant_output_1_accuracy: 0.0353\n",
      "Epoch 2/10\n",
      "34/34 [==============================] - 8s 227ms/step - loss: 0.1586 - participant_output_loss: 0.1469 - command_output_loss: 0.0113 - command_output_1_loss: 2.5894e-04 - participant_output_1_loss: 8.9044e-05 - participant_output_accuracy: 0.9986 - command_output_accuracy: 0.9972 - command_output_1_accuracy: 0.2902 - participant_output_1_accuracy: 0.0349\n",
      "Epoch 3/10\n",
      "34/34 [==============================] - 8s 239ms/step - loss: 0.1078 - participant_output_loss: 0.1052 - command_output_loss: 0.0023 - command_output_1_loss: 2.3439e-04 - participant_output_1_loss: 8.5292e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9991 - command_output_1_accuracy: 0.1400 - participant_output_1_accuracy: 0.0219\n",
      "Epoch 4/10\n",
      "34/34 [==============================] - 9s 254ms/step - loss: 0.0814 - participant_output_loss: 0.0810 - command_output_loss: 1.5549e-04 - command_output_1_loss: 1.7279e-04 - participant_output_1_loss: 7.4215e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.1540 - participant_output_1_accuracy: 0.0177\n",
      "Epoch 5/10\n",
      "34/34 [==============================] - 8s 241ms/step - loss: 0.0678 - participant_output_loss: 0.0675 - command_output_loss: 1.0471e-04 - command_output_1_loss: 1.4445e-04 - participant_output_1_loss: 6.3705e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.3386 - participant_output_1_accuracy: 0.0219\n",
      "Epoch 6/10\n",
      "34/34 [==============================] - 8s 224ms/step - loss: 0.0582 - participant_output_loss: 0.0579 - command_output_loss: 8.2997e-05 - command_output_1_loss: 1.3104e-04 - participant_output_1_loss: 5.6483e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.3353 - participant_output_1_accuracy: 0.0181\n",
      "Epoch 7/10\n",
      "34/34 [==============================] - 7s 217ms/step - loss: 0.0509 - participant_output_loss: 0.0506 - command_output_loss: 6.8081e-05 - command_output_1_loss: 1.1943e-04 - participant_output_1_loss: 5.1767e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.3344 - participant_output_1_accuracy: 0.0209\n",
      "Epoch 8/10\n",
      "34/34 [==============================] - 7s 217ms/step - loss: 0.0446 - participant_output_loss: 0.0444 - command_output_loss: 5.8466e-05 - command_output_1_loss: 1.1043e-04 - participant_output_1_loss: 4.7745e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.3298 - participant_output_1_accuracy: 0.0209\n",
      "Epoch 9/10\n",
      "34/34 [==============================] - 7s 219ms/step - loss: 0.0396 - participant_output_loss: 0.0394 - command_output_loss: 5.0351e-05 - command_output_1_loss: 1.0210e-04 - participant_output_1_loss: 4.3425e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.3549 - participant_output_1_accuracy: 0.0256\n",
      "Epoch 10/10\n",
      "34/34 [==============================] - 7s 219ms/step - loss: 0.0358 - participant_output_loss: 0.0356 - command_output_loss: 4.6953e-05 - command_output_1_loss: 9.5336e-05 - participant_output_1_loss: 4.0387e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.3330 - participant_output_1_accuracy: 0.0233\n",
      "Epoch 1/10\n",
      "34/34 [==============================] - 8s 233ms/step - loss: 0.0324 - participant_output_loss: 0.0322 - command_output_loss: 4.3645e-05 - command_output_1_loss: 8.6869e-05 - participant_output_1_loss: 3.7333e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.3140 - participant_output_1_accuracy: 0.0274\n",
      "Epoch 2/10\n",
      "34/34 [==============================] - 8s 223ms/step - loss: 0.0296 - participant_output_loss: 0.0295 - command_output_loss: 4.1343e-05 - command_output_1_loss: 7.9941e-05 - participant_output_1_loss: 3.4712e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.3284 - participant_output_1_accuracy: 0.0312\n",
      "Epoch 3/10\n",
      "34/34 [==============================] - 8s 223ms/step - loss: 0.0272 - participant_output_loss: 0.0271 - command_output_loss: 3.7496e-05 - command_output_1_loss: 7.4940e-05 - participant_output_1_loss: 3.2871e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.3851 - participant_output_1_accuracy: 0.0344\n",
      "Epoch 4/10\n",
      "34/34 [==============================] - 8s 223ms/step - loss: 0.0251 - participant_output_loss: 0.0249 - command_output_loss: 3.5396e-05 - command_output_1_loss: 7.0264e-05 - participant_output_1_loss: 3.0686e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.3498 - participant_output_1_accuracy: 0.0367\n",
      "Epoch 5/10\n",
      "34/34 [==============================] - 8s 240ms/step - loss: 0.0232 - participant_output_loss: 0.0230 - command_output_loss: 3.2917e-05 - command_output_1_loss: 6.5745e-05 - participant_output_1_loss: 2.9130e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.3730 - participant_output_1_accuracy: 0.0367\n",
      "Epoch 6/10\n",
      "34/34 [==============================] - 8s 239ms/step - loss: 0.0215 - participant_output_loss: 0.0214 - command_output_loss: 3.1211e-05 - command_output_1_loss: 6.1272e-05 - participant_output_1_loss: 2.7895e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.3102 - participant_output_1_accuracy: 0.0349\n",
      "Epoch 7/10\n",
      "34/34 [==============================] - 8s 229ms/step - loss: 0.0200 - participant_output_loss: 0.0199 - command_output_loss: 3.0130e-05 - command_output_1_loss: 5.7076e-05 - participant_output_1_loss: 2.6006e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.2953 - participant_output_1_accuracy: 0.0409\n",
      "Epoch 8/10\n",
      "34/34 [==============================] - 8s 221ms/step - loss: 0.0187 - participant_output_loss: 0.0186 - command_output_loss: 2.9757e-05 - command_output_1_loss: 5.2924e-05 - participant_output_1_loss: 2.4726e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.2967 - participant_output_1_accuracy: 0.0405\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 7s 217ms/step - loss: 0.0175 - participant_output_loss: 0.0174 - command_output_loss: 2.7694e-05 - command_output_1_loss: 4.9388e-05 - participant_output_1_loss: 2.3187e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.3042 - participant_output_1_accuracy: 0.0456\n",
      "Epoch 10/10\n",
      "34/34 [==============================] - 7s 218ms/step - loss: 0.0165 - participant_output_loss: 0.0164 - command_output_loss: 2.6688e-05 - command_output_1_loss: 4.5977e-05 - participant_output_1_loss: 2.2214e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.3214 - participant_output_1_accuracy: 0.0493\n",
      "Epoch 1/10\n",
      "35/35 [==============================] - 8s 237ms/step - loss: 0.5797 - participant_output_loss: 0.5780 - command_output_loss: 1.3706e-04 - command_output_1_loss: 0.0013 - participant_output_1_loss: 3.0470e-04 - participant_output_accuracy: 0.9277 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.1414 - participant_output_1_accuracy: 0.0436\n",
      "Epoch 2/10\n",
      "35/35 [==============================] - 8s 223ms/step - loss: 0.1749 - participant_output_loss: 0.1746 - command_output_loss: 1.2913e-04 - command_output_1_loss: 1.1633e-04 - participant_output_1_loss: 8.5154e-05 - participant_output_accuracy: 0.9923 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.2564 - participant_output_1_accuracy: 0.0118\n",
      "Epoch 3/10\n",
      "35/35 [==============================] - 8s 226ms/step - loss: 0.1254 - participant_output_loss: 0.1251 - command_output_loss: 7.9147e-05 - command_output_1_loss: 8.4497e-05 - participant_output_1_loss: 5.7480e-05 - participant_output_accuracy: 0.9959 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.3645 - participant_output_1_accuracy: 0.0164\n",
      "Epoch 4/10\n",
      "35/35 [==============================] - 8s 226ms/step - loss: 0.0919 - participant_output_loss: 0.0907 - command_output_loss: 0.0010 - command_output_1_loss: 8.5453e-05 - participant_output_1_loss: 4.9543e-05 - participant_output_accuracy: 0.9991 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.3018 - participant_output_1_accuracy: 0.0305\n",
      "Epoch 5/10\n",
      "35/35 [==============================] - 8s 217ms/step - loss: 0.0770 - participant_output_loss: 0.0765 - command_output_loss: 4.0365e-04 - command_output_1_loss: 1.0192e-04 - participant_output_1_loss: 5.5598e-05 - participant_output_accuracy: 0.9986 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.2482 - participant_output_1_accuracy: 0.0159\n",
      "Epoch 6/10\n",
      "35/35 [==============================] - 8s 229ms/step - loss: 0.0570 - participant_output_loss: 0.0567 - command_output_loss: 1.7444e-04 - command_output_1_loss: 6.1030e-05 - participant_output_1_loss: 5.1807e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.1073 - participant_output_1_accuracy: 0.0214\n",
      "Epoch 7/10\n",
      "35/35 [==============================] - 8s 219ms/step - loss: 0.0485 - participant_output_loss: 0.0483 - command_output_loss: 8.1936e-05 - command_output_1_loss: 4.9011e-05 - participant_output_1_loss: 4.5458e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.5609 - participant_output_1_accuracy: 0.0314\n",
      "Epoch 8/10\n",
      "35/35 [==============================] - 8s 216ms/step - loss: 0.0428 - participant_output_loss: 0.0426 - command_output_loss: 5.1162e-05 - command_output_1_loss: 4.3108e-05 - participant_output_1_loss: 4.0900e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.4236 - participant_output_1_accuracy: 0.0277\n",
      "Epoch 9/10\n",
      "35/35 [==============================] - 8s 225ms/step - loss: 0.0385 - participant_output_loss: 0.0384 - command_output_loss: 4.0085e-05 - command_output_1_loss: 3.8682e-05 - participant_output_1_loss: 3.7794e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.5836 - participant_output_1_accuracy: 0.0273\n",
      "Epoch 10/10\n",
      "35/35 [==============================] - 8s 242ms/step - loss: 0.0347 - participant_output_loss: 0.0346 - command_output_loss: 3.3782e-05 - command_output_1_loss: 3.4546e-05 - participant_output_1_loss: 3.4842e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.5436 - participant_output_1_accuracy: 0.0336\n",
      "Epoch 1/10\n",
      "35/35 [==============================] - 8s 234ms/step - loss: 0.0316 - participant_output_loss: 0.0315 - command_output_loss: 3.0786e-05 - command_output_1_loss: 3.0632e-05 - participant_output_1_loss: 3.2550e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.5909 - participant_output_1_accuracy: 0.0509\n",
      "Epoch 2/10\n",
      "35/35 [==============================] - 8s 217ms/step - loss: 0.0289 - participant_output_loss: 0.0288 - command_output_loss: 2.7535e-05 - command_output_1_loss: 2.6610e-05 - participant_output_1_loss: 3.0565e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.6795 - participant_output_1_accuracy: 0.0373\n",
      "Epoch 3/10\n",
      "35/35 [==============================] - 8s 219ms/step - loss: 0.0266 - participant_output_loss: 0.0265 - command_output_loss: 2.4903e-05 - command_output_1_loss: 2.2893e-05 - participant_output_1_loss: 2.8818e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.6050 - participant_output_1_accuracy: 0.0441\n",
      "Epoch 4/10\n",
      "35/35 [==============================] - 8s 219ms/step - loss: 0.0246 - participant_output_loss: 0.0245 - command_output_loss: 2.3497e-05 - command_output_1_loss: 1.9834e-05 - participant_output_1_loss: 2.7216e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.6755 - participant_output_1_accuracy: 0.0473\n",
      "Epoch 5/10\n",
      "35/35 [==============================] - 8s 217ms/step - loss: 0.0228 - participant_output_loss: 0.0227 - command_output_loss: 2.1624e-05 - command_output_1_loss: 1.7063e-05 - participant_output_1_loss: 2.5859e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.6805 - participant_output_1_accuracy: 0.0468\n",
      "Epoch 6/10\n",
      "35/35 [==============================] - 8s 220ms/step - loss: 0.0211 - participant_output_loss: 0.0210 - command_output_loss: 2.0633e-05 - command_output_1_loss: 1.4483e-05 - participant_output_1_loss: 2.4640e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.6945 - participant_output_1_accuracy: 0.0509\n",
      "Epoch 7/10\n",
      "35/35 [==============================] - 8s 217ms/step - loss: 0.0197 - participant_output_loss: 0.0196 - command_output_loss: 1.9052e-05 - command_output_1_loss: 1.2044e-05 - participant_output_1_loss: 2.3290e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.6250 - participant_output_1_accuracy: 0.0482\n",
      "Epoch 8/10\n",
      "35/35 [==============================] - 8s 232ms/step - loss: 0.0185 - participant_output_loss: 0.0184 - command_output_loss: 1.7951e-05 - command_output_1_loss: 9.9438e-06 - participant_output_1_loss: 2.2295e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.6536 - participant_output_1_accuracy: 0.0541\n",
      "Epoch 9/10\n",
      "35/35 [==============================] - 8s 236ms/step - loss: 0.0173 - participant_output_loss: 0.0173 - command_output_loss: 1.7376e-05 - command_output_1_loss: 8.1169e-06 - participant_output_1_loss: 2.1264e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.6714 - participant_output_1_accuracy: 0.0455\n",
      "Epoch 10/10\n",
      "35/35 [==============================] - 8s 234ms/step - loss: 0.0163 - participant_output_loss: 0.0162 - command_output_loss: 1.5807e-05 - command_output_1_loss: 6.6234e-06 - participant_output_1_loss: 2.0320e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.5895 - participant_output_1_accuracy: 0.0505\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 9s 240ms/step - loss: 0.5429 - participant_output_loss: 0.5359 - command_output_loss: 0.0055 - command_output_1_loss: 0.0012 - participant_output_1_loss: 2.8058e-04 - participant_output_accuracy: 0.9520 - command_output_accuracy: 0.9987 - command_output_1_accuracy: 0.1378 - participant_output_1_accuracy: 4.4444e-04\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - 8s 226ms/step - loss: 0.1543 - participant_output_loss: 0.1521 - command_output_loss: 0.0020 - command_output_1_loss: 1.6089e-04 - participant_output_1_loss: 1.2463e-04 - participant_output_accuracy: 0.9978 - command_output_accuracy: 0.9996 - command_output_1_accuracy: 0.0942 - participant_output_1_accuracy: 0.0080\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - 8s 216ms/step - loss: 0.1212 - participant_output_loss: 0.1185 - command_output_loss: 0.0025 - command_output_1_loss: 1.3503e-04 - participant_output_1_loss: 1.1434e-04 - participant_output_accuracy: 0.9978 - command_output_accuracy: 0.9991 - command_output_1_accuracy: 0.0364 - participant_output_1_accuracy: 0.0156\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - 8s 225ms/step - loss: 0.0925 - participant_output_loss: 0.0914 - command_output_loss: 8.8496e-04 - command_output_1_loss: 1.2232e-04 - participant_output_1_loss: 9.7703e-05 - participant_output_accuracy: 0.9991 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0164 - participant_output_1_accuracy: 0.0289\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - 8s 236ms/step - loss: 0.0678 - participant_output_loss: 0.0673 - command_output_loss: 2.7708e-04 - command_output_1_loss: 9.8305e-05 - participant_output_1_loss: 8.5477e-05 - participant_output_accuracy: 0.9996 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.1160 - participant_output_1_accuracy: 0.0342\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - 8s 233ms/step - loss: 0.0553 - participant_output_loss: 0.0550 - command_output_loss: 1.1963e-04 - command_output_1_loss: 8.4907e-05 - participant_output_1_loss: 7.3454e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.1622 - participant_output_1_accuracy: 0.0444\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - 8s 231ms/step - loss: 0.0482 - participant_output_loss: 0.0479 - command_output_loss: 7.8535e-05 - command_output_1_loss: 7.7202e-05 - participant_output_1_loss: 6.4870e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.2102 - participant_output_1_accuracy: 0.0404\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - 8s 232ms/step - loss: 0.0428 - participant_output_loss: 0.0426 - command_output_loss: 6.2095e-05 - command_output_1_loss: 7.0590e-05 - participant_output_1_loss: 5.7959e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.1396 - participant_output_1_accuracy: 0.0453\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - 8s 220ms/step - loss: 0.0383 - participant_output_loss: 0.0381 - command_output_loss: 5.1386e-05 - command_output_1_loss: 6.3664e-05 - participant_output_1_loss: 5.2198e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.1364 - participant_output_1_accuracy: 0.0364\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - 8s 214ms/step - loss: 0.0344 - participant_output_loss: 0.0342 - command_output_loss: 4.8117e-05 - command_output_1_loss: 5.8754e-05 - participant_output_1_loss: 4.7701e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.1702 - participant_output_1_accuracy: 0.0356\n",
      "Epoch 1/10\n",
      "36/36 [==============================] - 8s 229ms/step - loss: 0.0314 - participant_output_loss: 0.0313 - command_output_loss: 4.2886e-05 - command_output_1_loss: 5.4176e-05 - participant_output_1_loss: 4.4997e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.1098 - participant_output_1_accuracy: 0.0404\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - 8s 216ms/step - loss: 0.0286 - participant_output_loss: 0.0285 - command_output_loss: 3.8805e-05 - command_output_1_loss: 4.9593e-05 - participant_output_1_loss: 4.1044e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.1107 - participant_output_1_accuracy: 0.0444\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - 8s 217ms/step - loss: 0.0264 - participant_output_loss: 0.0263 - command_output_loss: 3.4770e-05 - command_output_1_loss: 4.3692e-05 - participant_output_1_loss: 3.8349e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.1996 - participant_output_1_accuracy: 0.0404\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - 8s 220ms/step - loss: 0.0243 - participant_output_loss: 0.0242 - command_output_loss: 3.1157e-05 - command_output_1_loss: 3.9096e-05 - participant_output_1_loss: 3.6131e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.1844 - participant_output_1_accuracy: 0.0382\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - 8s 228ms/step - loss: 0.0225 - participant_output_loss: 0.0224 - command_output_loss: 2.9955e-05 - command_output_1_loss: 3.5629e-05 - participant_output_1_loss: 3.3457e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.1347 - participant_output_1_accuracy: 0.0378\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - 8s 234ms/step - loss: 0.0208 - participant_output_loss: 0.0207 - command_output_loss: 2.7479e-05 - command_output_1_loss: 3.2652e-05 - participant_output_1_loss: 3.1471e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.1218 - participant_output_1_accuracy: 0.0391\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - 9s 246ms/step - loss: 0.0195 - participant_output_loss: 0.0194 - command_output_loss: 2.6462e-05 - command_output_1_loss: 2.9681e-05 - participant_output_1_loss: 2.9794e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.1471 - participant_output_1_accuracy: 0.0347\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - 9s 240ms/step - loss: 0.0181 - participant_output_loss: 0.0181 - command_output_loss: 2.5006e-05 - command_output_1_loss: 2.6801e-05 - participant_output_1_loss: 2.8643e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.1884 - participant_output_1_accuracy: 0.0391\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - 8s 219ms/step - loss: 0.0169 - participant_output_loss: 0.0168 - command_output_loss: 2.3833e-05 - command_output_1_loss: 2.4619e-05 - participant_output_1_loss: 2.6915e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.2084 - participant_output_1_accuracy: 0.0422\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - 8s 214ms/step - loss: 0.0158 - participant_output_loss: 0.0158 - command_output_loss: 2.2321e-05 - command_output_1_loss: 2.2950e-05 - participant_output_1_loss: 2.5529e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.2004 - participant_output_1_accuracy: 0.0413\n"
     ]
    }
   ],
   "source": [
    "# new_speaker = 6\n",
    "add_data = 5 # 10%-->5; 20%-->10; 30%--> 15; 40% -->20;\n",
    "\n",
    "for new_speaker in range(speaker_number+1,31):\n",
    "    \n",
    "    ####################################################################################################################\n",
    "    # training \n",
    "    new_select_indexs = (image_no<=add_data-1)&(ALL_participant_class==new_speaker)\n",
    "    new_Train_Inputs = All_Inputs[new_select_indexs]\n",
    "    new_Train_participant_class = All_participant_class[new_select_indexs][:,0:new_speaker]\n",
    "    new_Train_participant_uniform = new_Train_participant_class*0+1/new_speaker\n",
    "    new_Train_command_class = All_command_class[new_select_indexs]\n",
    "    new_Train_command_uniform = new_Train_command_class*0+1/10\n",
    "\n",
    "    # testing\n",
    "    new_select_indexs_test = (image_no>39)&(image_no<=49)&(ALL_participant_class==new_speaker)\n",
    "    new_Test_Inputs = All_Inputs[new_select_indexs_test]\n",
    "    new_Test_participant_class = All_participant_class[new_select_indexs_test][:,0:new_speaker]\n",
    "    new_Test_participant_uniform = new_Test_participant_class*0+1/new_speaker\n",
    "    new_Test_command_class = All_command_class[new_select_indexs_test]\n",
    "    new_Test_command_uniform = new_Test_command_class*0+1/10\n",
    "\n",
    "    # combine training\n",
    "    update_Train_participant_class = np.vstack((np.hstack((Existing_Train_participant_class,np.zeros([len(Existing_Train_participant_class),1]))),new_Train_participant_class))\n",
    "    update_Train_participant_uniform = update_Train_participant_class*0+1/new_speaker\n",
    "    update_Train_command_class = np.vstack((Existing_Train_command_class,new_Train_command_class))\n",
    "    update_Train_command_uniform = update_Train_command_class*0+1/10\n",
    "    update_Train_Inputs = np.vstack((Existing_Train_Inputs,new_Train_Inputs))\n",
    "\n",
    "    # combine testing\n",
    "    update_Test_participant_class = np.vstack((np.hstack((Existing_Test_participant_class,np.zeros([len(Existing_Test_participant_class),1]))),new_Test_participant_class))\n",
    "    update_Test_participant_uniform = update_Test_participant_class*0+1/new_speaker\n",
    "    update_Test_command_class = np.vstack((Existing_Test_command_class,new_Test_command_class))\n",
    "    update_Test_command_uniform = update_Test_command_class*0+1/10\n",
    "    update_Test_Inputs = np.vstack((Existing_Test_Inputs,new_Test_Inputs))\n",
    "    \n",
    "\n",
    "    ####################################################################################################################\n",
    "    ### feature extraction layers\n",
    "    resnet_model = Model(resnet_model_0.input, resnet_model_0.layers[174].output)\n",
    "\n",
    "    d = resnet_model.output.shape[-1] # dimension of last layer\n",
    "\n",
    "    ###################### model 1 ###################### \n",
    "#      # chenge the weights in speaker task to initial weights\n",
    "#     initializer = tf.keras.initializers.GlorotUniform()\n",
    "#     w1 = initializer(shape=resnet_model.get_layer(name = \"weight_1\").get_weights()[0].shape)\n",
    "#     initializer = tf.keras.initializers.Zeros()\n",
    "#     w2 = initializer(shape=resnet_model.get_layer(name = \"weight_1\").get_weights()[1].shape)\n",
    "#     resnet_model.get_layer(name = \"weight_1\").set_weights([w1,w2])\n",
    "    \n",
    "    layer_1_0 = tf.keras.layers.Dense(d,name=\"weight_1\")(resnet_model.output) #times weight before flatten\n",
    "    layer_1_1 = tf.keras.layers.Flatten(name='flatten_1')(layer_1_0)\n",
    "\n",
    "    Dense_1_1 = tf.keras.layers.Dense(shape_1_1, activation = actv_fun_1_1,name='fc1_1')\n",
    "    layer_1_2 = Dense_1_1(layer_1_1)\n",
    "    Dense_1_2 = tf.keras.layers.Dense(shape_1_2, activation = actv_fun_1_2,name='fc1_2')\n",
    "    layer_1_3 = Dense_1_2(layer_1_2)\n",
    "\n",
    "    Dense_1_3 = tf.keras.layers.Dense(new_speaker, activation='softmax' ,name='participant_output')\n",
    "    out_layer_1 = Dense_1_3(layer_1_3)\n",
    "\n",
    "    ###################### model 2 ###################### \n",
    "    w1 = tf.constant_initializer(resnet_model_0.get_layer(name = \"weight_2\").get_weights()[0])\n",
    "    w2 = tf.constant_initializer(resnet_model_0.get_layer(name = \"weight_2\").get_weights()[1])\n",
    "    layer_2_0 = tf.keras.layers.Dense(d,name=\"weight_2\",kernel_initializer = w1 ,bias_initializer = w2)(resnet_model.output) #times weight before flatten\n",
    "\n",
    "    layer_2_1 = tf.keras.layers.Flatten(name='flatten_2')(layer_2_0)\n",
    "\n",
    "    w1 = tf.constant_initializer(resnet_model_0.get_layer(name = \"fc2_1\").get_weights()[0])\n",
    "    w2 = tf.constant_initializer(resnet_model_0.get_layer(name = \"fc2_1\").get_weights()[1])\n",
    "    Dense_2_1 = tf.keras.layers.Dense(shape_2_1, activation=actv_fun_2_1,kernel_initializer = w1 ,bias_initializer = w2,name='fc2_1')\n",
    "    layer_2_2  = Dense_2_1(layer_2_1)\n",
    "\n",
    "    w1 = tf.constant_initializer(resnet_model_0.get_layer(name = \"fc2_2\").get_weights()[0])\n",
    "    w2 = tf.constant_initializer(resnet_model_0.get_layer(name = \"fc2_2\").get_weights()[1])\n",
    "    Dense_2_2 = tf.keras.layers.Dense(shape_2_2, activation=actv_fun_2_2,kernel_initializer = w1 ,bias_initializer = w2, name='fc2_2')\n",
    "    layer_2_3  = Dense_2_2(layer_2_2)\n",
    "\n",
    "    w1 = tf.constant_initializer(resnet_model_0.get_layer(name = \"command_output\").get_weights()[0])\n",
    "    w2 = tf.constant_initializer(resnet_model_0.get_layer(name = \"command_output\").get_weights()[1])\n",
    "    Dense_2_3 = tf.keras.layers.Dense(10, activation='softmax',kernel_initializer = w1 ,bias_initializer = w2,name='command_output')\n",
    "    out_layer_2 = Dense_2_3(layer_2_3)\n",
    "\n",
    "    ###################### model 1' ###################### \n",
    "    layer_1_2_  = Dense_2_1(layer_1_1)\n",
    "    layer_1_3_  = Dense_2_2(layer_1_2_)\n",
    "    out_layer_1_ = Dense_2_3(layer_1_3_)\n",
    "\n",
    "    ###################### model 1' ###################### \n",
    "    layer_2_2_  = Dense_1_1(layer_2_1)\n",
    "    layer_2_3_  = Dense_1_2(layer_2_2_)\n",
    "    out_layer_2_ = Dense_1_3(layer_2_3_)\n",
    "\n",
    "    resnet_model = tf.keras.Model(resnet_model.input, [out_layer_1,out_layer_2,out_layer_1_,out_layer_2_])\n",
    "\n",
    "    # resnet_model.summary() \n",
    "\n",
    "    w_1, w_2, w_1_, w_2_ = 1,1,1,1\n",
    "    ##################### training ############################\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "    callbacks = [MyEarlyStopping(monitor1 = resnet_model.layers[-1].name+'_accuracy',\n",
    "                                  monitor2 = resnet_model.layers[-2].name+'_accuracy',\n",
    "                                  patience=10,restore_best_weights=True)]\n",
    "    resnet_model.compile(optimizer=opt, loss=[\"categorical_crossentropy\",\"categorical_crossentropy\",\"mse\",\"mse\"],\n",
    "                         loss_weights=[w_1, w_2, w_1_, w_2_], metrics=['accuracy'])\n",
    "    \n",
    "    for layer in resnet_model.layers[0:175]:\n",
    "        layer.trainable = False\n",
    "    history = resnet_model.fit(update_Train_Inputs, \n",
    "                               {resnet_model.layers[-2].name:update_Train_participant_class, \n",
    "                                resnet_model.layers[-1].name:update_Train_command_class,\n",
    "                                resnet_model.layers[-1].name+\"_1\":update_Train_command_uniform, \n",
    "                                resnet_model.layers[-2].name+\"_1\":update_Train_participant_uniform}, \n",
    "                               callbacks=callbacks,\n",
    "                               batch_size=64,\n",
    "                               epochs=10)\n",
    "    \n",
    "    for layer in resnet_model.layers[0:175]:\n",
    "        layer.trainable = True\n",
    "    history = resnet_model.fit(update_Train_Inputs, \n",
    "                               {resnet_model.layers[-2].name:update_Train_participant_class, \n",
    "                                resnet_model.layers[-1].name:update_Train_command_class,\n",
    "                                resnet_model.layers[-1].name+\"_1\":update_Train_command_uniform, \n",
    "                                resnet_model.layers[-2].name+\"_1\":update_Train_participant_uniform}, \n",
    "                               callbacks=callbacks,\n",
    "                               batch_size=64,\n",
    "                               epochs=10)\n",
    "\n",
    " \n",
    "    \n",
    "    resnet_model.save('resnet_model_0531_digit_refine_group_5->30_final_free&unfree.h5')\n",
    "    ####################################################################################################################\n",
    "    ####################################################################################################################\n",
    "\n",
    "    subject_accuracy = []\n",
    "    command_accuracy = []\n",
    "    \n",
    "    for i in range(1,61):\n",
    "\n",
    "        select_indexs_test_i = (image_no>39)&(image_no<=49)&(ALL_participant_class==i)\n",
    "        Test_Inputs_i = All_Inputs[select_indexs_test_i]\n",
    "        Test_command_class_i = All_command_class[select_indexs_test_i]\n",
    "        Test_command_uniform_i = Test_command_class_i*0+1/10\n",
    "\n",
    "        # subject prediction \n",
    "        predictions = resnet_model.predict(Test_Inputs_i)[0]\n",
    "        predicted_classes = np.argmax(predictions, axis=1)\n",
    "        true_classes = np.array([j.split(\"/\")[1].split(\"_\")[1] for j in All_data_generator.filenames])\n",
    "        true_classes = np.array(list(map(int, true_classes)))[select_indexs_test_i]-1\n",
    "\n",
    "        subject_accuracy.append(round(sum(x == y for x, y in zip(true_classes, predicted_classes)) / len(true_classes),4))\n",
    "\n",
    "        # command prediction \n",
    "        predictions = resnet_model.predict(Test_Inputs_i)[1]\n",
    "        predicted_classes = np.argmax(predictions, axis=1)\n",
    "        true_classes = np.array([j.split(\"/\")[0] for j in All_data_generator.filenames])\n",
    "        true_classes = np.array(list(map(int, true_classes)))[select_indexs_test_i]\n",
    "\n",
    "        command_accuracy.append(round(sum(x == y for x, y in zip(true_classes, predicted_classes)) / len(true_classes),4))\n",
    "    \n",
    "    # store the performance \n",
    "    performance_command = performance_command.append({\"Subject_No\":new_speaker,\"add_data\":str(int(100*add_data/50))+\"%\"}, ignore_index=True)\n",
    "    performance_speaker = performance_speaker.append({\"Subject_No\":new_speaker,\"add_data\":str(int(100*add_data/50))+\"%\"}, ignore_index=True)\n",
    "    performance_command.iloc[performance_command['Subject_No']==new_speaker,2:] = command_accuracy\n",
    "    performance_speaker.iloc[performance_speaker['Subject_No']==new_speaker,2:] = subject_accuracy\n",
    "    \n",
    "    \n",
    "    resnet_model_0 = tf.keras.models.load_model('resnet_model_0531_digit_refine_group_5->30_final_free&unfree.h5')\n",
    "    Existing_Train_participant_class = update_Train_participant_class \n",
    "    Existing_Train_participant_uniform =  update_Train_participant_uniform\n",
    "    Existing_Train_command_class = update_Train_command_class \n",
    "    Existing_Train_command_uniform = update_Train_command_uniform \n",
    "    Existing_Train_Inputs = update_Train_Inputs\n",
    "    Existing_Test_participant_class = update_Test_participant_class \n",
    "    Existing_Test_participant_uniform =  update_Test_participant_uniform\n",
    "    Existing_Test_command_class = update_Test_command_class \n",
    "    Existing_Test_command_uniform = update_Test_command_uniform \n",
    "    Existing_Test_Inputs = update_Test_Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a80e9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d48747fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject_No</th>\n",
       "      <th>add_data</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>40%</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>10%</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>10%</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>10%</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>10%</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10</td>\n",
       "      <td>10%</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11</td>\n",
       "      <td>10%</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>12</td>\n",
       "      <td>10%</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.96</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>13</td>\n",
       "      <td>10%</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>14</td>\n",
       "      <td>10%</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>15</td>\n",
       "      <td>10%</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>16</td>\n",
       "      <td>10%</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>17</td>\n",
       "      <td>10%</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.93</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>18</td>\n",
       "      <td>10%</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>19</td>\n",
       "      <td>10%</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.99</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>20</td>\n",
       "      <td>10%</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>21</td>\n",
       "      <td>10%</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>22</td>\n",
       "      <td>10%</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>23</td>\n",
       "      <td>10%</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>24</td>\n",
       "      <td>10%</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>25</td>\n",
       "      <td>10%</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.95</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>26</td>\n",
       "      <td>10%</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>27</td>\n",
       "      <td>10%</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>28</td>\n",
       "      <td>10%</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>29</td>\n",
       "      <td>10%</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>30</td>\n",
       "      <td>10%</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Subject_No add_data     1     2     3     4     5     6     7     8  ...  \\\n",
       "0            5      40%  0.99  0.99  1.00  0.98  1.00  0.00  0.00  0.00  ...   \n",
       "1            6      10%  0.99  1.00  1.00  1.00  1.00  0.96  0.00  0.00  ...   \n",
       "2            7      10%  1.00  1.00  1.00  1.00  1.00  0.98  1.00  0.00  ...   \n",
       "3            8      10%  1.00  1.00  1.00  1.00  1.00  0.95  0.99  1.00  ...   \n",
       "4            9      10%  0.99  1.00  1.00  0.99  1.00  0.99  1.00  1.00  ...   \n",
       "5           10      10%  0.99  1.00  1.00  0.99  1.00  0.99  0.99  0.99  ...   \n",
       "6           11      10%  0.99  1.00  1.00  1.00  1.00  0.98  0.99  0.99  ...   \n",
       "7           12      10%  0.98  1.00  0.99  1.00  1.00  0.98  0.99  0.96  ...   \n",
       "8           13      10%  0.99  1.00  1.00  1.00  1.00  0.99  1.00  0.99  ...   \n",
       "9           14      10%  1.00  1.00  1.00  1.00  1.00  1.00  0.99  1.00  ...   \n",
       "10          15      10%  0.99  1.00  1.00  1.00  1.00  1.00  0.98  0.99  ...   \n",
       "11          16      10%  1.00  0.99  1.00  0.99  1.00  0.97  0.94  1.00  ...   \n",
       "12          17      10%  1.00  0.98  1.00  0.99  0.99  0.98  0.93  1.00  ...   \n",
       "13          18      10%  1.00  0.99  1.00  0.98  1.00  0.99  1.00  0.99  ...   \n",
       "14          19      10%  1.00  0.99  1.00  0.98  1.00  0.97  0.97  0.99  ...   \n",
       "15          20      10%  1.00  1.00  1.00  0.98  1.00  0.99  1.00  1.00  ...   \n",
       "16          21      10%  0.98  1.00  1.00  0.99  1.00  0.99  0.96  1.00  ...   \n",
       "17          22      10%  1.00  1.00  1.00  1.00  1.00  0.96  0.98  1.00  ...   \n",
       "18          23      10%  1.00  1.00  1.00  1.00  1.00  0.97  0.98  1.00  ...   \n",
       "19          24      10%  1.00  0.99  1.00  1.00  1.00  0.94  0.98  0.94  ...   \n",
       "20          25      10%  1.00  1.00  1.00  0.99  1.00  0.95  0.98  0.95  ...   \n",
       "21          26      10%  0.99  1.00  0.98  1.00  1.00  0.97  1.00  1.00  ...   \n",
       "22          27      10%  1.00  1.00  1.00  0.99  1.00  0.97  1.00  0.99  ...   \n",
       "23          28      10%  1.00  1.00  1.00  1.00  1.00  0.98  0.99  0.99  ...   \n",
       "24          29      10%  1.00  0.99  1.00  0.97  1.00  0.99  0.97  1.00  ...   \n",
       "25          30      10%  1.00  1.00  1.00  0.98  1.00  0.98  0.98  0.99  ...   \n",
       "\n",
       "     51   52   53   54   55   56   57   58   59   60  \n",
       "0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "5   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "6   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "7   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "8   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "9   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "10  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "11  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "12  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "13  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "14  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "15  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "16  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "17  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "18  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "19  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "20  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "21  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "22  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "23  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "24  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "25  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[26 rows x 62 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_speaker.iloc[:,0:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "67a46106",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject_No</th>\n",
       "      <th>add_data</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>40%</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>10%</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>10%</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>10%</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>10%</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.93</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10</td>\n",
       "      <td>10%</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11</td>\n",
       "      <td>10%</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>12</td>\n",
       "      <td>10%</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>13</td>\n",
       "      <td>10%</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.83</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>14</td>\n",
       "      <td>10%</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.87</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>15</td>\n",
       "      <td>10%</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.89</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>16</td>\n",
       "      <td>10%</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.89</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>17</td>\n",
       "      <td>10%</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.86</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>18</td>\n",
       "      <td>10%</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.89</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>19</td>\n",
       "      <td>10%</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>20</td>\n",
       "      <td>10%</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.89</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>21</td>\n",
       "      <td>10%</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.89</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>22</td>\n",
       "      <td>10%</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>23</td>\n",
       "      <td>10%</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>24</td>\n",
       "      <td>10%</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>25</td>\n",
       "      <td>10%</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.89</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>26</td>\n",
       "      <td>10%</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.86</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>27</td>\n",
       "      <td>10%</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>28</td>\n",
       "      <td>10%</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>29</td>\n",
       "      <td>10%</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>30</td>\n",
       "      <td>10%</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.89</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Subject_No add_data     1    2     3     4    5     6     7    8  ...  \\\n",
       "0            5      40%  0.99  1.0  1.00  1.00  1.0  0.96  0.97  1.0  ...   \n",
       "1            6      10%  1.00  1.0  1.00  1.00  1.0  1.00  0.98  1.0  ...   \n",
       "2            7      10%  1.00  1.0  0.99  1.00  1.0  1.00  1.00  1.0  ...   \n",
       "3            8      10%  1.00  1.0  1.00  1.00  1.0  1.00  1.00  1.0  ...   \n",
       "4            9      10%  1.00  1.0  0.99  1.00  1.0  0.99  1.00  1.0  ...   \n",
       "5           10      10%  1.00  1.0  0.99  1.00  1.0  1.00  0.99  1.0  ...   \n",
       "6           11      10%  1.00  1.0  1.00  1.00  1.0  1.00  1.00  1.0  ...   \n",
       "7           12      10%  1.00  1.0  1.00  1.00  1.0  0.99  1.00  1.0  ...   \n",
       "8           13      10%  1.00  1.0  1.00  1.00  1.0  1.00  0.99  1.0  ...   \n",
       "9           14      10%  1.00  1.0  1.00  0.99  1.0  1.00  0.99  1.0  ...   \n",
       "10          15      10%  1.00  1.0  1.00  0.99  1.0  1.00  1.00  1.0  ...   \n",
       "11          16      10%  1.00  1.0  0.99  1.00  1.0  1.00  1.00  1.0  ...   \n",
       "12          17      10%  1.00  1.0  1.00  1.00  1.0  1.00  1.00  1.0  ...   \n",
       "13          18      10%  1.00  1.0  1.00  1.00  1.0  1.00  1.00  1.0  ...   \n",
       "14          19      10%  1.00  1.0  1.00  1.00  1.0  1.00  0.99  1.0  ...   \n",
       "15          20      10%  1.00  1.0  1.00  0.99  1.0  1.00  0.99  1.0  ...   \n",
       "16          21      10%  1.00  1.0  1.00  1.00  1.0  1.00  1.00  1.0  ...   \n",
       "17          22      10%  1.00  1.0  1.00  1.00  1.0  1.00  0.99  1.0  ...   \n",
       "18          23      10%  1.00  1.0  1.00  1.00  1.0  1.00  0.99  1.0  ...   \n",
       "19          24      10%  1.00  1.0  1.00  0.99  1.0  1.00  1.00  1.0  ...   \n",
       "20          25      10%  1.00  1.0  1.00  0.99  1.0  1.00  1.00  1.0  ...   \n",
       "21          26      10%  1.00  1.0  1.00  1.00  1.0  1.00  1.00  1.0  ...   \n",
       "22          27      10%  1.00  1.0  1.00  0.99  1.0  1.00  1.00  1.0  ...   \n",
       "23          28      10%  1.00  1.0  1.00  1.00  1.0  1.00  1.00  1.0  ...   \n",
       "24          29      10%  1.00  1.0  1.00  0.98  1.0  1.00  0.99  1.0  ...   \n",
       "25          30      10%  1.00  1.0  1.00  0.99  1.0  1.00  1.00  1.0  ...   \n",
       "\n",
       "      51    52    53    54    55    56    57    58    59    60  \n",
       "0   0.96  0.88  0.89  0.99  0.99  0.97  0.86  0.95  0.90  0.88  \n",
       "1   0.98  0.96  0.99  0.99  1.00  0.99  0.91  1.00  0.97  0.92  \n",
       "2   0.98  0.92  0.99  0.97  0.99  0.96  0.85  0.98  0.96  0.85  \n",
       "3   0.97  0.92  0.98  0.96  0.99  1.00  0.88  0.98  0.98  0.89  \n",
       "4   0.97  0.97  1.00  0.93  1.00  0.99  0.86  0.99  0.98  0.89  \n",
       "5   0.98  0.96  1.00  0.95  1.00  0.94  0.86  0.98  0.94  0.84  \n",
       "6   0.97  0.94  1.00  0.92  1.00  0.95  0.84  0.99  0.97  0.84  \n",
       "7   0.98  0.91  1.00  0.98  1.00  0.97  0.83  0.99  0.95  0.88  \n",
       "8   1.00  0.93  0.99  0.98  1.00  0.95  0.83  1.00  0.96  0.84  \n",
       "9   1.00  0.96  1.00  0.98  1.00  0.99  0.87  1.00  0.97  0.85  \n",
       "10  1.00  0.98  1.00  0.99  1.00  0.99  0.89  1.00  0.96  0.83  \n",
       "11  1.00  0.99  1.00  1.00  1.00  1.00  0.89  1.00  0.96  0.81  \n",
       "12  1.00  0.98  1.00  0.99  1.00  0.99  0.86  1.00  0.97  0.80  \n",
       "13  1.00  0.99  1.00  0.98  1.00  0.96  0.89  1.00  0.98  0.83  \n",
       "14  1.00  0.96  1.00  0.96  1.00  0.99  0.90  1.00  0.97  0.87  \n",
       "15  1.00  0.98  1.00  0.98  1.00  1.00  0.89  1.00  0.92  0.85  \n",
       "16  1.00  0.96  1.00  1.00  1.00  0.99  0.89  1.00  0.98  0.88  \n",
       "17  1.00  0.98  1.00  1.00  1.00  0.99  0.91  1.00  0.95  0.89  \n",
       "18  1.00  0.98  1.00  0.98  0.99  1.00  0.90  1.00  0.98  0.91  \n",
       "19  0.99  0.99  1.00  0.99  1.00  1.00  0.91  1.00  0.98  0.88  \n",
       "20  1.00  0.99  1.00  1.00  1.00  0.99  0.89  1.00  0.97  0.91  \n",
       "21  1.00  0.94  1.00  1.00  1.00  0.99  0.86  1.00  0.93  0.91  \n",
       "22  1.00  1.00  1.00  1.00  1.00  1.00  0.90  1.00  0.92  0.90  \n",
       "23  1.00  1.00  1.00  1.00  1.00  0.99  0.90  1.00  0.94  0.87  \n",
       "24  1.00  1.00  1.00  1.00  1.00  0.99  0.90  1.00  0.94  0.87  \n",
       "25  1.00  1.00  1.00  1.00  1.00  1.00  0.89  1.00  0.97  0.89  \n",
       "\n",
       "[26 rows x 62 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_command.iloc[:,0:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "462688e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "fig = plt.figure(figsize=(8,5))\n",
    "plt.subplot(2,1,1)\n",
    "sns.boxplot(data=performance_speaker.transpose()[performance_speaker.transpose().iloc[2:,:]>0],width=0.5,color=\"teal\")\n",
    "plt.box(False)\n",
    "plt.ylim([0.7,1.00])\n",
    "plt.yticks(fontsize=14)\n",
    "plt.xticks(range(len(performance_speaker)),performance_speaker[\"Subject_No\"],fontsize=14)\n",
    "plt.title(\"Speaker\",fontsize=14)\n",
    "plt.ylabel(None)\n",
    "plt.subplot(2,1,2)\n",
    "sns.boxplot(data=performance_command.transpose()[performance_speaker.transpose().iloc[2:,:]>0],width=0.5,color=\"teal\")\n",
    "plt.box(False)\n",
    "plt.ylim([0.7,1.00])\n",
    "plt.yticks(fontsize=14)\n",
    "plt.xticks(range(len(performance_speaker)),performance_speaker[\"Subject_No\"],fontsize=14)\n",
    "plt.ylabel(None)\n",
    "plt.title(\"Command\",fontsize=14)\n",
    "plt.xlabel(\"Add speakers\",fontsize=14)\n",
    "# fig.text(0.5, -0.05, 'Accuracy', ha='center', va='center', rotation='horizontal',fontsize=14)\n",
    "fig.text(0.5, 1.0, 'Speaker and Command Accuracy on exsiting Subjects', ha='center', va='center', rotation='horizontal',fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2b9f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b4fd29f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_speaker.to_csv(\"performance_speaker_0531_5->30_final_free&unfree.csv\",index=False)\n",
    "performance_command.to_csv(\"performance_command_0531_5->30_final_free&unfree.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8be0ce0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ef33bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877353d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4f547f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a12ceb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f77e25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
