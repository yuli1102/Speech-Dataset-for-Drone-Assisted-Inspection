{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"   #(xxxx is your specific GPU ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.layers import Activation, Dense, Flatten, GlobalAveragePooling2D\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Sequential\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from MyEarlyStopping import MyEarlyStopping\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "# from keras.optimizers import adam\n",
    "\n",
    "import timeit\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.preprocessing import LabelEncoder  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_number = 5\n",
    "train_image = 10 #10:20%, 20: 40%, 30:60%\n",
    "train_image_s1 = 20 #10:20%, 20: 40%, 30:60%\n",
    "train_image_s2 = 30 #10:20%, 20: 40%, 30:60%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training dataset (40%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1714 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "train_generator = train_data.flow_from_directory('/data/home/cou/yuli5/semg/Audio_MEL_Data/train',\n",
    "                                                batch_size=1,\n",
    "                                                target_size=(224,224),\n",
    "                                                class_mode='categorical',\n",
    "                                               shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_names = train_generator.filenames\n",
    "image_no = [i.split(\"/\")[1].split(\"_\")[2].split(\".\")[0] for i in image_names]\n",
    "image_no = np.array(list(map(int, image_no)))\n",
    "ALL_participant_class = [i.split(\"/\")[1].split(\"_\")[1] for i in image_names]\n",
    "ALL_participant_class = np.array(list(map(int, ALL_participant_class)))\n",
    "command_class = train_generator.classes\n",
    "All_participant_class = tf.keras.utils.to_categorical(ALL_participant_class-1, num_classes=train_number)\n",
    "All_command_class = tf.keras.utils.to_categorical(command_class, num_classes=10)\n",
    "All_command_uniform = All_command_class*0+1/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "All_Inputs = [next(train_generator)[0][0] for _ in range(len(train_generator))]\n",
    "All_Inputs = np.array(All_Inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([200., 300., 100., 100., 100.], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_indexs_train = ((image_no<train_image)&(ALL_participant_class>2))|((image_no<train_image_s1)&(ALL_participant_class==1))|((image_no<train_image_s2)&(ALL_participant_class==2))\n",
    "Train_Inputs = All_Inputs[select_indexs_train]\n",
    "Train_participant_class = All_participant_class[select_indexs_train]\n",
    "Train_participant_uniform = Train_participant_class*0+1/train_number\n",
    "Train_command_class = All_command_class[select_indexs_train]\n",
    "Train_command_uniform = Train_command_class*0+1/10\n",
    "sum(Train_participant_class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation dataset (20%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 543 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "val_data = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "val_generator = val_data.flow_from_directory('/data/home/cou/yuli5/semg/Audio_MEL_Data/validation',\n",
    "                                                batch_size=1,\n",
    "                                                target_size=(224,224),\n",
    "                                                class_mode='categorical',\n",
    "                                               shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_names = val_generator.filenames\n",
    "participant_class = [i.split(\"/\", 1)[1].split(\"_\")[1] for i in image_names]\n",
    "participant_class = np.array(list(map(int, participant_class)))\n",
    "command_class = val_generator.classes\n",
    "Val_participant_class = tf.keras.utils.to_categorical(participant_class-1, num_classes=train_number)\n",
    "Val_participant_uniform = Val_participant_class*0+1/train_number\n",
    "Val_command_class = tf.keras.utils.to_categorical(command_class, num_classes=10)\n",
    "Val_command_uniform = Val_command_class*0+1/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Val_Inputs = [next(val_generator)[0][0] for _ in range(len(val_generator))]\n",
    "Val_Inputs = np.array(Val_Inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test dataset (20%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 543 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "test_data = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "test_generator = test_data.flow_from_directory('/data/home/cou/yuli5/semg/Audio_MEL_Data/test',\n",
    "                                                batch_size=1,\n",
    "                                                target_size=(224,224),\n",
    "                                                class_mode='categorical',\n",
    "                                                shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_names = test_generator.filenames\n",
    "participant_class = [i.split(\"/\", 1)[1].split(\"_\")[1] for i in image_names]\n",
    "test_unit_participant_class = np.array(list(map(int, participant_class)))\n",
    "test_unit_command_class = test_generator.classes\n",
    "Test_participant_class = tf.keras.utils.to_categorical(test_unit_participant_class-1, num_classes=train_number)\n",
    "Test_participant_uniform = Test_participant_class*0+1/train_number\n",
    "Test_command_class = tf.keras.utils.to_categorical(test_unit_command_class, num_classes=10)\n",
    "Test_command_uniform = Test_command_class*0+1/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_Inputs = [next(test_generator)[0][0] for _ in range(len(test_generator))]\n",
    "Test_Inputs = np.array(Test_Inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_Inputs_1 = Test_Inputs[np.where(test_unit_participant_class == 1)]\n",
    "Test_command_class_1 = Test_command_class[np.where(test_unit_participant_class == 1)]\n",
    "Test_Inputs_2 = Test_Inputs[np.where(test_unit_participant_class == 2)]\n",
    "Test_command_class_2 = Test_command_class[np.where(test_unit_participant_class == 2)]\n",
    "Test_Inputs_3 = Test_Inputs[np.where(test_unit_participant_class == 3)]\n",
    "Test_command_class_3 = Test_command_class[np.where(test_unit_participant_class == 3)]\n",
    "Test_Inputs_4 = Test_Inputs[np.where(test_unit_participant_class == 4)]\n",
    "Test_command_class_4 = Test_command_class[np.where(test_unit_participant_class == 4)]\n",
    "Test_Inputs_5 = Test_Inputs[np.where(test_unit_participant_class == 5)]\n",
    "Test_command_class_5 = Test_command_class[np.where(test_unit_participant_class == 5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speaker 6 Test dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "test_data_6 = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "test_generator_6 = test_data_6.flow_from_directory('/data/home/cou/yuli5/semg/Audio_MEL_subject/p_6_split/test',\n",
    "                                                batch_size=1,\n",
    "                                                target_size=(224,224),\n",
    "                                                class_mode='categorical',\n",
    "                                                shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_names = test_generator_6.filenames\n",
    "command_class = [i.split(\"/\", 1)[0]for i in image_names]\n",
    "le = LabelEncoder()\n",
    "test_unit_command_class_6 = le.fit_transform(command_class)\n",
    "Test_command_class_6 = tf.keras.utils.to_categorical(test_unit_command_class_6, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_Inputs_6 = [next(test_generator_6)[0][0] for _ in range(len(test_generator_6))]\n",
    "Test_Inputs_6 = np.array(Test_Inputs_6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speaker 7 Test dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 125 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "test_data_7 = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "test_generator_7 = test_data_6.flow_from_directory('/data/home/cou/yuli5/semg/Audio_MEL_subject/p_7_split/test',\n",
    "                                                batch_size=1,\n",
    "                                                target_size=(224,224),\n",
    "                                                class_mode='categorical',\n",
    "                                                shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_names = test_generator_7.filenames\n",
    "command_class = [i.split(\"/\", 1)[0]for i in image_names]\n",
    "le = LabelEncoder()\n",
    "test_unit_command_class_7 = le.fit_transform(command_class)\n",
    "Test_command_class_7 = tf.keras.utils.to_categorical(test_unit_command_class_7, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_Inputs_7 = [next(test_generator_7)[0][0] for _ in range(len(test_generator_7))]\n",
    "Test_Inputs_7 = np.array(Test_Inputs_7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speaker 8 Test dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 101 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "test_data_8 = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "test_generator_8 = test_data_6.flow_from_directory('/data/home/cou/yuli5/semg/Audio_MEL_subject/p_8_split/test',\n",
    "                                                batch_size=1,\n",
    "                                                target_size=(224,224),\n",
    "                                                class_mode='categorical',\n",
    "                                                shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_names = test_generator_8.filenames\n",
    "command_class = [i.split(\"/\", 1)[0]for i in image_names]\n",
    "le = LabelEncoder()\n",
    "test_unit_command_class_8 = le.fit_transform(command_class)\n",
    "Test_command_class_8 = tf.keras.utils.to_categorical(test_unit_command_class_8, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_Inputs_8 = [next(test_generator_8)[0][0] for _ in range(len(test_generator_8))]\n",
    "Test_Inputs_8 = np.array(Test_Inputs_8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pd file store performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Size</th>\n",
       "      <th>Time</th>\n",
       "      <th>Partcp_Acc_p15</th>\n",
       "      <th>Command_Acc_p15</th>\n",
       "      <th>Partcp_Acc_p1</th>\n",
       "      <th>Command_Acc_p1</th>\n",
       "      <th>Partcp_Acc_p2</th>\n",
       "      <th>Command_Acc_p2</th>\n",
       "      <th>Partcp_Acc_p3</th>\n",
       "      <th>Command_Acc_p3</th>\n",
       "      <th>Partcp_Acc_p4</th>\n",
       "      <th>Command_Acc_p4</th>\n",
       "      <th>Partcp_Acc_p5</th>\n",
       "      <th>Command_Acc_p5</th>\n",
       "      <th>Acc_p6</th>\n",
       "      <th>Acc_p7</th>\n",
       "      <th>Acc_p8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Group</td>\n",
       "      <td>20%</td>\n",
       "      <td>47.540156</td>\n",
       "      <td>0.9724</td>\n",
       "      <td>0.9484</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.9550</td>\n",
       "      <td>0.9259</td>\n",
       "      <td>0.8796</td>\n",
       "      <td>0.9652</td>\n",
       "      <td>0.9565</td>\n",
       "      <td>0.9817</td>\n",
       "      <td>0.9633</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.528</td>\n",
       "      <td>0.3366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Group</td>\n",
       "      <td>20%</td>\n",
       "      <td>48.307249</td>\n",
       "      <td>0.9779</td>\n",
       "      <td>0.9521</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.9369</td>\n",
       "      <td>0.9352</td>\n",
       "      <td>0.8796</td>\n",
       "      <td>0.9739</td>\n",
       "      <td>0.9652</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.528</td>\n",
       "      <td>0.2970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Group</td>\n",
       "      <td>20%</td>\n",
       "      <td>46.201615</td>\n",
       "      <td>0.9613</td>\n",
       "      <td>0.9448</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.9369</td>\n",
       "      <td>0.9074</td>\n",
       "      <td>0.8611</td>\n",
       "      <td>0.9826</td>\n",
       "      <td>0.9652</td>\n",
       "      <td>0.9358</td>\n",
       "      <td>0.9725</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.432</td>\n",
       "      <td>0.2673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Group</td>\n",
       "      <td>20%</td>\n",
       "      <td>43.692362</td>\n",
       "      <td>0.9650</td>\n",
       "      <td>0.9521</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.9459</td>\n",
       "      <td>0.9074</td>\n",
       "      <td>0.8704</td>\n",
       "      <td>0.9826</td>\n",
       "      <td>0.9652</td>\n",
       "      <td>0.9358</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.504</td>\n",
       "      <td>0.2673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Group</td>\n",
       "      <td>20%</td>\n",
       "      <td>44.504580</td>\n",
       "      <td>0.9687</td>\n",
       "      <td>0.9484</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.9550</td>\n",
       "      <td>0.9259</td>\n",
       "      <td>0.8796</td>\n",
       "      <td>0.9739</td>\n",
       "      <td>0.9652</td>\n",
       "      <td>0.9541</td>\n",
       "      <td>0.9541</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.472</td>\n",
       "      <td>0.3267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Group</td>\n",
       "      <td>20%</td>\n",
       "      <td>44.229166</td>\n",
       "      <td>0.9705</td>\n",
       "      <td>0.9521</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.9550</td>\n",
       "      <td>0.9074</td>\n",
       "      <td>0.8796</td>\n",
       "      <td>0.9826</td>\n",
       "      <td>0.9739</td>\n",
       "      <td>0.9633</td>\n",
       "      <td>0.9633</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.456</td>\n",
       "      <td>0.3069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Group</td>\n",
       "      <td>20%</td>\n",
       "      <td>44.535541</td>\n",
       "      <td>0.9632</td>\n",
       "      <td>0.9540</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.9369</td>\n",
       "      <td>0.9259</td>\n",
       "      <td>0.8981</td>\n",
       "      <td>0.9565</td>\n",
       "      <td>0.9652</td>\n",
       "      <td>0.9541</td>\n",
       "      <td>0.9817</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.496</td>\n",
       "      <td>0.3267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Group</td>\n",
       "      <td>20%</td>\n",
       "      <td>42.948731</td>\n",
       "      <td>0.9724</td>\n",
       "      <td>0.9595</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.9550</td>\n",
       "      <td>0.9074</td>\n",
       "      <td>0.8889</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9739</td>\n",
       "      <td>0.9633</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.496</td>\n",
       "      <td>0.2574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Group</td>\n",
       "      <td>20%</td>\n",
       "      <td>45.444911</td>\n",
       "      <td>0.9724</td>\n",
       "      <td>0.9503</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.9459</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>0.8796</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9652</td>\n",
       "      <td>0.9633</td>\n",
       "      <td>0.9725</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.552</td>\n",
       "      <td>0.2673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Group</td>\n",
       "      <td>20%</td>\n",
       "      <td>42.707019</td>\n",
       "      <td>0.9669</td>\n",
       "      <td>0.9540</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.9459</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>0.8704</td>\n",
       "      <td>0.9739</td>\n",
       "      <td>0.9652</td>\n",
       "      <td>0.9541</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.480</td>\n",
       "      <td>0.4059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Group</td>\n",
       "      <td>40%</td>\n",
       "      <td>67.289367</td>\n",
       "      <td>0.9945</td>\n",
       "      <td>0.9761</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.9640</td>\n",
       "      <td>0.9907</td>\n",
       "      <td>0.9352</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.472</td>\n",
       "      <td>0.2772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Group</td>\n",
       "      <td>40%</td>\n",
       "      <td>64.328163</td>\n",
       "      <td>0.9890</td>\n",
       "      <td>0.9761</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.9730</td>\n",
       "      <td>0.9815</td>\n",
       "      <td>0.9259</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.480</td>\n",
       "      <td>0.2871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Group</td>\n",
       "      <td>40%</td>\n",
       "      <td>61.978212</td>\n",
       "      <td>0.9926</td>\n",
       "      <td>0.9797</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.9730</td>\n",
       "      <td>0.9907</td>\n",
       "      <td>0.9444</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.3168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Group</td>\n",
       "      <td>40%</td>\n",
       "      <td>60.036626</td>\n",
       "      <td>0.9926</td>\n",
       "      <td>0.9779</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.9730</td>\n",
       "      <td>0.9907</td>\n",
       "      <td>0.9352</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.456</td>\n",
       "      <td>0.3267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Group</td>\n",
       "      <td>40%</td>\n",
       "      <td>58.215136</td>\n",
       "      <td>0.9890</td>\n",
       "      <td>0.9761</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.9730</td>\n",
       "      <td>0.9815</td>\n",
       "      <td>0.9352</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9826</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.448</td>\n",
       "      <td>0.2871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Group</td>\n",
       "      <td>40%</td>\n",
       "      <td>49.347837</td>\n",
       "      <td>0.9871</td>\n",
       "      <td>0.9761</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.9730</td>\n",
       "      <td>0.9815</td>\n",
       "      <td>0.9352</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9817</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.472</td>\n",
       "      <td>0.2772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Group</td>\n",
       "      <td>40%</td>\n",
       "      <td>59.879732</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.9779</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.9730</td>\n",
       "      <td>0.9815</td>\n",
       "      <td>0.9444</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9826</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.3366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Group</td>\n",
       "      <td>40%</td>\n",
       "      <td>57.413757</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.9761</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.9640</td>\n",
       "      <td>0.9815</td>\n",
       "      <td>0.9444</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9826</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.3168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Group</td>\n",
       "      <td>40%</td>\n",
       "      <td>50.219540</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.9761</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.9730</td>\n",
       "      <td>0.9815</td>\n",
       "      <td>0.9352</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.456</td>\n",
       "      <td>0.2772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Group</td>\n",
       "      <td>40%</td>\n",
       "      <td>53.871787</td>\n",
       "      <td>0.9945</td>\n",
       "      <td>0.9742</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.9730</td>\n",
       "      <td>0.9907</td>\n",
       "      <td>0.9259</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.9817</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.424</td>\n",
       "      <td>0.2673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Group</td>\n",
       "      <td>60%</td>\n",
       "      <td>80.966223</td>\n",
       "      <td>0.9926</td>\n",
       "      <td>0.9871</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.9820</td>\n",
       "      <td>0.9815</td>\n",
       "      <td>0.9722</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.2772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Group</td>\n",
       "      <td>60%</td>\n",
       "      <td>77.376384</td>\n",
       "      <td>0.9926</td>\n",
       "      <td>0.9797</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.9820</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9537</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9826</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.9817</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.456</td>\n",
       "      <td>0.2178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Group</td>\n",
       "      <td>60%</td>\n",
       "      <td>79.340686</td>\n",
       "      <td>0.9945</td>\n",
       "      <td>0.9816</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.9820</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9444</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.2970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Group</td>\n",
       "      <td>60%</td>\n",
       "      <td>63.791425</td>\n",
       "      <td>0.9890</td>\n",
       "      <td>0.9871</td>\n",
       "      <td>0.973</td>\n",
       "      <td>0.9910</td>\n",
       "      <td>0.9815</td>\n",
       "      <td>0.9630</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.424</td>\n",
       "      <td>0.3069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Group</td>\n",
       "      <td>60%</td>\n",
       "      <td>78.678261</td>\n",
       "      <td>0.9926</td>\n",
       "      <td>0.9797</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.9820</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9537</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9826</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.9817</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.424</td>\n",
       "      <td>0.2376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Group</td>\n",
       "      <td>60%</td>\n",
       "      <td>71.382334</td>\n",
       "      <td>0.9945</td>\n",
       "      <td>0.9834</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.9820</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9537</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.408</td>\n",
       "      <td>0.2475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Group</td>\n",
       "      <td>60%</td>\n",
       "      <td>76.130331</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.9853</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.9910</td>\n",
       "      <td>0.9907</td>\n",
       "      <td>0.9537</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.416</td>\n",
       "      <td>0.2673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Group</td>\n",
       "      <td>60%</td>\n",
       "      <td>70.832085</td>\n",
       "      <td>0.9945</td>\n",
       "      <td>0.9871</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.9820</td>\n",
       "      <td>0.9907</td>\n",
       "      <td>0.9722</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.2673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Group</td>\n",
       "      <td>60%</td>\n",
       "      <td>73.439023</td>\n",
       "      <td>0.9945</td>\n",
       "      <td>0.9890</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.9910</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9722</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.424</td>\n",
       "      <td>0.2277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Group</td>\n",
       "      <td>60%</td>\n",
       "      <td>72.148432</td>\n",
       "      <td>0.9945</td>\n",
       "      <td>0.9834</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.9910</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9444</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.416</td>\n",
       "      <td>0.2772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Group</td>\n",
       "      <td>mix_20%&amp;s2_40%</td>\n",
       "      <td>47.769887</td>\n",
       "      <td>0.9834</td>\n",
       "      <td>0.9669</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.9459</td>\n",
       "      <td>0.9815</td>\n",
       "      <td>0.9352</td>\n",
       "      <td>0.9739</td>\n",
       "      <td>0.9826</td>\n",
       "      <td>0.9725</td>\n",
       "      <td>0.9817</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.552</td>\n",
       "      <td>0.3267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Group</td>\n",
       "      <td>mix_20%&amp;s2_40%</td>\n",
       "      <td>49.705597</td>\n",
       "      <td>0.9816</td>\n",
       "      <td>0.9576</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.9369</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9259</td>\n",
       "      <td>0.9739</td>\n",
       "      <td>0.9652</td>\n",
       "      <td>0.9450</td>\n",
       "      <td>0.9817</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.512</td>\n",
       "      <td>0.3168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Group</td>\n",
       "      <td>mix_20%&amp;s2_40%</td>\n",
       "      <td>44.363904</td>\n",
       "      <td>0.9797</td>\n",
       "      <td>0.9576</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.9550</td>\n",
       "      <td>0.9815</td>\n",
       "      <td>0.9259</td>\n",
       "      <td>0.9652</td>\n",
       "      <td>0.9478</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.9725</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.536</td>\n",
       "      <td>0.2376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Group</td>\n",
       "      <td>mix_20%&amp;s2_40%</td>\n",
       "      <td>46.206470</td>\n",
       "      <td>0.9945</td>\n",
       "      <td>0.9650</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.9550</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9259</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9652</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.480</td>\n",
       "      <td>0.2673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Group</td>\n",
       "      <td>mix_20%&amp;s2_40%</td>\n",
       "      <td>47.192904</td>\n",
       "      <td>0.9797</td>\n",
       "      <td>0.9632</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.9369</td>\n",
       "      <td>0.9907</td>\n",
       "      <td>0.9444</td>\n",
       "      <td>0.9739</td>\n",
       "      <td>0.9652</td>\n",
       "      <td>0.9541</td>\n",
       "      <td>0.9817</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.504</td>\n",
       "      <td>0.2871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Group</td>\n",
       "      <td>mix_20%&amp;s2_40%</td>\n",
       "      <td>47.685570</td>\n",
       "      <td>0.9761</td>\n",
       "      <td>0.9558</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.9279</td>\n",
       "      <td>0.9907</td>\n",
       "      <td>0.9352</td>\n",
       "      <td>0.9565</td>\n",
       "      <td>0.9565</td>\n",
       "      <td>0.9633</td>\n",
       "      <td>0.9817</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.472</td>\n",
       "      <td>0.2871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Group</td>\n",
       "      <td>mix_20%&amp;s2_40%</td>\n",
       "      <td>44.867667</td>\n",
       "      <td>0.9816</td>\n",
       "      <td>0.9687</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.9550</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9537</td>\n",
       "      <td>0.9652</td>\n",
       "      <td>0.9652</td>\n",
       "      <td>0.9541</td>\n",
       "      <td>0.9817</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.496</td>\n",
       "      <td>0.2673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Group</td>\n",
       "      <td>mix_20%&amp;s2_40%</td>\n",
       "      <td>44.795298</td>\n",
       "      <td>0.9853</td>\n",
       "      <td>0.9724</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.9550</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9630</td>\n",
       "      <td>0.9652</td>\n",
       "      <td>0.9739</td>\n",
       "      <td>0.9633</td>\n",
       "      <td>0.9817</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.544</td>\n",
       "      <td>0.3069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Group</td>\n",
       "      <td>mix_20%&amp;s2_40%</td>\n",
       "      <td>40.871670</td>\n",
       "      <td>0.9742</td>\n",
       "      <td>0.9558</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.9459</td>\n",
       "      <td>0.9815</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>0.9391</td>\n",
       "      <td>0.9565</td>\n",
       "      <td>0.9541</td>\n",
       "      <td>0.9725</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.480</td>\n",
       "      <td>0.2970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Group</td>\n",
       "      <td>mix_20%&amp;s2_40%</td>\n",
       "      <td>42.479896</td>\n",
       "      <td>0.9834</td>\n",
       "      <td>0.9687</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.9550</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9352</td>\n",
       "      <td>0.9739</td>\n",
       "      <td>0.9826</td>\n",
       "      <td>0.9633</td>\n",
       "      <td>0.9817</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.536</td>\n",
       "      <td>0.2673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Group</td>\n",
       "      <td>mix_20%&amp;s12_40%</td>\n",
       "      <td>51.959552</td>\n",
       "      <td>0.9834</td>\n",
       "      <td>0.9687</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.9730</td>\n",
       "      <td>0.9907</td>\n",
       "      <td>0.9444</td>\n",
       "      <td>0.9826</td>\n",
       "      <td>0.9565</td>\n",
       "      <td>0.9541</td>\n",
       "      <td>0.9817</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.504</td>\n",
       "      <td>0.3168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Group</td>\n",
       "      <td>mix_20%&amp;s12_40%</td>\n",
       "      <td>52.339809</td>\n",
       "      <td>0.9705</td>\n",
       "      <td>0.9669</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.9730</td>\n",
       "      <td>0.9907</td>\n",
       "      <td>0.9444</td>\n",
       "      <td>0.9478</td>\n",
       "      <td>0.9652</td>\n",
       "      <td>0.9358</td>\n",
       "      <td>0.9725</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.424</td>\n",
       "      <td>0.2673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Group</td>\n",
       "      <td>mix_20%&amp;s12_40%</td>\n",
       "      <td>53.653035</td>\n",
       "      <td>0.9724</td>\n",
       "      <td>0.9705</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.9910</td>\n",
       "      <td>0.9907</td>\n",
       "      <td>0.9259</td>\n",
       "      <td>0.9826</td>\n",
       "      <td>0.9652</td>\n",
       "      <td>0.8899</td>\n",
       "      <td>0.9817</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.544</td>\n",
       "      <td>0.3168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Group</td>\n",
       "      <td>mix_20%&amp;s12_40%</td>\n",
       "      <td>49.510542</td>\n",
       "      <td>0.9705</td>\n",
       "      <td>0.9669</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.9640</td>\n",
       "      <td>0.9907</td>\n",
       "      <td>0.9444</td>\n",
       "      <td>0.9304</td>\n",
       "      <td>0.9565</td>\n",
       "      <td>0.9541</td>\n",
       "      <td>0.9725</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.464</td>\n",
       "      <td>0.3168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Group</td>\n",
       "      <td>mix_20%&amp;s12_40%</td>\n",
       "      <td>49.548754</td>\n",
       "      <td>0.9834</td>\n",
       "      <td>0.9669</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.9550</td>\n",
       "      <td>0.9907</td>\n",
       "      <td>0.9444</td>\n",
       "      <td>0.9826</td>\n",
       "      <td>0.9652</td>\n",
       "      <td>0.9450</td>\n",
       "      <td>0.9817</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.488</td>\n",
       "      <td>0.2970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Group</td>\n",
       "      <td>mix_20%&amp;s12_40%</td>\n",
       "      <td>53.723940</td>\n",
       "      <td>0.9761</td>\n",
       "      <td>0.9669</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.9820</td>\n",
       "      <td>0.9907</td>\n",
       "      <td>0.9444</td>\n",
       "      <td>0.9739</td>\n",
       "      <td>0.9391</td>\n",
       "      <td>0.9450</td>\n",
       "      <td>0.9817</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.488</td>\n",
       "      <td>0.3069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Group</td>\n",
       "      <td>mix_20%&amp;s12_40%</td>\n",
       "      <td>50.595989</td>\n",
       "      <td>0.9761</td>\n",
       "      <td>0.9595</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.9550</td>\n",
       "      <td>0.9815</td>\n",
       "      <td>0.9352</td>\n",
       "      <td>0.9826</td>\n",
       "      <td>0.9565</td>\n",
       "      <td>0.9174</td>\n",
       "      <td>0.9633</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.456</td>\n",
       "      <td>0.3069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Group</td>\n",
       "      <td>mix_20%&amp;s12_40%</td>\n",
       "      <td>48.617480</td>\n",
       "      <td>0.9797</td>\n",
       "      <td>0.9632</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.9730</td>\n",
       "      <td>0.9907</td>\n",
       "      <td>0.9352</td>\n",
       "      <td>0.9652</td>\n",
       "      <td>0.9565</td>\n",
       "      <td>0.9541</td>\n",
       "      <td>0.9725</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.480</td>\n",
       "      <td>0.2475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Group</td>\n",
       "      <td>mix_20%&amp;s12_40%</td>\n",
       "      <td>47.476377</td>\n",
       "      <td>0.9834</td>\n",
       "      <td>0.9705</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.9910</td>\n",
       "      <td>0.9815</td>\n",
       "      <td>0.9259</td>\n",
       "      <td>0.9739</td>\n",
       "      <td>0.9739</td>\n",
       "      <td>0.9725</td>\n",
       "      <td>0.9817</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.472</td>\n",
       "      <td>0.3168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Group</td>\n",
       "      <td>mix_20%&amp;s12_40%</td>\n",
       "      <td>48.240296</td>\n",
       "      <td>0.9797</td>\n",
       "      <td>0.9687</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.9730</td>\n",
       "      <td>0.9907</td>\n",
       "      <td>0.9444</td>\n",
       "      <td>0.9652</td>\n",
       "      <td>0.9565</td>\n",
       "      <td>0.9450</td>\n",
       "      <td>0.9817</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.496</td>\n",
       "      <td>0.3069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Group</td>\n",
       "      <td>mix_20%&amp;s2_60%</td>\n",
       "      <td>50.357350</td>\n",
       "      <td>0.9926</td>\n",
       "      <td>0.9705</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.9369</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9722</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9652</td>\n",
       "      <td>0.9725</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.512</td>\n",
       "      <td>0.3069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Group</td>\n",
       "      <td>mix_20%&amp;s2_60%</td>\n",
       "      <td>52.448013</td>\n",
       "      <td>0.9871</td>\n",
       "      <td>0.9669</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.9459</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9630</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9652</td>\n",
       "      <td>0.9633</td>\n",
       "      <td>0.9817</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.496</td>\n",
       "      <td>0.3465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Group</td>\n",
       "      <td>mix_20%&amp;s2_60%</td>\n",
       "      <td>46.477153</td>\n",
       "      <td>0.9705</td>\n",
       "      <td>0.9650</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.9459</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9537</td>\n",
       "      <td>0.9652</td>\n",
       "      <td>0.9652</td>\n",
       "      <td>0.9358</td>\n",
       "      <td>0.9725</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.496</td>\n",
       "      <td>0.3663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Group</td>\n",
       "      <td>mix_20%&amp;s2_60%</td>\n",
       "      <td>50.288148</td>\n",
       "      <td>0.9871</td>\n",
       "      <td>0.9503</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.9099</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9537</td>\n",
       "      <td>0.9826</td>\n",
       "      <td>0.9391</td>\n",
       "      <td>0.9633</td>\n",
       "      <td>0.9725</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.3168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Group</td>\n",
       "      <td>mix_20%&amp;s2_60%</td>\n",
       "      <td>51.380808</td>\n",
       "      <td>0.9890</td>\n",
       "      <td>0.9595</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.9189</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9537</td>\n",
       "      <td>0.9739</td>\n",
       "      <td>0.9652</td>\n",
       "      <td>0.9817</td>\n",
       "      <td>0.9817</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.2772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Group</td>\n",
       "      <td>mix_20%&amp;s2_60%</td>\n",
       "      <td>51.368167</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.9595</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.9099</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9537</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9652</td>\n",
       "      <td>0.9817</td>\n",
       "      <td>0.9817</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.504</td>\n",
       "      <td>0.2871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Group</td>\n",
       "      <td>mix_20%&amp;s2_60%</td>\n",
       "      <td>49.387344</td>\n",
       "      <td>0.9816</td>\n",
       "      <td>0.9595</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.9369</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9630</td>\n",
       "      <td>0.9652</td>\n",
       "      <td>0.9478</td>\n",
       "      <td>0.9633</td>\n",
       "      <td>0.9725</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.536</td>\n",
       "      <td>0.2970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Group</td>\n",
       "      <td>mix_20%&amp;s2_60%</td>\n",
       "      <td>43.176742</td>\n",
       "      <td>0.9816</td>\n",
       "      <td>0.9669</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.9459</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9537</td>\n",
       "      <td>0.9739</td>\n",
       "      <td>0.9652</td>\n",
       "      <td>0.9358</td>\n",
       "      <td>0.9817</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.480</td>\n",
       "      <td>0.2871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Group</td>\n",
       "      <td>mix_20%&amp;s2_60%</td>\n",
       "      <td>48.327896</td>\n",
       "      <td>0.9853</td>\n",
       "      <td>0.9558</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.9279</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9537</td>\n",
       "      <td>0.9826</td>\n",
       "      <td>0.9391</td>\n",
       "      <td>0.9633</td>\n",
       "      <td>0.9817</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.512</td>\n",
       "      <td>0.2970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Group</td>\n",
       "      <td>mix_20%&amp;s2_60%</td>\n",
       "      <td>47.509030</td>\n",
       "      <td>0.9816</td>\n",
       "      <td>0.9669</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.9459</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9630</td>\n",
       "      <td>0.9739</td>\n",
       "      <td>0.9652</td>\n",
       "      <td>0.9450</td>\n",
       "      <td>0.9817</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.512</td>\n",
       "      <td>0.2772</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Model             Size       Time  Partcp_Acc_p15  Command_Acc_p15  \\\n",
       "0   Group              20%  47.540156          0.9724           0.9484   \n",
       "1   Group              20%  48.307249          0.9779           0.9521   \n",
       "2   Group              20%  46.201615          0.9613           0.9448   \n",
       "3   Group              20%  43.692362          0.9650           0.9521   \n",
       "4   Group              20%  44.504580          0.9687           0.9484   \n",
       "5   Group              20%  44.229166          0.9705           0.9521   \n",
       "6   Group              20%  44.535541          0.9632           0.9540   \n",
       "7   Group              20%  42.948731          0.9724           0.9595   \n",
       "8   Group              20%  45.444911          0.9724           0.9503   \n",
       "9   Group              20%  42.707019          0.9669           0.9540   \n",
       "10  Group              40%  67.289367          0.9945           0.9761   \n",
       "11  Group              40%  64.328163          0.9890           0.9761   \n",
       "12  Group              40%  61.978212          0.9926           0.9797   \n",
       "13  Group              40%  60.036626          0.9926           0.9779   \n",
       "14  Group              40%  58.215136          0.9890           0.9761   \n",
       "15  Group              40%  49.347837          0.9871           0.9761   \n",
       "16  Group              40%  59.879732          0.9908           0.9779   \n",
       "17  Group              40%  57.413757          0.9908           0.9761   \n",
       "18  Group              40%  50.219540          0.9908           0.9761   \n",
       "19  Group              40%  53.871787          0.9945           0.9742   \n",
       "20  Group              60%  80.966223          0.9926           0.9871   \n",
       "21  Group              60%  77.376384          0.9926           0.9797   \n",
       "22  Group              60%  79.340686          0.9945           0.9816   \n",
       "23  Group              60%  63.791425          0.9890           0.9871   \n",
       "24  Group              60%  78.678261          0.9926           0.9797   \n",
       "25  Group              60%  71.382334          0.9945           0.9834   \n",
       "26  Group              60%  76.130331          0.9908           0.9853   \n",
       "27  Group              60%  70.832085          0.9945           0.9871   \n",
       "28  Group              60%  73.439023          0.9945           0.9890   \n",
       "29  Group              60%  72.148432          0.9945           0.9834   \n",
       "30  Group   mix_20%&s2_40%  47.769887          0.9834           0.9669   \n",
       "31  Group   mix_20%&s2_40%  49.705597          0.9816           0.9576   \n",
       "32  Group   mix_20%&s2_40%  44.363904          0.9797           0.9576   \n",
       "33  Group   mix_20%&s2_40%  46.206470          0.9945           0.9650   \n",
       "34  Group   mix_20%&s2_40%  47.192904          0.9797           0.9632   \n",
       "35  Group   mix_20%&s2_40%  47.685570          0.9761           0.9558   \n",
       "36  Group   mix_20%&s2_40%  44.867667          0.9816           0.9687   \n",
       "37  Group   mix_20%&s2_40%  44.795298          0.9853           0.9724   \n",
       "38  Group   mix_20%&s2_40%  40.871670          0.9742           0.9558   \n",
       "39  Group   mix_20%&s2_40%  42.479896          0.9834           0.9687   \n",
       "40  Group  mix_20%&s12_40%  51.959552          0.9834           0.9687   \n",
       "41  Group  mix_20%&s12_40%  52.339809          0.9705           0.9669   \n",
       "42  Group  mix_20%&s12_40%  53.653035          0.9724           0.9705   \n",
       "43  Group  mix_20%&s12_40%  49.510542          0.9705           0.9669   \n",
       "44  Group  mix_20%&s12_40%  49.548754          0.9834           0.9669   \n",
       "45  Group  mix_20%&s12_40%  53.723940          0.9761           0.9669   \n",
       "46  Group  mix_20%&s12_40%  50.595989          0.9761           0.9595   \n",
       "47  Group  mix_20%&s12_40%  48.617480          0.9797           0.9632   \n",
       "48  Group  mix_20%&s12_40%  47.476377          0.9834           0.9705   \n",
       "49  Group  mix_20%&s12_40%  48.240296          0.9797           0.9687   \n",
       "50  Group   mix_20%&s2_60%  50.357350          0.9926           0.9705   \n",
       "51  Group   mix_20%&s2_60%  52.448013          0.9871           0.9669   \n",
       "52  Group   mix_20%&s2_60%  46.477153          0.9705           0.9650   \n",
       "53  Group   mix_20%&s2_60%  50.288148          0.9871           0.9503   \n",
       "54  Group   mix_20%&s2_60%  51.380808          0.9890           0.9595   \n",
       "55  Group   mix_20%&s2_60%  51.368167          0.9908           0.9595   \n",
       "56  Group   mix_20%&s2_60%  49.387344          0.9816           0.9595   \n",
       "57  Group   mix_20%&s2_60%  43.176742          0.9816           0.9669   \n",
       "58  Group   mix_20%&s2_60%  48.327896          0.9853           0.9558   \n",
       "59  Group   mix_20%&s2_60%  47.509030          0.9816           0.9669   \n",
       "\n",
       "    Partcp_Acc_p1  Command_Acc_p1  Partcp_Acc_p2  Command_Acc_p2  \\\n",
       "0           0.991          0.9550         0.9259          0.8796   \n",
       "1           1.000          0.9369         0.9352          0.8796   \n",
       "2           0.991          0.9369         0.9074          0.8611   \n",
       "3           1.000          0.9459         0.9074          0.8704   \n",
       "4           0.991          0.9550         0.9259          0.8796   \n",
       "5           1.000          0.9550         0.9074          0.8796   \n",
       "6           0.991          0.9369         0.9259          0.8981   \n",
       "7           1.000          0.9550         0.9074          0.8889   \n",
       "8           0.991          0.9459         0.9167          0.8796   \n",
       "9           0.991          0.9459         0.9167          0.8704   \n",
       "10          0.991          0.9640         0.9907          0.9352   \n",
       "11          0.982          0.9730         0.9815          0.9259   \n",
       "12          0.991          0.9730         0.9907          0.9444   \n",
       "13          0.991          0.9730         0.9907          0.9352   \n",
       "14          0.982          0.9730         0.9815          0.9352   \n",
       "15          0.982          0.9730         0.9815          0.9352   \n",
       "16          0.991          0.9730         0.9815          0.9444   \n",
       "17          0.991          0.9640         0.9815          0.9444   \n",
       "18          0.991          0.9730         0.9815          0.9352   \n",
       "19          1.000          0.9730         0.9907          0.9259   \n",
       "20          0.991          0.9820         0.9815          0.9722   \n",
       "21          0.982          0.9820         1.0000          0.9537   \n",
       "22          0.982          0.9820         1.0000          0.9444   \n",
       "23          0.973          0.9910         0.9815          0.9630   \n",
       "24          0.982          0.9820         1.0000          0.9537   \n",
       "25          0.982          0.9820         1.0000          0.9537   \n",
       "26          0.982          0.9910         0.9907          0.9537   \n",
       "27          0.991          0.9820         0.9907          0.9722   \n",
       "28          0.982          0.9910         1.0000          0.9722   \n",
       "29          0.982          0.9910         1.0000          0.9444   \n",
       "30          0.991          0.9459         0.9815          0.9352   \n",
       "31          0.991          0.9369         1.0000          0.9259   \n",
       "32          0.991          0.9550         0.9815          0.9259   \n",
       "33          0.991          0.9550         1.0000          0.9259   \n",
       "34          0.982          0.9369         0.9907          0.9444   \n",
       "35          0.991          0.9279         0.9907          0.9352   \n",
       "36          0.991          0.9550         1.0000          0.9537   \n",
       "37          1.000          0.9550         1.0000          0.9630   \n",
       "38          1.000          0.9459         0.9815          0.9167   \n",
       "39          0.982          0.9550         1.0000          0.9352   \n",
       "40          1.000          0.9730         0.9907          0.9444   \n",
       "41          1.000          0.9730         0.9907          0.9444   \n",
       "42          1.000          0.9910         0.9907          0.9259   \n",
       "43          0.991          0.9640         0.9907          0.9444   \n",
       "44          1.000          0.9550         0.9907          0.9444   \n",
       "45          0.991          0.9820         0.9907          0.9444   \n",
       "46          1.000          0.9550         0.9815          0.9352   \n",
       "47          0.991          0.9730         0.9907          0.9352   \n",
       "48          0.991          0.9910         0.9815          0.9259   \n",
       "49          1.000          0.9730         0.9907          0.9444   \n",
       "50          0.991          0.9369         1.0000          0.9722   \n",
       "51          0.991          0.9459         1.0000          0.9630   \n",
       "52          0.991          0.9459         1.0000          0.9537   \n",
       "53          1.000          0.9099         1.0000          0.9537   \n",
       "54          1.000          0.9189         1.0000          0.9537   \n",
       "55          0.991          0.9099         1.0000          0.9537   \n",
       "56          0.991          0.9369         1.0000          0.9630   \n",
       "57          1.000          0.9459         1.0000          0.9537   \n",
       "58          0.991          0.9279         1.0000          0.9537   \n",
       "59          0.991          0.9459         1.0000          0.9630   \n",
       "\n",
       "    Partcp_Acc_p3  Command_Acc_p3  Partcp_Acc_p4  Command_Acc_p4  \\\n",
       "0          0.9652          0.9565         0.9817          0.9633   \n",
       "1          0.9739          0.9652         0.9908          0.9908   \n",
       "2          0.9826          0.9652         0.9358          0.9725   \n",
       "3          0.9826          0.9652         0.9358          0.9908   \n",
       "4          0.9739          0.9652         0.9541          0.9541   \n",
       "5          0.9826          0.9739         0.9633          0.9633   \n",
       "6          0.9565          0.9652         0.9541          0.9817   \n",
       "7          0.9913          0.9739         0.9633          0.9908   \n",
       "8          0.9913          0.9652         0.9633          0.9725   \n",
       "9          0.9739          0.9652         0.9541          0.9908   \n",
       "10         1.0000          0.9913         0.9908          0.9908   \n",
       "11         0.9913          0.9913         0.9908          0.9908   \n",
       "12         0.9913          0.9913         0.9908          0.9908   \n",
       "13         0.9913          0.9913         0.9908          0.9908   \n",
       "14         0.9913          0.9826         0.9908          0.9908   \n",
       "15         0.9913          0.9913         0.9817          0.9908   \n",
       "16         0.9913          0.9826         0.9908          0.9908   \n",
       "17         0.9913          0.9826         0.9908          0.9908   \n",
       "18         0.9913          0.9913         0.9908          0.9908   \n",
       "19         0.9913          0.9913         0.9908          0.9817   \n",
       "20         1.0000          0.9913         0.9908          0.9908   \n",
       "21         0.9913          0.9826         0.9908          0.9817   \n",
       "22         1.0000          0.9913         0.9908          0.9908   \n",
       "23         1.0000          0.9913         0.9908          0.9908   \n",
       "24         0.9913          0.9826         0.9908          0.9817   \n",
       "25         1.0000          0.9913         0.9908          0.9908   \n",
       "26         0.9913          0.9913         0.9908          0.9908   \n",
       "27         1.0000          0.9913         0.9908          0.9908   \n",
       "28         1.0000          0.9913         0.9908          0.9908   \n",
       "29         1.0000          0.9913         0.9908          0.9908   \n",
       "30         0.9739          0.9826         0.9725          0.9817   \n",
       "31         0.9739          0.9652         0.9450          0.9817   \n",
       "32         0.9652          0.9478         0.9908          0.9725   \n",
       "33         0.9913          0.9652         0.9908          0.9908   \n",
       "34         0.9739          0.9652         0.9541          0.9817   \n",
       "35         0.9565          0.9565         0.9633          0.9817   \n",
       "36         0.9652          0.9652         0.9541          0.9817   \n",
       "37         0.9652          0.9739         0.9633          0.9817   \n",
       "38         0.9391          0.9565         0.9541          0.9725   \n",
       "39         0.9739          0.9826         0.9633          0.9817   \n",
       "40         0.9826          0.9565         0.9541          0.9817   \n",
       "41         0.9478          0.9652         0.9358          0.9725   \n",
       "42         0.9826          0.9652         0.8899          0.9817   \n",
       "43         0.9304          0.9565         0.9541          0.9725   \n",
       "44         0.9826          0.9652         0.9450          0.9817   \n",
       "45         0.9739          0.9391         0.9450          0.9817   \n",
       "46         0.9826          0.9565         0.9174          0.9633   \n",
       "47         0.9652          0.9565         0.9541          0.9725   \n",
       "48         0.9739          0.9739         0.9725          0.9817   \n",
       "49         0.9652          0.9565         0.9450          0.9817   \n",
       "50         1.0000          0.9652         0.9725          0.9908   \n",
       "51         0.9913          0.9652         0.9633          0.9817   \n",
       "52         0.9652          0.9652         0.9358          0.9725   \n",
       "53         0.9826          0.9391         0.9633          0.9725   \n",
       "54         0.9739          0.9652         0.9817          0.9817   \n",
       "55         0.9913          0.9652         0.9817          0.9817   \n",
       "56         0.9652          0.9478         0.9633          0.9725   \n",
       "57         0.9739          0.9652         0.9358          0.9817   \n",
       "58         0.9826          0.9391         0.9633          0.9817   \n",
       "59         0.9739          0.9652         0.9450          0.9817   \n",
       "\n",
       "    Partcp_Acc_p5  Command_Acc_p5  Acc_p6  Acc_p7  Acc_p8  \n",
       "0            1.00            0.99    0.67   0.528  0.3366  \n",
       "1            0.99            0.99    0.59   0.528  0.2970  \n",
       "2            0.99            0.99    0.67   0.432  0.2673  \n",
       "3            1.00            0.99    0.62   0.504  0.2673  \n",
       "4            1.00            0.99    0.59   0.472  0.3267  \n",
       "5            1.00            0.99    0.62   0.456  0.3069  \n",
       "6            0.99            0.99    0.67   0.496  0.3267  \n",
       "7            1.00            0.99    0.67   0.496  0.2574  \n",
       "8            1.00            0.99    0.60   0.552  0.2673  \n",
       "9            1.00            1.00    0.66   0.480  0.4059  \n",
       "10           1.00            1.00    0.65   0.472  0.2772  \n",
       "11           1.00            1.00    0.63   0.480  0.2871  \n",
       "12           1.00            1.00    0.69   0.400  0.3168  \n",
       "13           1.00            1.00    0.70   0.456  0.3267  \n",
       "14           1.00            1.00    0.70   0.448  0.2871  \n",
       "15           1.00            0.99    0.70   0.472  0.2772  \n",
       "16           1.00            1.00    0.70   0.440  0.3366  \n",
       "17           1.00            1.00    0.67   0.440  0.3168  \n",
       "18           1.00            0.99    0.63   0.456  0.2772  \n",
       "19           1.00            1.00    0.65   0.424  0.2673  \n",
       "20           1.00            1.00    0.69   0.440  0.2772  \n",
       "21           1.00            1.00    0.72   0.456  0.2178  \n",
       "22           1.00            1.00    0.68   0.440  0.2970  \n",
       "23           1.00            1.00    0.68   0.424  0.3069  \n",
       "24           1.00            1.00    0.68   0.424  0.2376  \n",
       "25           1.00            1.00    0.66   0.408  0.2475  \n",
       "26           1.00            1.00    0.73   0.416  0.2673  \n",
       "27           1.00            1.00    0.70   0.440  0.2673  \n",
       "28           1.00            1.00    0.70   0.424  0.2277  \n",
       "29           1.00            1.00    0.70   0.416  0.2772  \n",
       "30           1.00            0.99    0.69   0.552  0.3267  \n",
       "31           1.00            0.98    0.69   0.512  0.3168  \n",
       "32           0.97            0.99    0.72   0.536  0.2376  \n",
       "33           1.00            0.99    0.70   0.480  0.2673  \n",
       "34           1.00            0.99    0.69   0.504  0.2871  \n",
       "35           0.98            0.98    0.72   0.472  0.2871  \n",
       "36           1.00            0.99    0.66   0.496  0.2673  \n",
       "37           1.00            0.99    0.68   0.544  0.3069  \n",
       "38           1.00            0.99    0.71   0.480  0.2970  \n",
       "39           1.00            0.99    0.73   0.536  0.2673  \n",
       "40           0.99            0.99    0.66   0.504  0.3168  \n",
       "41           0.98            0.98    0.67   0.424  0.2673  \n",
       "42           1.00            0.99    0.67   0.544  0.3168  \n",
       "43           0.99            1.00    0.67   0.464  0.3168  \n",
       "44           1.00            0.99    0.65   0.488  0.2970  \n",
       "45           0.98            0.99    0.66   0.488  0.3069  \n",
       "46           1.00            0.99    0.64   0.456  0.3069  \n",
       "47           1.00            0.98    0.65   0.480  0.2475  \n",
       "48           1.00            0.98    0.59   0.472  0.3168  \n",
       "49           1.00            0.99    0.69   0.496  0.3069  \n",
       "50           1.00            0.99    0.65   0.512  0.3069  \n",
       "51           0.99            0.98    0.68   0.496  0.3465  \n",
       "52           0.96            0.99    0.63   0.496  0.3663  \n",
       "53           0.99            0.98    0.66   0.560  0.3168  \n",
       "54           0.99            0.98    0.74   0.520  0.2772  \n",
       "55           0.99            0.99    0.68   0.504  0.2871  \n",
       "56           0.99            0.98    0.70   0.536  0.2970  \n",
       "57           1.00            0.99    0.67   0.480  0.2871  \n",
       "58           0.99            0.98    0.65   0.512  0.2970  \n",
       "59           1.00            0.98    0.70   0.512  0.2772  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pd file store performance\n",
    "# Perfomance = pd.DataFrame(columns = ['Model','Time','Partcp_Acc_p15','Command_Acc_p15','Partcp_Acc_p1','Command_Acc_p1',\n",
    "#                                       'Partcp_Acc_p2','Command_Acc_p2','Partcp_Acc_p3','Command_Acc_p3',\n",
    "#                                       'Partcp_Acc_p4','Command_Acc_p4','Partcp_Acc_p5','Command_Acc_p5','Acc_p6','Acc_p7','Acc_p8'])\n",
    "\n",
    "Perfomance = pd.read_csv('Performance_0608_training_Data_Size.csv')\n",
    "# Perfomance\n",
    "Perfomance                                                        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "actv_fun_1_1 = \"relu\" \n",
    "actv_fun_1_2 = \"sigmoid\"\n",
    "shape_1_1 = 128\n",
    "shape_1_2 = 256\n",
    "actv_fun_2_1 = \"sigmoid\" \n",
    "actv_fun_2_2 = \"sigmoid\"\n",
    "shape_2_1 = 512\n",
    "shape_2_2 = 512\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "13/13 [==============================] - 4s 320ms/step - loss: 3.6081 - participant_output_loss: 1.3137 - command_output_loss: 2.2896 - command_output_1_loss: 4.1801e-04 - participant_output_1_loss: 0.0043 - participant_output_accuracy: 0.4812 - command_output_accuracy: 0.2400 - command_output_1_accuracy: 0.0463 - participant_output_1_accuracy: 0.2713 - val_loss: 3.2813 - val_participant_output_loss: 1.2508 - val_command_output_loss: 2.0303 - val_command_output_1_loss: 1.5159e-04 - val_participant_output_1_loss: 1.3046e-04 - val_participant_output_accuracy: 0.5856 - val_command_output_accuracy: 0.5046 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.4788\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - 2s 169ms/step - loss: 2.8636 - participant_output_loss: 0.9232 - command_output_loss: 1.9401 - command_output_1_loss: 9.5907e-05 - participant_output_1_loss: 1.8242e-04 - participant_output_accuracy: 0.6950 - command_output_accuracy: 0.6650 - command_output_1_accuracy: 0.0063 - participant_output_1_accuracy: 0.0938 - val_loss: 2.8925 - val_participant_output_loss: 1.0054 - val_command_output_loss: 1.8869 - val_command_output_1_loss: 6.2624e-05 - val_participant_output_1_loss: 1.2289e-04 - val_participant_output_accuracy: 0.6096 - val_command_output_accuracy: 0.7293 - val_command_output_1_accuracy: 0.1308 - val_participant_output_1_accuracy: 0.5893\n",
      "Epoch 3/10\n",
      "13/13 [==============================] - 2s 173ms/step - loss: 2.4964 - participant_output_loss: 0.6871 - command_output_loss: 1.8092 - command_output_1_loss: 5.1953e-05 - participant_output_1_loss: 8.6913e-05 - participant_output_accuracy: 0.8275 - command_output_accuracy: 0.7925 - command_output_1_accuracy: 0.3400 - participant_output_1_accuracy: 0.3400 - val_loss: 2.5581 - val_participant_output_loss: 0.7995 - val_command_output_loss: 1.7585 - val_command_output_1_loss: 8.2398e-05 - val_participant_output_1_loss: 6.4165e-05 - val_participant_output_accuracy: 0.7219 - val_command_output_accuracy: 0.8471 - val_command_output_1_accuracy: 0.3333 - val_participant_output_1_accuracy: 0.0755\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - 2s 162ms/step - loss: 2.2197 - participant_output_loss: 0.5381 - command_output_loss: 1.6814 - command_output_1_loss: 1.1914e-04 - participant_output_1_loss: 5.6857e-05 - participant_output_accuracy: 0.8950 - command_output_accuracy: 0.8725 - command_output_1_accuracy: 0.1637 - participant_output_1_accuracy: 0.1388 - val_loss: 2.2932 - val_participant_output_loss: 0.6542 - val_command_output_loss: 1.6389 - val_command_output_1_loss: 8.5751e-05 - val_participant_output_1_loss: 5.3647e-05 - val_participant_output_accuracy: 0.8619 - val_command_output_accuracy: 0.8398 - val_command_output_1_accuracy: 0.3462 - val_participant_output_1_accuracy: 0.2155\n",
      "Epoch 5/10\n",
      "13/13 [==============================] - 2s 176ms/step - loss: 1.9800 - participant_output_loss: 0.4193 - command_output_loss: 1.5606 - command_output_1_loss: 5.0194e-05 - participant_output_1_loss: 5.3232e-05 - participant_output_accuracy: 0.9438 - command_output_accuracy: 0.9200 - command_output_1_accuracy: 0.3988 - participant_output_1_accuracy: 0.1650 - val_loss: 2.1180 - val_participant_output_loss: 0.5929 - val_command_output_loss: 1.5249 - val_command_output_1_loss: 3.6789e-05 - val_participant_output_1_loss: 5.5758e-05 - val_participant_output_accuracy: 0.8600 - val_command_output_accuracy: 0.8987 - val_command_output_1_accuracy: 0.0552 - val_participant_output_1_accuracy: 0.0976\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - 2s 169ms/step - loss: 1.7733 - participant_output_loss: 0.3383 - command_output_loss: 1.4349 - command_output_1_loss: 5.0068e-05 - participant_output_1_loss: 4.7809e-05 - participant_output_accuracy: 0.9650 - command_output_accuracy: 0.9588 - command_output_1_accuracy: 0.0113 - participant_output_1_accuracy: 0.1363 - val_loss: 1.8536 - val_participant_output_loss: 0.4459 - val_command_output_loss: 1.4076 - val_command_output_1_loss: 5.3314e-05 - val_participant_output_1_loss: 5.3284e-05 - val_participant_output_accuracy: 0.9448 - val_command_output_accuracy: 0.9282 - val_command_output_1_accuracy: 0.0018 - val_participant_output_1_accuracy: 0.1308\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - 2s 168ms/step - loss: 1.5825 - participant_output_loss: 0.2651 - command_output_loss: 1.3173 - command_output_1_loss: 5.5312e-05 - participant_output_1_loss: 4.5681e-05 - participant_output_accuracy: 0.9862 - command_output_accuracy: 0.9588 - command_output_1_accuracy: 0.3537 - participant_output_1_accuracy: 0.1713 - val_loss: 1.7044 - val_participant_output_loss: 0.4077 - val_command_output_loss: 1.2966 - val_command_output_1_loss: 4.3516e-05 - val_participant_output_1_loss: 5.1919e-05 - val_participant_output_accuracy: 0.9392 - val_command_output_accuracy: 0.9374 - val_command_output_1_accuracy: 0.3849 - val_participant_output_1_accuracy: 0.0902\n",
      "Epoch 8/10\n",
      "13/13 [==============================] - 2s 169ms/step - loss: 1.4157 - participant_output_loss: 0.2209 - command_output_loss: 1.1948 - command_output_1_loss: 5.7718e-05 - participant_output_1_loss: 4.3772e-05 - participant_output_accuracy: 0.9887 - command_output_accuracy: 0.9825 - command_output_1_accuracy: 0.0425 - participant_output_1_accuracy: 0.1525 - val_loss: 1.5294 - val_participant_output_loss: 0.3443 - val_command_output_loss: 1.1850 - val_command_output_1_loss: 5.8788e-05 - val_participant_output_1_loss: 5.1717e-05 - val_participant_output_accuracy: 0.9669 - val_command_output_accuracy: 0.9466 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.1565\n",
      "Epoch 9/10\n",
      "13/13 [==============================] - 2s 165ms/step - loss: 1.2689 - participant_output_loss: 0.1871 - command_output_loss: 1.0817 - command_output_1_loss: 4.7795e-05 - participant_output_1_loss: 4.3220e-05 - participant_output_accuracy: 0.9962 - command_output_accuracy: 0.9937 - command_output_1_accuracy: 0.0237 - participant_output_1_accuracy: 0.1375 - val_loss: 1.3851 - val_participant_output_loss: 0.3072 - val_command_output_loss: 1.0778 - val_command_output_1_loss: 5.4413e-05 - val_participant_output_1_loss: 5.2871e-05 - val_participant_output_accuracy: 0.9687 - val_command_output_accuracy: 0.9595 - val_command_output_1_accuracy: 0.0479 - val_participant_output_1_accuracy: 0.1915\n",
      "Epoch 10/10\n",
      "13/13 [==============================] - 2s 129ms/step - loss: 1.1329 - participant_output_loss: 0.1587 - command_output_loss: 0.9741 - command_output_1_loss: 4.7943e-05 - participant_output_1_loss: 4.1709e-05 - participant_output_accuracy: 0.9987 - command_output_accuracy: 0.9950 - command_output_1_accuracy: 0.0250 - participant_output_1_accuracy: 0.1363 - val_loss: 1.2678 - val_participant_output_loss: 0.2861 - val_command_output_loss: 0.9816 - val_command_output_1_loss: 3.1973e-05 - val_participant_output_1_loss: 5.2751e-05 - val_participant_output_accuracy: 0.9669 - val_command_output_accuracy: 0.9540 - val_command_output_1_accuracy: 0.1639 - val_participant_output_1_accuracy: 0.1547\n",
      "Epoch 1/10\n",
      "13/13 [==============================] - 3s 241ms/step - loss: 1.0073 - participant_output_loss: 0.1392 - command_output_loss: 0.8680 - command_output_1_loss: 4.3414e-05 - participant_output_1_loss: 4.2302e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9962 - command_output_1_accuracy: 0.2037 - participant_output_1_accuracy: 0.1462 - val_loss: 1.1802 - val_participant_output_loss: 0.2893 - val_command_output_loss: 0.8908 - val_command_output_1_loss: 4.0074e-05 - val_participant_output_1_loss: 5.3879e-05 - val_participant_output_accuracy: 0.9540 - val_command_output_accuracy: 0.9576 - val_command_output_1_accuracy: 0.3407 - val_participant_output_1_accuracy: 0.1842\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - 3s 194ms/step - loss: 0.8912 - participant_output_loss: 0.1248 - command_output_loss: 0.7663 - command_output_1_loss: 3.6925e-05 - participant_output_1_loss: 4.1193e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9987 - command_output_1_accuracy: 0.1050 - participant_output_1_accuracy: 0.1325 - val_loss: 1.0587 - val_participant_output_loss: 0.2650 - val_command_output_loss: 0.7936 - val_command_output_1_loss: 3.1055e-05 - val_participant_output_1_loss: 5.3312e-05 - val_participant_output_accuracy: 0.9613 - val_command_output_accuracy: 0.9650 - val_command_output_1_accuracy: 0.0166 - val_participant_output_1_accuracy: 0.1713\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10\n",
      "13/13 [==============================] - 2s 176ms/step - loss: 0.7911 - participant_output_loss: 0.1119 - command_output_loss: 0.6790 - command_output_1_loss: 3.7188e-05 - participant_output_1_loss: 4.0124e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9987 - command_output_1_accuracy: 0.0125 - participant_output_1_accuracy: 0.1325 - val_loss: 0.9656 - val_participant_output_loss: 0.2473 - val_command_output_loss: 0.7182 - val_command_output_1_loss: 3.1775e-05 - val_participant_output_1_loss: 5.2002e-05 - val_participant_output_accuracy: 0.9669 - val_command_output_accuracy: 0.9650 - val_command_output_1_accuracy: 0.0092 - val_participant_output_1_accuracy: 0.1492\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - 2s 131ms/step - loss: 0.7010 - participant_output_loss: 0.0981 - command_output_loss: 0.6028 - command_output_1_loss: 3.4966e-05 - participant_output_1_loss: 3.7791e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9987 - command_output_1_accuracy: 0.0075 - participant_output_1_accuracy: 0.1325 - val_loss: 0.8744 - val_participant_output_loss: 0.2242 - val_command_output_loss: 0.6500 - val_command_output_1_loss: 2.4003e-05 - val_participant_output_1_loss: 5.2738e-05 - val_participant_output_accuracy: 0.9687 - val_command_output_accuracy: 0.9632 - val_command_output_1_accuracy: 0.0552 - val_participant_output_1_accuracy: 0.1731\n",
      "Epoch 5/10\n",
      "13/13 [==============================] - 2s 173ms/step - loss: 0.6163 - participant_output_loss: 0.0878 - command_output_loss: 0.5284 - command_output_1_loss: 5.4456e-05 - participant_output_1_loss: 3.6703e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9987 - command_output_1_accuracy: 0.0338 - participant_output_1_accuracy: 0.1388 - val_loss: 0.7802 - val_participant_output_loss: 0.1969 - val_command_output_loss: 0.5832 - val_command_output_1_loss: 3.4574e-05 - val_participant_output_1_loss: 5.1767e-05 - val_participant_output_accuracy: 0.9742 - val_command_output_accuracy: 0.9650 - val_command_output_1_accuracy: 0.1786 - val_participant_output_1_accuracy: 0.1492\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - 2s 177ms/step - loss: 0.5402 - participant_output_loss: 0.0804 - command_output_loss: 0.4598 - command_output_1_loss: 3.9248e-05 - participant_output_1_loss: 3.5854e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9987 - command_output_1_accuracy: 0.0675 - participant_output_1_accuracy: 0.1425 - val_loss: 0.7081 - val_participant_output_loss: 0.1923 - val_command_output_loss: 0.5157 - val_command_output_1_loss: 3.4697e-05 - val_participant_output_1_loss: 5.0281e-05 - val_participant_output_accuracy: 0.9742 - val_command_output_accuracy: 0.9724 - val_command_output_1_accuracy: 0.0147 - val_participant_output_1_accuracy: 0.1252\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - 2s 192ms/step - loss: 0.4746 - participant_output_loss: 0.0742 - command_output_loss: 0.4004 - command_output_1_loss: 2.2515e-05 - participant_output_1_loss: 3.3317e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9987 - command_output_1_accuracy: 0.0050 - participant_output_1_accuracy: 0.1350 - val_loss: 0.6427 - val_participant_output_loss: 0.1815 - val_command_output_loss: 0.4612 - val_command_output_1_loss: 2.5580e-05 - val_participant_output_1_loss: 4.7880e-05 - val_participant_output_accuracy: 0.9761 - val_command_output_accuracy: 0.9705 - val_command_output_1_accuracy: 0.0203 - val_participant_output_1_accuracy: 0.1381\n",
      "Epoch 8/10\n",
      "13/13 [==============================] - 2s 151ms/step - loss: 0.4169 - participant_output_loss: 0.0693 - command_output_loss: 0.3476 - command_output_1_loss: 2.2206e-05 - participant_output_1_loss: 3.1881e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0725 - participant_output_1_accuracy: 0.1600 - val_loss: 0.5978 - val_participant_output_loss: 0.1794 - val_command_output_loss: 0.4182 - val_command_output_1_loss: 2.4169e-05 - val_participant_output_1_loss: 4.8811e-05 - val_participant_output_accuracy: 0.9742 - val_command_output_accuracy: 0.9705 - val_command_output_1_accuracy: 0.2910 - val_participant_output_1_accuracy: 0.1713\n",
      "Epoch 9/10\n",
      "13/13 [==============================] - 2s 159ms/step - loss: 0.3688 - participant_output_loss: 0.0644 - command_output_loss: 0.3044 - command_output_1_loss: 1.9862e-05 - participant_output_1_loss: 3.0377e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.2937 - participant_output_1_accuracy: 0.1400 - val_loss: 0.5486 - val_participant_output_loss: 0.1726 - val_command_output_loss: 0.3760 - val_command_output_1_loss: 1.4466e-05 - val_participant_output_1_loss: 4.6472e-05 - val_participant_output_accuracy: 0.9724 - val_command_output_accuracy: 0.9705 - val_command_output_1_accuracy: 0.1565 - val_participant_output_1_accuracy: 0.1529\n",
      "Epoch 10/10\n",
      "13/13 [==============================] - 3s 194ms/step - loss: 0.3254 - participant_output_loss: 0.0596 - command_output_loss: 0.2658 - command_output_1_loss: 1.3698e-05 - participant_output_1_loss: 2.8143e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.2125 - participant_output_1_accuracy: 0.1550 - val_loss: 0.5104 - val_participant_output_loss: 0.1706 - val_command_output_loss: 0.3398 - val_command_output_1_loss: 1.4986e-05 - val_participant_output_1_loss: 4.4411e-05 - val_participant_output_accuracy: 0.9742 - val_command_output_accuracy: 0.9742 - val_command_output_1_accuracy: 0.0442 - val_participant_output_1_accuracy: 0.1289\n",
      "Epoch 1/10\n",
      "13/13 [==============================] - 4s 282ms/step - loss: 3.5590 - participant_output_loss: 1.3746 - command_output_loss: 2.1820 - command_output_1_loss: 8.7092e-04 - participant_output_1_loss: 0.0015 - participant_output_accuracy: 0.4712 - command_output_accuracy: 0.3250 - command_output_1_accuracy: 0.0613 - participant_output_1_accuracy: 0.2150 - val_loss: 3.3018 - val_participant_output_loss: 1.3202 - val_command_output_loss: 1.9811 - val_command_output_1_loss: 1.0428e-04 - val_participant_output_1_loss: 3.7635e-04 - val_participant_output_accuracy: 0.3794 - val_command_output_accuracy: 0.6206 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.0074\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - 2s 178ms/step - loss: 2.8436 - participant_output_loss: 0.9611 - command_output_loss: 1.8822 - command_output_1_loss: 9.8967e-05 - participant_output_1_loss: 2.5466e-04 - participant_output_accuracy: 0.6513 - command_output_accuracy: 0.7412 - command_output_1_accuracy: 0.0012 - participant_output_1_accuracy: 0.1412 - val_loss: 2.8502 - val_participant_output_loss: 1.0203 - val_command_output_loss: 1.8296 - val_command_output_1_loss: 1.1238e-04 - val_participant_output_1_loss: 1.3703e-04 - val_participant_output_accuracy: 0.6575 - val_command_output_accuracy: 0.7164 - val_command_output_1_accuracy: 0.0018 - val_participant_output_1_accuracy: 0.1952\n",
      "Epoch 3/10\n",
      "13/13 [==============================] - 3s 194ms/step - loss: 2.4709 - participant_output_loss: 0.7322 - command_output_loss: 1.7386 - command_output_1_loss: 7.5345e-05 - participant_output_1_loss: 1.3173e-04 - participant_output_accuracy: 0.8025 - command_output_accuracy: 0.8413 - command_output_1_accuracy: 0.2338 - participant_output_1_accuracy: 0.2900 - val_loss: 2.5251 - val_participant_output_loss: 0.8313 - val_command_output_loss: 1.6937 - val_command_output_1_loss: 3.6365e-05 - val_participant_output_1_loss: 8.8889e-05 - val_participant_output_accuracy: 0.8122 - val_command_output_accuracy: 0.8306 - val_command_output_1_accuracy: 0.4088 - val_participant_output_1_accuracy: 0.2762\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - 2s 183ms/step - loss: 2.1674 - participant_output_loss: 0.5607 - command_output_loss: 1.6066 - command_output_1_loss: 4.0269e-05 - participant_output_1_loss: 8.0051e-05 - participant_output_accuracy: 0.9075 - command_output_accuracy: 0.8913 - command_output_1_accuracy: 0.1975 - participant_output_1_accuracy: 0.2200 - val_loss: 2.2608 - val_participant_output_loss: 0.6864 - val_command_output_loss: 1.5742 - val_command_output_1_loss: 7.0193e-05 - val_participant_output_1_loss: 8.2697e-05 - val_participant_output_accuracy: 0.8379 - val_command_output_accuracy: 0.8785 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.4052\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10\n",
      "13/13 [==============================] - 3s 199ms/step - loss: 1.9291 - participant_output_loss: 0.4488 - command_output_loss: 1.4801 - command_output_1_loss: 8.6950e-05 - participant_output_1_loss: 6.5992e-05 - participant_output_accuracy: 0.9438 - command_output_accuracy: 0.9438 - command_output_1_accuracy: 0.0025 - participant_output_1_accuracy: 0.2775 - val_loss: 2.0399 - val_participant_output_loss: 0.5852 - val_command_output_loss: 1.4546 - val_command_output_1_loss: 4.1692e-05 - val_participant_output_1_loss: 7.2924e-05 - val_participant_output_accuracy: 0.9079 - val_command_output_accuracy: 0.9208 - val_command_output_1_accuracy: 0.0442 - val_participant_output_1_accuracy: 0.1952\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - 3s 195ms/step - loss: 1.7447 - participant_output_loss: 0.3879 - command_output_loss: 1.3567 - command_output_1_loss: 5.2286e-05 - participant_output_1_loss: 5.8115e-05 - participant_output_accuracy: 0.9613 - command_output_accuracy: 0.9588 - command_output_1_accuracy: 0.0525 - participant_output_1_accuracy: 0.2262 - val_loss: 1.8455 - val_participant_output_loss: 0.5106 - val_command_output_loss: 1.3347 - val_command_output_1_loss: 5.9875e-05 - val_participant_output_1_loss: 7.0276e-05 - val_participant_output_accuracy: 0.9337 - val_command_output_accuracy: 0.9374 - val_command_output_1_accuracy: 0.2155 - val_participant_output_1_accuracy: 0.2578\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - 2s 188ms/step - loss: 1.5598 - participant_output_loss: 0.3273 - command_output_loss: 1.2324 - command_output_1_loss: 7.2691e-05 - participant_output_1_loss: 5.5484e-05 - participant_output_accuracy: 0.9787 - command_output_accuracy: 0.9800 - command_output_1_accuracy: 0.3787 - participant_output_1_accuracy: 0.2262 - val_loss: 1.6925 - val_participant_output_loss: 0.4669 - val_command_output_loss: 1.2255 - val_command_output_1_loss: 6.6362e-05 - val_participant_output_1_loss: 7.5219e-05 - val_participant_output_accuracy: 0.9392 - val_command_output_accuracy: 0.9484 - val_command_output_1_accuracy: 0.0387 - val_participant_output_1_accuracy: 0.2431\n",
      "Epoch 8/10\n",
      "13/13 [==============================] - 3s 205ms/step - loss: 1.3982 - participant_output_loss: 0.2882 - command_output_loss: 1.1100 - command_output_1_loss: 5.7556e-05 - participant_output_1_loss: 5.2044e-05 - participant_output_accuracy: 0.9912 - command_output_accuracy: 0.9837 - command_output_1_accuracy: 0.0113 - participant_output_1_accuracy: 0.2338 - val_loss: 1.5451 - val_participant_output_loss: 0.4266 - val_command_output_loss: 1.1183 - val_command_output_1_loss: 6.8678e-05 - val_participant_output_1_loss: 6.8550e-05 - val_participant_output_accuracy: 0.9540 - val_command_output_accuracy: 0.9576 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.1842\n",
      "Epoch 9/10\n",
      "13/13 [==============================] - 2s 159ms/step - loss: 1.2595 - participant_output_loss: 0.2583 - command_output_loss: 1.0012 - command_output_1_loss: 5.6052e-05 - participant_output_1_loss: 4.8639e-05 - participant_output_accuracy: 0.9925 - command_output_accuracy: 0.9900 - command_output_1_accuracy: 0.1000 - participant_output_1_accuracy: 0.1975 - val_loss: 1.4369 - val_participant_output_loss: 0.4155 - val_command_output_loss: 1.0213 - val_command_output_1_loss: 4.0180e-05 - val_participant_output_1_loss: 6.5079e-05 - val_participant_output_accuracy: 0.9411 - val_command_output_accuracy: 0.9632 - val_command_output_1_accuracy: 0.3462 - val_participant_output_1_accuracy: 0.2247\n",
      "Epoch 10/10\n",
      "13/13 [==============================] - 3s 199ms/step - loss: 1.1355 - participant_output_loss: 0.2365 - command_output_loss: 0.8988 - command_output_1_loss: 4.9614e-05 - participant_output_1_loss: 4.5396e-05 - participant_output_accuracy: 0.9937 - command_output_accuracy: 0.9937 - command_output_1_accuracy: 0.1863 - participant_output_1_accuracy: 0.2400 - val_loss: 1.2990 - val_participant_output_loss: 0.3774 - val_command_output_loss: 0.9215 - val_command_output_1_loss: 5.0835e-05 - val_participant_output_1_loss: 6.4649e-05 - val_participant_output_accuracy: 0.9595 - val_command_output_accuracy: 0.9669 - val_command_output_1_accuracy: 0.1050 - val_participant_output_1_accuracy: 0.2726\n",
      "Epoch 1/10\n",
      "13/13 [==============================] - 3s 219ms/step - loss: 1.0148 - participant_output_loss: 0.2115 - command_output_loss: 0.8033 - command_output_1_loss: 5.4814e-05 - participant_output_1_loss: 4.2144e-05 - participant_output_accuracy: 0.9975 - command_output_accuracy: 0.9962 - command_output_1_accuracy: 0.0712 - participant_output_1_accuracy: 0.2163 - val_loss: 1.1736 - val_participant_output_loss: 0.3353 - val_command_output_loss: 0.8382 - val_command_output_1_loss: 5.2328e-05 - val_participant_output_1_loss: 6.2441e-05 - val_participant_output_accuracy: 0.9687 - val_command_output_accuracy: 0.9669 - val_command_output_1_accuracy: 0.0387 - val_participant_output_1_accuracy: 0.2413\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - 2s 169ms/step - loss: 0.8945 - participant_output_loss: 0.1776 - command_output_loss: 0.7168 - command_output_1_loss: 5.3162e-05 - participant_output_1_loss: 3.9435e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9987 - command_output_1_accuracy: 0.1075 - participant_output_1_accuracy: 0.1975 - val_loss: 1.0832 - val_participant_output_loss: 0.3167 - val_command_output_loss: 0.7664 - val_command_output_1_loss: 3.5948e-05 - val_participant_output_1_loss: 6.1096e-05 - val_participant_output_accuracy: 0.9650 - val_command_output_accuracy: 0.9724 - val_command_output_1_accuracy: 0.0589 - val_participant_output_1_accuracy: 0.2339\n",
      "Epoch 3/10\n",
      "13/13 [==============================] - 2s 163ms/step - loss: 0.7996 - participant_output_loss: 0.1574 - command_output_loss: 0.6421 - command_output_1_loss: 5.5470e-05 - participant_output_1_loss: 3.8564e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9987 - command_output_1_accuracy: 0.0175 - participant_output_1_accuracy: 0.2013 - val_loss: 0.9877 - val_participant_output_loss: 0.2939 - val_command_output_loss: 0.6936 - val_command_output_1_loss: 3.9276e-05 - val_participant_output_1_loss: 6.1773e-05 - val_participant_output_accuracy: 0.9650 - val_command_output_accuracy: 0.9650 - val_command_output_1_accuracy: 0.0534 - val_participant_output_1_accuracy: 0.2947\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - 2s 164ms/step - loss: 0.7122 - participant_output_loss: 0.1419 - command_output_loss: 0.5703 - command_output_1_loss: 4.8826e-05 - participant_output_1_loss: 3.6018e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9987 - command_output_1_accuracy: 0.0812 - participant_output_1_accuracy: 0.2113 - val_loss: 0.9042 - val_participant_output_loss: 0.2718 - val_command_output_loss: 0.6323 - val_command_output_1_loss: 5.7161e-05 - val_participant_output_1_loss: 5.6131e-05 - val_participant_output_accuracy: 0.9650 - val_command_output_accuracy: 0.9687 - val_command_output_1_accuracy: 0.0589 - val_participant_output_1_accuracy: 0.2339\n",
      "Epoch 5/10\n",
      "13/13 [==============================] - 2s 156ms/step - loss: 0.6388 - participant_output_loss: 0.1299 - command_output_loss: 0.5088 - command_output_1_loss: 4.2600e-05 - participant_output_1_loss: 3.3694e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9987 - command_output_1_accuracy: 0.0800 - participant_output_1_accuracy: 0.1988 - val_loss: 0.8346 - val_participant_output_loss: 0.2617 - val_command_output_loss: 0.5728 - val_command_output_1_loss: 2.4405e-05 - val_participant_output_1_loss: 5.4915e-05 - val_participant_output_accuracy: 0.9669 - val_command_output_accuracy: 0.9669 - val_command_output_1_accuracy: 0.1455 - val_participant_output_1_accuracy: 0.1915\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - 2s 160ms/step - loss: 0.5725 - participant_output_loss: 0.1182 - command_output_loss: 0.4543 - command_output_1_loss: 3.3596e-05 - participant_output_1_loss: 3.2428e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.1887 - participant_output_1_accuracy: 0.1887 - val_loss: 0.7683 - val_participant_output_loss: 0.2440 - val_command_output_loss: 0.5242 - val_command_output_1_loss: 2.3007e-05 - val_participant_output_1_loss: 5.5953e-05 - val_participant_output_accuracy: 0.9669 - val_command_output_accuracy: 0.9669 - val_command_output_1_accuracy: 0.1584 - val_participant_output_1_accuracy: 0.3241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10\n",
      "13/13 [==============================] - 3s 198ms/step - loss: 0.5146 - participant_output_loss: 0.1074 - command_output_loss: 0.4071 - command_output_1_loss: 2.9417e-05 - participant_output_1_loss: 3.0326e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0250 - participant_output_1_accuracy: 0.2250 - val_loss: 0.7174 - val_participant_output_loss: 0.2413 - val_command_output_loss: 0.4761 - val_command_output_1_loss: 2.0981e-05 - val_participant_output_1_loss: 5.3182e-05 - val_participant_output_accuracy: 0.9650 - val_command_output_accuracy: 0.9705 - val_command_output_1_accuracy: 0.0166 - val_participant_output_1_accuracy: 0.2560\n",
      "Epoch 1/10\n",
      "13/13 [==============================] - 4s 292ms/step - loss: 3.6000 - participant_output_loss: 1.2889 - command_output_loss: 2.3021 - command_output_1_loss: 0.0038 - participant_output_1_loss: 0.0051 - participant_output_accuracy: 0.4863 - command_output_accuracy: 0.2037 - command_output_1_accuracy: 0.1350 - participant_output_1_accuracy: 0.2288 - val_loss: 3.3504 - val_participant_output_loss: 1.2349 - val_command_output_loss: 2.1145 - val_command_output_1_loss: 2.2942e-04 - val_participant_output_1_loss: 7.6581e-04 - val_participant_output_accuracy: 0.4843 - val_command_output_accuracy: 0.5193 - val_command_output_1_accuracy: 0.1215 - val_participant_output_1_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - 3s 202ms/step - loss: 2.9078 - participant_output_loss: 0.8349 - command_output_loss: 2.0725 - command_output_1_loss: 1.4037e-04 - participant_output_1_loss: 2.8372e-04 - participant_output_accuracy: 0.7450 - command_output_accuracy: 0.5938 - command_output_1_accuracy: 0.0962 - participant_output_1_accuracy: 0.2425 - val_loss: 2.9417 - val_participant_output_loss: 0.8928 - val_command_output_loss: 2.0486 - val_command_output_1_loss: 1.1030e-04 - val_participant_output_1_loss: 1.6065e-04 - val_participant_output_accuracy: 0.7017 - val_command_output_accuracy: 0.6041 - val_command_output_1_accuracy: 0.1455 - val_participant_output_1_accuracy: 0.6759\n",
      "Epoch 3/10\n",
      "13/13 [==============================] - 3s 212ms/step - loss: 2.5955 - participant_output_loss: 0.5980 - command_output_loss: 1.9973 - command_output_1_loss: 7.1864e-05 - participant_output_1_loss: 8.4226e-05 - participant_output_accuracy: 0.8650 - command_output_accuracy: 0.7625 - command_output_1_accuracy: 0.4400 - participant_output_1_accuracy: 0.2600 - val_loss: 2.6837 - val_participant_output_loss: 0.7142 - val_command_output_loss: 1.9694 - val_command_output_1_loss: 5.8075e-05 - val_participant_output_1_loss: 6.2737e-05 - val_participant_output_accuracy: 0.8048 - val_command_output_accuracy: 0.8435 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.0018\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - 3s 201ms/step - loss: 2.3929 - participant_output_loss: 0.4683 - command_output_loss: 1.9244 - command_output_1_loss: 8.5820e-05 - participant_output_1_loss: 4.2722e-05 - participant_output_accuracy: 0.9175 - command_output_accuracy: 0.8537 - command_output_1_accuracy: 0.0000e+00 - participant_output_1_accuracy: 0.0812 - val_loss: 2.5395 - val_participant_output_loss: 0.6381 - val_command_output_loss: 1.9014 - val_command_output_1_loss: 4.2602e-05 - val_participant_output_1_loss: 3.3123e-05 - val_participant_output_accuracy: 0.8343 - val_command_output_accuracy: 0.8564 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.1492\n",
      "Epoch 5/10\n",
      "13/13 [==============================] - 3s 196ms/step - loss: 2.2173 - participant_output_loss: 0.3661 - command_output_loss: 1.8511 - command_output_1_loss: 6.2963e-05 - participant_output_1_loss: 2.6153e-05 - participant_output_accuracy: 0.9538 - command_output_accuracy: 0.9325 - command_output_1_accuracy: 0.0000e+00 - participant_output_1_accuracy: 0.1863 - val_loss: 2.3564 - val_participant_output_loss: 0.5188 - val_command_output_loss: 1.8376 - val_command_output_1_loss: 3.7605e-05 - val_participant_output_1_loss: 2.8041e-05 - val_participant_output_accuracy: 0.8932 - val_command_output_accuracy: 0.9098 - val_command_output_1_accuracy: 0.0018 - val_participant_output_1_accuracy: 0.0810\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - 2s 163ms/step - loss: 2.0785 - participant_output_loss: 0.2960 - command_output_loss: 1.7824 - command_output_1_loss: 4.9389e-05 - participant_output_1_loss: 2.1911e-05 - participant_output_accuracy: 0.9737 - command_output_accuracy: 0.9125 - command_output_1_accuracy: 0.0000e+00 - participant_output_1_accuracy: 0.0938 - val_loss: 2.1863 - val_participant_output_loss: 0.4192 - val_command_output_loss: 1.7671 - val_command_output_1_loss: 4.1164e-05 - val_participant_output_1_loss: 2.3322e-05 - val_participant_output_accuracy: 0.9171 - val_command_output_accuracy: 0.8803 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.1160\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - 3s 206ms/step - loss: 1.9365 - participant_output_loss: 0.2366 - command_output_loss: 1.6999 - command_output_1_loss: 3.8826e-05 - participant_output_1_loss: 1.9789e-05 - participant_output_accuracy: 0.9825 - command_output_accuracy: 0.9488 - command_output_1_accuracy: 0.0325 - participant_output_1_accuracy: 0.1388 - val_loss: 2.0786 - val_participant_output_loss: 0.3842 - val_command_output_loss: 1.6943 - val_command_output_1_loss: 6.0614e-05 - val_participant_output_1_loss: 2.2690e-05 - val_participant_output_accuracy: 0.9319 - val_command_output_accuracy: 0.9116 - val_command_output_1_accuracy: 0.1179 - val_participant_output_1_accuracy: 0.1363\n",
      "Epoch 8/10\n",
      "13/13 [==============================] - 3s 197ms/step - loss: 1.8256 - participant_output_loss: 0.1981 - command_output_loss: 1.6274 - command_output_1_loss: 7.6757e-05 - participant_output_1_loss: 1.9426e-05 - participant_output_accuracy: 0.9925 - command_output_accuracy: 0.9800 - command_output_1_accuracy: 0.2587 - participant_output_1_accuracy: 0.1262 - val_loss: 1.9519 - val_participant_output_loss: 0.3248 - val_command_output_loss: 1.6270 - val_command_output_1_loss: 3.8808e-05 - val_participant_output_1_loss: 2.2590e-05 - val_participant_output_accuracy: 0.9632 - val_command_output_accuracy: 0.9374 - val_command_output_1_accuracy: 0.0295 - val_participant_output_1_accuracy: 0.1252\n",
      "Epoch 9/10\n",
      "13/13 [==============================] - 2s 192ms/step - loss: 1.7176 - participant_output_loss: 0.1697 - command_output_loss: 1.5478 - command_output_1_loss: 4.8636e-05 - participant_output_1_loss: 1.9093e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9850 - command_output_1_accuracy: 0.0025 - participant_output_1_accuracy: 0.1275 - val_loss: 1.8551 - val_participant_output_loss: 0.3044 - val_command_output_loss: 1.5507 - val_command_output_1_loss: 4.8733e-05 - val_participant_output_1_loss: 2.2456e-05 - val_participant_output_accuracy: 0.9613 - val_command_output_accuracy: 0.9484 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.1381\n",
      "Epoch 10/10\n",
      "13/13 [==============================] - 2s 166ms/step - loss: 1.6209 - participant_output_loss: 0.1460 - command_output_loss: 1.4749 - command_output_1_loss: 4.7795e-05 - participant_output_1_loss: 1.8248e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9875 - command_output_1_accuracy: 0.0000e+00 - participant_output_1_accuracy: 0.1300 - val_loss: 1.7594 - val_participant_output_loss: 0.2770 - val_command_output_loss: 1.4823 - val_command_output_1_loss: 3.3448e-05 - val_participant_output_1_loss: 2.2555e-05 - val_participant_output_accuracy: 0.9613 - val_command_output_accuracy: 0.9484 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.1823\n",
      "Epoch 1/10\n",
      "13/13 [==============================] - 3s 249ms/step - loss: 1.5290 - participant_output_loss: 0.1255 - command_output_loss: 1.4035 - command_output_1_loss: 4.2231e-05 - participant_output_1_loss: 1.7580e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9875 - command_output_1_accuracy: 0.0012 - participant_output_1_accuracy: 0.1725 - val_loss: 1.6771 - val_participant_output_loss: 0.2561 - val_command_output_loss: 1.4209 - val_command_output_1_loss: 3.4243e-05 - val_participant_output_1_loss: 2.2058e-05 - val_participant_output_accuracy: 0.9595 - val_command_output_accuracy: 0.9484 - val_command_output_1_accuracy: 0.0055 - val_participant_output_1_accuracy: 0.1326\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10\n",
      "13/13 [==============================] - 2s 179ms/step - loss: 1.4419 - participant_output_loss: 0.1106 - command_output_loss: 1.3312 - command_output_1_loss: 4.2165e-05 - participant_output_1_loss: 1.7559e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9937 - command_output_1_accuracy: 0.0025 - participant_output_1_accuracy: 0.1437 - val_loss: 1.5795 - val_participant_output_loss: 0.2369 - val_command_output_loss: 1.3426 - val_command_output_1_loss: 3.3527e-05 - val_participant_output_1_loss: 2.1168e-05 - val_participant_output_accuracy: 0.9669 - val_command_output_accuracy: 0.9595 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.1418\n",
      "Epoch 3/10\n",
      "13/13 [==============================] - 2s 187ms/step - loss: 1.3555 - participant_output_loss: 0.0970 - command_output_loss: 1.2585 - command_output_1_loss: 3.7709e-05 - participant_output_1_loss: 1.7053e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9962 - command_output_1_accuracy: 0.0000e+00 - participant_output_1_accuracy: 0.1700 - val_loss: 1.5004 - val_participant_output_loss: 0.2180 - val_command_output_loss: 1.2823 - val_command_output_1_loss: 5.7456e-05 - val_participant_output_1_loss: 2.2831e-05 - val_participant_output_accuracy: 0.9650 - val_command_output_accuracy: 0.9632 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.1068\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - 3s 195ms/step - loss: 1.2736 - participant_output_loss: 0.0853 - command_output_loss: 1.1882 - command_output_1_loss: 4.6413e-05 - participant_output_1_loss: 1.6252e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9975 - command_output_1_accuracy: 0.0025 - participant_output_1_accuracy: 0.1663 - val_loss: 1.4197 - val_participant_output_loss: 0.2019 - val_command_output_loss: 1.2178 - val_command_output_1_loss: 3.3997e-05 - val_participant_output_1_loss: 2.1057e-05 - val_participant_output_accuracy: 0.9650 - val_command_output_accuracy: 0.9687 - val_command_output_1_accuracy: 0.0129 - val_participant_output_1_accuracy: 0.1197\n",
      "Epoch 5/10\n",
      "13/13 [==============================] - 2s 164ms/step - loss: 1.1979 - participant_output_loss: 0.0767 - command_output_loss: 1.1211 - command_output_1_loss: 4.4135e-05 - participant_output_1_loss: 1.5430e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9987 - command_output_1_accuracy: 0.0262 - participant_output_1_accuracy: 0.1525 - val_loss: 1.3381 - val_participant_output_loss: 0.1837 - val_command_output_loss: 1.1543 - val_command_output_1_loss: 3.9243e-05 - val_participant_output_1_loss: 2.0716e-05 - val_participant_output_accuracy: 0.9687 - val_command_output_accuracy: 0.9650 - val_command_output_1_accuracy: 0.0037 - val_participant_output_1_accuracy: 0.1731\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - 3s 196ms/step - loss: 1.1232 - participant_output_loss: 0.0693 - command_output_loss: 1.0538 - command_output_1_loss: 6.5353e-05 - participant_output_1_loss: 1.4392e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9987 - command_output_1_accuracy: 0.0025 - participant_output_1_accuracy: 0.1737 - val_loss: 1.2731 - val_participant_output_loss: 0.1794 - val_command_output_loss: 1.0937 - val_command_output_1_loss: 5.0973e-05 - val_participant_output_1_loss: 1.9920e-05 - val_participant_output_accuracy: 0.9687 - val_command_output_accuracy: 0.9742 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.1436\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - 2s 158ms/step - loss: 1.0575 - participant_output_loss: 0.0634 - command_output_loss: 0.9940 - command_output_1_loss: 4.1305e-05 - participant_output_1_loss: 1.3879e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0300 - participant_output_1_accuracy: 0.1663 - val_loss: 1.2074 - val_participant_output_loss: 0.1707 - val_command_output_loss: 1.0366 - val_command_output_1_loss: 3.5741e-05 - val_participant_output_1_loss: 2.0310e-05 - val_participant_output_accuracy: 0.9687 - val_command_output_accuracy: 0.9705 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.1750\n",
      "Epoch 8/10\n",
      "13/13 [==============================] - 2s 168ms/step - loss: 0.9916 - participant_output_loss: 0.0594 - command_output_loss: 0.9321 - command_output_1_loss: 5.2082e-05 - participant_output_1_loss: 1.3405e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0000e+00 - participant_output_1_accuracy: 0.1800 - val_loss: 1.1477 - val_participant_output_loss: 0.1691 - val_command_output_loss: 0.9785 - val_command_output_1_loss: 4.9545e-05 - val_participant_output_1_loss: 1.9303e-05 - val_participant_output_accuracy: 0.9687 - val_command_output_accuracy: 0.9669 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.1768\n",
      "Epoch 9/10\n",
      "13/13 [==============================] - 2s 155ms/step - loss: 0.9268 - participant_output_loss: 0.0550 - command_output_loss: 0.8717 - command_output_1_loss: 3.3186e-05 - participant_output_1_loss: 1.2877e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.1037 - participant_output_1_accuracy: 0.1525 - val_loss: 1.0966 - val_participant_output_loss: 0.1728 - val_command_output_loss: 0.9238 - val_command_output_1_loss: 2.9355e-05 - val_participant_output_1_loss: 1.9289e-05 - val_participant_output_accuracy: 0.9632 - val_command_output_accuracy: 0.9687 - val_command_output_1_accuracy: 0.3573 - val_participant_output_1_accuracy: 0.1584\n",
      "Epoch 10/10\n",
      "13/13 [==============================] - 2s 161ms/step - loss: 0.8690 - participant_output_loss: 0.0521 - command_output_loss: 0.8168 - command_output_1_loss: 4.4023e-05 - participant_output_1_loss: 1.2129e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0988 - participant_output_1_accuracy: 0.1912 - val_loss: 1.0383 - val_participant_output_loss: 0.1649 - val_command_output_loss: 0.8733 - val_command_output_1_loss: 2.8069e-05 - val_participant_output_1_loss: 1.8802e-05 - val_participant_output_accuracy: 0.9669 - val_command_output_accuracy: 0.9687 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.1050\n",
      "Epoch 1/10\n",
      "13/13 [==============================] - 4s 294ms/step - loss: 3.4977 - participant_output_loss: 1.3794 - command_output_loss: 2.1154 - command_output_1_loss: 6.6288e-04 - participant_output_1_loss: 0.0024 - participant_output_accuracy: 0.5050 - command_output_accuracy: 0.3575 - command_output_1_accuracy: 0.1100 - participant_output_1_accuracy: 0.1412 - val_loss: 3.2206 - val_participant_output_loss: 1.3271 - val_command_output_loss: 1.8930 - val_command_output_1_loss: 2.7209e-04 - val_participant_output_1_loss: 1.6635e-04 - val_participant_output_accuracy: 0.4917 - val_command_output_accuracy: 0.6851 - val_command_output_1_accuracy: 0.9982 - val_participant_output_1_accuracy: 0.8379\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - 2s 170ms/step - loss: 2.7314 - participant_output_loss: 0.9666 - command_output_loss: 1.7646 - command_output_1_loss: 1.3070e-04 - participant_output_1_loss: 9.0071e-05 - participant_output_accuracy: 0.6675 - command_output_accuracy: 0.7750 - command_output_1_accuracy: 0.5525 - participant_output_1_accuracy: 0.5100 - val_loss: 2.6918 - val_participant_output_loss: 1.0161 - val_command_output_loss: 1.6756 - val_command_output_1_loss: 3.6672e-05 - val_participant_output_1_loss: 5.8061e-05 - val_participant_output_accuracy: 0.6556 - val_command_output_accuracy: 0.8103 - val_command_output_1_accuracy: 0.0018 - val_participant_output_1_accuracy: 0.0018\n",
      "Epoch 3/10\n",
      "13/13 [==============================] - 2s 180ms/step - loss: 2.3078 - participant_output_loss: 0.7459 - command_output_loss: 1.5618 - command_output_1_loss: 5.4150e-05 - participant_output_1_loss: 4.2254e-05 - participant_output_accuracy: 0.8087 - command_output_accuracy: 0.8750 - command_output_1_accuracy: 0.0000e+00 - participant_output_1_accuracy: 0.1037 - val_loss: 2.3602 - val_participant_output_loss: 0.8631 - val_command_output_loss: 1.4971 - val_command_output_1_loss: 7.3494e-05 - val_participant_output_1_loss: 3.6473e-05 - val_participant_output_accuracy: 0.7587 - val_command_output_accuracy: 0.8711 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.4678\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10\n",
      "13/13 [==============================] - 2s 175ms/step - loss: 1.9753 - participant_output_loss: 0.5936 - command_output_loss: 1.3816 - command_output_1_loss: 5.9385e-05 - participant_output_1_loss: 3.2352e-05 - participant_output_accuracy: 0.8850 - command_output_accuracy: 0.9400 - command_output_1_accuracy: 0.0150 - participant_output_1_accuracy: 0.3938 - val_loss: 2.0182 - val_participant_output_loss: 0.6937 - val_command_output_loss: 1.3244 - val_command_output_1_loss: 5.0580e-05 - val_participant_output_1_loss: 2.9982e-05 - val_participant_output_accuracy: 0.8600 - val_command_output_accuracy: 0.9190 - val_command_output_1_accuracy: 0.0203 - val_participant_output_1_accuracy: 0.1786\n",
      "Epoch 5/10\n",
      "13/13 [==============================] - 2s 188ms/step - loss: 1.6846 - participant_output_loss: 0.4747 - command_output_loss: 1.2098 - command_output_1_loss: 5.0759e-05 - participant_output_1_loss: 2.9111e-05 - participant_output_accuracy: 0.9413 - command_output_accuracy: 0.9525 - command_output_1_accuracy: 0.0525 - participant_output_1_accuracy: 0.1713 - val_loss: 1.7306 - val_participant_output_loss: 0.5649 - val_command_output_loss: 1.1656 - val_command_output_1_loss: 4.6247e-05 - val_participant_output_1_loss: 3.1957e-05 - val_participant_output_accuracy: 0.9300 - val_command_output_accuracy: 0.9245 - val_command_output_1_accuracy: 0.4199 - val_participant_output_1_accuracy: 0.2284\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - 3s 198ms/step - loss: 1.4243 - participant_output_loss: 0.3749 - command_output_loss: 1.0493 - command_output_1_loss: 6.0433e-05 - participant_output_1_loss: 2.9419e-05 - participant_output_accuracy: 0.9700 - command_output_accuracy: 0.9812 - command_output_1_accuracy: 0.4700 - participant_output_1_accuracy: 0.3275 - val_loss: 1.5243 - val_participant_output_loss: 0.5023 - val_command_output_loss: 1.0219 - val_command_output_1_loss: 4.9204e-05 - val_participant_output_1_loss: 3.3274e-05 - val_participant_output_accuracy: 0.9245 - val_command_output_accuracy: 0.9374 - val_command_output_1_accuracy: 0.0405 - val_participant_output_1_accuracy: 0.1934\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - 2s 179ms/step - loss: 1.2183 - participant_output_loss: 0.3136 - command_output_loss: 0.9047 - command_output_1_loss: 5.1745e-05 - participant_output_1_loss: 2.8708e-05 - participant_output_accuracy: 0.9800 - command_output_accuracy: 0.9812 - command_output_1_accuracy: 0.0088 - participant_output_1_accuracy: 0.2350 - val_loss: 1.3522 - val_participant_output_loss: 0.4565 - val_command_output_loss: 0.8956 - val_command_output_1_loss: 4.6397e-05 - val_participant_output_1_loss: 3.1425e-05 - val_participant_output_accuracy: 0.9355 - val_command_output_accuracy: 0.9613 - val_command_output_1_accuracy: 0.0295 - val_participant_output_1_accuracy: 0.3020\n",
      "Epoch 8/10\n",
      "13/13 [==============================] - 2s 188ms/step - loss: 1.0505 - participant_output_loss: 0.2728 - command_output_loss: 0.7777 - command_output_1_loss: 4.7777e-05 - participant_output_1_loss: 2.7672e-05 - participant_output_accuracy: 0.9850 - command_output_accuracy: 0.9912 - command_output_1_accuracy: 0.0550 - participant_output_1_accuracy: 0.2700 - val_loss: 1.1689 - val_participant_output_loss: 0.3880 - val_command_output_loss: 0.7808 - val_command_output_1_loss: 4.1162e-05 - val_participant_output_1_loss: 3.1083e-05 - val_participant_output_accuracy: 0.9595 - val_command_output_accuracy: 0.9613 - val_command_output_1_accuracy: 0.0976 - val_participant_output_1_accuracy: 0.2284\n",
      "Epoch 9/10\n",
      "13/13 [==============================] - 2s 159ms/step - loss: 0.8988 - participant_output_loss: 0.2325 - command_output_loss: 0.6662 - command_output_1_loss: 4.4452e-05 - participant_output_1_loss: 2.5716e-05 - participant_output_accuracy: 0.9937 - command_output_accuracy: 0.9937 - command_output_1_accuracy: 0.1287 - participant_output_1_accuracy: 0.2625 - val_loss: 1.0659 - val_participant_output_loss: 0.3822 - val_command_output_loss: 0.6837 - val_command_output_1_loss: 4.6946e-05 - val_participant_output_1_loss: 2.9118e-05 - val_participant_output_accuracy: 0.9484 - val_command_output_accuracy: 0.9595 - val_command_output_1_accuracy: 0.1897 - val_participant_output_1_accuracy: 0.2744\n",
      "Epoch 10/10\n",
      "13/13 [==============================] - 3s 200ms/step - loss: 0.7740 - participant_output_loss: 0.2087 - command_output_loss: 0.5652 - command_output_1_loss: 4.1774e-05 - participant_output_1_loss: 2.4662e-05 - participant_output_accuracy: 0.9950 - command_output_accuracy: 0.9975 - command_output_1_accuracy: 0.0763 - participant_output_1_accuracy: 0.2600 - val_loss: 0.9184 - val_participant_output_loss: 0.3235 - val_command_output_loss: 0.5947 - val_command_output_1_loss: 4.4247e-05 - val_participant_output_1_loss: 2.8031e-05 - val_participant_output_accuracy: 0.9669 - val_command_output_accuracy: 0.9705 - val_command_output_1_accuracy: 0.2505 - val_participant_output_1_accuracy: 0.2505\n",
      "Epoch 1/10\n",
      "13/13 [==============================] - 3s 227ms/step - loss: 0.6638 - participant_output_loss: 0.1814 - command_output_loss: 0.4824 - command_output_1_loss: 3.7683e-05 - participant_output_1_loss: 2.3384e-05 - participant_output_accuracy: 0.9950 - command_output_accuracy: 0.9987 - command_output_1_accuracy: 0.1863 - participant_output_1_accuracy: 0.2450 - val_loss: 0.8607 - val_participant_output_loss: 0.3300 - val_command_output_loss: 0.5306 - val_command_output_1_loss: 4.2935e-05 - val_participant_output_1_loss: 2.7574e-05 - val_participant_output_accuracy: 0.9521 - val_command_output_accuracy: 0.9724 - val_command_output_1_accuracy: 0.0258 - val_participant_output_1_accuracy: 0.2320\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - 2s 187ms/step - loss: 0.5715 - participant_output_loss: 0.1604 - command_output_loss: 0.4110 - command_output_1_loss: 3.6412e-05 - participant_output_1_loss: 2.2329e-05 - participant_output_accuracy: 0.9987 - command_output_accuracy: 0.9987 - command_output_1_accuracy: 0.0100 - participant_output_1_accuracy: 0.2900 - val_loss: 0.7493 - val_participant_output_loss: 0.2832 - val_command_output_loss: 0.4660 - val_command_output_1_loss: 3.1641e-05 - val_participant_output_1_loss: 2.7902e-05 - val_participant_output_accuracy: 0.9650 - val_command_output_accuracy: 0.9669 - val_command_output_1_accuracy: 0.0516 - val_participant_output_1_accuracy: 0.1878\n",
      "Epoch 3/10\n",
      "13/13 [==============================] - 2s 165ms/step - loss: 0.4945 - participant_output_loss: 0.1428 - command_output_loss: 0.3517 - command_output_1_loss: 2.8359e-05 - participant_output_1_loss: 2.0545e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9987 - command_output_1_accuracy: 0.1762 - participant_output_1_accuracy: 0.2450 - val_loss: 0.6911 - val_participant_output_loss: 0.2759 - val_command_output_loss: 0.4151 - val_command_output_1_loss: 3.2363e-05 - val_participant_output_1_loss: 2.5351e-05 - val_participant_output_accuracy: 0.9595 - val_command_output_accuracy: 0.9669 - val_command_output_1_accuracy: 0.2339 - val_participant_output_1_accuracy: 0.2578\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - 3s 201ms/step - loss: 0.4268 - participant_output_loss: 0.1288 - command_output_loss: 0.2980 - command_output_1_loss: 2.7562e-05 - participant_output_1_loss: 1.9653e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0688 - participant_output_1_accuracy: 0.2775 - val_loss: 0.6082 - val_participant_output_loss: 0.2406 - val_command_output_loss: 0.3676 - val_command_output_1_loss: 2.6214e-05 - val_participant_output_1_loss: 2.3917e-05 - val_participant_output_accuracy: 0.9687 - val_command_output_accuracy: 0.9669 - val_command_output_1_accuracy: 0.0773 - val_participant_output_1_accuracy: 0.2799\n",
      "Epoch 5/10\n",
      "13/13 [==============================] - 2s 182ms/step - loss: 0.3686 - participant_output_loss: 0.1139 - command_output_loss: 0.2547 - command_output_1_loss: 2.1844e-05 - participant_output_1_loss: 1.8066e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.2362 - participant_output_1_accuracy: 0.2338 - val_loss: 0.5512 - val_participant_output_loss: 0.2221 - val_command_output_loss: 0.3291 - val_command_output_1_loss: 2.2111e-05 - val_participant_output_1_loss: 2.2891e-05 - val_participant_output_accuracy: 0.9650 - val_command_output_accuracy: 0.9742 - val_command_output_1_accuracy: 0.1031 - val_participant_output_1_accuracy: 0.2873\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10\n",
      "13/13 [==============================] - 2s 155ms/step - loss: 0.3227 - participant_output_loss: 0.1024 - command_output_loss: 0.2202 - command_output_1_loss: 1.9985e-05 - participant_output_1_loss: 1.7240e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0288 - participant_output_1_accuracy: 0.2950 - val_loss: 0.5083 - val_participant_output_loss: 0.2093 - val_command_output_loss: 0.2990 - val_command_output_1_loss: 2.0130e-05 - val_participant_output_1_loss: 2.2711e-05 - val_participant_output_accuracy: 0.9687 - val_command_output_accuracy: 0.9705 - val_command_output_1_accuracy: 0.0387 - val_participant_output_1_accuracy: 0.2320\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - 3s 192ms/step - loss: 0.2876 - participant_output_loss: 0.0953 - command_output_loss: 0.1923 - command_output_1_loss: 1.7981e-05 - participant_output_1_loss: 1.6495e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0950 - participant_output_1_accuracy: 0.2338 - val_loss: 0.4676 - val_participant_output_loss: 0.1942 - val_command_output_loss: 0.2733 - val_command_output_1_loss: 1.7863e-05 - val_participant_output_1_loss: 2.1896e-05 - val_participant_output_accuracy: 0.9761 - val_command_output_accuracy: 0.9761 - val_command_output_1_accuracy: 0.0810 - val_participant_output_1_accuracy: 0.2910\n",
      "Epoch 8/10\n",
      "13/13 [==============================] - 2s 168ms/step - loss: 0.2573 - participant_output_loss: 0.0889 - command_output_loss: 0.1683 - command_output_1_loss: 1.6097e-05 - participant_output_1_loss: 1.5556e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0475 - participant_output_1_accuracy: 0.2600 - val_loss: 0.4389 - val_participant_output_loss: 0.1906 - val_command_output_loss: 0.2482 - val_command_output_1_loss: 1.5268e-05 - val_participant_output_1_loss: 2.0861e-05 - val_participant_output_accuracy: 0.9687 - val_command_output_accuracy: 0.9705 - val_command_output_1_accuracy: 0.0829 - val_participant_output_1_accuracy: 0.2560\n",
      "Epoch 9/10\n",
      "13/13 [==============================] - 2s 156ms/step - loss: 0.2295 - participant_output_loss: 0.0812 - command_output_loss: 0.1483 - command_output_1_loss: 1.3136e-05 - participant_output_1_loss: 1.4757e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0775 - participant_output_1_accuracy: 0.2725 - val_loss: 0.4087 - val_participant_output_loss: 0.1804 - val_command_output_loss: 0.2283 - val_command_output_1_loss: 1.3458e-05 - val_participant_output_1_loss: 1.9985e-05 - val_participant_output_accuracy: 0.9742 - val_command_output_accuracy: 0.9742 - val_command_output_1_accuracy: 0.0589 - val_participant_output_1_accuracy: 0.2634\n",
      "Epoch 10/10\n",
      "13/13 [==============================] - 2s 161ms/step - loss: 0.2081 - participant_output_loss: 0.0764 - command_output_loss: 0.1316 - command_output_1_loss: 1.2064e-05 - participant_output_1_loss: 1.3841e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0325 - participant_output_1_accuracy: 0.2537 - val_loss: 0.3910 - val_participant_output_loss: 0.1782 - val_command_output_loss: 0.2128 - val_command_output_1_loss: 1.1877e-05 - val_participant_output_1_loss: 1.9433e-05 - val_participant_output_accuracy: 0.9742 - val_command_output_accuracy: 0.9742 - val_command_output_1_accuracy: 0.0755 - val_participant_output_1_accuracy: 0.2983\n",
      "Epoch 1/10\n",
      "13/13 [==============================] - 4s 295ms/step - loss: 3.4833 - participant_output_loss: 1.3266 - command_output_loss: 2.1509 - command_output_1_loss: 5.2331e-04 - participant_output_1_loss: 0.0052 - participant_output_accuracy: 0.4575 - command_output_accuracy: 0.3212 - command_output_1_accuracy: 0.0025 - participant_output_1_accuracy: 0.1350 - val_loss: 3.2545 - val_participant_output_loss: 1.3231 - val_command_output_loss: 1.9310 - val_command_output_1_loss: 1.6390e-04 - val_participant_output_1_loss: 2.3209e-04 - val_participant_output_accuracy: 0.4862 - val_command_output_accuracy: 0.6280 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.8122\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - 2s 170ms/step - loss: 2.7635 - participant_output_loss: 0.9313 - command_output_loss: 1.8319 - command_output_1_loss: 7.0898e-05 - participant_output_1_loss: 1.7635e-04 - participant_output_accuracy: 0.6888 - command_output_accuracy: 0.7212 - command_output_1_accuracy: 0.0712 - participant_output_1_accuracy: 0.3237 - val_loss: 2.7463 - val_participant_output_loss: 0.9903 - val_command_output_loss: 1.7559 - val_command_output_1_loss: 7.4365e-05 - val_participant_output_1_loss: 8.5804e-05 - val_participant_output_accuracy: 0.6151 - val_command_output_accuracy: 0.7145 - val_command_output_1_accuracy: 0.1252 - val_participant_output_1_accuracy: 0.0203\n",
      "Epoch 3/10\n",
      "13/13 [==============================] - 3s 199ms/step - loss: 2.3646 - participant_output_loss: 0.7038 - command_output_loss: 1.6606 - command_output_1_loss: 7.3925e-05 - participant_output_1_loss: 7.1283e-05 - participant_output_accuracy: 0.7837 - command_output_accuracy: 0.7750 - command_output_1_accuracy: 0.0312 - participant_output_1_accuracy: 0.4075 - val_loss: 2.4136 - val_participant_output_loss: 0.8122 - val_command_output_loss: 1.6012 - val_command_output_1_loss: 6.7349e-05 - val_participant_output_1_loss: 4.1983e-05 - val_participant_output_accuracy: 0.7808 - val_command_output_accuracy: 0.8269 - val_command_output_1_accuracy: 0.1031 - val_participant_output_1_accuracy: 0.0902\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - 3s 198ms/step - loss: 2.0652 - participant_output_loss: 0.5646 - command_output_loss: 1.5005 - command_output_1_loss: 1.2003e-04 - participant_output_1_loss: 3.8986e-05 - participant_output_accuracy: 0.8800 - command_output_accuracy: 0.9100 - command_output_1_accuracy: 0.3363 - participant_output_1_accuracy: 0.1425 - val_loss: 2.1434 - val_participant_output_loss: 0.6891 - val_command_output_loss: 1.4541 - val_command_output_1_loss: 9.7014e-05 - val_participant_output_1_loss: 3.6336e-05 - val_participant_output_accuracy: 0.8361 - val_command_output_accuracy: 0.8729 - val_command_output_1_accuracy: 0.3517 - val_participant_output_1_accuracy: 0.3131\n",
      "Epoch 5/10\n",
      "13/13 [==============================] - 3s 198ms/step - loss: 1.8001 - participant_output_loss: 0.4517 - command_output_loss: 1.3483 - command_output_1_loss: 7.3706e-05 - participant_output_1_loss: 3.0367e-05 - participant_output_accuracy: 0.9275 - command_output_accuracy: 0.9488 - command_output_1_accuracy: 0.1000 - participant_output_1_accuracy: 0.2425 - val_loss: 1.8802 - val_participant_output_loss: 0.5691 - val_command_output_loss: 1.3110 - val_command_output_1_loss: 7.1199e-05 - val_participant_output_1_loss: 3.1600e-05 - val_participant_output_accuracy: 0.9190 - val_command_output_accuracy: 0.9208 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.1952\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - 2s 156ms/step - loss: 1.5831 - participant_output_loss: 0.3726 - command_output_loss: 1.2105 - command_output_1_loss: 5.7894e-05 - participant_output_1_loss: 2.5501e-05 - participant_output_accuracy: 0.9663 - command_output_accuracy: 0.9538 - command_output_1_accuracy: 0.0088 - participant_output_1_accuracy: 0.2688 - val_loss: 1.7136 - val_participant_output_loss: 0.5290 - val_command_output_loss: 1.1845 - val_command_output_1_loss: 5.2865e-05 - val_participant_output_1_loss: 3.0441e-05 - val_participant_output_accuracy: 0.9098 - val_command_output_accuracy: 0.9134 - val_command_output_1_accuracy: 0.0645 - val_participant_output_1_accuracy: 0.2320\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - 3s 197ms/step - loss: 1.4006 - participant_output_loss: 0.3201 - command_output_loss: 1.0804 - command_output_1_loss: 5.5188e-05 - participant_output_1_loss: 2.5162e-05 - participant_output_accuracy: 0.9750 - command_output_accuracy: 0.9737 - command_output_1_accuracy: 0.0562 - participant_output_1_accuracy: 0.2688 - val_loss: 1.5270 - val_participant_output_loss: 0.4663 - val_command_output_loss: 1.0606 - val_command_output_1_loss: 5.4323e-05 - val_participant_output_1_loss: 3.3481e-05 - val_participant_output_accuracy: 0.9153 - val_command_output_accuracy: 0.9558 - val_command_output_1_accuracy: 0.2155 - val_participant_output_1_accuracy: 0.1842\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10\n",
      "13/13 [==============================] - 3s 204ms/step - loss: 1.2145 - participant_output_loss: 0.2633 - command_output_loss: 0.9511 - command_output_1_loss: 5.9601e-05 - participant_output_1_loss: 2.5724e-05 - participant_output_accuracy: 0.9850 - command_output_accuracy: 0.9787 - command_output_1_accuracy: 0.1813 - participant_output_1_accuracy: 0.2150 - val_loss: 1.3469 - val_participant_output_loss: 0.4018 - val_command_output_loss: 0.9451 - val_command_output_1_loss: 4.4417e-05 - val_participant_output_1_loss: 3.0843e-05 - val_participant_output_accuracy: 0.9411 - val_command_output_accuracy: 0.9576 - val_command_output_1_accuracy: 0.3131 - val_participant_output_1_accuracy: 0.2965\n",
      "Epoch 9/10\n",
      "13/13 [==============================] - 2s 151ms/step - loss: 1.0518 - participant_output_loss: 0.2175 - command_output_loss: 0.8341 - command_output_1_loss: 6.2504e-05 - participant_output_1_loss: 2.4270e-05 - participant_output_accuracy: 0.9912 - command_output_accuracy: 0.9912 - command_output_1_accuracy: 0.1200 - participant_output_1_accuracy: 0.2575 - val_loss: 1.2142 - val_participant_output_loss: 0.3616 - val_command_output_loss: 0.8525 - val_command_output_1_loss: 4.8645e-05 - val_participant_output_1_loss: 3.1742e-05 - val_participant_output_accuracy: 0.9392 - val_command_output_accuracy: 0.9540 - val_command_output_1_accuracy: 0.0313 - val_participant_output_1_accuracy: 0.2799\n",
      "Epoch 10/10\n",
      "13/13 [==============================] - 2s 192ms/step - loss: 0.9095 - participant_output_loss: 0.1831 - command_output_loss: 0.7264 - command_output_1_loss: 5.2108e-05 - participant_output_1_loss: 2.2751e-05 - participant_output_accuracy: 0.9925 - command_output_accuracy: 0.9937 - command_output_1_accuracy: 0.0550 - participant_output_1_accuracy: 0.2325 - val_loss: 1.0744 - val_participant_output_loss: 0.3224 - val_command_output_loss: 0.7520 - val_command_output_1_loss: 4.6468e-05 - val_participant_output_1_loss: 3.0651e-05 - val_participant_output_accuracy: 0.9466 - val_command_output_accuracy: 0.9669 - val_command_output_1_accuracy: 0.1031 - val_participant_output_1_accuracy: 0.2799\n",
      "Epoch 1/10\n",
      "13/13 [==============================] - 3s 241ms/step - loss: 0.7814 - participant_output_loss: 0.1530 - command_output_loss: 0.6283 - command_output_1_loss: 3.7692e-05 - participant_output_1_loss: 2.2415e-05 - participant_output_accuracy: 0.9987 - command_output_accuracy: 0.9962 - command_output_1_accuracy: 0.0988 - participant_output_1_accuracy: 0.2713 - val_loss: 0.9376 - val_participant_output_loss: 0.2766 - val_command_output_loss: 0.6610 - val_command_output_1_loss: 3.9036e-05 - val_participant_output_1_loss: 3.0660e-05 - val_participant_output_accuracy: 0.9650 - val_command_output_accuracy: 0.9650 - val_command_output_1_accuracy: 0.1013 - val_participant_output_1_accuracy: 0.1952\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - 2s 178ms/step - loss: 0.6776 - participant_output_loss: 0.1339 - command_output_loss: 0.5436 - command_output_1_loss: 3.9148e-05 - participant_output_1_loss: 2.1322e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9975 - command_output_1_accuracy: 0.0988 - participant_output_1_accuracy: 0.2575 - val_loss: 0.8466 - val_participant_output_loss: 0.2618 - val_command_output_loss: 0.5847 - val_command_output_1_loss: 3.2612e-05 - val_participant_output_1_loss: 2.9284e-05 - val_participant_output_accuracy: 0.9650 - val_command_output_accuracy: 0.9687 - val_command_output_1_accuracy: 0.0295 - val_participant_output_1_accuracy: 0.2063\n",
      "Epoch 3/10\n",
      "13/13 [==============================] - 3s 195ms/step - loss: 0.5861 - participant_output_loss: 0.1136 - command_output_loss: 0.4725 - command_output_1_loss: 4.2948e-05 - participant_output_1_loss: 2.0350e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9987 - command_output_1_accuracy: 0.0088 - participant_output_1_accuracy: 0.2450 - val_loss: 0.7525 - val_participant_output_loss: 0.2340 - val_command_output_loss: 0.5185 - val_command_output_1_loss: 2.8856e-05 - val_participant_output_1_loss: 2.8937e-05 - val_participant_output_accuracy: 0.9650 - val_command_output_accuracy: 0.9705 - val_command_output_1_accuracy: 0.0976 - val_participant_output_1_accuracy: 0.2634\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - 2s 150ms/step - loss: 0.5040 - participant_output_loss: 0.0965 - command_output_loss: 0.4075 - command_output_1_loss: 2.9406e-05 - participant_output_1_loss: 1.9288e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9987 - command_output_1_accuracy: 0.1063 - participant_output_1_accuracy: 0.2488 - val_loss: 0.6816 - val_participant_output_loss: 0.2162 - val_command_output_loss: 0.4653 - val_command_output_1_loss: 4.2536e-05 - val_participant_output_1_loss: 2.8697e-05 - val_participant_output_accuracy: 0.9669 - val_command_output_accuracy: 0.9669 - val_command_output_1_accuracy: 0.0902 - val_participant_output_1_accuracy: 0.2689\n",
      "Epoch 5/10\n",
      "13/13 [==============================] - 3s 193ms/step - loss: 0.4425 - participant_output_loss: 0.0859 - command_output_loss: 0.3566 - command_output_1_loss: 3.2245e-05 - participant_output_1_loss: 1.8626e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9987 - command_output_1_accuracy: 0.1213 - participant_output_1_accuracy: 0.2500 - val_loss: 0.6193 - val_participant_output_loss: 0.2037 - val_command_output_loss: 0.4155 - val_command_output_1_loss: 2.1469e-05 - val_participant_output_1_loss: 2.8215e-05 - val_participant_output_accuracy: 0.9687 - val_command_output_accuracy: 0.9724 - val_command_output_1_accuracy: 0.0958 - val_participant_output_1_accuracy: 0.2265\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - 2s 161ms/step - loss: 0.3893 - participant_output_loss: 0.0767 - command_output_loss: 0.3126 - command_output_1_loss: 2.5756e-05 - participant_output_1_loss: 1.8757e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0288 - participant_output_1_accuracy: 0.2288 - val_loss: 0.5786 - val_participant_output_loss: 0.1936 - val_command_output_loss: 0.3850 - val_command_output_1_loss: 2.8486e-05 - val_participant_output_1_loss: 3.0465e-05 - val_participant_output_accuracy: 0.9669 - val_command_output_accuracy: 0.9669 - val_command_output_1_accuracy: 0.0313 - val_participant_output_1_accuracy: 0.2007\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - 2s 157ms/step - loss: 0.3438 - participant_output_loss: 0.0686 - command_output_loss: 0.2752 - command_output_1_loss: 1.9292e-05 - participant_output_1_loss: 1.8311e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0088 - participant_output_1_accuracy: 0.2275 - val_loss: 0.5348 - val_participant_output_loss: 0.1865 - val_command_output_loss: 0.3483 - val_command_output_1_loss: 1.8295e-05 - val_participant_output_1_loss: 2.7966e-05 - val_participant_output_accuracy: 0.9669 - val_command_output_accuracy: 0.9687 - val_command_output_1_accuracy: 0.0663 - val_participant_output_1_accuracy: 0.2818\n",
      "Epoch 8/10\n",
      "13/13 [==============================] - 2s 161ms/step - loss: 0.3061 - participant_output_loss: 0.0627 - command_output_loss: 0.2434 - command_output_1_loss: 1.7313e-05 - participant_output_1_loss: 1.7279e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.4412 - participant_output_1_accuracy: 0.2587 - val_loss: 0.5008 - val_participant_output_loss: 0.1826 - val_command_output_loss: 0.3182 - val_command_output_1_loss: 1.7725e-05 - val_participant_output_1_loss: 2.7236e-05 - val_participant_output_accuracy: 0.9669 - val_command_output_accuracy: 0.9724 - val_command_output_1_accuracy: 0.2707 - val_participant_output_1_accuracy: 0.1971\n",
      "Epoch 9/10\n",
      "13/13 [==============================] - 2s 161ms/step - loss: 0.2736 - participant_output_loss: 0.0576 - command_output_loss: 0.2159 - command_output_1_loss: 1.7321e-05 - participant_output_1_loss: 1.6650e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0463 - participant_output_1_accuracy: 0.2425 - val_loss: 0.4633 - val_participant_output_loss: 0.1715 - val_command_output_loss: 0.2917 - val_command_output_1_loss: 1.1761e-05 - val_participant_output_1_loss: 2.6699e-05 - val_participant_output_accuracy: 0.9687 - val_command_output_accuracy: 0.9687 - val_command_output_1_accuracy: 0.0479 - val_participant_output_1_accuracy: 0.2136\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10\n",
      "13/13 [==============================] - 2s 171ms/step - loss: 0.2458 - participant_output_loss: 0.0528 - command_output_loss: 0.1930 - command_output_1_loss: 1.1549e-05 - participant_output_1_loss: 1.5176e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.1800 - participant_output_1_accuracy: 0.2475 - val_loss: 0.4398 - val_participant_output_loss: 0.1697 - val_command_output_loss: 0.2701 - val_command_output_1_loss: 1.2479e-05 - val_participant_output_1_loss: 2.6118e-05 - val_participant_output_accuracy: 0.9669 - val_command_output_accuracy: 0.9724 - val_command_output_1_accuracy: 0.1897 - val_participant_output_1_accuracy: 0.2265\n",
      "Epoch 1/10\n",
      "13/13 [==============================] - 4s 298ms/step - loss: 3.6934 - participant_output_loss: 1.3440 - command_output_loss: 2.3402 - command_output_1_loss: 0.0019 - participant_output_1_loss: 0.0073 - participant_output_accuracy: 0.4625 - command_output_accuracy: 0.1163 - command_output_1_accuracy: 0.0000e+00 - participant_output_1_accuracy: 0.1063 - val_loss: 3.4207 - val_participant_output_loss: 1.1946 - val_command_output_loss: 2.2253 - val_command_output_1_loss: 4.1247e-04 - val_participant_output_1_loss: 3.4152e-04 - val_participant_output_accuracy: 0.5378 - val_command_output_accuracy: 0.3057 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - 2s 174ms/step - loss: 3.0785 - participant_output_loss: 0.8898 - command_output_loss: 2.1882 - command_output_1_loss: 3.1843e-04 - participant_output_1_loss: 2.2976e-04 - participant_output_accuracy: 0.7475 - command_output_accuracy: 0.4588 - command_output_1_accuracy: 0.0000e+00 - participant_output_1_accuracy: 0.0000e+00 - val_loss: 3.1059 - val_participant_output_loss: 0.9473 - val_command_output_loss: 2.1583 - val_command_output_1_loss: 2.2282e-04 - val_participant_output_1_loss: 7.6205e-05 - val_participant_output_accuracy: 0.7201 - val_command_output_accuracy: 0.6427 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.0331\n",
      "Epoch 3/10\n",
      "13/13 [==============================] - 2s 186ms/step - loss: 2.8049 - participant_output_loss: 0.6718 - command_output_loss: 2.1329 - command_output_1_loss: 1.8388e-04 - participant_output_1_loss: 5.7849e-05 - participant_output_accuracy: 0.8625 - command_output_accuracy: 0.6112 - command_output_1_accuracy: 0.0000e+00 - participant_output_1_accuracy: 0.1700 - val_loss: 2.8520 - val_participant_output_loss: 0.7470 - val_command_output_loss: 2.1048 - val_command_output_1_loss: 1.0867e-04 - val_participant_output_1_loss: 5.7307e-05 - val_participant_output_accuracy: 0.8600 - val_command_output_accuracy: 0.6243 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.2339\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - 3s 208ms/step - loss: 2.5959 - participant_output_loss: 0.5170 - command_output_loss: 2.0787 - command_output_1_loss: 1.0520e-04 - participant_output_1_loss: 3.1434e-05 - participant_output_accuracy: 0.9337 - command_output_accuracy: 0.7613 - command_output_1_accuracy: 0.0000e+00 - participant_output_1_accuracy: 0.2562 - val_loss: 2.6990 - val_participant_output_loss: 0.6416 - val_command_output_loss: 2.0572 - val_command_output_1_loss: 6.7591e-05 - val_participant_output_1_loss: 2.2277e-05 - val_participant_output_accuracy: 0.8711 - val_command_output_accuracy: 0.7477 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.2320\n",
      "Epoch 5/10\n",
      "13/13 [==============================] - 2s 186ms/step - loss: 2.4415 - participant_output_loss: 0.4168 - command_output_loss: 2.0247 - command_output_1_loss: 4.4449e-05 - participant_output_1_loss: 2.0767e-05 - participant_output_accuracy: 0.9575 - command_output_accuracy: 0.7875 - command_output_1_accuracy: 0.4075 - participant_output_1_accuracy: 0.0763 - val_loss: 2.5692 - val_participant_output_loss: 0.5600 - val_command_output_loss: 2.0091 - val_command_output_1_loss: 1.6916e-05 - val_participant_output_1_loss: 2.3153e-05 - val_participant_output_accuracy: 0.8987 - val_command_output_accuracy: 0.7937 - val_command_output_1_accuracy: 0.0203 - val_participant_output_1_accuracy: 0.0700\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - 2s 190ms/step - loss: 2.3148 - participant_output_loss: 0.3452 - command_output_loss: 1.9695 - command_output_1_loss: 3.3905e-05 - participant_output_1_loss: 2.2358e-05 - participant_output_accuracy: 0.9737 - command_output_accuracy: 0.8888 - command_output_1_accuracy: 0.0037 - participant_output_1_accuracy: 0.1275 - val_loss: 2.4168 - val_participant_output_loss: 0.4665 - val_command_output_loss: 1.9503 - val_command_output_1_loss: 3.6556e-05 - val_participant_output_1_loss: 2.3264e-05 - val_participant_output_accuracy: 0.9429 - val_command_output_accuracy: 0.8177 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.2284\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - 3s 201ms/step - loss: 2.2009 - participant_output_loss: 0.2883 - command_output_loss: 1.9125 - command_output_1_loss: 4.1694e-05 - participant_output_1_loss: 1.9209e-05 - participant_output_accuracy: 0.9862 - command_output_accuracy: 0.8763 - command_output_1_accuracy: 0.0000e+00 - participant_output_1_accuracy: 0.2113 - val_loss: 2.3250 - val_participant_output_loss: 0.4248 - val_command_output_loss: 1.9002 - val_command_output_1_loss: 2.9828e-05 - val_participant_output_1_loss: 2.2735e-05 - val_participant_output_accuracy: 0.9521 - val_command_output_accuracy: 0.9282 - val_command_output_1_accuracy: 0.0055 - val_participant_output_1_accuracy: 0.1823\n",
      "Epoch 8/10\n",
      "13/13 [==============================] - 2s 164ms/step - loss: 2.1069 - participant_output_loss: 0.2443 - command_output_loss: 1.8625 - command_output_1_loss: 5.1266e-05 - participant_output_1_loss: 1.9637e-05 - participant_output_accuracy: 0.9900 - command_output_accuracy: 0.9087 - command_output_1_accuracy: 0.0200 - participant_output_1_accuracy: 0.2300 - val_loss: 2.2381 - val_participant_output_loss: 0.3891 - val_command_output_loss: 1.8489 - val_command_output_1_loss: 3.3142e-05 - val_participant_output_1_loss: 2.3906e-05 - val_participant_output_accuracy: 0.9484 - val_command_output_accuracy: 0.8913 - val_command_output_1_accuracy: 0.0055 - val_participant_output_1_accuracy: 0.3333\n",
      "Epoch 9/10\n",
      "13/13 [==============================] - 2s 187ms/step - loss: 2.0144 - participant_output_loss: 0.2143 - command_output_loss: 1.8001 - command_output_1_loss: 3.0214e-05 - participant_output_1_loss: 1.9165e-05 - participant_output_accuracy: 0.9962 - command_output_accuracy: 0.9700 - command_output_1_accuracy: 0.0338 - participant_output_1_accuracy: 0.2000 - val_loss: 2.1462 - val_participant_output_loss: 0.3558 - val_command_output_loss: 1.7904 - val_command_output_1_loss: 2.5536e-05 - val_participant_output_1_loss: 2.2785e-05 - val_participant_output_accuracy: 0.9558 - val_command_output_accuracy: 0.9540 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.1547\n",
      "Epoch 10/10\n",
      "13/13 [==============================] - 2s 163ms/step - loss: 1.9307 - participant_output_loss: 0.1849 - command_output_loss: 1.7458 - command_output_1_loss: 5.4969e-05 - participant_output_1_loss: 1.9651e-05 - participant_output_accuracy: 0.9950 - command_output_accuracy: 0.9413 - command_output_1_accuracy: 0.0000e+00 - participant_output_1_accuracy: 0.2138 - val_loss: 2.0664 - val_participant_output_loss: 0.3246 - val_command_output_loss: 1.7418 - val_command_output_1_loss: 2.9357e-05 - val_participant_output_1_loss: 2.4176e-05 - val_participant_output_accuracy: 0.9558 - val_command_output_accuracy: 0.9484 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.2228\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 3s 231ms/step - loss: 1.8472 - participant_output_loss: 0.1633 - command_output_loss: 1.6839 - command_output_1_loss: 5.1185e-05 - participant_output_1_loss: 1.9771e-05 - participant_output_accuracy: 0.9975 - command_output_accuracy: 0.9825 - command_output_1_accuracy: 0.0000e+00 - participant_output_1_accuracy: 0.1800 - val_loss: 1.9917 - val_participant_output_loss: 0.3063 - val_command_output_loss: 1.6853 - val_command_output_1_loss: 6.4164e-05 - val_participant_output_1_loss: 2.4001e-05 - val_participant_output_accuracy: 0.9613 - val_command_output_accuracy: 0.9595 - val_command_output_1_accuracy: 0.0018 - val_participant_output_1_accuracy: 0.2413\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - 2s 179ms/step - loss: 1.7699 - participant_output_loss: 0.1426 - command_output_loss: 1.6272 - command_output_1_loss: 3.8674e-05 - participant_output_1_loss: 1.9546e-05 - participant_output_accuracy: 0.9987 - command_output_accuracy: 0.9900 - command_output_1_accuracy: 0.0012 - participant_output_1_accuracy: 0.1700 - val_loss: 1.9131 - val_participant_output_loss: 0.2790 - val_command_output_loss: 1.6342 - val_command_output_1_loss: 1.8635e-05 - val_participant_output_1_loss: 2.4195e-05 - val_participant_output_accuracy: 0.9669 - val_command_output_accuracy: 0.9632 - val_command_output_1_accuracy: 0.0166 - val_participant_output_1_accuracy: 0.1842\n",
      "Epoch 3/10\n",
      "13/13 [==============================] - 2s 172ms/step - loss: 1.6964 - participant_output_loss: 0.1247 - command_output_loss: 1.5717 - command_output_1_loss: 2.1881e-05 - participant_output_1_loss: 1.9305e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9900 - command_output_1_accuracy: 0.0512 - participant_output_1_accuracy: 0.2087 - val_loss: 1.8393 - val_participant_output_loss: 0.2608 - val_command_output_loss: 1.5784 - val_command_output_1_loss: 1.4170e-05 - val_participant_output_1_loss: 2.4621e-05 - val_participant_output_accuracy: 0.9650 - val_command_output_accuracy: 0.9669 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.1436\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - 2s 174ms/step - loss: 1.6277 - participant_output_loss: 0.1128 - command_output_loss: 1.5149 - command_output_1_loss: 4.8347e-05 - participant_output_1_loss: 1.8613e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9900 - command_output_1_accuracy: 0.0000e+00 - participant_output_1_accuracy: 0.1700 - val_loss: 1.7695 - val_participant_output_loss: 0.2431 - val_command_output_loss: 1.5263 - val_command_output_1_loss: 3.9112e-05 - val_participant_output_1_loss: 2.3284e-05 - val_participant_output_accuracy: 0.9650 - val_command_output_accuracy: 0.9742 - val_command_output_1_accuracy: 0.0129 - val_participant_output_1_accuracy: 0.2192\n",
      "Epoch 5/10\n",
      "13/13 [==============================] - 2s 146ms/step - loss: 1.5641 - participant_output_loss: 0.1033 - command_output_loss: 1.4607 - command_output_1_loss: 5.1681e-05 - participant_output_1_loss: 1.7570e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9962 - command_output_1_accuracy: 0.0037 - participant_output_1_accuracy: 0.1863 - val_loss: 1.7093 - val_participant_output_loss: 0.2346 - val_command_output_loss: 1.4747 - val_command_output_1_loss: 2.6774e-05 - val_participant_output_1_loss: 2.2668e-05 - val_participant_output_accuracy: 0.9650 - val_command_output_accuracy: 0.9724 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.1713\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - 2s 137ms/step - loss: 1.4944 - participant_output_loss: 0.0940 - command_output_loss: 1.4003 - command_output_1_loss: 3.7299e-05 - participant_output_1_loss: 1.6756e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9987 - command_output_1_accuracy: 0.0000e+00 - participant_output_1_accuracy: 0.1950 - val_loss: 1.6323 - val_participant_output_loss: 0.2141 - val_command_output_loss: 1.4181 - val_command_output_1_loss: 3.0382e-05 - val_participant_output_1_loss: 2.2355e-05 - val_participant_output_accuracy: 0.9705 - val_command_output_accuracy: 0.9687 - val_command_output_1_accuracy: 0.0037 - val_participant_output_1_accuracy: 0.1197\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - 2s 188ms/step - loss: 1.4283 - participant_output_loss: 0.0868 - command_output_loss: 1.3415 - command_output_1_loss: 3.5179e-05 - participant_output_1_loss: 1.6226e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9975 - command_output_1_accuracy: 0.4225 - participant_output_1_accuracy: 0.1675 - val_loss: 1.5608 - val_participant_output_loss: 0.2004 - val_command_output_loss: 1.3604 - val_command_output_1_loss: 2.5696e-05 - val_participant_output_1_loss: 2.1689e-05 - val_participant_output_accuracy: 0.9705 - val_command_output_accuracy: 0.9705 - val_command_output_1_accuracy: 0.0147 - val_participant_output_1_accuracy: 0.1989\n",
      "Epoch 8/10\n",
      "13/13 [==============================] - 2s 172ms/step - loss: 1.3640 - participant_output_loss: 0.0805 - command_output_loss: 1.2834 - command_output_1_loss: 7.6802e-05 - participant_output_1_loss: 1.5763e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9975 - command_output_1_accuracy: 0.0025 - participant_output_1_accuracy: 0.2075 - val_loss: 1.5036 - val_participant_output_loss: 0.1955 - val_command_output_loss: 1.3080 - val_command_output_1_loss: 5.1390e-05 - val_participant_output_1_loss: 2.1605e-05 - val_participant_output_accuracy: 0.9705 - val_command_output_accuracy: 0.9779 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.1547\n",
      "Epoch 9/10\n",
      "13/13 [==============================] - 2s 148ms/step - loss: 1.2994 - participant_output_loss: 0.0740 - command_output_loss: 1.2253 - command_output_1_loss: 4.9652e-05 - participant_output_1_loss: 1.5449e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9987 - command_output_1_accuracy: 0.0012 - participant_output_1_accuracy: 0.1975 - val_loss: 1.4451 - val_participant_output_loss: 0.1909 - val_command_output_loss: 1.2542 - val_command_output_1_loss: 4.7477e-05 - val_participant_output_1_loss: 2.1855e-05 - val_participant_output_accuracy: 0.9687 - val_command_output_accuracy: 0.9761 - val_command_output_1_accuracy: 0.0331 - val_participant_output_1_accuracy: 0.1860\n",
      "Epoch 10/10\n",
      "13/13 [==============================] - 2s 155ms/step - loss: 1.2351 - participant_output_loss: 0.0675 - command_output_loss: 1.1675 - command_output_1_loss: 3.3570e-05 - participant_output_1_loss: 1.5302e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9987 - command_output_1_accuracy: 0.0063 - participant_output_1_accuracy: 0.2050 - val_loss: 1.3891 - val_participant_output_loss: 0.1892 - val_command_output_loss: 1.1999 - val_command_output_1_loss: 2.6515e-05 - val_participant_output_1_loss: 2.0825e-05 - val_participant_output_accuracy: 0.9705 - val_command_output_accuracy: 0.9742 - val_command_output_1_accuracy: 0.0037 - val_participant_output_1_accuracy: 0.1547\n",
      "Epoch 1/10\n",
      "13/13 [==============================] - 4s 311ms/step - loss: 3.5750 - participant_output_loss: 1.4696 - command_output_loss: 2.1009 - command_output_1_loss: 9.1328e-04 - participant_output_1_loss: 0.0035 - participant_output_accuracy: 0.4613 - command_output_accuracy: 0.3738 - command_output_1_accuracy: 0.0413 - participant_output_1_accuracy: 0.1575 - val_loss: 3.1727 - val_participant_output_loss: 1.3057 - val_command_output_loss: 1.8666 - val_command_output_1_loss: 9.5445e-05 - val_participant_output_1_loss: 2.7039e-04 - val_participant_output_accuracy: 0.4383 - val_command_output_accuracy: 0.6906 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.1694\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - 2s 179ms/step - loss: 2.7381 - participant_output_loss: 0.9621 - command_output_loss: 1.7757 - command_output_1_loss: 1.0165e-04 - participant_output_1_loss: 1.6701e-04 - participant_output_accuracy: 0.7000 - command_output_accuracy: 0.8062 - command_output_1_accuracy: 0.0037 - participant_output_1_accuracy: 0.0388 - val_loss: 2.7600 - val_participant_output_loss: 1.0647 - val_command_output_loss: 1.6951 - val_command_output_1_loss: 5.7462e-05 - val_participant_output_1_loss: 8.6732e-05 - val_participant_output_accuracy: 0.6501 - val_command_output_accuracy: 0.8103 - val_command_output_1_accuracy: 0.0866 - val_participant_output_1_accuracy: 0.2357\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10\n",
      "13/13 [==============================] - 2s 170ms/step - loss: 2.3512 - participant_output_loss: 0.7613 - command_output_loss: 1.5897 - command_output_1_loss: 9.5052e-05 - participant_output_1_loss: 6.6275e-05 - participant_output_accuracy: 0.8125 - command_output_accuracy: 0.8988 - command_output_1_accuracy: 0.0312 - participant_output_1_accuracy: 0.1700 - val_loss: 2.4293 - val_participant_output_loss: 0.9131 - val_command_output_loss: 1.5161 - val_command_output_1_loss: 1.0728e-04 - val_participant_output_1_loss: 4.0592e-05 - val_participant_output_accuracy: 0.7145 - val_command_output_accuracy: 0.9079 - val_command_output_1_accuracy: 0.0221 - val_participant_output_1_accuracy: 0.1326\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - 2s 176ms/step - loss: 2.0529 - participant_output_loss: 0.6312 - command_output_loss: 1.4216 - command_output_1_loss: 7.4768e-05 - participant_output_1_loss: 3.5012e-05 - participant_output_accuracy: 0.8838 - command_output_accuracy: 0.9300 - command_output_1_accuracy: 0.0037 - participant_output_1_accuracy: 0.1838 - val_loss: 2.1634 - val_participant_output_loss: 0.7957 - val_command_output_loss: 1.3676 - val_command_output_1_loss: 6.0575e-05 - val_participant_output_1_loss: 3.3837e-05 - val_participant_output_accuracy: 0.7974 - val_command_output_accuracy: 0.9153 - val_command_output_1_accuracy: 0.0018 - val_participant_output_1_accuracy: 0.1160\n",
      "Epoch 5/10\n",
      "13/13 [==============================] - 2s 174ms/step - loss: 1.8110 - participant_output_loss: 0.5376 - command_output_loss: 1.2734 - command_output_1_loss: 6.8222e-05 - participant_output_1_loss: 2.9254e-05 - participant_output_accuracy: 0.9325 - command_output_accuracy: 0.9538 - command_output_1_accuracy: 0.0063 - participant_output_1_accuracy: 0.1637 - val_loss: 1.9182 - val_participant_output_loss: 0.6890 - val_command_output_loss: 1.2291 - val_command_output_1_loss: 9.8902e-05 - val_participant_output_1_loss: 2.9166e-05 - val_participant_output_accuracy: 0.8674 - val_command_output_accuracy: 0.9319 - val_command_output_1_accuracy: 0.0092 - val_participant_output_1_accuracy: 0.1915\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - 2s 162ms/step - loss: 1.5906 - participant_output_loss: 0.4595 - command_output_loss: 1.1310 - command_output_1_loss: 6.8356e-05 - participant_output_1_loss: 2.5080e-05 - participant_output_accuracy: 0.9600 - command_output_accuracy: 0.9700 - command_output_1_accuracy: 0.0000e+00 - participant_output_1_accuracy: 0.1412 - val_loss: 1.7131 - val_participant_output_loss: 0.6109 - val_command_output_loss: 1.1021 - val_command_output_1_loss: 4.6984e-05 - val_participant_output_1_loss: 2.7552e-05 - val_participant_output_accuracy: 0.8969 - val_command_output_accuracy: 0.9521 - val_command_output_1_accuracy: 0.0055 - val_participant_output_1_accuracy: 0.2707\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - 3s 193ms/step - loss: 1.4056 - participant_output_loss: 0.4075 - command_output_loss: 0.9980 - command_output_1_loss: 4.7629e-05 - participant_output_1_loss: 2.3652e-05 - participant_output_accuracy: 0.9712 - command_output_accuracy: 0.9800 - command_output_1_accuracy: 0.4200 - participant_output_1_accuracy: 0.2125 - val_loss: 1.5580 - val_participant_output_loss: 0.5678 - val_command_output_loss: 0.9901 - val_command_output_1_loss: 3.6903e-05 - val_participant_output_1_loss: 2.7177e-05 - val_participant_output_accuracy: 0.9042 - val_command_output_accuracy: 0.9540 - val_command_output_1_accuracy: 0.4088 - val_participant_output_1_accuracy: 0.1381\n",
      "Epoch 8/10\n",
      "13/13 [==============================] - 2s 188ms/step - loss: 1.2378 - participant_output_loss: 0.3587 - command_output_loss: 0.8790 - command_output_1_loss: 6.1228e-05 - participant_output_1_loss: 2.3846e-05 - participant_output_accuracy: 0.9800 - command_output_accuracy: 0.9925 - command_output_1_accuracy: 0.0625 - participant_output_1_accuracy: 0.1637 - val_loss: 1.3873 - val_participant_output_loss: 0.5141 - val_command_output_loss: 0.8731 - val_command_output_1_loss: 6.5442e-05 - val_participant_output_1_loss: 2.8266e-05 - val_participant_output_accuracy: 0.9282 - val_command_output_accuracy: 0.9650 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.1252\n",
      "Epoch 9/10\n",
      "13/13 [==============================] - 3s 200ms/step - loss: 1.0899 - participant_output_loss: 0.3217 - command_output_loss: 0.7681 - command_output_1_loss: 6.6786e-05 - participant_output_1_loss: 2.3420e-05 - participant_output_accuracy: 0.9837 - command_output_accuracy: 0.9962 - command_output_1_accuracy: 0.0000e+00 - participant_output_1_accuracy: 0.1825 - val_loss: 1.2516 - val_participant_output_loss: 0.4723 - val_command_output_loss: 0.7791 - val_command_output_1_loss: 4.3325e-05 - val_participant_output_1_loss: 2.7490e-05 - val_participant_output_accuracy: 0.9319 - val_command_output_accuracy: 0.9632 - val_command_output_1_accuracy: 0.0110 - val_participant_output_1_accuracy: 0.2063\n",
      "Epoch 10/10\n",
      "13/13 [==============================] - 2s 189ms/step - loss: 0.9576 - participant_output_loss: 0.2866 - command_output_loss: 0.6709 - command_output_1_loss: 4.3331e-05 - participant_output_1_loss: 2.2369e-05 - participant_output_accuracy: 0.9925 - command_output_accuracy: 0.9975 - command_output_1_accuracy: 0.0500 - participant_output_1_accuracy: 0.1775 - val_loss: 1.1336 - val_participant_output_loss: 0.4342 - val_command_output_loss: 0.6994 - val_command_output_1_loss: 4.1209e-05 - val_participant_output_1_loss: 2.7935e-05 - val_participant_output_accuracy: 0.9484 - val_command_output_accuracy: 0.9669 - val_command_output_1_accuracy: 0.0589 - val_participant_output_1_accuracy: 0.1823\n",
      "Epoch 1/10\n",
      "13/13 [==============================] - 3s 229ms/step - loss: 0.8369 - participant_output_loss: 0.2563 - command_output_loss: 0.5805 - command_output_1_loss: 3.3235e-05 - participant_output_1_loss: 2.1954e-05 - participant_output_accuracy: 0.9925 - command_output_accuracy: 0.9987 - command_output_1_accuracy: 0.1275 - participant_output_1_accuracy: 0.1875 - val_loss: 1.0284 - val_participant_output_loss: 0.4070 - val_command_output_loss: 0.6214 - val_command_output_1_loss: 2.4041e-05 - val_participant_output_1_loss: 2.7703e-05 - val_participant_output_accuracy: 0.9429 - val_command_output_accuracy: 0.9687 - val_command_output_1_accuracy: 0.0147 - val_participant_output_1_accuracy: 0.2118\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - 2s 172ms/step - loss: 0.7263 - participant_output_loss: 0.2225 - command_output_loss: 0.5037 - command_output_1_loss: 3.5778e-05 - participant_output_1_loss: 2.0896e-05 - participant_output_accuracy: 0.9975 - command_output_accuracy: 0.9987 - command_output_1_accuracy: 0.0037 - participant_output_1_accuracy: 0.1950 - val_loss: 0.9044 - val_participant_output_loss: 0.3557 - val_command_output_loss: 0.5486 - val_command_output_1_loss: 3.7083e-05 - val_participant_output_1_loss: 2.7615e-05 - val_participant_output_accuracy: 0.9613 - val_command_output_accuracy: 0.9687 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.1842\n",
      "Epoch 3/10\n",
      "13/13 [==============================] - 2s 172ms/step - loss: 0.6327 - participant_output_loss: 0.1959 - command_output_loss: 0.4368 - command_output_1_loss: 3.0390e-05 - participant_output_1_loss: 1.9906e-05 - participant_output_accuracy: 0.9975 - command_output_accuracy: 0.9987 - command_output_1_accuracy: 0.0075 - participant_output_1_accuracy: 0.1850 - val_loss: 0.8299 - val_participant_output_loss: 0.3377 - val_command_output_loss: 0.4922 - val_command_output_1_loss: 3.4051e-05 - val_participant_output_1_loss: 2.7698e-05 - val_participant_output_accuracy: 0.9613 - val_command_output_accuracy: 0.9724 - val_command_output_1_accuracy: 0.0737 - val_participant_output_1_accuracy: 0.1584\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - 2s 173ms/step - loss: 0.5477 - participant_output_loss: 0.1703 - command_output_loss: 0.3775 - command_output_1_loss: 2.5697e-05 - participant_output_1_loss: 1.9108e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9987 - command_output_1_accuracy: 0.1225 - participant_output_1_accuracy: 0.1825 - val_loss: 0.7551 - val_participant_output_loss: 0.3148 - val_command_output_loss: 0.4404 - val_command_output_1_loss: 2.2098e-05 - val_participant_output_1_loss: 2.6116e-05 - val_participant_output_accuracy: 0.9632 - val_command_output_accuracy: 0.9705 - val_command_output_1_accuracy: 0.0405 - val_participant_output_1_accuracy: 0.1842\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10\n",
      "13/13 [==============================] - 2s 173ms/step - loss: 0.4798 - participant_output_loss: 0.1511 - command_output_loss: 0.3286 - command_output_1_loss: 1.9624e-05 - participant_output_1_loss: 1.8126e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9987 - command_output_1_accuracy: 0.0200 - participant_output_1_accuracy: 0.2025 - val_loss: 0.6820 - val_participant_output_loss: 0.2873 - val_command_output_loss: 0.3947 - val_command_output_1_loss: 1.7911e-05 - val_participant_output_1_loss: 2.5598e-05 - val_participant_output_accuracy: 0.9632 - val_command_output_accuracy: 0.9742 - val_command_output_1_accuracy: 0.0203 - val_participant_output_1_accuracy: 0.1510\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - 2s 144ms/step - loss: 0.4198 - participant_output_loss: 0.1339 - command_output_loss: 0.2858 - command_output_1_loss: 1.7914e-05 - participant_output_1_loss: 1.7484e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9987 - command_output_1_accuracy: 0.0962 - participant_output_1_accuracy: 0.1825 - val_loss: 0.6203 - val_participant_output_loss: 0.2649 - val_command_output_loss: 0.3553 - val_command_output_1_loss: 1.8566e-05 - val_participant_output_1_loss: 2.5630e-05 - val_participant_output_accuracy: 0.9650 - val_command_output_accuracy: 0.9724 - val_command_output_1_accuracy: 0.0203 - val_participant_output_1_accuracy: 0.1971\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - 2s 185ms/step - loss: 0.3681 - participant_output_loss: 0.1203 - command_output_loss: 0.2478 - command_output_1_loss: 1.5912e-05 - participant_output_1_loss: 1.6552e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0075 - participant_output_1_accuracy: 0.1775 - val_loss: 0.5750 - val_participant_output_loss: 0.2558 - val_command_output_loss: 0.3192 - val_command_output_1_loss: 1.5054e-05 - val_participant_output_1_loss: 2.4220e-05 - val_participant_output_accuracy: 0.9669 - val_command_output_accuracy: 0.9724 - val_command_output_1_accuracy: 0.0110 - val_participant_output_1_accuracy: 0.1786\n",
      "Epoch 8/10\n",
      "13/13 [==============================] - 2s 191ms/step - loss: 0.3255 - participant_output_loss: 0.1092 - command_output_loss: 0.2163 - command_output_1_loss: 1.7666e-05 - participant_output_1_loss: 1.5880e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0650 - participant_output_1_accuracy: 0.1775 - val_loss: 0.5324 - val_participant_output_loss: 0.2412 - val_command_output_loss: 0.2912 - val_command_output_1_loss: 1.6931e-05 - val_participant_output_1_loss: 2.3803e-05 - val_participant_output_accuracy: 0.9669 - val_command_output_accuracy: 0.9742 - val_command_output_1_accuracy: 0.1713 - val_participant_output_1_accuracy: 0.1786\n",
      "Epoch 9/10\n",
      "13/13 [==============================] - 2s 160ms/step - loss: 0.2901 - participant_output_loss: 0.1005 - command_output_loss: 0.1895 - command_output_1_loss: 1.6835e-05 - participant_output_1_loss: 1.5087e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0575 - participant_output_1_accuracy: 0.1863 - val_loss: 0.5157 - val_participant_output_loss: 0.2477 - val_command_output_loss: 0.2680 - val_command_output_1_loss: 1.7956e-05 - val_participant_output_1_loss: 2.3185e-05 - val_participant_output_accuracy: 0.9632 - val_command_output_accuracy: 0.9761 - val_command_output_1_accuracy: 0.0074 - val_participant_output_1_accuracy: 0.1878\n",
      "Epoch 10/10\n",
      "13/13 [==============================] - 2s 154ms/step - loss: 0.2621 - participant_output_loss: 0.0943 - command_output_loss: 0.1677 - command_output_1_loss: 1.2296e-05 - participant_output_1_loss: 1.3964e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0700 - participant_output_1_accuracy: 0.2062 - val_loss: 0.4777 - val_participant_output_loss: 0.2305 - val_command_output_loss: 0.2471 - val_command_output_1_loss: 1.1400e-05 - val_participant_output_1_loss: 2.2321e-05 - val_participant_output_accuracy: 0.9650 - val_command_output_accuracy: 0.9742 - val_command_output_1_accuracy: 0.0755 - val_participant_output_1_accuracy: 0.1842\n",
      "Epoch 1/10\n",
      "13/13 [==============================] - 4s 290ms/step - loss: 3.5665 - participant_output_loss: 1.3387 - command_output_loss: 2.2188 - command_output_1_loss: 0.0019 - participant_output_1_loss: 0.0072 - participant_output_accuracy: 0.4525 - command_output_accuracy: 0.3100 - command_output_1_accuracy: 0.0000e+00 - participant_output_1_accuracy: 0.2313 - val_loss: 3.3227 - val_participant_output_loss: 1.2650 - val_command_output_loss: 2.0562 - val_command_output_1_loss: 6.7315e-04 - val_participant_output_1_loss: 7.9258e-04 - val_participant_output_accuracy: 0.4438 - val_command_output_accuracy: 0.6206 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.6593\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - 2s 168ms/step - loss: 2.8972 - participant_output_loss: 0.9020 - command_output_loss: 1.9943 - command_output_1_loss: 4.5251e-04 - participant_output_1_loss: 5.4029e-04 - participant_output_accuracy: 0.6913 - command_output_accuracy: 0.7337 - command_output_1_accuracy: 0.0000e+00 - participant_output_1_accuracy: 0.1037 - val_loss: 2.9040 - val_participant_output_loss: 0.9617 - val_command_output_loss: 1.9419 - val_command_output_1_loss: 2.5103e-04 - val_participant_output_1_loss: 1.3757e-04 - val_participant_output_accuracy: 0.6611 - val_command_output_accuracy: 0.7716 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.1326\n",
      "Epoch 3/10\n",
      "13/13 [==============================] - 2s 177ms/step - loss: 2.5282 - participant_output_loss: 0.6506 - command_output_loss: 1.8772 - command_output_1_loss: 2.0973e-04 - participant_output_1_loss: 1.6004e-04 - participant_output_accuracy: 0.8438 - command_output_accuracy: 0.8487 - command_output_1_accuracy: 0.0000e+00 - participant_output_1_accuracy: 0.0812 - val_loss: 2.5916 - val_participant_output_loss: 0.7594 - val_command_output_loss: 1.8319 - val_command_output_1_loss: 1.6615e-04 - val_participant_output_1_loss: 5.6773e-05 - val_participant_output_accuracy: 0.7864 - val_command_output_accuracy: 0.7974 - val_command_output_1_accuracy: 0.0037 - val_participant_output_1_accuracy: 0.0792\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - 2s 180ms/step - loss: 2.2486 - participant_output_loss: 0.4771 - command_output_loss: 1.7714 - command_output_1_loss: 1.2125e-04 - participant_output_1_loss: 6.0150e-05 - participant_output_accuracy: 0.9287 - command_output_accuracy: 0.8737 - command_output_1_accuracy: 0.0162 - participant_output_1_accuracy: 0.1800 - val_loss: 2.3262 - val_participant_output_loss: 0.5896 - val_command_output_loss: 1.7365 - val_command_output_1_loss: 3.5782e-05 - val_participant_output_1_loss: 5.2052e-05 - val_participant_output_accuracy: 0.8711 - val_command_output_accuracy: 0.8858 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.2670\n",
      "Epoch 5/10\n",
      "13/13 [==============================] - 2s 174ms/step - loss: 2.0258 - participant_output_loss: 0.3567 - command_output_loss: 1.6689 - command_output_1_loss: 9.8367e-05 - participant_output_1_loss: 4.3708e-05 - participant_output_accuracy: 0.9563 - command_output_accuracy: 0.9362 - command_output_1_accuracy: 0.0000e+00 - participant_output_1_accuracy: 0.2175 - val_loss: 2.1282 - val_participant_output_loss: 0.4861 - val_command_output_loss: 1.6419 - val_command_output_1_loss: 1.0146e-04 - val_participant_output_1_loss: 4.3481e-05 - val_participant_output_accuracy: 0.9190 - val_command_output_accuracy: 0.9042 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.1418\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - 2s 186ms/step - loss: 1.8510 - participant_output_loss: 0.2830 - command_output_loss: 1.5679 - command_output_1_loss: 9.1137e-05 - participant_output_1_loss: 3.4327e-05 - participant_output_accuracy: 0.9725 - command_output_accuracy: 0.9625 - command_output_1_accuracy: 0.0000e+00 - participant_output_1_accuracy: 0.1663 - val_loss: 1.9550 - val_participant_output_loss: 0.4084 - val_command_output_loss: 1.5465 - val_command_output_1_loss: 8.9260e-05 - val_participant_output_1_loss: 3.4646e-05 - val_participant_output_accuracy: 0.9429 - val_command_output_accuracy: 0.9466 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.2947\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10\n",
      "13/13 [==============================] - 3s 196ms/step - loss: 1.6857 - participant_output_loss: 0.2193 - command_output_loss: 1.4664 - command_output_1_loss: 8.4497e-05 - participant_output_1_loss: 3.0246e-05 - participant_output_accuracy: 0.9887 - command_output_accuracy: 0.9762 - command_output_1_accuracy: 0.0000e+00 - participant_output_1_accuracy: 0.2025 - val_loss: 1.7917 - val_participant_output_loss: 0.3430 - val_command_output_loss: 1.4486 - val_command_output_1_loss: 5.1189e-05 - val_participant_output_1_loss: 3.3126e-05 - val_participant_output_accuracy: 0.9484 - val_command_output_accuracy: 0.9558 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.1878\n",
      "Epoch 8/10\n",
      "13/13 [==============================] - 2s 150ms/step - loss: 1.5387 - participant_output_loss: 0.1727 - command_output_loss: 1.3659 - command_output_1_loss: 5.4358e-05 - participant_output_1_loss: 2.8470e-05 - participant_output_accuracy: 0.9950 - command_output_accuracy: 0.9850 - command_output_1_accuracy: 0.2075 - participant_output_1_accuracy: 0.2125 - val_loss: 1.6672 - val_participant_output_loss: 0.3030 - val_command_output_loss: 1.3641 - val_command_output_1_loss: 4.6899e-05 - val_participant_output_1_loss: 3.2496e-05 - val_participant_output_accuracy: 0.9613 - val_command_output_accuracy: 0.9411 - val_command_output_1_accuracy: 0.3149 - val_participant_output_1_accuracy: 0.2099\n",
      "Epoch 9/10\n",
      "13/13 [==============================] - 3s 193ms/step - loss: 1.4107 - participant_output_loss: 0.1436 - command_output_loss: 1.2670 - command_output_1_loss: 4.8273e-05 - participant_output_1_loss: 2.8230e-05 - participant_output_accuracy: 0.9975 - command_output_accuracy: 0.9925 - command_output_1_accuracy: 0.0613 - participant_output_1_accuracy: 0.2150 - val_loss: 1.5389 - val_participant_output_loss: 0.2769 - val_command_output_loss: 1.2619 - val_command_output_1_loss: 4.7134e-05 - val_participant_output_1_loss: 3.2626e-05 - val_participant_output_accuracy: 0.9650 - val_command_output_accuracy: 0.9613 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.1860\n",
      "Epoch 10/10\n",
      "13/13 [==============================] - 2s 159ms/step - loss: 1.2848 - participant_output_loss: 0.1184 - command_output_loss: 1.1664 - command_output_1_loss: 5.2405e-05 - participant_output_1_loss: 2.7249e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9925 - command_output_1_accuracy: 0.0025 - participant_output_1_accuracy: 0.1975 - val_loss: 1.4294 - val_participant_output_loss: 0.2501 - val_command_output_loss: 1.1792 - val_command_output_1_loss: 3.3853e-05 - val_participant_output_1_loss: 3.2247e-05 - val_participant_output_accuracy: 0.9613 - val_command_output_accuracy: 0.9650 - val_command_output_1_accuracy: 0.0460 - val_participant_output_1_accuracy: 0.2505\n",
      "Epoch 1/10\n",
      "13/13 [==============================] - 3s 218ms/step - loss: 1.1741 - participant_output_loss: 0.1030 - command_output_loss: 1.0711 - command_output_1_loss: 4.1229e-05 - participant_output_1_loss: 2.6234e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9937 - command_output_1_accuracy: 0.0850 - participant_output_1_accuracy: 0.2087 - val_loss: 1.3342 - val_participant_output_loss: 0.2476 - val_command_output_loss: 1.0865 - val_command_output_1_loss: 2.9315e-05 - val_participant_output_1_loss: 3.2315e-05 - val_participant_output_accuracy: 0.9669 - val_command_output_accuracy: 0.9650 - val_command_output_1_accuracy: 0.0460 - val_participant_output_1_accuracy: 0.2357\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - 2s 133ms/step - loss: 1.0745 - participant_output_loss: 0.0915 - command_output_loss: 0.9829 - command_output_1_loss: 4.1381e-05 - participant_output_1_loss: 2.5555e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9975 - command_output_1_accuracy: 0.0037 - participant_output_1_accuracy: 0.2125 - val_loss: 1.2225 - val_participant_output_loss: 0.2177 - val_command_output_loss: 1.0048 - val_command_output_1_loss: 3.6490e-05 - val_participant_output_1_loss: 3.1442e-05 - val_participant_output_accuracy: 0.9650 - val_command_output_accuracy: 0.9632 - val_command_output_1_accuracy: 0.0350 - val_participant_output_1_accuracy: 0.2394\n",
      "Epoch 3/10\n",
      "13/13 [==============================] - 2s 139ms/step - loss: 0.9778 - participant_output_loss: 0.0826 - command_output_loss: 0.8951 - command_output_1_loss: 4.4419e-05 - participant_output_1_loss: 2.4585e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9987 - command_output_1_accuracy: 0.6550 - participant_output_1_accuracy: 0.2050 - val_loss: 1.1378 - val_participant_output_loss: 0.2104 - val_command_output_loss: 0.9273 - val_command_output_1_loss: 3.1627e-05 - val_participant_output_1_loss: 3.1392e-05 - val_participant_output_accuracy: 0.9632 - val_command_output_accuracy: 0.9687 - val_command_output_1_accuracy: 0.1123 - val_participant_output_1_accuracy: 0.3002\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - 2s 134ms/step - loss: 0.8870 - participant_output_loss: 0.0730 - command_output_loss: 0.8139 - command_output_1_loss: 5.4035e-05 - participant_output_1_loss: 2.3970e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9987 - command_output_1_accuracy: 0.0037 - participant_output_1_accuracy: 0.2175 - val_loss: 1.0532 - val_participant_output_loss: 0.1949 - val_command_output_loss: 0.8582 - val_command_output_1_loss: 5.5401e-05 - val_participant_output_1_loss: 3.0527e-05 - val_participant_output_accuracy: 0.9650 - val_command_output_accuracy: 0.9613 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.2118\n",
      "Epoch 5/10\n",
      "13/13 [==============================] - 2s 137ms/step - loss: 0.8066 - participant_output_loss: 0.0665 - command_output_loss: 0.7400 - command_output_1_loss: 4.3487e-05 - participant_output_1_loss: 2.2653e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9987 - command_output_1_accuracy: 0.0950 - participant_output_1_accuracy: 0.2450 - val_loss: 0.9880 - val_participant_output_loss: 0.1943 - val_command_output_loss: 0.7937 - val_command_output_1_loss: 3.5855e-05 - val_participant_output_1_loss: 3.0532e-05 - val_participant_output_accuracy: 0.9650 - val_command_output_accuracy: 0.9669 - val_command_output_1_accuracy: 0.7459 - val_participant_output_1_accuracy: 0.1473\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - 2s 162ms/step - loss: 0.7321 - participant_output_loss: 0.0608 - command_output_loss: 0.6712 - command_output_1_loss: 4.0046e-05 - participant_output_1_loss: 2.2374e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9987 - command_output_1_accuracy: 0.4525 - participant_output_1_accuracy: 0.1875 - val_loss: 0.9006 - val_participant_output_loss: 0.1762 - val_command_output_loss: 0.7243 - val_command_output_1_loss: 3.4857e-05 - val_participant_output_1_loss: 3.0358e-05 - val_participant_output_accuracy: 0.9687 - val_command_output_accuracy: 0.9724 - val_command_output_1_accuracy: 0.1308 - val_participant_output_1_accuracy: 0.1694\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - 2s 135ms/step - loss: 0.6645 - participant_output_loss: 0.0562 - command_output_loss: 0.6082 - command_output_1_loss: 3.8676e-05 - participant_output_1_loss: 2.1242e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9987 - command_output_1_accuracy: 0.0562 - participant_output_1_accuracy: 0.2125 - val_loss: 0.8404 - val_participant_output_loss: 0.1718 - val_command_output_loss: 0.6685 - val_command_output_1_loss: 2.8236e-05 - val_participant_output_1_loss: 2.8798e-05 - val_participant_output_accuracy: 0.9632 - val_command_output_accuracy: 0.9705 - val_command_output_1_accuracy: 0.1529 - val_participant_output_1_accuracy: 0.1860\n",
      "Epoch 8/10\n",
      "13/13 [==============================] - 2s 138ms/step - loss: 0.6060 - participant_output_loss: 0.0522 - command_output_loss: 0.5537 - command_output_1_loss: 2.9337e-05 - participant_output_1_loss: 2.0259e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9987 - command_output_1_accuracy: 0.3363 - participant_output_1_accuracy: 0.2125 - val_loss: 0.7833 - val_participant_output_loss: 0.1658 - val_command_output_loss: 0.6175 - val_command_output_1_loss: 4.0216e-05 - val_participant_output_1_loss: 2.9099e-05 - val_participant_output_accuracy: 0.9669 - val_command_output_accuracy: 0.9724 - val_command_output_1_accuracy: 0.1436 - val_participant_output_1_accuracy: 0.1602\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10\n",
      "13/13 [==============================] - 2s 132ms/step - loss: 0.5531 - participant_output_loss: 0.0491 - command_output_loss: 0.5039 - command_output_1_loss: 5.1068e-05 - participant_output_1_loss: 1.9479e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9987 - command_output_1_accuracy: 0.0538 - participant_output_1_accuracy: 0.2025 - val_loss: 0.7337 - val_participant_output_loss: 0.1607 - val_command_output_loss: 0.5730 - val_command_output_1_loss: 3.9219e-05 - val_participant_output_1_loss: 2.7322e-05 - val_participant_output_accuracy: 0.9669 - val_command_output_accuracy: 0.9724 - val_command_output_1_accuracy: 0.0166 - val_participant_output_1_accuracy: 0.1823\n",
      "Epoch 10/10\n",
      "13/13 [==============================] - 2s 141ms/step - loss: 0.5036 - participant_output_loss: 0.0458 - command_output_loss: 0.4577 - command_output_1_loss: 3.6684e-05 - participant_output_1_loss: 1.8148e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9987 - command_output_1_accuracy: 0.0125 - participant_output_1_accuracy: 0.1875 - val_loss: 0.6913 - val_participant_output_loss: 0.1595 - val_command_output_loss: 0.5317 - val_command_output_1_loss: 2.8406e-05 - val_participant_output_1_loss: 2.6272e-05 - val_participant_output_accuracy: 0.9669 - val_command_output_accuracy: 0.9705 - val_command_output_1_accuracy: 0.0074 - val_participant_output_1_accuracy: 0.2394\n",
      "Epoch 1/10\n",
      "13/13 [==============================] - 4s 297ms/step - loss: 3.6192 - participant_output_loss: 1.3495 - command_output_loss: 2.2662 - command_output_1_loss: 8.8496e-04 - participant_output_1_loss: 0.0027 - participant_output_accuracy: 0.4688 - command_output_accuracy: 0.2225 - command_output_1_accuracy: 0.0012 - participant_output_1_accuracy: 0.1125 - val_loss: 3.3575 - val_participant_output_loss: 1.2728 - val_command_output_loss: 2.0842 - val_command_output_1_loss: 2.5850e-04 - val_participant_output_1_loss: 2.8577e-04 - val_participant_output_accuracy: 0.5230 - val_command_output_accuracy: 0.4788 - val_command_output_1_accuracy: 0.0110 - val_participant_output_1_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - 2s 176ms/step - loss: 2.9273 - participant_output_loss: 0.9019 - command_output_loss: 2.0251 - command_output_1_loss: 1.6247e-04 - participant_output_1_loss: 1.1969e-04 - participant_output_accuracy: 0.7150 - command_output_accuracy: 0.6363 - command_output_1_accuracy: 0.0113 - participant_output_1_accuracy: 0.4013 - val_loss: 2.9516 - val_participant_output_loss: 0.9680 - val_command_output_loss: 1.9834 - val_command_output_1_loss: 7.9359e-05 - val_participant_output_1_loss: 5.5625e-05 - val_participant_output_accuracy: 0.6667 - val_command_output_accuracy: 0.6280 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.1197\n",
      "Epoch 3/10\n",
      "13/13 [==============================] - 2s 172ms/step - loss: 2.6063 - participant_output_loss: 0.6804 - command_output_loss: 1.9258 - command_output_1_loss: 5.1433e-05 - participant_output_1_loss: 4.5645e-05 - participant_output_accuracy: 0.8325 - command_output_accuracy: 0.7638 - command_output_1_accuracy: 0.0000e+00 - participant_output_1_accuracy: 0.0712 - val_loss: 2.7145 - val_participant_output_loss: 0.8268 - val_command_output_loss: 1.8876 - val_command_output_1_loss: 3.8163e-05 - val_participant_output_1_loss: 3.1947e-05 - val_participant_output_accuracy: 0.7348 - val_command_output_accuracy: 0.8416 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.0902\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - 2s 175ms/step - loss: 2.3661 - participant_output_loss: 0.5385 - command_output_loss: 1.8274 - command_output_1_loss: 6.0646e-05 - participant_output_1_loss: 3.1647e-05 - participant_output_accuracy: 0.8938 - command_output_accuracy: 0.9087 - command_output_1_accuracy: 0.0000e+00 - participant_output_1_accuracy: 0.2887 - val_loss: 2.4833 - val_participant_output_loss: 0.6848 - val_command_output_loss: 1.7985 - val_command_output_1_loss: 6.5333e-05 - val_participant_output_1_loss: 2.9186e-05 - val_participant_output_accuracy: 0.8674 - val_command_output_accuracy: 0.8840 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.1492\n",
      "Epoch 5/10\n",
      "13/13 [==============================] - 2s 179ms/step - loss: 2.1826 - participant_output_loss: 0.4464 - command_output_loss: 1.7362 - command_output_1_loss: 6.5763e-05 - participant_output_1_loss: 2.5462e-05 - participant_output_accuracy: 0.9463 - command_output_accuracy: 0.9362 - command_output_1_accuracy: 0.0150 - participant_output_1_accuracy: 0.1538 - val_loss: 2.3034 - val_participant_output_loss: 0.5904 - val_command_output_loss: 1.7130 - val_command_output_1_loss: 4.3916e-05 - val_participant_output_1_loss: 2.4352e-05 - val_participant_output_accuracy: 0.9079 - val_command_output_accuracy: 0.9116 - val_command_output_1_accuracy: 0.1455 - val_participant_output_1_accuracy: 0.1602\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - 2s 168ms/step - loss: 2.0091 - participant_output_loss: 0.3657 - command_output_loss: 1.6433 - command_output_1_loss: 4.9904e-05 - participant_output_1_loss: 2.2773e-05 - participant_output_accuracy: 0.9675 - command_output_accuracy: 0.9563 - command_output_1_accuracy: 0.0400 - participant_output_1_accuracy: 0.2025 - val_loss: 2.1641 - val_participant_output_loss: 0.5333 - val_command_output_loss: 1.6307 - val_command_output_1_loss: 3.6995e-05 - val_participant_output_1_loss: 2.3340e-05 - val_participant_output_accuracy: 0.9024 - val_command_output_accuracy: 0.9190 - val_command_output_1_accuracy: 0.0110 - val_participant_output_1_accuracy: 0.1179\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - 2s 171ms/step - loss: 1.8603 - participant_output_loss: 0.3074 - command_output_loss: 1.5528 - command_output_1_loss: 3.2471e-05 - participant_output_1_loss: 2.0981e-05 - participant_output_accuracy: 0.9787 - command_output_accuracy: 0.9737 - command_output_1_accuracy: 0.1488 - participant_output_1_accuracy: 0.1813 - val_loss: 1.9923 - val_participant_output_loss: 0.4568 - val_command_output_loss: 1.5354 - val_command_output_1_loss: 2.8108e-05 - val_participant_output_1_loss: 2.2066e-05 - val_participant_output_accuracy: 0.9448 - val_command_output_accuracy: 0.9448 - val_command_output_1_accuracy: 0.3278 - val_participant_output_1_accuracy: 0.1676\n",
      "Epoch 8/10\n",
      "13/13 [==============================] - 2s 140ms/step - loss: 1.7320 - participant_output_loss: 0.2670 - command_output_loss: 1.4649 - command_output_1_loss: 6.5655e-05 - participant_output_1_loss: 1.9968e-05 - participant_output_accuracy: 0.9900 - command_output_accuracy: 0.9762 - command_output_1_accuracy: 0.0975 - participant_output_1_accuracy: 0.1462 - val_loss: 1.8754 - val_participant_output_loss: 0.4255 - val_command_output_loss: 1.4498 - val_command_output_1_loss: 3.3639e-05 - val_participant_output_1_loss: 2.1482e-05 - val_participant_output_accuracy: 0.9337 - val_command_output_accuracy: 0.9558 - val_command_output_1_accuracy: 0.0645 - val_participant_output_1_accuracy: 0.2044\n",
      "Epoch 9/10\n",
      "13/13 [==============================] - 2s 168ms/step - loss: 1.6101 - participant_output_loss: 0.2354 - command_output_loss: 1.3745 - command_output_1_loss: 9.4702e-05 - participant_output_1_loss: 1.9270e-05 - participant_output_accuracy: 0.9950 - command_output_accuracy: 0.9875 - command_output_1_accuracy: 0.0050 - participant_output_1_accuracy: 0.1875 - val_loss: 1.7515 - val_participant_output_loss: 0.3814 - val_command_output_loss: 1.3700 - val_command_output_1_loss: 6.2121e-05 - val_participant_output_1_loss: 2.1463e-05 - val_participant_output_accuracy: 0.9632 - val_command_output_accuracy: 0.9650 - val_command_output_1_accuracy: 0.0313 - val_participant_output_1_accuracy: 0.1731\n",
      "Epoch 10/10\n",
      "13/13 [==============================] - 2s 139ms/step - loss: 1.4849 - participant_output_loss: 0.2029 - command_output_loss: 1.2819 - command_output_1_loss: 4.8903e-05 - participant_output_1_loss: 1.8745e-05 - participant_output_accuracy: 0.9975 - command_output_accuracy: 0.9925 - command_output_1_accuracy: 0.2675 - participant_output_1_accuracy: 0.1825 - val_loss: 1.6400 - val_participant_output_loss: 0.3437 - val_command_output_loss: 1.2961 - val_command_output_1_loss: 1.0228e-04 - val_participant_output_1_loss: 2.1382e-05 - val_participant_output_accuracy: 0.9576 - val_command_output_accuracy: 0.9576 - val_command_output_1_accuracy: 0.0018 - val_participant_output_1_accuracy: 0.1878\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "13/13 [==============================] - 3s 248ms/step - loss: 1.3729 - participant_output_loss: 0.1722 - command_output_loss: 1.2006 - command_output_1_loss: 9.6160e-05 - participant_output_1_loss: 1.8361e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9925 - command_output_1_accuracy: 0.0012 - participant_output_1_accuracy: 0.1725 - val_loss: 1.5190 - val_participant_output_loss: 0.3067 - val_command_output_loss: 1.2123 - val_command_output_1_loss: 4.0370e-05 - val_participant_output_1_loss: 2.1190e-05 - val_participant_output_accuracy: 0.9650 - val_command_output_accuracy: 0.9595 - val_command_output_1_accuracy: 0.0055 - val_participant_output_1_accuracy: 0.2081\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - 2s 171ms/step - loss: 1.2665 - participant_output_loss: 0.1520 - command_output_loss: 1.1144 - command_output_1_loss: 8.4027e-05 - participant_output_1_loss: 1.8116e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9962 - command_output_1_accuracy: 0.0012 - participant_output_1_accuracy: 0.1950 - val_loss: 1.4177 - val_participant_output_loss: 0.2895 - val_command_output_loss: 1.1281 - val_command_output_1_loss: 6.2834e-05 - val_participant_output_1_loss: 2.2185e-05 - val_participant_output_accuracy: 0.9650 - val_command_output_accuracy: 0.9669 - val_command_output_1_accuracy: 0.0037 - val_participant_output_1_accuracy: 0.1473\n",
      "Epoch 3/10\n",
      "13/13 [==============================] - 2s 167ms/step - loss: 1.1588 - participant_output_loss: 0.1364 - command_output_loss: 1.0223 - command_output_1_loss: 4.3706e-05 - participant_output_1_loss: 1.8452e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9987 - command_output_1_accuracy: 0.0700 - participant_output_1_accuracy: 0.1925 - val_loss: 1.3161 - val_participant_output_loss: 0.2729 - val_command_output_loss: 1.0432 - val_command_output_1_loss: 4.7832e-05 - val_participant_output_1_loss: 2.1637e-05 - val_participant_output_accuracy: 0.9650 - val_command_output_accuracy: 0.9687 - val_command_output_1_accuracy: 0.1786 - val_participant_output_1_accuracy: 0.1510\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - 2s 151ms/step - loss: 1.0678 - participant_output_loss: 0.1244 - command_output_loss: 0.9434 - command_output_1_loss: 4.4033e-05 - participant_output_1_loss: 1.7452e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9987 - command_output_1_accuracy: 0.0325 - participant_output_1_accuracy: 0.1762 - val_loss: 1.2279 - val_participant_output_loss: 0.2529 - val_command_output_loss: 0.9749 - val_command_output_1_loss: 2.1752e-05 - val_participant_output_1_loss: 2.1489e-05 - val_participant_output_accuracy: 0.9650 - val_command_output_accuracy: 0.9613 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.2762\n",
      "Epoch 5/10\n",
      "13/13 [==============================] - 2s 186ms/step - loss: 0.9758 - participant_output_loss: 0.1125 - command_output_loss: 0.8632 - command_output_1_loss: 2.8936e-05 - participant_output_1_loss: 1.7565e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9987 - command_output_1_accuracy: 0.5775 - participant_output_1_accuracy: 0.1963 - val_loss: 1.1409 - val_participant_output_loss: 0.2430 - val_command_output_loss: 0.8978 - val_command_output_1_loss: 4.3597e-05 - val_participant_output_1_loss: 2.1508e-05 - val_participant_output_accuracy: 0.9687 - val_command_output_accuracy: 0.9687 - val_command_output_1_accuracy: 0.3904 - val_participant_output_1_accuracy: 0.2228\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - 2s 184ms/step - loss: 0.8872 - participant_output_loss: 0.0997 - command_output_loss: 0.7874 - command_output_1_loss: 5.1763e-05 - participant_output_1_loss: 1.7069e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9987 - command_output_1_accuracy: 0.0938 - participant_output_1_accuracy: 0.2037 - val_loss: 1.0572 - val_participant_output_loss: 0.2329 - val_command_output_loss: 0.8242 - val_command_output_1_loss: 2.8460e-05 - val_participant_output_1_loss: 2.1527e-05 - val_participant_output_accuracy: 0.9650 - val_command_output_accuracy: 0.9724 - val_command_output_1_accuracy: 0.0405 - val_participant_output_1_accuracy: 0.2063\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - 2s 155ms/step - loss: 0.8053 - participant_output_loss: 0.0908 - command_output_loss: 0.7144 - command_output_1_loss: 2.5294e-05 - participant_output_1_loss: 1.6326e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9987 - command_output_1_accuracy: 0.0000e+00 - participant_output_1_accuracy: 0.1875 - val_loss: 0.9825 - val_participant_output_loss: 0.2184 - val_command_output_loss: 0.7640 - val_command_output_1_loss: 3.9438e-05 - val_participant_output_1_loss: 2.1572e-05 - val_participant_output_accuracy: 0.9650 - val_command_output_accuracy: 0.9724 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.2855\n",
      "Epoch 8/10\n",
      "13/13 [==============================] - 2s 164ms/step - loss: 0.7364 - participant_output_loss: 0.0839 - command_output_loss: 0.6525 - command_output_1_loss: 3.9711e-05 - participant_output_1_loss: 1.6037e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9987 - command_output_1_accuracy: 0.0063 - participant_output_1_accuracy: 0.1950 - val_loss: 0.9150 - val_participant_output_loss: 0.2086 - val_command_output_loss: 0.7064 - val_command_output_1_loss: 1.7056e-05 - val_participant_output_1_loss: 2.1354e-05 - val_participant_output_accuracy: 0.9650 - val_command_output_accuracy: 0.9687 - val_command_output_1_accuracy: 0.0626 - val_participant_output_1_accuracy: 0.2670\n",
      "Epoch 9/10\n",
      "13/13 [==============================] - 2s 181ms/step - loss: 0.6719 - participant_output_loss: 0.0785 - command_output_loss: 0.5933 - command_output_1_loss: 2.9425e-05 - participant_output_1_loss: 1.5472e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9987 - command_output_1_accuracy: 0.0350 - participant_output_1_accuracy: 0.2050 - val_loss: 0.8440 - val_participant_output_loss: 0.1933 - val_command_output_loss: 0.6506 - val_command_output_1_loss: 1.9830e-05 - val_participant_output_1_loss: 2.1018e-05 - val_participant_output_accuracy: 0.9687 - val_command_output_accuracy: 0.9724 - val_command_output_1_accuracy: 0.0442 - val_participant_output_1_accuracy: 0.2099\n",
      "Epoch 10/10\n",
      "13/13 [==============================] - 2s 161ms/step - loss: 0.6107 - participant_output_loss: 0.0705 - command_output_loss: 0.5402 - command_output_1_loss: 2.6427e-05 - participant_output_1_loss: 1.4904e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9987 - command_output_1_accuracy: 0.0312 - participant_output_1_accuracy: 0.2175 - val_loss: 0.7836 - val_participant_output_loss: 0.1842 - val_command_output_loss: 0.5994 - val_command_output_1_loss: 8.5061e-06 - val_participant_output_1_loss: 2.0505e-05 - val_participant_output_accuracy: 0.9650 - val_command_output_accuracy: 0.9724 - val_command_output_1_accuracy: 0.1823 - val_participant_output_1_accuracy: 0.2247\n",
      "Epoch 1/10\n",
      "13/13 [==============================] - 4s 304ms/step - loss: 3.5436 - participant_output_loss: 1.3199 - command_output_loss: 2.2198 - command_output_1_loss: 4.0021e-04 - participant_output_1_loss: 0.0036 - participant_output_accuracy: 0.4875 - command_output_accuracy: 0.2288 - command_output_1_accuracy: 0.0213 - participant_output_1_accuracy: 0.3237 - val_loss: 3.2084 - val_participant_output_loss: 1.2105 - val_command_output_loss: 1.9976 - val_command_output_1_loss: 1.7708e-04 - val_participant_output_1_loss: 1.4796e-04 - val_participant_output_accuracy: 0.5230 - val_command_output_accuracy: 0.5341 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.1179\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - 2s 176ms/step - loss: 2.7809 - participant_output_loss: 0.8728 - command_output_loss: 1.9079 - command_output_1_loss: 9.8849e-05 - participant_output_1_loss: 1.8723e-04 - participant_output_accuracy: 0.7063 - command_output_accuracy: 0.6200 - command_output_1_accuracy: 0.0000e+00 - participant_output_1_accuracy: 0.1350 - val_loss: 2.7988 - val_participant_output_loss: 0.9497 - val_command_output_loss: 1.8490 - val_command_output_1_loss: 5.5702e-05 - val_participant_output_1_loss: 5.6495e-05 - val_participant_output_accuracy: 0.6740 - val_command_output_accuracy: 0.7311 - val_command_output_1_accuracy: 0.0055 - val_participant_output_1_accuracy: 0.4954\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10\n",
      "13/13 [==============================] - 2s 174ms/step - loss: 2.4375 - participant_output_loss: 0.6672 - command_output_loss: 1.7702 - command_output_1_loss: 7.5834e-05 - participant_output_1_loss: 5.9840e-05 - participant_output_accuracy: 0.8575 - command_output_accuracy: 0.7800 - command_output_1_accuracy: 0.1225 - participant_output_1_accuracy: 0.2150 - val_loss: 2.4660 - val_participant_output_loss: 0.7449 - val_command_output_loss: 1.7210 - val_command_output_1_loss: 7.9948e-05 - val_participant_output_1_loss: 4.5495e-05 - val_participant_output_accuracy: 0.8122 - val_command_output_accuracy: 0.8029 - val_command_output_1_accuracy: 0.2063 - val_participant_output_1_accuracy: 0.4604\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - 2s 172ms/step - loss: 2.1334 - participant_output_loss: 0.4931 - command_output_loss: 1.6401 - command_output_1_loss: 1.1831e-04 - participant_output_1_loss: 4.1071e-05 - participant_output_accuracy: 0.9162 - command_output_accuracy: 0.8650 - command_output_1_accuracy: 0.1088 - participant_output_1_accuracy: 0.2225 - val_loss: 2.2220 - val_participant_output_loss: 0.6179 - val_command_output_loss: 1.6039 - val_command_output_1_loss: 1.2132e-04 - val_participant_output_1_loss: 3.8744e-05 - val_participant_output_accuracy: 0.8527 - val_command_output_accuracy: 0.8656 - val_command_output_1_accuracy: 0.0221 - val_participant_output_1_accuracy: 0.0387\n",
      "Epoch 5/10\n",
      "13/13 [==============================] - 2s 185ms/step - loss: 1.8853 - participant_output_loss: 0.3705 - command_output_loss: 1.5147 - command_output_1_loss: 8.0477e-05 - participant_output_1_loss: 3.3552e-05 - participant_output_accuracy: 0.9450 - command_output_accuracy: 0.9463 - command_output_1_accuracy: 0.0113 - participant_output_1_accuracy: 0.2175 - val_loss: 1.9323 - val_participant_output_loss: 0.4434 - val_command_output_loss: 1.4888 - val_command_output_1_loss: 3.4269e-05 - val_participant_output_1_loss: 3.3770e-05 - val_participant_output_accuracy: 0.9319 - val_command_output_accuracy: 0.9116 - val_command_output_1_accuracy: 0.0295 - val_participant_output_1_accuracy: 0.1786\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - 3s 193ms/step - loss: 1.6578 - participant_output_loss: 0.2654 - command_output_loss: 1.3922 - command_output_1_loss: 5.2617e-05 - participant_output_1_loss: 3.0549e-05 - participant_output_accuracy: 0.9775 - command_output_accuracy: 0.9663 - command_output_1_accuracy: 0.0400 - participant_output_1_accuracy: 0.1762 - val_loss: 1.7178 - val_participant_output_loss: 0.3481 - val_command_output_loss: 1.3695 - val_command_output_1_loss: 4.4918e-05 - val_participant_output_1_loss: 3.1640e-05 - val_participant_output_accuracy: 0.9521 - val_command_output_accuracy: 0.9337 - val_command_output_1_accuracy: 0.0479 - val_participant_output_1_accuracy: 0.1989\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - 2s 182ms/step - loss: 1.4766 - participant_output_loss: 0.2063 - command_output_loss: 1.2703 - command_output_1_loss: 4.2216e-05 - participant_output_1_loss: 2.8317e-05 - participant_output_accuracy: 0.9837 - command_output_accuracy: 0.9762 - command_output_1_accuracy: 0.0388 - participant_output_1_accuracy: 0.1713 - val_loss: 1.5722 - val_participant_output_loss: 0.3072 - val_command_output_loss: 1.2650 - val_command_output_1_loss: 3.4443e-05 - val_participant_output_1_loss: 3.1115e-05 - val_participant_output_accuracy: 0.9503 - val_command_output_accuracy: 0.9392 - val_command_output_1_accuracy: 0.0203 - val_participant_output_1_accuracy: 0.2007\n",
      "Epoch 8/10\n",
      "13/13 [==============================] - 3s 198ms/step - loss: 1.3118 - participant_output_loss: 0.1576 - command_output_loss: 1.1541 - command_output_1_loss: 4.4400e-05 - participant_output_1_loss: 2.7402e-05 - participant_output_accuracy: 0.9900 - command_output_accuracy: 0.9900 - command_output_1_accuracy: 0.0175 - participant_output_1_accuracy: 0.1875 - val_loss: 1.4040 - val_participant_output_loss: 0.2547 - val_command_output_loss: 1.1492 - val_command_output_1_loss: 4.0803e-05 - val_participant_output_1_loss: 3.0192e-05 - val_participant_output_accuracy: 0.9595 - val_command_output_accuracy: 0.9540 - val_command_output_1_accuracy: 0.0534 - val_participant_output_1_accuracy: 0.2099\n",
      "Epoch 9/10\n",
      "13/13 [==============================] - 2s 192ms/step - loss: 1.1677 - participant_output_loss: 0.1232 - command_output_loss: 1.0444 - command_output_1_loss: 4.5576e-05 - participant_output_1_loss: 2.5944e-05 - participant_output_accuracy: 0.9962 - command_output_accuracy: 0.9937 - command_output_1_accuracy: 0.2438 - participant_output_1_accuracy: 0.1737 - val_loss: 1.2839 - val_participant_output_loss: 0.2262 - val_command_output_loss: 1.0576 - val_command_output_1_loss: 5.3006e-05 - val_participant_output_1_loss: 2.9588e-05 - val_participant_output_accuracy: 0.9669 - val_command_output_accuracy: 0.9558 - val_command_output_1_accuracy: 0.0571 - val_participant_output_1_accuracy: 0.1934\n",
      "Epoch 10/10\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 1.0425 - participant_output_loss: 0.1007 - command_output_loss: 0.9418 - command_output_1_loss: 3.9510e-05 - participant_output_1_loss: 2.5232e-05 - participant_output_accuracy: 0.9987 - command_output_accuracy: 0.9962 - command_output_1_accuracy: 0.1100 - participant_output_1_accuracy: 0.1600 - val_loss: 1.1538 - val_participant_output_loss: 0.1997 - val_command_output_loss: 0.9541 - val_command_output_1_loss: 4.0665e-05 - val_participant_output_1_loss: 2.8975e-05 - val_participant_output_accuracy: 0.9650 - val_command_output_accuracy: 0.9576 - val_command_output_1_accuracy: 0.0018 - val_participant_output_1_accuracy: 0.1713\n",
      "Epoch 1/10\n",
      "13/13 [==============================] - 3s 220ms/step - loss: 0.9269 - participant_output_loss: 0.0832 - command_output_loss: 0.8437 - command_output_1_loss: 6.3478e-05 - participant_output_1_loss: 2.4765e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9987 - command_output_1_accuracy: 0.0012 - participant_output_1_accuracy: 0.1550 - val_loss: 1.0460 - val_participant_output_loss: 0.1767 - val_command_output_loss: 0.8692 - val_command_output_1_loss: 3.6654e-05 - val_participant_output_1_loss: 2.8583e-05 - val_participant_output_accuracy: 0.9650 - val_command_output_accuracy: 0.9650 - val_command_output_1_accuracy: 0.0221 - val_participant_output_1_accuracy: 0.1639\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - 2s 173ms/step - loss: 0.8191 - participant_output_loss: 0.0702 - command_output_loss: 0.7489 - command_output_1_loss: 3.8593e-05 - participant_output_1_loss: 2.3749e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9987 - command_output_1_accuracy: 0.3050 - participant_output_1_accuracy: 0.1513 - val_loss: 0.9512 - val_participant_output_loss: 0.1677 - val_command_output_loss: 0.7835 - val_command_output_1_loss: 4.7352e-05 - val_participant_output_1_loss: 2.9042e-05 - val_participant_output_accuracy: 0.9687 - val_command_output_accuracy: 0.9687 - val_command_output_1_accuracy: 0.2891 - val_participant_output_1_accuracy: 0.1105\n",
      "Epoch 3/10\n",
      "13/13 [==============================] - 2s 158ms/step - loss: 0.7249 - participant_output_loss: 0.0600 - command_output_loss: 0.6648 - command_output_1_loss: 4.3210e-05 - participant_output_1_loss: 2.2872e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.1037 - participant_output_1_accuracy: 0.1612 - val_loss: 0.8762 - val_participant_output_loss: 0.1652 - val_command_output_loss: 0.7110 - val_command_output_1_loss: 2.6834e-05 - val_participant_output_1_loss: 2.8358e-05 - val_participant_output_accuracy: 0.9669 - val_command_output_accuracy: 0.9687 - val_command_output_1_accuracy: 0.0037 - val_participant_output_1_accuracy: 0.1418\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - 2s 168ms/step - loss: 0.6408 - participant_output_loss: 0.0516 - command_output_loss: 0.5891 - command_output_1_loss: 3.3426e-05 - participant_output_1_loss: 2.2003e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0050 - participant_output_1_accuracy: 0.1663 - val_loss: 0.7957 - val_participant_output_loss: 0.1542 - val_command_output_loss: 0.6415 - val_command_output_1_loss: 2.9898e-05 - val_participant_output_1_loss: 2.7901e-05 - val_participant_output_accuracy: 0.9687 - val_command_output_accuracy: 0.9705 - val_command_output_1_accuracy: 0.0147 - val_participant_output_1_accuracy: 0.1878\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10\n",
      "13/13 [==============================] - 2s 137ms/step - loss: 0.5694 - participant_output_loss: 0.0467 - command_output_loss: 0.5226 - command_output_1_loss: 3.9036e-05 - participant_output_1_loss: 2.1492e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0213 - participant_output_1_accuracy: 0.1525 - val_loss: 0.7352 - val_participant_output_loss: 0.1514 - val_command_output_loss: 0.5837 - val_command_output_1_loss: 3.0064e-05 - val_participant_output_1_loss: 2.7867e-05 - val_participant_output_accuracy: 0.9669 - val_command_output_accuracy: 0.9724 - val_command_output_1_accuracy: 0.0239 - val_participant_output_1_accuracy: 0.2597\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - 2s 167ms/step - loss: 0.5050 - participant_output_loss: 0.0423 - command_output_loss: 0.4627 - command_output_1_loss: 2.7774e-05 - participant_output_1_loss: 2.0682e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0413 - participant_output_1_accuracy: 0.1550 - val_loss: 0.6737 - val_participant_output_loss: 0.1485 - val_command_output_loss: 0.5251 - val_command_output_1_loss: 2.9478e-05 - val_participant_output_1_loss: 2.7232e-05 - val_participant_output_accuracy: 0.9687 - val_command_output_accuracy: 0.9742 - val_command_output_1_accuracy: 0.0589 - val_participant_output_1_accuracy: 0.2744\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - 2s 132ms/step - loss: 0.4482 - participant_output_loss: 0.0391 - command_output_loss: 0.4091 - command_output_1_loss: 2.4786e-05 - participant_output_1_loss: 1.9747e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0587 - participant_output_1_accuracy: 0.1688 - val_loss: 0.6181 - val_participant_output_loss: 0.1403 - val_command_output_loss: 0.4777 - val_command_output_1_loss: 2.0430e-05 - val_participant_output_1_loss: 2.6426e-05 - val_participant_output_accuracy: 0.9669 - val_command_output_accuracy: 0.9705 - val_command_output_1_accuracy: 0.0184 - val_participant_output_1_accuracy: 0.1786\n",
      "Epoch 8/10\n",
      "13/13 [==============================] - 2s 176ms/step - loss: 0.3986 - participant_output_loss: 0.0350 - command_output_loss: 0.3636 - command_output_1_loss: 2.0219e-05 - participant_output_1_loss: 1.8800e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0137 - participant_output_1_accuracy: 0.1663 - val_loss: 0.5682 - val_participant_output_loss: 0.1307 - val_command_output_loss: 0.4374 - val_command_output_1_loss: 2.0610e-05 - val_participant_output_1_loss: 2.5942e-05 - val_participant_output_accuracy: 0.9705 - val_command_output_accuracy: 0.9742 - val_command_output_1_accuracy: 0.0203 - val_participant_output_1_accuracy: 0.2063\n",
      "Epoch 9/10\n",
      "13/13 [==============================] - 2s 135ms/step - loss: 0.3563 - participant_output_loss: 0.0322 - command_output_loss: 0.3240 - command_output_1_loss: 1.8973e-05 - participant_output_1_loss: 1.8013e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0213 - participant_output_1_accuracy: 0.1625 - val_loss: 0.5235 - val_participant_output_loss: 0.1242 - val_command_output_loss: 0.3993 - val_command_output_1_loss: 1.6699e-05 - val_participant_output_1_loss: 2.5417e-05 - val_participant_output_accuracy: 0.9705 - val_command_output_accuracy: 0.9724 - val_command_output_1_accuracy: 0.0037 - val_participant_output_1_accuracy: 0.1860\n",
      "Epoch 10/10\n",
      "13/13 [==============================] - 2s 154ms/step - loss: 0.3181 - participant_output_loss: 0.0300 - command_output_loss: 0.2881 - command_output_1_loss: 1.9290e-05 - participant_output_1_loss: 1.6961e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0000e+00 - participant_output_1_accuracy: 0.1737 - val_loss: 0.4855 - val_participant_output_loss: 0.1214 - val_command_output_loss: 0.3640 - val_command_output_1_loss: 1.6523e-05 - val_participant_output_1_loss: 2.4887e-05 - val_participant_output_accuracy: 0.9705 - val_command_output_accuracy: 0.9742 - val_command_output_1_accuracy: 0.0018 - val_participant_output_1_accuracy: 0.1326\n"
     ]
    }
   ],
   "source": [
    "high_acc = 0\n",
    "for run in range(0,10):\n",
    "    # feature extraction layers\n",
    "    resnet_model = ResNet50(input_shape=(224, 224,3), include_top=False, weights=\"imagenet\")\n",
    "    for layer in resnet_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    d = resnet_model.output.shape[-1] # dimension of last layer\n",
    "\n",
    "    ###################### model 1 ###################### \n",
    "    layer_1_0 = tf.keras.layers.Dense(d,name=\"weight_1\")(resnet_model.output) #times weight before flatten\n",
    "    layer_1_1 = tf.keras.layers.Flatten(name='flatten_1')(layer_1_0)\n",
    "\n",
    "    Dense_1_1 = tf.keras.layers.Dense(shape_1_1, activation=actv_fun_1_1,name='fc1_1')\n",
    "    layer_1_2 = Dense_1_1(layer_1_1)\n",
    "    Dense_1_2 = tf.keras.layers.Dense(shape_1_2, activation=actv_fun_1_2,name='fc1_2')\n",
    "    layer_1_3 = Dense_1_2(layer_1_2)\n",
    "\n",
    "    Dense_1_3 = tf.keras.layers.Dense(train_number, activation='softmax' ,name='participant_output')\n",
    "    out_layer_1 = Dense_1_3(layer_1_3)\n",
    "\n",
    "    ###################### model 2 ###################### \n",
    "    layer_2_0 = tf.keras.layers.Dense(d,name=\"weight_2\")(resnet_model.output) #times weight before flatten\n",
    "    layer_2_1 = tf.keras.layers.Flatten(name='flatten_2')(layer_2_0)\n",
    "\n",
    "    Dense_2_1 = tf.keras.layers.Dense(shape_2_1, activation=actv_fun_2_1,name='fc2_1')\n",
    "    layer_2_2  = Dense_2_1(layer_2_1)\n",
    "    Dense_2_2 = tf.keras.layers.Dense(shape_2_2, activation=actv_fun_2_2,name='fc2_2')\n",
    "    layer_2_3  = Dense_2_2(layer_2_2)\n",
    "\n",
    "    Dense_2_3 = tf.keras.layers.Dense(10, activation='softmax',name='command_output')\n",
    "    out_layer_2 = Dense_2_3(layer_2_3)\n",
    "\n",
    "    ###################### model 1' ###################### \n",
    "    layer_1_2_  = Dense_2_1(layer_1_1)\n",
    "    layer_1_3_  = Dense_2_2(layer_1_2_)\n",
    "    out_layer_1_ = Dense_2_3(layer_1_3_)\n",
    "\n",
    "    ###################### model 1' ###################### \n",
    "    layer_2_2_  = Dense_1_1(layer_2_1)\n",
    "    layer_2_3_  = Dense_1_2(layer_2_2_)\n",
    "    out_layer_2_ = Dense_1_3(layer_2_3_)\n",
    "\n",
    "    resnet_model = tf.keras.Model(resnet_model.input, [out_layer_1,out_layer_2,out_layer_1_,out_layer_2_])\n",
    "\n",
    "\n",
    "    # resnet_model.summary() \n",
    "\n",
    "    w_1, w_2, w_1_, w_2_ = 1,1,1,1\n",
    "    ##################### training ############################\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "    callbacks = [MyEarlyStopping(monitor1 = 'val_' + resnet_model.layers[-1].name+'_accuracy',\n",
    "                                  monitor2 = 'val_' + resnet_model.layers[-2].name+'_accuracy',\n",
    "                                  patience=5,restore_best_weights=True)]\n",
    "    resnet_model.compile(optimizer=opt, loss=[\"categorical_crossentropy\",\"categorical_crossentropy\",\"mse\",\"mse\"],\n",
    "                         loss_weights=[w_1, w_2, w_1_, w_2_], metrics=['accuracy'])\n",
    "\n",
    "    \n",
    "    start = timeit.default_timer()\n",
    "       \n",
    "    history1 = resnet_model.fit(Train_Inputs, \n",
    "                           {resnet_model.layers[-2].name:Train_participant_class, \n",
    "                            resnet_model.layers[-1].name:Train_command_class,\n",
    "                            resnet_model.layers[-1].name+\"_1\":Train_command_uniform, \n",
    "                            resnet_model.layers[-2].name+\"_1\":Train_participant_uniform}, \n",
    "                            validation_data=(Val_Inputs,\n",
    "                                             {resnet_model.layers[-2].name:Val_participant_class,\n",
    "                                              resnet_model.layers[-1].name:Val_command_class,\n",
    "                                              resnet_model.layers[-1].name+\"_1\":Val_command_uniform,\n",
    "                                              resnet_model.layers[-2].name+\"_1\":Val_participant_uniform}), \n",
    "                           callbacks=callbacks,\n",
    "                           batch_size=64,\n",
    "                           epochs=10)\n",
    "    \n",
    "    for layer in resnet_model.layers[0:175]:\n",
    "        layer.trainable = True\n",
    "        \n",
    "    history2 = resnet_model.fit(Train_Inputs, \n",
    "                               {resnet_model.layers[-2].name:Train_participant_class, \n",
    "                                resnet_model.layers[-1].name:Train_command_class,\n",
    "                                resnet_model.layers[-1].name+\"_1\":Train_command_uniform, \n",
    "                                resnet_model.layers[-2].name+\"_1\":Train_participant_uniform}, \n",
    "                                validation_data=(Val_Inputs,\n",
    "                                                 {resnet_model.layers[-2].name:Val_participant_class,\n",
    "                                                  resnet_model.layers[-1].name:Val_command_class,\n",
    "                                                  resnet_model.layers[-1].name+\"_1\":Val_command_uniform,\n",
    "                                                  resnet_model.layers[-2].name+\"_1\":Val_participant_uniform}), \n",
    "                               callbacks=callbacks,\n",
    "                               batch_size=64,\n",
    "                               epochs=10)\n",
    "\n",
    "    stop = timeit.default_timer()\n",
    "    run_time = stop - start\n",
    "    \n",
    "    ##################### test performance ############################\n",
    "    predictions = resnet_model.predict(Test_Inputs)[0]\n",
    "    predicted_classes = np.argmax(predictions, axis=1)+1\n",
    "    true_classes = test_unit_participant_class\n",
    "    acc_p15_s = metrics.accuracy_score(true_classes, predicted_classes).round(4)\n",
    "\n",
    "    predictions = resnet_model.predict(Test_Inputs)[1]\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    true_classes = test_unit_command_class\n",
    "    acc_p15_c = metrics.accuracy_score(true_classes, predicted_classes).round(4)\n",
    "\n",
    "\n",
    "    # test on p1\n",
    "    ## speaker classification\n",
    "    predictions = resnet_model.predict(Test_Inputs_1)[0]\n",
    "    predicted_classes = np.argmax(predictions, axis=1)+1\n",
    "    true_classes = np.array([1]*len(predicted_classes))\n",
    "    acc_p1_s = metrics.accuracy_score(true_classes, predicted_classes).round(4)   \n",
    "    ## command classification\n",
    "    predictions = resnet_model.predict(Test_Inputs_1)[1]\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    true_classes = np.argmax(Test_command_class_1, axis=-1)\n",
    "    acc_p1_c = metrics.accuracy_score(true_classes, predicted_classes).round(4)   \n",
    "\n",
    "    # test on p2\n",
    "    ## speaker classification\n",
    "    predictions = resnet_model.predict(Test_Inputs_2)[0]\n",
    "    predicted_classes = np.argmax(predictions, axis=1)+1\n",
    "    true_classes = np.array([2]*len(predicted_classes))\n",
    "    acc_p2_s = metrics.accuracy_score(true_classes, predicted_classes).round(4)   \n",
    "    ## command classification\n",
    "    predictions = resnet_model.predict(Test_Inputs_2)[1]\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    true_classes = np.argmax(Test_command_class_2, axis=-1)\n",
    "    acc_p2_c = metrics.accuracy_score(true_classes, predicted_classes).round(4)   \n",
    "\n",
    "    # test on p3\n",
    "    ## speaker classification\n",
    "    predictions = resnet_model.predict(Test_Inputs_3)[0]\n",
    "    predicted_classes = np.argmax(predictions, axis=1)+1\n",
    "    true_classes = np.array([3]*len(predicted_classes))\n",
    "    acc_p3_s = metrics.accuracy_score(true_classes, predicted_classes).round(4)   \n",
    "    ## command classification\n",
    "    predictions = resnet_model.predict(Test_Inputs_3)[1]\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    true_classes = np.argmax(Test_command_class_3, axis=-1)\n",
    "    acc_p3_c = metrics.accuracy_score(true_classes, predicted_classes).round(4)   \n",
    "\n",
    "    # test on p4\n",
    "    ## speaker classification\n",
    "    predictions = resnet_model.predict(Test_Inputs_4)[0]\n",
    "    predicted_classes = np.argmax(predictions, axis=1)+1\n",
    "    true_classes = np.array([4]*len(predicted_classes))\n",
    "    acc_p4_s = metrics.accuracy_score(true_classes, predicted_classes).round(4)   \n",
    "    ## command classification\n",
    "    predictions = resnet_model.predict(Test_Inputs_4)[1]\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    true_classes = np.argmax(Test_command_class_4, axis=-1)\n",
    "    acc_p4_c = metrics.accuracy_score(true_classes, predicted_classes).round(4)   \n",
    "\n",
    "    # test on p5\n",
    "    ## speaker classification\n",
    "    predictions = resnet_model.predict(Test_Inputs_5)[0]\n",
    "    predicted_classes = np.argmax(predictions, axis=1)+1\n",
    "    true_classes = np.array([5]*len(predicted_classes))\n",
    "    acc_p5_s = metrics.accuracy_score(true_classes, predicted_classes).round(4)   \n",
    "    ## command classification\n",
    "    predictions = resnet_model.predict(Test_Inputs_5)[1]\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    true_classes = np.argmax(Test_command_class_5, axis=-1)\n",
    "    acc_p5_c = metrics.accuracy_score(true_classes, predicted_classes).round(4)   \n",
    "\n",
    "    # test on p6 \n",
    "    ## command classification\n",
    "    predictions = resnet_model.predict(Test_Inputs_6)[1]\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    true_classes = test_unit_command_class_6\n",
    "    acc_p6 = metrics.accuracy_score(true_classes, predicted_classes).round(4)                \n",
    "\n",
    "    # test on p7 \n",
    "    ## command classification\n",
    "    predictions = resnet_model.predict(Test_Inputs_7)[1]\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    true_classes = test_unit_command_class_7\n",
    "    acc_p7 = metrics.accuracy_score(true_classes, predicted_classes).round(4)    \n",
    "\n",
    "    # test on p8 \n",
    "    ## command classification\n",
    "    predictions = resnet_model.predict(Test_Inputs_8)[1]\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    true_classes = test_unit_command_class_8\n",
    "    acc_p8 = metrics.accuracy_score(true_classes, predicted_classes).round(4)    \n",
    "\n",
    "    Perfomance = Perfomance.append({'Model': \"Group\",'Size':'mix_20%&s1_60%&s2_40%','Time':run_time,\n",
    "                                    'Partcp_Acc_p15':acc_p15_s,'Command_Acc_p15':acc_p15_c,'Partcp_Acc_p1':acc_p1_s,\n",
    "                                    'Command_Acc_p1':acc_p1_c,'Partcp_Acc_p2':acc_p2_s,'Command_Acc_p2':acc_p2_c,\n",
    "                                    'Partcp_Acc_p3':acc_p3_s,'Command_Acc_p3':acc_p3_c,'Partcp_Acc_p4':acc_p4_s,\n",
    "                                    'Command_Acc_p4':acc_p4_c,'Partcp_Acc_p5':acc_p5_s,'Command_Acc_p5':acc_p5_c,\n",
    "                                    'Acc_p6':acc_p6,'Acc_p7':acc_p7,'Acc_p8':acc_p8}, ignore_index=True)\n",
    "\n",
    "\n",
    "    if high_acc < acc_p15_c + acc_p15_s:\n",
    "        resnet_model.save('Initial_group_model_mix_20p_s1(40p)_s2(60p)_0608.h5')\n",
    "        high_acc = acc_p15_c + acc_p15_s\n",
    "        best_index = run\n",
    "        pd.DataFrame.from_dict(history1.history).to_csv('mix_20p_s1(40p)_s2(60p)_history1_0608.csv',index=False)\n",
    "        pd.DataFrame.from_dict(history2.history).to_csv('mix_20p_s1(40p)_s2(60p)_history2_0608.csv',index=False)\n",
    "        \n",
    "    del resnet_model\n",
    "    run = run + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "0.9816 0.9724\n"
     ]
    }
   ],
   "source": [
    "resnet_model = tf.keras.models.load_model('Initial_group_model_mix_20p_s1(40p)_s2(60p)_0608.h5')\n",
    "predictions = resnet_model.predict(Test_Inputs)[0]\n",
    "predicted_classes = np.argmax(predictions, axis=1)+1\n",
    "acc_c = round(sum(x == y for x, y in zip(test_unit_participant_class, predicted_classes)) / len(test_unit_participant_class),4)\n",
    "\n",
    "predictions = resnet_model.predict(Test_Inputs)[1]\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "acc_s = round(sum(x == y for x, y in zip(test_unit_command_class, predicted_classes)) / len(test_unit_command_class),4)\n",
    "overall_acc = acc_c + acc_s\n",
    "print(acc_c,acc_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Size</th>\n",
       "      <th>Time</th>\n",
       "      <th>Partcp_Acc_p15</th>\n",
       "      <th>Command_Acc_p15</th>\n",
       "      <th>Partcp_Acc_p1</th>\n",
       "      <th>Command_Acc_p1</th>\n",
       "      <th>Partcp_Acc_p2</th>\n",
       "      <th>Command_Acc_p2</th>\n",
       "      <th>Partcp_Acc_p3</th>\n",
       "      <th>Command_Acc_p3</th>\n",
       "      <th>Partcp_Acc_p4</th>\n",
       "      <th>Command_Acc_p4</th>\n",
       "      <th>Partcp_Acc_p5</th>\n",
       "      <th>Command_Acc_p5</th>\n",
       "      <th>Acc_p6</th>\n",
       "      <th>Acc_p7</th>\n",
       "      <th>Acc_p8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Group</td>\n",
       "      <td>20%</td>\n",
       "      <td>47.540156</td>\n",
       "      <td>0.9724</td>\n",
       "      <td>0.9484</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.9550</td>\n",
       "      <td>0.9259</td>\n",
       "      <td>0.8796</td>\n",
       "      <td>0.9652</td>\n",
       "      <td>0.9565</td>\n",
       "      <td>0.9817</td>\n",
       "      <td>0.9633</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.528</td>\n",
       "      <td>0.3366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Group</td>\n",
       "      <td>20%</td>\n",
       "      <td>48.307249</td>\n",
       "      <td>0.9779</td>\n",
       "      <td>0.9521</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.9369</td>\n",
       "      <td>0.9352</td>\n",
       "      <td>0.8796</td>\n",
       "      <td>0.9739</td>\n",
       "      <td>0.9652</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.528</td>\n",
       "      <td>0.2970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Group</td>\n",
       "      <td>20%</td>\n",
       "      <td>46.201615</td>\n",
       "      <td>0.9613</td>\n",
       "      <td>0.9448</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.9369</td>\n",
       "      <td>0.9074</td>\n",
       "      <td>0.8611</td>\n",
       "      <td>0.9826</td>\n",
       "      <td>0.9652</td>\n",
       "      <td>0.9358</td>\n",
       "      <td>0.9725</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.432</td>\n",
       "      <td>0.2673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Group</td>\n",
       "      <td>20%</td>\n",
       "      <td>43.692362</td>\n",
       "      <td>0.9650</td>\n",
       "      <td>0.9521</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.9459</td>\n",
       "      <td>0.9074</td>\n",
       "      <td>0.8704</td>\n",
       "      <td>0.9826</td>\n",
       "      <td>0.9652</td>\n",
       "      <td>0.9358</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.504</td>\n",
       "      <td>0.2673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Group</td>\n",
       "      <td>20%</td>\n",
       "      <td>44.504580</td>\n",
       "      <td>0.9687</td>\n",
       "      <td>0.9484</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.9550</td>\n",
       "      <td>0.9259</td>\n",
       "      <td>0.8796</td>\n",
       "      <td>0.9739</td>\n",
       "      <td>0.9652</td>\n",
       "      <td>0.9541</td>\n",
       "      <td>0.9541</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.472</td>\n",
       "      <td>0.3267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Group</td>\n",
       "      <td>mix_20%&amp;s1_60%&amp;s2_40%</td>\n",
       "      <td>53.714297</td>\n",
       "      <td>0.9797</td>\n",
       "      <td>0.9687</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.9550</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9630</td>\n",
       "      <td>0.9826</td>\n",
       "      <td>0.9565</td>\n",
       "      <td>0.9358</td>\n",
       "      <td>0.9817</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.456</td>\n",
       "      <td>0.3366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>Group</td>\n",
       "      <td>mix_20%&amp;s1_60%&amp;s2_40%</td>\n",
       "      <td>54.407596</td>\n",
       "      <td>0.9761</td>\n",
       "      <td>0.9742</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.9730</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9722</td>\n",
       "      <td>0.9739</td>\n",
       "      <td>0.9565</td>\n",
       "      <td>0.9174</td>\n",
       "      <td>0.9817</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.2673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>Group</td>\n",
       "      <td>mix_20%&amp;s1_60%&amp;s2_40%</td>\n",
       "      <td>49.085995</td>\n",
       "      <td>0.9779</td>\n",
       "      <td>0.9687</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.9730</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9537</td>\n",
       "      <td>0.9565</td>\n",
       "      <td>0.9565</td>\n",
       "      <td>0.9541</td>\n",
       "      <td>0.9817</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.2970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Group</td>\n",
       "      <td>mix_20%&amp;s1_60%&amp;s2_40%</td>\n",
       "      <td>51.799617</td>\n",
       "      <td>0.9779</td>\n",
       "      <td>0.9724</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.9820</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9537</td>\n",
       "      <td>0.9478</td>\n",
       "      <td>0.9565</td>\n",
       "      <td>0.9541</td>\n",
       "      <td>0.9817</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.488</td>\n",
       "      <td>0.2673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>Group</td>\n",
       "      <td>mix_20%&amp;s1_60%&amp;s2_40%</td>\n",
       "      <td>52.066547</td>\n",
       "      <td>0.9779</td>\n",
       "      <td>0.9742</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.9640</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9722</td>\n",
       "      <td>0.9478</td>\n",
       "      <td>0.9652</td>\n",
       "      <td>0.9541</td>\n",
       "      <td>0.9725</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.448</td>\n",
       "      <td>0.3564</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Model                   Size       Time  Partcp_Acc_p15  Command_Acc_p15  \\\n",
       "0   Group                    20%  47.540156          0.9724           0.9484   \n",
       "1   Group                    20%  48.307249          0.9779           0.9521   \n",
       "2   Group                    20%  46.201615          0.9613           0.9448   \n",
       "3   Group                    20%  43.692362          0.9650           0.9521   \n",
       "4   Group                    20%  44.504580          0.9687           0.9484   \n",
       "..    ...                    ...        ...             ...              ...   \n",
       "65  Group  mix_20%&s1_60%&s2_40%  53.714297          0.9797           0.9687   \n",
       "66  Group  mix_20%&s1_60%&s2_40%  54.407596          0.9761           0.9742   \n",
       "67  Group  mix_20%&s1_60%&s2_40%  49.085995          0.9779           0.9687   \n",
       "68  Group  mix_20%&s1_60%&s2_40%  51.799617          0.9779           0.9724   \n",
       "69  Group  mix_20%&s1_60%&s2_40%  52.066547          0.9779           0.9742   \n",
       "\n",
       "    Partcp_Acc_p1  Command_Acc_p1  Partcp_Acc_p2  Command_Acc_p2  \\\n",
       "0           0.991          0.9550         0.9259          0.8796   \n",
       "1           1.000          0.9369         0.9352          0.8796   \n",
       "2           0.991          0.9369         0.9074          0.8611   \n",
       "3           1.000          0.9459         0.9074          0.8704   \n",
       "4           0.991          0.9550         0.9259          0.8796   \n",
       "..            ...             ...            ...             ...   \n",
       "65          0.991          0.9550         1.0000          0.9630   \n",
       "66          1.000          0.9730         1.0000          0.9722   \n",
       "67          0.991          0.9730         1.0000          0.9537   \n",
       "68          0.991          0.9820         1.0000          0.9537   \n",
       "69          1.000          0.9640         1.0000          0.9722   \n",
       "\n",
       "    Partcp_Acc_p3  Command_Acc_p3  Partcp_Acc_p4  Command_Acc_p4  \\\n",
       "0          0.9652          0.9565         0.9817          0.9633   \n",
       "1          0.9739          0.9652         0.9908          0.9908   \n",
       "2          0.9826          0.9652         0.9358          0.9725   \n",
       "3          0.9826          0.9652         0.9358          0.9908   \n",
       "4          0.9739          0.9652         0.9541          0.9541   \n",
       "..            ...             ...            ...             ...   \n",
       "65         0.9826          0.9565         0.9358          0.9817   \n",
       "66         0.9739          0.9565         0.9174          0.9817   \n",
       "67         0.9565          0.9565         0.9541          0.9817   \n",
       "68         0.9478          0.9565         0.9541          0.9817   \n",
       "69         0.9478          0.9652         0.9541          0.9725   \n",
       "\n",
       "    Partcp_Acc_p5  Command_Acc_p5  Acc_p6  Acc_p7  Acc_p8  \n",
       "0            1.00            0.99    0.67   0.528  0.3366  \n",
       "1            0.99            0.99    0.59   0.528  0.2970  \n",
       "2            0.99            0.99    0.67   0.432  0.2673  \n",
       "3            1.00            0.99    0.62   0.504  0.2673  \n",
       "4            1.00            0.99    0.59   0.472  0.3267  \n",
       "..            ...             ...     ...     ...     ...  \n",
       "65           0.99            0.99    0.69   0.456  0.3366  \n",
       "66           0.99            0.99    0.68   0.440  0.2673  \n",
       "67           0.99            0.98    0.59   0.440  0.2970  \n",
       "68           1.00            0.99    0.70   0.488  0.2673  \n",
       "69           0.99            1.00    0.65   0.448  0.3564  \n",
       "\n",
       "[70 rows x 18 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Perfomance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "Perfomance.to_csv('Performance_0608_training_Data_Size.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
