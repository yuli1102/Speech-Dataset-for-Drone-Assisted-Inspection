{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"   #(xxxx is your specific GPU ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.layers import Activation, Dense, Flatten, GlobalAveragePooling2D\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Sequential\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "# from MyEarlyStopping import MyEarlyStopping\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "# from keras.optimizers import adam\n",
    "\n",
    "import timeit\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.preprocessing import LabelEncoder  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training dataset (40%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1714 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "train_generator = train_data.flow_from_directory('/data/home/cou/yuli5/semg/Audio_MEL_Data/train',\n",
    "                                                batch_size=1,\n",
    "                                                target_size=(224,224),\n",
    "                                                class_mode='categorical',\n",
    "                                               shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_names = train_generator.filenames\n",
    "image_no = [i.split(\"/\")[1].split(\"_\")[2].split(\".\")[0] for i in image_names]\n",
    "image_no = np.array(list(map(int, image_no)))\n",
    "ALL_participant_class = [i.split(\"/\")[1].split(\"_\")[1] for i in image_names]\n",
    "ALL_participant_class = np.array(list(map(int, ALL_participant_class)))\n",
    "command_class = train_generator.classes\n",
    "All_command_class = tf.keras.utils.to_categorical(command_class, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "All_Inputs = [next(train_generator)[0][0] for _ in range(len(train_generator))]\n",
    "All_Inputs = np.array(All_Inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = 3\n",
    "train_image = 10 #10:20%, 20: 40%, 30:60%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10., 10., 10., 10., 10., 10., 10., 10., 10., 10.], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_indexs_train = (image_no<train_image)&(ALL_participant_class==subject)\n",
    "Train_Inputs = All_Inputs[select_indexs_train]\n",
    "Train_command_class = All_command_class[select_indexs_train]\n",
    "sum(Train_command_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation dataset (20%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 543 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "val_data = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "val_generator = val_data.flow_from_directory('/data/home/cou/yuli5/semg/Audio_MEL_Data/validation',\n",
    "                                                batch_size=1,\n",
    "                                                target_size=(224,224),\n",
    "                                                class_mode='categorical',\n",
    "                                               shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_names = val_generator.filenames\n",
    "participant_class = [i.split(\"/\", 1)[1].split(\"_\")[1] for i in image_names]\n",
    "participant_class = np.array(list(map(int, participant_class)))\n",
    "command_class = val_generator.classes\n",
    "Val_command_class = tf.keras.utils.to_categorical(command_class, num_classes=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_Val_Inputs = [next(val_generator)[0][0] for _ in range(len(val_generator))]\n",
    "ALL_Val_Inputs = np.array(ALL_Val_Inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11., 11., 13., 11., 14., 11., 11., 10., 11., 12.], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_indexs_val = participant_class==subject\n",
    "Val_Inputs = ALL_Val_Inputs[select_indexs_val]\n",
    "Val_command_class = Val_command_class[select_indexs_val]\n",
    "sum(Val_command_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test dataset (20%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 543 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "test_data = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "test_generator = test_data.flow_from_directory('/data/home/cou/yuli5/semg/Audio_MEL_Data/test',\n",
    "                                                batch_size=1,\n",
    "                                                target_size=(224,224),\n",
    "                                                class_mode='categorical',\n",
    "                                                shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_names = test_generator.filenames\n",
    "participant_class = [i.split(\"/\", 1)[1].split(\"_\")[1] for i in image_names]\n",
    "test_unit_participant_class = np.array(list(map(int, participant_class)))\n",
    "test_unit_command_class = test_generator.classes\n",
    "Test_command_class = tf.keras.utils.to_categorical(test_unit_command_class, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_Inputs = [next(test_generator)[0][0] for _ in range(len(test_generator))]\n",
    "Test_Inputs = np.array(Test_Inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_Inputs_1 = Test_Inputs[np.where(test_unit_participant_class == 1)]\n",
    "Test_command_class_1 = Test_command_class[np.where(test_unit_participant_class == 1)]\n",
    "Test_Inputs_2 = Test_Inputs[np.where(test_unit_participant_class == 2)]\n",
    "Test_command_class_2 = Test_command_class[np.where(test_unit_participant_class == 2)]\n",
    "Test_Inputs_3 = Test_Inputs[np.where(test_unit_participant_class == 3)]\n",
    "Test_command_class_3 = Test_command_class[np.where(test_unit_participant_class == 3)]\n",
    "Test_Inputs_4 = Test_Inputs[np.where(test_unit_participant_class == 4)]\n",
    "Test_command_class_4 = Test_command_class[np.where(test_unit_participant_class == 4)]\n",
    "Test_Inputs_5 = Test_Inputs[np.where(test_unit_participant_class == 5)]\n",
    "Test_command_class_5 = Test_command_class[np.where(test_unit_participant_class == 5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum(Test_command_class_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speaker 6 Test dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "test_data_6 = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "test_generator_6 = test_data_6.flow_from_directory('/data/home/cou/yuli5/semg/Audio_MEL_subject/p_6_split/test',\n",
    "                                                batch_size=1,\n",
    "                                                target_size=(224,224),\n",
    "                                                class_mode='categorical',\n",
    "                                                shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_names = test_generator_6.filenames\n",
    "command_class = [i.split(\"/\", 1)[0]for i in image_names]\n",
    "le = LabelEncoder()\n",
    "test_unit_command_class_6 = le.fit_transform(command_class)\n",
    "Test_command_class_6 = tf.keras.utils.to_categorical(test_unit_command_class_6, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_Inputs_6 = [next(test_generator_6)[0][0] for _ in range(len(test_generator_6))]\n",
    "Test_Inputs_6 = np.array(Test_Inputs_6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speaker 7 Test dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 125 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "test_data_7 = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "test_generator_7 = test_data_6.flow_from_directory('/data/home/cou/yuli5/semg/Audio_MEL_subject/p_7_split/test',\n",
    "                                                batch_size=1,\n",
    "                                                target_size=(224,224),\n",
    "                                                class_mode='categorical',\n",
    "                                                shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_names = test_generator_7.filenames\n",
    "command_class = [i.split(\"/\", 1)[0]for i in image_names]\n",
    "le = LabelEncoder()\n",
    "test_unit_command_class_7 = le.fit_transform(command_class)\n",
    "Test_command_class_7 = tf.keras.utils.to_categorical(test_unit_command_class_7, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_Inputs_7 = [next(test_generator_7)[0][0] for _ in range(len(test_generator_7))]\n",
    "Test_Inputs_7 = np.array(Test_Inputs_7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speaker 8 Test dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 101 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "test_data_8 = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "test_generator_8 = test_data_6.flow_from_directory('/data/home/cou/yuli5/semg/Audio_MEL_subject/p_8_split/test',\n",
    "                                                batch_size=1,\n",
    "                                                target_size=(224,224),\n",
    "                                                class_mode='categorical',\n",
    "                                                shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_names = test_generator_8.filenames\n",
    "command_class = [i.split(\"/\", 1)[0]for i in image_names]\n",
    "le = LabelEncoder()\n",
    "test_unit_command_class_8 = le.fit_transform(command_class)\n",
    "Test_command_class_8 = tf.keras.utils.to_categorical(test_unit_command_class_8, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_Inputs_8 = [next(test_generator_8)[0][0] for _ in range(len(test_generator_8))]\n",
    "Test_Inputs_8 = np.array(Test_Inputs_8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pd file store performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Time</th>\n",
       "      <th>Command_Acc_p15</th>\n",
       "      <th>Command_Acc_p1</th>\n",
       "      <th>Command_Acc_p2</th>\n",
       "      <th>Command_Acc_p3</th>\n",
       "      <th>Command_Acc_p4</th>\n",
       "      <th>Command_Acc_p5</th>\n",
       "      <th>Acc_p6</th>\n",
       "      <th>Acc_p7</th>\n",
       "      <th>Acc_p8</th>\n",
       "      <th>Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Subjet_1</td>\n",
       "      <td>15.269878</td>\n",
       "      <td>0.6243</td>\n",
       "      <td>0.9369</td>\n",
       "      <td>0.3889</td>\n",
       "      <td>0.5391</td>\n",
       "      <td>0.6239</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.384</td>\n",
       "      <td>0.2673</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Subjet_1</td>\n",
       "      <td>12.062418</td>\n",
       "      <td>0.5709</td>\n",
       "      <td>0.9189</td>\n",
       "      <td>0.3148</td>\n",
       "      <td>0.4696</td>\n",
       "      <td>0.5413</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.2673</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Subjet_1</td>\n",
       "      <td>13.520935</td>\n",
       "      <td>0.6335</td>\n",
       "      <td>0.9550</td>\n",
       "      <td>0.3889</td>\n",
       "      <td>0.5478</td>\n",
       "      <td>0.6514</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.384</td>\n",
       "      <td>0.2475</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Subjet_1</td>\n",
       "      <td>14.664869</td>\n",
       "      <td>0.6225</td>\n",
       "      <td>0.9550</td>\n",
       "      <td>0.2685</td>\n",
       "      <td>0.5217</td>\n",
       "      <td>0.6789</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.456</td>\n",
       "      <td>0.2970</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Subjet_1</td>\n",
       "      <td>13.347304</td>\n",
       "      <td>0.6188</td>\n",
       "      <td>0.9279</td>\n",
       "      <td>0.3796</td>\n",
       "      <td>0.5652</td>\n",
       "      <td>0.5780</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.416</td>\n",
       "      <td>0.2574</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Subjet_1</td>\n",
       "      <td>14.131006</td>\n",
       "      <td>0.5672</td>\n",
       "      <td>0.9279</td>\n",
       "      <td>0.2870</td>\n",
       "      <td>0.4696</td>\n",
       "      <td>0.5780</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.2673</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Subjet_1</td>\n",
       "      <td>13.651466</td>\n",
       "      <td>0.5930</td>\n",
       "      <td>0.9459</td>\n",
       "      <td>0.2685</td>\n",
       "      <td>0.5130</td>\n",
       "      <td>0.6239</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.2673</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Subjet_1</td>\n",
       "      <td>12.100064</td>\n",
       "      <td>0.5727</td>\n",
       "      <td>0.9279</td>\n",
       "      <td>0.2870</td>\n",
       "      <td>0.4957</td>\n",
       "      <td>0.5413</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.384</td>\n",
       "      <td>0.2574</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Subjet_1</td>\n",
       "      <td>13.176442</td>\n",
       "      <td>0.6151</td>\n",
       "      <td>0.9459</td>\n",
       "      <td>0.3611</td>\n",
       "      <td>0.4957</td>\n",
       "      <td>0.6147</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.408</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Subjet_1</td>\n",
       "      <td>13.929373</td>\n",
       "      <td>0.6446</td>\n",
       "      <td>0.9369</td>\n",
       "      <td>0.4722</td>\n",
       "      <td>0.5391</td>\n",
       "      <td>0.6147</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.408</td>\n",
       "      <td>0.2673</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Subjet_1</td>\n",
       "      <td>15.902663</td>\n",
       "      <td>0.6409</td>\n",
       "      <td>0.9820</td>\n",
       "      <td>0.3704</td>\n",
       "      <td>0.5565</td>\n",
       "      <td>0.6514</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.2178</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Subjet_1</td>\n",
       "      <td>13.805319</td>\n",
       "      <td>0.6538</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.3519</td>\n",
       "      <td>0.5913</td>\n",
       "      <td>0.6697</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.2277</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Subjet_1</td>\n",
       "      <td>15.685424</td>\n",
       "      <td>0.6298</td>\n",
       "      <td>0.9820</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.5391</td>\n",
       "      <td>0.6422</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.408</td>\n",
       "      <td>0.2277</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Subjet_1</td>\n",
       "      <td>16.194757</td>\n",
       "      <td>0.6390</td>\n",
       "      <td>0.9820</td>\n",
       "      <td>0.3981</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.6147</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.384</td>\n",
       "      <td>0.2475</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Subjet_1</td>\n",
       "      <td>15.364569</td>\n",
       "      <td>0.6611</td>\n",
       "      <td>0.9820</td>\n",
       "      <td>0.3796</td>\n",
       "      <td>0.5739</td>\n",
       "      <td>0.6972</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.2673</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Subjet_1</td>\n",
       "      <td>14.957827</td>\n",
       "      <td>0.6317</td>\n",
       "      <td>0.9730</td>\n",
       "      <td>0.3981</td>\n",
       "      <td>0.5652</td>\n",
       "      <td>0.6239</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.2475</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Subjet_1</td>\n",
       "      <td>15.528849</td>\n",
       "      <td>0.6409</td>\n",
       "      <td>0.9910</td>\n",
       "      <td>0.4352</td>\n",
       "      <td>0.5565</td>\n",
       "      <td>0.6239</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.2079</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Subjet_1</td>\n",
       "      <td>15.993745</td>\n",
       "      <td>0.6538</td>\n",
       "      <td>0.9910</td>\n",
       "      <td>0.3611</td>\n",
       "      <td>0.5913</td>\n",
       "      <td>0.6697</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.2277</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Subjet_1</td>\n",
       "      <td>16.823134</td>\n",
       "      <td>0.6446</td>\n",
       "      <td>0.9730</td>\n",
       "      <td>0.3704</td>\n",
       "      <td>0.5478</td>\n",
       "      <td>0.6606</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.384</td>\n",
       "      <td>0.2475</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Subjet_1</td>\n",
       "      <td>15.812350</td>\n",
       "      <td>0.6354</td>\n",
       "      <td>0.9820</td>\n",
       "      <td>0.3889</td>\n",
       "      <td>0.5304</td>\n",
       "      <td>0.6422</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.408</td>\n",
       "      <td>0.2772</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Subjet_1</td>\n",
       "      <td>16.680686</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.3889</td>\n",
       "      <td>0.5913</td>\n",
       "      <td>0.6697</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.352</td>\n",
       "      <td>0.2079</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Subjet_1</td>\n",
       "      <td>14.529958</td>\n",
       "      <td>0.6851</td>\n",
       "      <td>0.9910</td>\n",
       "      <td>0.4259</td>\n",
       "      <td>0.5826</td>\n",
       "      <td>0.7248</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.2178</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Subjet_1</td>\n",
       "      <td>17.791133</td>\n",
       "      <td>0.6796</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.4352</td>\n",
       "      <td>0.5652</td>\n",
       "      <td>0.7156</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.2277</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Subjet_1</td>\n",
       "      <td>16.228115</td>\n",
       "      <td>0.6483</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.3704</td>\n",
       "      <td>0.5565</td>\n",
       "      <td>0.6697</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.344</td>\n",
       "      <td>0.2079</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Subjet_1</td>\n",
       "      <td>14.815590</td>\n",
       "      <td>0.6740</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.4167</td>\n",
       "      <td>0.5565</td>\n",
       "      <td>0.7339</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.344</td>\n",
       "      <td>0.2079</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Subjet_1</td>\n",
       "      <td>16.099657</td>\n",
       "      <td>0.6980</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.4630</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.7523</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.352</td>\n",
       "      <td>0.2079</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Subjet_1</td>\n",
       "      <td>14.533707</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.9910</td>\n",
       "      <td>0.3981</td>\n",
       "      <td>0.5826</td>\n",
       "      <td>0.6514</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.2277</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Subjet_1</td>\n",
       "      <td>15.714685</td>\n",
       "      <td>0.6501</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.4167</td>\n",
       "      <td>0.5391</td>\n",
       "      <td>0.6606</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.2277</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Subjet_1</td>\n",
       "      <td>15.797302</td>\n",
       "      <td>0.6556</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.4259</td>\n",
       "      <td>0.5565</td>\n",
       "      <td>0.6514</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.352</td>\n",
       "      <td>0.2079</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Subjet_1</td>\n",
       "      <td>19.045552</td>\n",
       "      <td>0.6924</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.5463</td>\n",
       "      <td>0.5739</td>\n",
       "      <td>0.7156</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.376</td>\n",
       "      <td>0.2277</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Subjet_2</td>\n",
       "      <td>15.484598</td>\n",
       "      <td>0.3959</td>\n",
       "      <td>0.2342</td>\n",
       "      <td>0.8611</td>\n",
       "      <td>0.3130</td>\n",
       "      <td>0.3303</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.344</td>\n",
       "      <td>0.2178</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Subjet_2</td>\n",
       "      <td>14.018696</td>\n",
       "      <td>0.4144</td>\n",
       "      <td>0.2432</td>\n",
       "      <td>0.8611</td>\n",
       "      <td>0.3478</td>\n",
       "      <td>0.3578</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Subjet_2</td>\n",
       "      <td>11.138138</td>\n",
       "      <td>0.3738</td>\n",
       "      <td>0.1982</td>\n",
       "      <td>0.7778</td>\n",
       "      <td>0.3043</td>\n",
       "      <td>0.3028</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.272</td>\n",
       "      <td>0.3465</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Subjet_2</td>\n",
       "      <td>14.840607</td>\n",
       "      <td>0.4033</td>\n",
       "      <td>0.2162</td>\n",
       "      <td>0.8611</td>\n",
       "      <td>0.3478</td>\n",
       "      <td>0.3303</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.312</td>\n",
       "      <td>0.3168</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Subjet_2</td>\n",
       "      <td>12.762539</td>\n",
       "      <td>0.3996</td>\n",
       "      <td>0.2072</td>\n",
       "      <td>0.8426</td>\n",
       "      <td>0.3565</td>\n",
       "      <td>0.3028</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.312</td>\n",
       "      <td>0.3168</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Subjet_2</td>\n",
       "      <td>14.125518</td>\n",
       "      <td>0.4144</td>\n",
       "      <td>0.2162</td>\n",
       "      <td>0.8611</td>\n",
       "      <td>0.3391</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.352</td>\n",
       "      <td>0.3168</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Subjet_2</td>\n",
       "      <td>10.908749</td>\n",
       "      <td>0.3812</td>\n",
       "      <td>0.1802</td>\n",
       "      <td>0.8519</td>\n",
       "      <td>0.2696</td>\n",
       "      <td>0.3303</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.256</td>\n",
       "      <td>0.2673</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Subjet_2</td>\n",
       "      <td>13.933343</td>\n",
       "      <td>0.3941</td>\n",
       "      <td>0.2523</td>\n",
       "      <td>0.8333</td>\n",
       "      <td>0.2957</td>\n",
       "      <td>0.3578</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.288</td>\n",
       "      <td>0.2178</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Subjet_2</td>\n",
       "      <td>13.496468</td>\n",
       "      <td>0.4217</td>\n",
       "      <td>0.2523</td>\n",
       "      <td>0.8611</td>\n",
       "      <td>0.3304</td>\n",
       "      <td>0.3670</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.3366</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Subjet_2</td>\n",
       "      <td>13.351789</td>\n",
       "      <td>0.3886</td>\n",
       "      <td>0.1982</td>\n",
       "      <td>0.8704</td>\n",
       "      <td>0.2870</td>\n",
       "      <td>0.3303</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.272</td>\n",
       "      <td>0.2673</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Subjet_2</td>\n",
       "      <td>14.123689</td>\n",
       "      <td>0.3959</td>\n",
       "      <td>0.2162</td>\n",
       "      <td>0.8889</td>\n",
       "      <td>0.2696</td>\n",
       "      <td>0.3211</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.368</td>\n",
       "      <td>0.3168</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Subjet_2</td>\n",
       "      <td>15.569148</td>\n",
       "      <td>0.4015</td>\n",
       "      <td>0.2973</td>\n",
       "      <td>0.8611</td>\n",
       "      <td>0.3130</td>\n",
       "      <td>0.2936</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.296</td>\n",
       "      <td>0.2079</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Subjet_2</td>\n",
       "      <td>15.396336</td>\n",
       "      <td>0.4180</td>\n",
       "      <td>0.2252</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>0.3130</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.336</td>\n",
       "      <td>0.2673</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Subjet_2</td>\n",
       "      <td>16.548319</td>\n",
       "      <td>0.4180</td>\n",
       "      <td>0.2883</td>\n",
       "      <td>0.8981</td>\n",
       "      <td>0.2870</td>\n",
       "      <td>0.3028</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Subjet_2</td>\n",
       "      <td>14.802912</td>\n",
       "      <td>0.4420</td>\n",
       "      <td>0.2973</td>\n",
       "      <td>0.9074</td>\n",
       "      <td>0.3913</td>\n",
       "      <td>0.3303</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.3564</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Subjet_2</td>\n",
       "      <td>14.052941</td>\n",
       "      <td>0.4125</td>\n",
       "      <td>0.2432</td>\n",
       "      <td>0.8889</td>\n",
       "      <td>0.3478</td>\n",
       "      <td>0.2936</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.304</td>\n",
       "      <td>0.2673</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Subjet_2</td>\n",
       "      <td>14.914502</td>\n",
       "      <td>0.4217</td>\n",
       "      <td>0.2072</td>\n",
       "      <td>0.9537</td>\n",
       "      <td>0.3217</td>\n",
       "      <td>0.3303</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.368</td>\n",
       "      <td>0.2772</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Subjet_2</td>\n",
       "      <td>16.833878</td>\n",
       "      <td>0.4033</td>\n",
       "      <td>0.2072</td>\n",
       "      <td>0.9259</td>\n",
       "      <td>0.2957</td>\n",
       "      <td>0.3119</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.2970</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Subjet_2</td>\n",
       "      <td>15.493673</td>\n",
       "      <td>0.4217</td>\n",
       "      <td>0.2432</td>\n",
       "      <td>0.9444</td>\n",
       "      <td>0.2870</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.2772</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Subjet_2</td>\n",
       "      <td>15.888272</td>\n",
       "      <td>0.4088</td>\n",
       "      <td>0.2432</td>\n",
       "      <td>0.9259</td>\n",
       "      <td>0.2870</td>\n",
       "      <td>0.3119</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.2970</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Subjet_2</td>\n",
       "      <td>17.029416</td>\n",
       "      <td>0.4678</td>\n",
       "      <td>0.2793</td>\n",
       "      <td>0.9630</td>\n",
       "      <td>0.3304</td>\n",
       "      <td>0.4495</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.2574</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Subjet_2</td>\n",
       "      <td>16.197719</td>\n",
       "      <td>0.4512</td>\n",
       "      <td>0.2973</td>\n",
       "      <td>0.9352</td>\n",
       "      <td>0.3478</td>\n",
       "      <td>0.3578</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.2772</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Subjet_2</td>\n",
       "      <td>14.890030</td>\n",
       "      <td>0.4549</td>\n",
       "      <td>0.2793</td>\n",
       "      <td>0.9352</td>\n",
       "      <td>0.3652</td>\n",
       "      <td>0.3761</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.3267</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Subjet_2</td>\n",
       "      <td>15.636124</td>\n",
       "      <td>0.4401</td>\n",
       "      <td>0.2793</td>\n",
       "      <td>0.9444</td>\n",
       "      <td>0.2957</td>\n",
       "      <td>0.3670</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.344</td>\n",
       "      <td>0.2772</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Subjet_2</td>\n",
       "      <td>16.359275</td>\n",
       "      <td>0.4715</td>\n",
       "      <td>0.2883</td>\n",
       "      <td>0.9352</td>\n",
       "      <td>0.3913</td>\n",
       "      <td>0.4312</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.2970</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Subjet_2</td>\n",
       "      <td>15.138366</td>\n",
       "      <td>0.4346</td>\n",
       "      <td>0.2703</td>\n",
       "      <td>0.9352</td>\n",
       "      <td>0.3217</td>\n",
       "      <td>0.3394</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.336</td>\n",
       "      <td>0.2772</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Subjet_2</td>\n",
       "      <td>18.673174</td>\n",
       "      <td>0.4678</td>\n",
       "      <td>0.3153</td>\n",
       "      <td>0.9352</td>\n",
       "      <td>0.3913</td>\n",
       "      <td>0.3761</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.424</td>\n",
       "      <td>0.3465</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Subjet_2</td>\n",
       "      <td>18.714967</td>\n",
       "      <td>0.4733</td>\n",
       "      <td>0.3243</td>\n",
       "      <td>0.9352</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.3761</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.368</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Subjet_2</td>\n",
       "      <td>16.846094</td>\n",
       "      <td>0.4180</td>\n",
       "      <td>0.2432</td>\n",
       "      <td>0.9259</td>\n",
       "      <td>0.2522</td>\n",
       "      <td>0.3761</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.288</td>\n",
       "      <td>0.3267</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Subjet_2</td>\n",
       "      <td>18.354382</td>\n",
       "      <td>0.4788</td>\n",
       "      <td>0.2883</td>\n",
       "      <td>0.9444</td>\n",
       "      <td>0.3739</td>\n",
       "      <td>0.4771</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.3069</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Model       Time  Command_Acc_p15  Command_Acc_p1  Command_Acc_p2  \\\n",
       "0   Subjet_1  15.269878           0.6243          0.9369          0.3889   \n",
       "1   Subjet_1  12.062418           0.5709          0.9189          0.3148   \n",
       "2   Subjet_1  13.520935           0.6335          0.9550          0.3889   \n",
       "3   Subjet_1  14.664869           0.6225          0.9550          0.2685   \n",
       "4   Subjet_1  13.347304           0.6188          0.9279          0.3796   \n",
       "5   Subjet_1  14.131006           0.5672          0.9279          0.2870   \n",
       "6   Subjet_1  13.651466           0.5930          0.9459          0.2685   \n",
       "7   Subjet_1  12.100064           0.5727          0.9279          0.2870   \n",
       "8   Subjet_1  13.176442           0.6151          0.9459          0.3611   \n",
       "9   Subjet_1  13.929373           0.6446          0.9369          0.4722   \n",
       "10  Subjet_1  15.902663           0.6409          0.9820          0.3704   \n",
       "11  Subjet_1  13.805319           0.6538          1.0000          0.3519   \n",
       "12  Subjet_1  15.685424           0.6298          0.9820          0.3333   \n",
       "13  Subjet_1  16.194757           0.6390          0.9820          0.3981   \n",
       "14  Subjet_1  15.364569           0.6611          0.9820          0.3796   \n",
       "15  Subjet_1  14.957827           0.6317          0.9730          0.3981   \n",
       "16  Subjet_1  15.528849           0.6409          0.9910          0.4352   \n",
       "17  Subjet_1  15.993745           0.6538          0.9910          0.3611   \n",
       "18  Subjet_1  16.823134           0.6446          0.9730          0.3704   \n",
       "19  Subjet_1  15.812350           0.6354          0.9820          0.3889   \n",
       "20  Subjet_1  16.680686           0.6667          1.0000          0.3889   \n",
       "21  Subjet_1  14.529958           0.6851          0.9910          0.4259   \n",
       "22  Subjet_1  17.791133           0.6796          1.0000          0.4352   \n",
       "23  Subjet_1  16.228115           0.6483          1.0000          0.3704   \n",
       "24  Subjet_1  14.815590           0.6740          1.0000          0.4167   \n",
       "25  Subjet_1  16.099657           0.6980          1.0000          0.4630   \n",
       "26  Subjet_1  14.533707           0.6667          0.9910          0.3981   \n",
       "27  Subjet_1  15.714685           0.6501          1.0000          0.4167   \n",
       "28  Subjet_1  15.797302           0.6556          1.0000          0.4259   \n",
       "29  Subjet_1  19.045552           0.6924          1.0000          0.5463   \n",
       "30  Subjet_2  15.484598           0.3959          0.2342          0.8611   \n",
       "31  Subjet_2  14.018696           0.4144          0.2432          0.8611   \n",
       "32  Subjet_2  11.138138           0.3738          0.1982          0.7778   \n",
       "33  Subjet_2  14.840607           0.4033          0.2162          0.8611   \n",
       "34  Subjet_2  12.762539           0.3996          0.2072          0.8426   \n",
       "35  Subjet_2  14.125518           0.4144          0.2162          0.8611   \n",
       "36  Subjet_2  10.908749           0.3812          0.1802          0.8519   \n",
       "37  Subjet_2  13.933343           0.3941          0.2523          0.8333   \n",
       "38  Subjet_2  13.496468           0.4217          0.2523          0.8611   \n",
       "39  Subjet_2  13.351789           0.3886          0.1982          0.8704   \n",
       "40  Subjet_2  14.123689           0.3959          0.2162          0.8889   \n",
       "41  Subjet_2  15.569148           0.4015          0.2973          0.8611   \n",
       "42  Subjet_2  15.396336           0.4180          0.2252          0.9167   \n",
       "43  Subjet_2  16.548319           0.4180          0.2883          0.8981   \n",
       "44  Subjet_2  14.802912           0.4420          0.2973          0.9074   \n",
       "45  Subjet_2  14.052941           0.4125          0.2432          0.8889   \n",
       "46  Subjet_2  14.914502           0.4217          0.2072          0.9537   \n",
       "47  Subjet_2  16.833878           0.4033          0.2072          0.9259   \n",
       "48  Subjet_2  15.493673           0.4217          0.2432          0.9444   \n",
       "49  Subjet_2  15.888272           0.4088          0.2432          0.9259   \n",
       "50  Subjet_2  17.029416           0.4678          0.2793          0.9630   \n",
       "51  Subjet_2  16.197719           0.4512          0.2973          0.9352   \n",
       "52  Subjet_2  14.890030           0.4549          0.2793          0.9352   \n",
       "53  Subjet_2  15.636124           0.4401          0.2793          0.9444   \n",
       "54  Subjet_2  16.359275           0.4715          0.2883          0.9352   \n",
       "55  Subjet_2  15.138366           0.4346          0.2703          0.9352   \n",
       "56  Subjet_2  18.673174           0.4678          0.3153          0.9352   \n",
       "57  Subjet_2  18.714967           0.4733          0.3243          0.9352   \n",
       "58  Subjet_2  16.846094           0.4180          0.2432          0.9259   \n",
       "59  Subjet_2  18.354382           0.4788          0.2883          0.9444   \n",
       "\n",
       "    Command_Acc_p3  Command_Acc_p4  Command_Acc_p5  Acc_p6  Acc_p7  Acc_p8  \\\n",
       "0           0.5391          0.6239            0.63    0.38   0.384  0.2673   \n",
       "1           0.4696          0.5413            0.61    0.33   0.320  0.2673   \n",
       "2           0.5478          0.6514            0.62    0.48   0.384  0.2475   \n",
       "3           0.5217          0.6789            0.69    0.26   0.456  0.2970   \n",
       "4           0.5652          0.5780            0.64    0.39   0.416  0.2574   \n",
       "5           0.4696          0.5780            0.57    0.25   0.328  0.2673   \n",
       "6           0.5130          0.6239            0.61    0.43   0.440  0.2673   \n",
       "7           0.4957          0.5413            0.61    0.41   0.384  0.2574   \n",
       "8           0.4957          0.6147            0.66    0.41   0.408  0.2871   \n",
       "9           0.5391          0.6147            0.66    0.48   0.408  0.2673   \n",
       "10          0.5565          0.6514            0.64    0.34   0.400  0.2178   \n",
       "11          0.5913          0.6697            0.65    0.45   0.360  0.2277   \n",
       "12          0.5391          0.6422            0.65    0.43   0.408  0.2277   \n",
       "13          0.6000          0.6147            0.59    0.36   0.384  0.2475   \n",
       "14          0.5739          0.6972            0.67    0.44   0.400  0.2673   \n",
       "15          0.5652          0.6239            0.59    0.38   0.440  0.2475   \n",
       "16          0.5565          0.6239            0.59    0.37   0.360  0.2079   \n",
       "17          0.5913          0.6697            0.65    0.41   0.360  0.2277   \n",
       "18          0.5478          0.6606            0.67    0.37   0.384  0.2475   \n",
       "19          0.5304          0.6422            0.63    0.33   0.408  0.2772   \n",
       "20          0.5913          0.6697            0.68    0.43   0.352  0.2079   \n",
       "21          0.5826          0.7248            0.70    0.42   0.360  0.2178   \n",
       "22          0.5652          0.7156            0.68    0.36   0.328  0.2277   \n",
       "23          0.5565          0.6697            0.64    0.41   0.344  0.2079   \n",
       "24          0.5565          0.7339            0.66    0.45   0.344  0.2079   \n",
       "25          0.6000          0.7523            0.67    0.37   0.352  0.2079   \n",
       "26          0.5826          0.6514            0.71    0.36   0.360  0.2277   \n",
       "27          0.5391          0.6606            0.63    0.38   0.360  0.2277   \n",
       "28          0.5565          0.6514            0.64    0.39   0.352  0.2079   \n",
       "29          0.5739          0.7156            0.62    0.41   0.376  0.2277   \n",
       "30          0.3130          0.3303            0.24    0.21   0.344  0.2178   \n",
       "31          0.3478          0.3578            0.26    0.14   0.320  0.2871   \n",
       "32          0.3043          0.3028            0.29    0.16   0.272  0.3465   \n",
       "33          0.3478          0.3303            0.26    0.21   0.312  0.3168   \n",
       "34          0.3565          0.3028            0.29    0.16   0.312  0.3168   \n",
       "35          0.3391          0.3486            0.31    0.22   0.352  0.3168   \n",
       "36          0.2696          0.3303            0.28    0.14   0.256  0.2673   \n",
       "37          0.2957          0.3578            0.23    0.27   0.288  0.2178   \n",
       "38          0.3304          0.3670            0.30    0.18   0.280  0.3366   \n",
       "39          0.2870          0.3303            0.26    0.13   0.272  0.2673   \n",
       "40          0.2696          0.3211            0.29    0.17   0.368  0.3168   \n",
       "41          0.3130          0.2936            0.24    0.22   0.296  0.2079   \n",
       "42          0.3130          0.3486            0.29    0.23   0.336  0.2673   \n",
       "43          0.2870          0.3028            0.32    0.25   0.360  0.2871   \n",
       "44          0.3913          0.3303            0.28    0.17   0.320  0.3564   \n",
       "45          0.3478          0.2936            0.29    0.24   0.304  0.2673   \n",
       "46          0.3217          0.3303            0.30    0.19   0.368  0.2772   \n",
       "47          0.2957          0.3119            0.28    0.23   0.360  0.2970   \n",
       "48          0.2870          0.3486            0.29    0.17   0.328  0.2772   \n",
       "49          0.2870          0.3119            0.28    0.21   0.320  0.2970   \n",
       "50          0.3304          0.4495            0.32    0.19   0.328  0.2574   \n",
       "51          0.3478          0.3578            0.32    0.24   0.320  0.2772   \n",
       "52          0.3652          0.3761            0.32    0.23   0.400  0.3267   \n",
       "53          0.2957          0.3670            0.32    0.19   0.344  0.2772   \n",
       "54          0.3913          0.4312            0.31    0.26   0.320  0.2970   \n",
       "55          0.3217          0.3394            0.31    0.27   0.336  0.2772   \n",
       "56          0.3913          0.3761            0.32    0.25   0.424  0.3465   \n",
       "57          0.4000          0.3761            0.33    0.26   0.368  0.2871   \n",
       "58          0.2522          0.3761            0.30    0.17   0.288  0.3267   \n",
       "59          0.3739          0.4771            0.31    0.28   0.320  0.3069   \n",
       "\n",
       "    Size  \n",
       "0     10  \n",
       "1     10  \n",
       "2     10  \n",
       "3     10  \n",
       "4     10  \n",
       "5     10  \n",
       "6     10  \n",
       "7     10  \n",
       "8     10  \n",
       "9     10  \n",
       "10    20  \n",
       "11    20  \n",
       "12    20  \n",
       "13    20  \n",
       "14    20  \n",
       "15    20  \n",
       "16    20  \n",
       "17    20  \n",
       "18    20  \n",
       "19    20  \n",
       "20    30  \n",
       "21    30  \n",
       "22    30  \n",
       "23    30  \n",
       "24    30  \n",
       "25    30  \n",
       "26    30  \n",
       "27    30  \n",
       "28    30  \n",
       "29    30  \n",
       "30    10  \n",
       "31    10  \n",
       "32    10  \n",
       "33    10  \n",
       "34    10  \n",
       "35    10  \n",
       "36    10  \n",
       "37    10  \n",
       "38    10  \n",
       "39    10  \n",
       "40    20  \n",
       "41    20  \n",
       "42    20  \n",
       "43    20  \n",
       "44    20  \n",
       "45    20  \n",
       "46    20  \n",
       "47    20  \n",
       "48    20  \n",
       "49    20  \n",
       "50    30  \n",
       "51    30  \n",
       "52    30  \n",
       "53    30  \n",
       "54    30  \n",
       "55    30  \n",
       "56    30  \n",
       "57    30  \n",
       "58    30  \n",
       "59    30  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pd file store performance\n",
    "# Perfomance = pd.DataFrame(columns = ['Model','Time','Command_Acc_p15','Command_Acc_p1','Command_Acc_p2',\n",
    "#                                      'Command_Acc_p3','Command_Acc_p4','Command_Acc_p5','Acc_p6','Acc_p7','Acc_p8'])\n",
    "\n",
    "Perfomance = pd.read_csv('Performance_0608_single_model.csv')\n",
    "# Perfomance\n",
    "Perfomance                                                        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "actv_fun_1_1 = \"relu\" \n",
    "actv_fun_1_2 = \"sigmoid\"\n",
    "shape_1_1 = 128\n",
    "shape_1_2 = 256\n",
    "actv_fun_2_1 = \"sigmoid\" \n",
    "actv_fun_2_2 = \"sigmoid\"\n",
    "shape_2_1 = 512\n",
    "shape_2_2 = 512\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single model size:10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2/2 [==============================] - 2s 867ms/step - loss: 2.5328 - accuracy: 0.0700 - val_loss: 2.2262 - val_accuracy: 0.3565\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 1s 347ms/step - loss: 2.1568 - accuracy: 0.4600 - val_loss: 2.0583 - val_accuracy: 0.6000\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 1s 306ms/step - loss: 1.9921 - accuracy: 0.7000 - val_loss: 1.9600 - val_accuracy: 0.7217\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 1s 300ms/step - loss: 1.8936 - accuracy: 0.8400 - val_loss: 1.8906 - val_accuracy: 0.8000\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 1s 302ms/step - loss: 1.8288 - accuracy: 0.8600 - val_loss: 1.8376 - val_accuracy: 0.8174\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 1s 303ms/step - loss: 1.7802 - accuracy: 0.8700 - val_loss: 1.7954 - val_accuracy: 0.8261\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 1s 319ms/step - loss: 1.7339 - accuracy: 0.8900 - val_loss: 1.7516 - val_accuracy: 0.8348\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 1s 303ms/step - loss: 1.6964 - accuracy: 0.9000 - val_loss: 1.7214 - val_accuracy: 0.8435\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 1s 295ms/step - loss: 1.6640 - accuracy: 0.9000 - val_loss: 1.6895 - val_accuracy: 0.9217\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 1s 297ms/step - loss: 1.6335 - accuracy: 0.9900 - val_loss: 1.6563 - val_accuracy: 0.9652\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 1s 293ms/step - loss: 1.6038 - accuracy: 1.0000 - val_loss: 1.6313 - val_accuracy: 0.9652\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 122ms/step - loss: 1.5791 - accuracy: 1.0000 - val_loss: 1.6075 - val_accuracy: 0.9652\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 1.5557 - accuracy: 1.0000 - val_loss: 1.5794 - val_accuracy: 0.9652\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 1.5296 - accuracy: 1.0000 - val_loss: 1.5559 - val_accuracy: 0.9652\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 1.5051 - accuracy: 1.0000 - val_loss: 1.5369 - val_accuracy: 0.9652\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 1s 274ms/step - loss: 1.4819 - accuracy: 1.0000 - val_loss: 1.5180 - val_accuracy: 0.9652\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 1s 604ms/step - loss: 2.5045 - accuracy: 0.1000 - val_loss: 2.1518 - val_accuracy: 0.3043\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 1s 309ms/step - loss: 2.0923 - accuracy: 0.3600 - val_loss: 1.9983 - val_accuracy: 0.5391\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 1s 363ms/step - loss: 1.9348 - accuracy: 0.7000 - val_loss: 1.8975 - val_accuracy: 0.6435\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 1s 286ms/step - loss: 1.8350 - accuracy: 0.7600 - val_loss: 1.8199 - val_accuracy: 0.7565\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 1s 294ms/step - loss: 1.7582 - accuracy: 0.9000 - val_loss: 1.7714 - val_accuracy: 0.8435\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 1s 292ms/step - loss: 1.7018 - accuracy: 0.9600 - val_loss: 1.7120 - val_accuracy: 0.8957\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 1s 292ms/step - loss: 1.6423 - accuracy: 0.9900 - val_loss: 1.6618 - val_accuracy: 0.9391\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 1s 385ms/step - loss: 1.5968 - accuracy: 0.9900 - val_loss: 1.6249 - val_accuracy: 0.9478\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 1s 288ms/step - loss: 1.5615 - accuracy: 0.9900 - val_loss: 1.5878 - val_accuracy: 0.9652\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 1s 288ms/step - loss: 1.5241 - accuracy: 0.9900 - val_loss: 1.5482 - val_accuracy: 0.9826\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 1s 296ms/step - loss: 1.4888 - accuracy: 0.9900 - val_loss: 1.5169 - val_accuracy: 0.9913\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 1.4558 - accuracy: 0.9900 - val_loss: 1.4856 - val_accuracy: 0.9913\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 1.4206 - accuracy: 1.0000 - val_loss: 1.4606 - val_accuracy: 0.9913\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 209ms/step - loss: 1.3903 - accuracy: 1.0000 - val_loss: 1.4341 - val_accuracy: 0.9913\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 1.3610 - accuracy: 1.0000 - val_loss: 1.4072 - val_accuracy: 0.9913\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 1s 277ms/step - loss: 1.3333 - accuracy: 1.0000 - val_loss: 1.3792 - val_accuracy: 0.9913\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 1s 664ms/step - loss: 2.4856 - accuracy: 0.1100 - val_loss: 2.1364 - val_accuracy: 0.3217\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 1s 286ms/step - loss: 2.0746 - accuracy: 0.3700 - val_loss: 1.9628 - val_accuracy: 0.4870\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 1s 286ms/step - loss: 1.9006 - accuracy: 0.5500 - val_loss: 1.8473 - val_accuracy: 0.7043\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 1s 409ms/step - loss: 1.7941 - accuracy: 0.7300 - val_loss: 1.7603 - val_accuracy: 0.7913\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 1s 329ms/step - loss: 1.6989 - accuracy: 0.8600 - val_loss: 1.7070 - val_accuracy: 0.8609\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 1.6400 - accuracy: 0.9100 - val_loss: 1.6442 - val_accuracy: 0.8609\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 1s 293ms/step - loss: 1.5773 - accuracy: 0.9400 - val_loss: 1.5937 - val_accuracy: 0.9652\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 1s 304ms/step - loss: 1.5300 - accuracy: 0.9900 - val_loss: 1.5497 - val_accuracy: 0.9739\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 1s 312ms/step - loss: 1.4849 - accuracy: 0.9900 - val_loss: 1.5086 - val_accuracy: 0.9826\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 1.4430 - accuracy: 0.9900 - val_loss: 1.4743 - val_accuracy: 0.9826\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 1s 293ms/step - loss: 1.4019 - accuracy: 1.0000 - val_loss: 1.4434 - val_accuracy: 0.9826\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 1s 291ms/step - loss: 1.3671 - accuracy: 1.0000 - val_loss: 1.4111 - val_accuracy: 0.9913\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 1.3303 - accuracy: 1.0000 - val_loss: 1.3750 - val_accuracy: 0.9913\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 1.2957 - accuracy: 1.0000 - val_loss: 1.3446 - val_accuracy: 0.9913\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 1.2658 - accuracy: 1.0000 - val_loss: 1.3185 - val_accuracy: 0.9826\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 1.2372 - accuracy: 1.0000 - val_loss: 1.2863 - val_accuracy: 0.9826\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 1s 414ms/step - loss: 1.2039 - accuracy: 1.0000 - val_loss: 1.2544 - val_accuracy: 0.9826\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 1s 679ms/step - loss: 2.5591 - accuracy: 0.0900 - val_loss: 2.1894 - val_accuracy: 0.3217\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 1s 292ms/step - loss: 2.1505 - accuracy: 0.3600 - val_loss: 2.0704 - val_accuracy: 0.4348\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 1s 300ms/step - loss: 2.0314 - accuracy: 0.5300 - val_loss: 1.9685 - val_accuracy: 0.6696\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 1s 296ms/step - loss: 1.9322 - accuracy: 0.8000 - val_loss: 1.9137 - val_accuracy: 0.8000\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 1s 304ms/step - loss: 1.8701 - accuracy: 0.8700 - val_loss: 1.8608 - val_accuracy: 0.8348\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 1s 303ms/step - loss: 1.8197 - accuracy: 0.8800 - val_loss: 1.8045 - val_accuracy: 0.8609\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 1s 290ms/step - loss: 1.7665 - accuracy: 0.8900 - val_loss: 1.7673 - val_accuracy: 0.8696\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 1s 303ms/step - loss: 1.7278 - accuracy: 0.8900 - val_loss: 1.7308 - val_accuracy: 0.8783\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 1.6902 - accuracy: 0.9000 - val_loss: 1.7028 - val_accuracy: 0.8783\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 103ms/step - loss: 1.6612 - accuracy: 0.9000 - val_loss: 1.6775 - val_accuracy: 0.8783\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 1s 321ms/step - loss: 1.6295 - accuracy: 0.9100 - val_loss: 1.6542 - val_accuracy: 0.9043\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 1s 311ms/step - loss: 1.6034 - accuracy: 0.9600 - val_loss: 1.6294 - val_accuracy: 0.9739\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 1s 308ms/step - loss: 1.5784 - accuracy: 0.9900 - val_loss: 1.6076 - val_accuracy: 0.9913\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 1.5571 - accuracy: 0.9900 - val_loss: 1.5871 - val_accuracy: 0.9826\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 1.5331 - accuracy: 0.9900 - val_loss: 1.5618 - val_accuracy: 0.9826\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 1.5063 - accuracy: 0.9900 - val_loss: 1.5396 - val_accuracy: 0.9565\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 1.4809 - accuracy: 0.9900 - val_loss: 1.5177 - val_accuracy: 0.9478\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 1s 286ms/step - loss: 1.4557 - accuracy: 0.9900 - val_loss: 1.4978 - val_accuracy: 0.9478\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 1s 673ms/step - loss: 2.4478 - accuracy: 0.1300 - val_loss: 2.1241 - val_accuracy: 0.3826\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 1s 310ms/step - loss: 2.0540 - accuracy: 0.4500 - val_loss: 1.9023 - val_accuracy: 0.6261\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 1s 297ms/step - loss: 1.8363 - accuracy: 0.7500 - val_loss: 1.7718 - val_accuracy: 0.8174\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 1s 280ms/step - loss: 1.7070 - accuracy: 0.9000 - val_loss: 1.6579 - val_accuracy: 0.8435\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 1s 282ms/step - loss: 1.5942 - accuracy: 0.9600 - val_loss: 1.5999 - val_accuracy: 0.9043\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 1s 315ms/step - loss: 1.5347 - accuracy: 0.9800 - val_loss: 1.5332 - val_accuracy: 0.9217\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 1.4710 - accuracy: 0.9800 - val_loss: 1.4883 - val_accuracy: 0.9130\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 1.4241 - accuracy: 0.9900 - val_loss: 1.4397 - val_accuracy: 0.9130\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 1.3711 - accuracy: 0.9900 - val_loss: 1.3905 - val_accuracy: 0.9217\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 1s 321ms/step - loss: 1.3269 - accuracy: 0.9900 - val_loss: 1.3527 - val_accuracy: 0.9391\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 1s 308ms/step - loss: 1.2870 - accuracy: 0.9900 - val_loss: 1.3166 - val_accuracy: 0.9391\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 1.2507 - accuracy: 0.9900 - val_loss: 1.2879 - val_accuracy: 0.9304\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 1.2162 - accuracy: 0.9900 - val_loss: 1.2554 - val_accuracy: 0.9217\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 143ms/step - loss: 1.1825 - accuracy: 0.9900 - val_loss: 1.2218 - val_accuracy: 0.9304\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 1s 311ms/step - loss: 1.1486 - accuracy: 0.9900 - val_loss: 1.1907 - val_accuracy: 0.9478\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 1.1181 - accuracy: 0.9900 - val_loss: 1.1608 - val_accuracy: 0.9478\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 1s 301ms/step - loss: 1.0864 - accuracy: 0.9900 - val_loss: 1.1282 - val_accuracy: 0.9565\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 1.0547 - accuracy: 1.0000 - val_loss: 1.1048 - val_accuracy: 0.9565\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 1.0282 - accuracy: 1.0000 - val_loss: 1.0751 - val_accuracy: 0.9565\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 0.9948 - accuracy: 1.0000 - val_loss: 1.0475 - val_accuracy: 0.9565\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 1s 717ms/step - loss: 2.6066 - accuracy: 0.0900 - val_loss: 2.2377 - val_accuracy: 0.2696\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 1s 288ms/step - loss: 2.1743 - accuracy: 0.3000 - val_loss: 2.1079 - val_accuracy: 0.2957\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 1s 306ms/step - loss: 2.0438 - accuracy: 0.4300 - val_loss: 2.0017 - val_accuracy: 0.5739\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 1s 291ms/step - loss: 1.9399 - accuracy: 0.7200 - val_loss: 1.9219 - val_accuracy: 0.7739\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 1s 268ms/step - loss: 1.8688 - accuracy: 0.8600 - val_loss: 1.8775 - val_accuracy: 0.8696\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 1.8200 - accuracy: 0.8900 - val_loss: 1.8314 - val_accuracy: 0.8522\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 141ms/step - loss: 1.7748 - accuracy: 0.8900 - val_loss: 1.7939 - val_accuracy: 0.8348\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 1.7422 - accuracy: 0.8900 - val_loss: 1.7637 - val_accuracy: 0.8348\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 1.7094 - accuracy: 0.8900 - val_loss: 1.7357 - val_accuracy: 0.8348\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 1s 275ms/step - loss: 1.6791 - accuracy: 0.9000 - val_loss: 1.7127 - val_accuracy: 0.8348\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 1s 312ms/step - loss: 1.8182 - accuracy: 0.8900 - val_loss: 1.8175 - val_accuracy: 0.8783\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 1.7581 - accuracy: 0.8900 - val_loss: 1.7775 - val_accuracy: 0.8696\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 1.7154 - accuracy: 0.9000 - val_loss: 1.7516 - val_accuracy: 0.8435\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 1.6808 - accuracy: 0.9000 - val_loss: 1.7203 - val_accuracy: 0.8435\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 1s 326ms/step - loss: 1.6478 - accuracy: 0.9100 - val_loss: 1.6876 - val_accuracy: 0.8870\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 1s 300ms/step - loss: 1.6212 - accuracy: 0.9600 - val_loss: 1.6582 - val_accuracy: 0.9043\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 1s 298ms/step - loss: 1.5935 - accuracy: 1.0000 - val_loss: 1.6336 - val_accuracy: 0.9217\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 1s 285ms/step - loss: 1.5708 - accuracy: 1.0000 - val_loss: 1.6084 - val_accuracy: 0.9478\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 1s 276ms/step - loss: 1.5465 - accuracy: 1.0000 - val_loss: 1.5873 - val_accuracy: 0.9565\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 1s 294ms/step - loss: 1.5238 - accuracy: 1.0000 - val_loss: 1.5664 - val_accuracy: 0.9652\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 1s 621ms/step - loss: 2.4705 - accuracy: 0.1300 - val_loss: 2.0938 - val_accuracy: 0.3565\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 1s 310ms/step - loss: 2.0320 - accuracy: 0.4800 - val_loss: 1.9190 - val_accuracy: 0.6957\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 1s 308ms/step - loss: 1.8556 - accuracy: 0.7900 - val_loss: 1.7754 - val_accuracy: 0.7913\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 1s 296ms/step - loss: 1.7256 - accuracy: 0.9200 - val_loss: 1.7168 - val_accuracy: 0.8696\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 1s 286ms/step - loss: 1.6519 - accuracy: 0.9600 - val_loss: 1.6416 - val_accuracy: 0.9130\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 1s 291ms/step - loss: 1.5785 - accuracy: 0.9800 - val_loss: 1.5705 - val_accuracy: 0.9304\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 1.5104 - accuracy: 0.9900 - val_loss: 1.5317 - val_accuracy: 0.9304\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 1.4651 - accuracy: 0.9900 - val_loss: 1.4879 - val_accuracy: 0.9217\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 1.4166 - accuracy: 0.9900 - val_loss: 1.4480 - val_accuracy: 0.9304\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 98ms/step - loss: 1.3756 - accuracy: 0.9900 - val_loss: 1.4086 - val_accuracy: 0.9217\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 1s 289ms/step - loss: 1.3340 - accuracy: 0.9900 - val_loss: 1.3712 - val_accuracy: 0.9391\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 1.2972 - accuracy: 0.9900 - val_loss: 1.3432 - val_accuracy: 0.9217\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 1.2650 - accuracy: 0.9900 - val_loss: 1.3146 - val_accuracy: 0.9217\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 1.2329 - accuracy: 1.0000 - val_loss: 1.2849 - val_accuracy: 0.9217\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 1.2011 - accuracy: 1.0000 - val_loss: 1.2569 - val_accuracy: 0.9391\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 1s 296ms/step - loss: 1.1708 - accuracy: 1.0000 - val_loss: 1.2253 - val_accuracy: 0.9478\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 1.1392 - accuracy: 1.0000 - val_loss: 1.1946 - val_accuracy: 0.9478\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 1.1112 - accuracy: 1.0000 - val_loss: 1.1671 - val_accuracy: 0.9478\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 1s 318ms/step - loss: 1.0828 - accuracy: 1.0000 - val_loss: 1.1405 - val_accuracy: 0.9739\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 1.0543 - accuracy: 1.0000 - val_loss: 1.1178 - val_accuracy: 0.9739\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 1s 628ms/step - loss: 2.4542 - accuracy: 0.1100 - val_loss: 2.1374 - val_accuracy: 0.4696\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 1s 311ms/step - loss: 2.0700 - accuracy: 0.5600 - val_loss: 1.9362 - val_accuracy: 0.6522\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 1s 306ms/step - loss: 1.8679 - accuracy: 0.6900 - val_loss: 1.8168 - val_accuracy: 0.6783\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 1s 280ms/step - loss: 1.7533 - accuracy: 0.7000 - val_loss: 1.6930 - val_accuracy: 0.7391\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 1s 278ms/step - loss: 1.6386 - accuracy: 0.8100 - val_loss: 1.6305 - val_accuracy: 0.7913\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 1s 290ms/step - loss: 1.5737 - accuracy: 0.9000 - val_loss: 1.5724 - val_accuracy: 0.8522\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 1s 420ms/step - loss: 1.5133 - accuracy: 0.9600 - val_loss: 1.5208 - val_accuracy: 0.8957\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 1s 286ms/step - loss: 1.4603 - accuracy: 0.9900 - val_loss: 1.4731 - val_accuracy: 0.9391\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 1s 300ms/step - loss: 1.4095 - accuracy: 0.9900 - val_loss: 1.4299 - val_accuracy: 0.9652\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 1s 312ms/step - loss: 1.3659 - accuracy: 1.0000 - val_loss: 1.3913 - val_accuracy: 0.9826\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 1s 296ms/step - loss: 1.3272 - accuracy: 1.0000 - val_loss: 1.3557 - val_accuracy: 0.9652\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 1.2895 - accuracy: 1.0000 - val_loss: 1.3177 - val_accuracy: 0.9652\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 1.2497 - accuracy: 1.0000 - val_loss: 1.2809 - val_accuracy: 0.9652\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 1s 300ms/step - loss: 1.2115 - accuracy: 1.0000 - val_loss: 1.2475 - val_accuracy: 0.9739\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 1.1779 - accuracy: 1.0000 - val_loss: 1.2174 - val_accuracy: 0.9739\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 1.1454 - accuracy: 1.0000 - val_loss: 1.1814 - val_accuracy: 0.9739\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 1.1070 - accuracy: 1.0000 - val_loss: 1.1508 - val_accuracy: 0.9652\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 1.0766 - accuracy: 1.0000 - val_loss: 1.1227 - val_accuracy: 0.9739\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 1s 271ms/step - loss: 1.0457 - accuracy: 1.0000 - val_loss: 1.0953 - val_accuracy: 0.9739\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 1s 702ms/step - loss: 2.3944 - accuracy: 0.2200 - val_loss: 2.1151 - val_accuracy: 0.2870\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 1s 311ms/step - loss: 2.0442 - accuracy: 0.3600 - val_loss: 1.8858 - val_accuracy: 0.6261\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 1s 287ms/step - loss: 1.8222 - accuracy: 0.7200 - val_loss: 1.7392 - val_accuracy: 0.7130\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 1s 291ms/step - loss: 1.6822 - accuracy: 0.8700 - val_loss: 1.6458 - val_accuracy: 0.8261\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 1s 287ms/step - loss: 1.5905 - accuracy: 0.9500 - val_loss: 1.5745 - val_accuracy: 0.9043\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 1s 280ms/step - loss: 1.5058 - accuracy: 0.9900 - val_loss: 1.4977 - val_accuracy: 0.9478\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 1s 288ms/step - loss: 1.4410 - accuracy: 0.9900 - val_loss: 1.4437 - val_accuracy: 0.9652\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 1.3863 - accuracy: 0.9900 - val_loss: 1.4048 - val_accuracy: 0.9565\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 1.3392 - accuracy: 0.9900 - val_loss: 1.3658 - val_accuracy: 0.9652\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 189ms/step - loss: 1.2952 - accuracy: 0.9900 - val_loss: 1.3205 - val_accuracy: 0.9652\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 1s 305ms/step - loss: 1.2501 - accuracy: 1.0000 - val_loss: 1.2738 - val_accuracy: 0.9652\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 1.2072 - accuracy: 1.0000 - val_loss: 1.2373 - val_accuracy: 0.9652\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 1.1701 - accuracy: 1.0000 - val_loss: 1.2046 - val_accuracy: 0.9652\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 1s 308ms/step - loss: 1.1341 - accuracy: 1.0000 - val_loss: 1.1715 - val_accuracy: 0.9826\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 1.0967 - accuracy: 1.0000 - val_loss: 1.1386 - val_accuracy: 0.9739\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 1.0612 - accuracy: 1.0000 - val_loss: 1.1060 - val_accuracy: 0.9739\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 1.0316 - accuracy: 1.0000 - val_loss: 1.0766 - val_accuracy: 0.9739\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 124ms/step - loss: 1.0019 - accuracy: 1.0000 - val_loss: 1.0434 - val_accuracy: 0.9739\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 1s 276ms/step - loss: 0.9686 - accuracy: 1.0000 - val_loss: 1.0169 - val_accuracy: 0.9739\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 1s 595ms/step - loss: 2.5116 - accuracy: 0.0900 - val_loss: 2.1519 - val_accuracy: 0.2087\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 1s 315ms/step - loss: 2.0912 - accuracy: 0.2700 - val_loss: 1.9705 - val_accuracy: 0.4696\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 1s 296ms/step - loss: 1.9185 - accuracy: 0.5200 - val_loss: 1.8671 - val_accuracy: 0.6870\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 1s 289ms/step - loss: 1.8109 - accuracy: 0.7600 - val_loss: 1.7808 - val_accuracy: 0.8348\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 1.7235 - accuracy: 0.8900 - val_loss: 1.7148 - val_accuracy: 0.8261\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 1s 291ms/step - loss: 1.6556 - accuracy: 0.9200 - val_loss: 1.6617 - val_accuracy: 0.9043\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 1s 296ms/step - loss: 1.5924 - accuracy: 0.9500 - val_loss: 1.5994 - val_accuracy: 0.9130\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 1s 287ms/step - loss: 1.5337 - accuracy: 0.9800 - val_loss: 1.5618 - val_accuracy: 0.9478\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 1s 281ms/step - loss: 1.4986 - accuracy: 0.9800 - val_loss: 1.5264 - val_accuracy: 0.9565\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 105ms/step - loss: 1.4565 - accuracy: 0.9900 - val_loss: 1.4919 - val_accuracy: 0.9391\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 1s 320ms/step - loss: 1.4160 - accuracy: 1.0000 - val_loss: 1.4631 - val_accuracy: 0.9478\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 1.3838 - accuracy: 1.0000 - val_loss: 1.4266 - val_accuracy: 0.9478\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 1.3451 - accuracy: 1.0000 - val_loss: 1.3893 - val_accuracy: 0.9478\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 119ms/step - loss: 1.3109 - accuracy: 1.0000 - val_loss: 1.3568 - val_accuracy: 0.9391\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 1s 328ms/step - loss: 1.2772 - accuracy: 1.0000 - val_loss: 1.3231 - val_accuracy: 0.9565\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 1s 294ms/step - loss: 1.2436 - accuracy: 1.0000 - val_loss: 1.2915 - val_accuracy: 0.9739\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 1.2130 - accuracy: 1.0000 - val_loss: 1.2620 - val_accuracy: 0.9652\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 1.1804 - accuracy: 1.0000 - val_loss: 1.2318 - val_accuracy: 0.9652\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 1.1516 - accuracy: 1.0000 - val_loss: 1.2061 - val_accuracy: 0.9739\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 1.1234 - accuracy: 1.0000 - val_loss: 1.1773 - val_accuracy: 0.9739\n"
     ]
    }
   ],
   "source": [
    "high_acc = 0\n",
    "for run in range(0,10):\n",
    "    # feature extraction layers\n",
    "    resnet_model = ResNet50(input_shape=(224, 224,3), include_top=False, weights=\"imagenet\")\n",
    "    for layer in resnet_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    d = resnet_model.output.shape[-1] # dimension of last layer\n",
    "\n",
    "\n",
    "    ###################### model 2 ###################### \n",
    "    layer_2_0 = tf.keras.layers.Dense(d,name=\"weight_2\")(resnet_model.output) #times weight before flatten\n",
    "    layer_2_1 = tf.keras.layers.Flatten(name='flatten_2')(layer_2_0)\n",
    "\n",
    "    Dense_2_1 = tf.keras.layers.Dense(shape_2_1, activation=actv_fun_2_1,name='fc2_1')\n",
    "    layer_2_2  = Dense_2_1(layer_2_1)\n",
    "    Dense_2_2 = tf.keras.layers.Dense(shape_2_2, activation=actv_fun_2_2,name='fc2_2')\n",
    "    layer_2_3  = Dense_2_2(layer_2_2)\n",
    "\n",
    "    Dense_2_3 = tf.keras.layers.Dense(10, activation='softmax',name='command_output')\n",
    "    out_layer_2 = Dense_2_3(layer_2_3)\n",
    "\n",
    "\n",
    "    resnet_model = tf.keras.Model(resnet_model.input, out_layer_2)\n",
    "\n",
    "\n",
    "    # resnet_model.summary() \n",
    "\n",
    "\n",
    "    ##################### training ############################\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "    callbacks = [EarlyStopping(monitor = 'val_accuracy', patience=5,restore_best_weights=True)]\n",
    "    resnet_model.compile(optimizer=opt, loss=\"categorical_crossentropy\",metrics=['accuracy'])\n",
    "\n",
    "    \n",
    "    start = timeit.default_timer()\n",
    "       \n",
    "    history1 = resnet_model.fit(Train_Inputs,Train_command_class,\n",
    "                                validation_data=(Val_Inputs,Val_command_class),\n",
    "                                callbacks=callbacks,\n",
    "                                batch_size=64,\n",
    "                                epochs=10)\n",
    "    \n",
    "    for layer in resnet_model.layers[0:175]:\n",
    "        layer.trainable = True\n",
    "        \n",
    "    history2 = resnet_model.fit(Train_Inputs,Train_command_class,\n",
    "                            validation_data=(Val_Inputs,Val_command_class), \n",
    "                           callbacks=callbacks,\n",
    "                           batch_size=64,\n",
    "                           epochs=10)\n",
    "\n",
    "    stop = timeit.default_timer()\n",
    "    run_time = stop - start\n",
    "    \n",
    "    ##################### test performance ############################\n",
    "    predictions = resnet_model.predict(Test_Inputs)\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    true_classes = test_unit_command_class\n",
    "    acc_p15_c = metrics.accuracy_score(true_classes, predicted_classes).round(4)\n",
    "\n",
    "\n",
    "    # test on p1\n",
    "    ## command classification\n",
    "    predictions = resnet_model.predict(Test_Inputs_1)\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    true_classes = np.argmax(Test_command_class_1, axis=-1)\n",
    "    acc_p1_c = metrics.accuracy_score(true_classes, predicted_classes).round(4)   \n",
    "\n",
    "    # test on p2\n",
    "    ## command classification\n",
    "    predictions = resnet_model.predict(Test_Inputs_2)\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    true_classes = np.argmax(Test_command_class_2, axis=-1)\n",
    "    acc_p2_c = metrics.accuracy_score(true_classes, predicted_classes).round(4)   \n",
    "\n",
    "    # test on p3 \n",
    "    ## command classification\n",
    "    predictions = resnet_model.predict(Test_Inputs_3)\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    true_classes = np.argmax(Test_command_class_3, axis=-1)\n",
    "    acc_p3_c = metrics.accuracy_score(true_classes, predicted_classes).round(4)   \n",
    "\n",
    "    # test on p4\n",
    "    ## command classification\n",
    "    predictions = resnet_model.predict(Test_Inputs_4)\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    true_classes = np.argmax(Test_command_class_4, axis=-1)\n",
    "    acc_p4_c = metrics.accuracy_score(true_classes, predicted_classes).round(4)   \n",
    "\n",
    "    # test on p5\n",
    "\n",
    "    ## command classification\n",
    "    predictions = resnet_model.predict(Test_Inputs_5)\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    true_classes = np.argmax(Test_command_class_5, axis=-1)\n",
    "    acc_p5_c = metrics.accuracy_score(true_classes, predicted_classes).round(4)   \n",
    "\n",
    "    # test on p6 \n",
    "    ## command classification\n",
    "    predictions = resnet_model.predict(Test_Inputs_6)\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    true_classes = test_unit_command_class_6\n",
    "    acc_p6 = metrics.accuracy_score(true_classes, predicted_classes).round(4)                \n",
    "\n",
    "    # test on p7 \n",
    "    ## command classification\n",
    "    predictions = resnet_model.predict(Test_Inputs_7)\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    true_classes = test_unit_command_class_7\n",
    "    acc_p7 = metrics.accuracy_score(true_classes, predicted_classes).round(4)    \n",
    "\n",
    "    # test on p8 \n",
    "    ## command classification\n",
    "    predictions = resnet_model.predict(Test_Inputs_8)\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    true_classes = test_unit_command_class_8\n",
    "    acc_p8 = metrics.accuracy_score(true_classes, predicted_classes).round(4)    \n",
    "\n",
    "    Perfomance = Perfomance.append({'Model': \"Subjet_3\",'Size':'10','Time':run_time,'Command_Acc_p15':acc_p15_c,\n",
    "                                    'Command_Acc_p1':acc_p1_c,'Command_Acc_p2':acc_p2_c,\n",
    "                                    'Command_Acc_p3':acc_p3_c,'Command_Acc_p4':acc_p4_c,'Command_Acc_p5':acc_p5_c,\n",
    "                                    'Acc_p6':acc_p6,'Acc_p7':acc_p7,'Acc_p8':acc_p8}, ignore_index=True)\n",
    "\n",
    "\n",
    "    if high_acc < acc_p15_c :\n",
    "        resnet_model.save('Initial_subject_3_model_size10_0608.h5')\n",
    "        high_acc = acc_p15_c \n",
    "        best_index = run\n",
    "        pd.DataFrame.from_dict(history1.history).to_csv('subject_3_size10_history1_0608.csv',index=False)\n",
    "        pd.DataFrame.from_dict(history2.history).to_csv('subject_3_size10_history2_0608.csv',index=False)\n",
    "        \n",
    "    del resnet_model\n",
    "    run = run + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "resnet_model = tf.keras.models.load_model('Initial_subject_3_model_size10_0608.h5')\n",
    "predictions = resnet_model.predict(Test_Inputs_3)\n",
    "predicted_classes =  np.argmax(predictions, axis=1)\n",
    "acc_c = round(sum(x == y for x, y in zip(np.argmax(Test_command_class_3, axis=1), predicted_classes)) / len(np.argmax(Test_command_class_3, axis=1)),4)\n",
    "print(acc_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Time</th>\n",
       "      <th>Command_Acc_p15</th>\n",
       "      <th>Command_Acc_p1</th>\n",
       "      <th>Command_Acc_p2</th>\n",
       "      <th>Command_Acc_p3</th>\n",
       "      <th>Command_Acc_p4</th>\n",
       "      <th>Command_Acc_p5</th>\n",
       "      <th>Acc_p6</th>\n",
       "      <th>Acc_p7</th>\n",
       "      <th>Acc_p8</th>\n",
       "      <th>Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Subjet_1</td>\n",
       "      <td>15.269878</td>\n",
       "      <td>0.6243</td>\n",
       "      <td>0.9369</td>\n",
       "      <td>0.3889</td>\n",
       "      <td>0.5391</td>\n",
       "      <td>0.6239</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.384</td>\n",
       "      <td>0.2673</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Subjet_1</td>\n",
       "      <td>12.062418</td>\n",
       "      <td>0.5709</td>\n",
       "      <td>0.9189</td>\n",
       "      <td>0.3148</td>\n",
       "      <td>0.4696</td>\n",
       "      <td>0.5413</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.2673</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Subjet_1</td>\n",
       "      <td>13.520935</td>\n",
       "      <td>0.6335</td>\n",
       "      <td>0.9550</td>\n",
       "      <td>0.3889</td>\n",
       "      <td>0.5478</td>\n",
       "      <td>0.6514</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.384</td>\n",
       "      <td>0.2475</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Subjet_1</td>\n",
       "      <td>14.664869</td>\n",
       "      <td>0.6225</td>\n",
       "      <td>0.9550</td>\n",
       "      <td>0.2685</td>\n",
       "      <td>0.5217</td>\n",
       "      <td>0.6789</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.456</td>\n",
       "      <td>0.2970</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Subjet_1</td>\n",
       "      <td>13.347304</td>\n",
       "      <td>0.6188</td>\n",
       "      <td>0.9279</td>\n",
       "      <td>0.3796</td>\n",
       "      <td>0.5652</td>\n",
       "      <td>0.5780</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.416</td>\n",
       "      <td>0.2574</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Subjet_3</td>\n",
       "      <td>13.904538</td>\n",
       "      <td>0.6409</td>\n",
       "      <td>0.4865</td>\n",
       "      <td>0.3981</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.6789</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.448</td>\n",
       "      <td>0.3366</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>Subjet_3</td>\n",
       "      <td>12.220064</td>\n",
       "      <td>0.6483</td>\n",
       "      <td>0.5045</td>\n",
       "      <td>0.4074</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.6789</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.3168</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>Subjet_3</td>\n",
       "      <td>14.080573</td>\n",
       "      <td>0.6317</td>\n",
       "      <td>0.5045</td>\n",
       "      <td>0.3889</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.6239</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.464</td>\n",
       "      <td>0.3069</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Subjet_3</td>\n",
       "      <td>12.665570</td>\n",
       "      <td>0.6390</td>\n",
       "      <td>0.5495</td>\n",
       "      <td>0.3704</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.6147</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.448</td>\n",
       "      <td>0.2574</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>Subjet_3</td>\n",
       "      <td>13.363397</td>\n",
       "      <td>0.6630</td>\n",
       "      <td>0.5405</td>\n",
       "      <td>0.3981</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.6697</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.448</td>\n",
       "      <td>0.2970</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70 rows  12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Model       Time  Command_Acc_p15  Command_Acc_p1  Command_Acc_p2  \\\n",
       "0   Subjet_1  15.269878           0.6243          0.9369          0.3889   \n",
       "1   Subjet_1  12.062418           0.5709          0.9189          0.3148   \n",
       "2   Subjet_1  13.520935           0.6335          0.9550          0.3889   \n",
       "3   Subjet_1  14.664869           0.6225          0.9550          0.2685   \n",
       "4   Subjet_1  13.347304           0.6188          0.9279          0.3796   \n",
       "..       ...        ...              ...             ...             ...   \n",
       "65  Subjet_3  13.904538           0.6409          0.4865          0.3981   \n",
       "66  Subjet_3  12.220064           0.6483          0.5045          0.4074   \n",
       "67  Subjet_3  14.080573           0.6317          0.5045          0.3889   \n",
       "68  Subjet_3  12.665570           0.6390          0.5495          0.3704   \n",
       "69  Subjet_3  13.363397           0.6630          0.5405          0.3981   \n",
       "\n",
       "    Command_Acc_p3  Command_Acc_p4  Command_Acc_p5  Acc_p6  Acc_p7  Acc_p8  \\\n",
       "0           0.5391          0.6239            0.63    0.38   0.384  0.2673   \n",
       "1           0.4696          0.5413            0.61    0.33   0.320  0.2673   \n",
       "2           0.5478          0.6514            0.62    0.48   0.384  0.2475   \n",
       "3           0.5217          0.6789            0.69    0.26   0.456  0.2970   \n",
       "4           0.5652          0.5780            0.64    0.39   0.416  0.2574   \n",
       "..             ...             ...             ...     ...     ...     ...   \n",
       "65          1.0000          0.6789            0.62    0.40   0.448  0.3366   \n",
       "66          0.9913          0.6789            0.64    0.43   0.440  0.3168   \n",
       "67          0.9913          0.6239            0.63    0.36   0.464  0.3069   \n",
       "68          1.0000          0.6147            0.64    0.37   0.448  0.2574   \n",
       "69          1.0000          0.6697            0.69    0.33   0.448  0.2970   \n",
       "\n",
       "   Size  \n",
       "0    10  \n",
       "1    10  \n",
       "2    10  \n",
       "3    10  \n",
       "4    10  \n",
       "..  ...  \n",
       "65   10  \n",
       "66   10  \n",
       "67   10  \n",
       "68   10  \n",
       "69   10  \n",
       "\n",
       "[70 rows x 12 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Perfomance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single model size:20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = 3\n",
    "train_image = 20 #10:20%, 20: 40%, 30:60%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([20., 20., 20., 20., 20., 20., 20., 20., 20., 20.], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_indexs_train = (image_no<train_image)&(ALL_participant_class==subject)\n",
    "Train_Inputs = All_Inputs[select_indexs_train]\n",
    "Train_command_class = All_command_class[select_indexs_train]\n",
    "sum(Train_command_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4/4 [==============================] - 2s 384ms/step - loss: 2.3545 - accuracy: 0.2850 - val_loss: 1.9593 - val_accuracy: 0.4957\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 1s 182ms/step - loss: 1.8965 - accuracy: 0.5100 - val_loss: 1.7262 - val_accuracy: 0.7652\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 1s 176ms/step - loss: 1.6809 - accuracy: 0.7900 - val_loss: 1.5902 - val_accuracy: 0.8609\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 1s 174ms/step - loss: 1.5586 - accuracy: 0.8950 - val_loss: 1.4810 - val_accuracy: 0.9043\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 1s 174ms/step - loss: 1.4592 - accuracy: 0.9400 - val_loss: 1.4033 - val_accuracy: 0.9652\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 1s 186ms/step - loss: 1.3750 - accuracy: 0.9650 - val_loss: 1.3237 - val_accuracy: 0.9826\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 1.3065 - accuracy: 0.9900 - val_loss: 1.2632 - val_accuracy: 0.9826\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 1.2380 - accuracy: 0.9900 - val_loss: 1.2045 - val_accuracy: 0.9739\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 1.1758 - accuracy: 0.9900 - val_loss: 1.1451 - val_accuracy: 0.9826\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 1.1108 - accuracy: 0.9900 - val_loss: 1.0871 - val_accuracy: 0.9826\n",
      "Epoch 1/10\n",
      "4/4 [==============================] - 1s 183ms/step - loss: 1.0563 - accuracy: 0.9950 - val_loss: 1.0383 - val_accuracy: 0.9739\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 1s 206ms/step - loss: 1.0048 - accuracy: 0.9950 - val_loss: 0.9878 - val_accuracy: 0.9826\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.9599 - accuracy: 0.9950 - val_loss: 0.9444 - val_accuracy: 0.9826\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 0.9070 - accuracy: 0.9950 - val_loss: 0.8956 - val_accuracy: 0.9739\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 0.8645 - accuracy: 0.9950 - val_loss: 0.8489 - val_accuracy: 0.9739\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 1s 176ms/step - loss: 0.8214 - accuracy: 0.9950 - val_loss: 0.8220 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 0.7838 - accuracy: 0.9950 - val_loss: 0.7680 - val_accuracy: 0.9826\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 0s 89ms/step - loss: 0.7376 - accuracy: 0.9950 - val_loss: 0.7406 - val_accuracy: 0.9739\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 0.7038 - accuracy: 0.9950 - val_loss: 0.6969 - val_accuracy: 0.9913\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.6644 - accuracy: 0.9950 - val_loss: 0.6631 - val_accuracy: 1.0000\n",
      "Epoch 1/10\n",
      "4/4 [==============================] - 2s 446ms/step - loss: 2.3687 - accuracy: 0.1950 - val_loss: 2.0557 - val_accuracy: 0.4000\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 1s 171ms/step - loss: 2.0034 - accuracy: 0.5250 - val_loss: 1.8880 - val_accuracy: 0.7217\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 1s 176ms/step - loss: 1.8485 - accuracy: 0.7900 - val_loss: 1.7956 - val_accuracy: 0.8000\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 1s 181ms/step - loss: 1.7676 - accuracy: 0.7800 - val_loss: 1.7085 - val_accuracy: 0.8609\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 1s 172ms/step - loss: 1.6828 - accuracy: 0.8550 - val_loss: 1.6397 - val_accuracy: 0.9130\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 1s 166ms/step - loss: 1.6217 - accuracy: 0.9650 - val_loss: 1.5879 - val_accuracy: 0.9652\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 1.5689 - accuracy: 0.9850 - val_loss: 1.5375 - val_accuracy: 0.9565\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 1.5195 - accuracy: 0.9700 - val_loss: 1.4929 - val_accuracy: 0.9478\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 1.4625 - accuracy: 0.9800 - val_loss: 1.4340 - val_accuracy: 0.9652\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 0s 87ms/step - loss: 1.4148 - accuracy: 0.9950 - val_loss: 1.3927 - val_accuracy: 0.9652\n",
      "Epoch 1/10\n",
      "4/4 [==============================] - 1s 180ms/step - loss: 1.3714 - accuracy: 0.9950 - val_loss: 1.3426 - val_accuracy: 0.9652\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 1s 172ms/step - loss: 1.3182 - accuracy: 0.9950 - val_loss: 1.3028 - val_accuracy: 0.9826\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 1s 171ms/step - loss: 1.2777 - accuracy: 0.9950 - val_loss: 1.2699 - val_accuracy: 0.9913\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 1s 173ms/step - loss: 1.2374 - accuracy: 0.9950 - val_loss: 1.2328 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 0s 96ms/step - loss: 1.2012 - accuracy: 0.9950 - val_loss: 1.1953 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 1.1619 - accuracy: 0.9950 - val_loss: 1.1597 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 1.1257 - accuracy: 0.9950 - val_loss: 1.1264 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 1.0879 - accuracy: 0.9950 - val_loss: 1.0858 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 1s 170ms/step - loss: 1.0508 - accuracy: 0.9950 - val_loss: 1.0521 - val_accuracy: 1.0000\n",
      "Epoch 1/10\n",
      "4/4 [==============================] - 2s 416ms/step - loss: 2.2791 - accuracy: 0.2400 - val_loss: 1.9618 - val_accuracy: 0.5652\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 1s 186ms/step - loss: 1.8941 - accuracy: 0.5950 - val_loss: 1.7673 - val_accuracy: 0.6522\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 1s 173ms/step - loss: 1.7351 - accuracy: 0.7200 - val_loss: 1.6695 - val_accuracy: 0.8261\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 1s 181ms/step - loss: 1.6304 - accuracy: 0.8400 - val_loss: 1.5690 - val_accuracy: 0.8957\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 1s 176ms/step - loss: 1.5458 - accuracy: 0.9450 - val_loss: 1.5076 - val_accuracy: 0.9217\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 1s 178ms/step - loss: 1.4766 - accuracy: 0.9900 - val_loss: 1.4473 - val_accuracy: 0.9565\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 1s 186ms/step - loss: 1.4173 - accuracy: 0.9950 - val_loss: 1.3913 - val_accuracy: 0.9826\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 1s 182ms/step - loss: 1.3625 - accuracy: 0.9950 - val_loss: 1.3353 - val_accuracy: 0.9913\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 1.3051 - accuracy: 0.9950 - val_loss: 1.2857 - val_accuracy: 0.9826\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 0s 90ms/step - loss: 1.2549 - accuracy: 0.9950 - val_loss: 1.2428 - val_accuracy: 0.9826\n",
      "Epoch 1/10\n",
      "4/4 [==============================] - 1s 192ms/step - loss: 1.2083 - accuracy: 0.9950 - val_loss: 1.1932 - val_accuracy: 0.9826\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 1s 179ms/step - loss: 1.1611 - accuracy: 0.9950 - val_loss: 1.1477 - val_accuracy: 0.9913\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 0s 96ms/step - loss: 1.1147 - accuracy: 0.9950 - val_loss: 1.1026 - val_accuracy: 0.9913\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 0s 111ms/step - loss: 1.0705 - accuracy: 0.9950 - val_loss: 1.0627 - val_accuracy: 0.9913\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 1.0300 - accuracy: 0.9950 - val_loss: 1.0220 - val_accuracy: 0.9913\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.9879 - accuracy: 0.9950 - val_loss: 0.9791 - val_accuracy: 0.9913\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 1s 172ms/step - loss: 0.9483 - accuracy: 0.9950 - val_loss: 0.9364 - val_accuracy: 0.9913\n",
      "Epoch 1/10\n",
      "4/4 [==============================] - 2s 519ms/step - loss: 2.3136 - accuracy: 0.2450 - val_loss: 1.9869 - val_accuracy: 0.6522\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 1.9181 - accuracy: 0.6400 - val_loss: 1.7929 - val_accuracy: 0.6261\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 1s 182ms/step - loss: 1.7634 - accuracy: 0.6350 - val_loss: 1.6555 - val_accuracy: 0.7043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10\n",
      "4/4 [==============================] - 1s 180ms/step - loss: 1.6325 - accuracy: 0.7300 - val_loss: 1.5724 - val_accuracy: 0.8870\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 1s 174ms/step - loss: 1.5495 - accuracy: 0.8500 - val_loss: 1.4979 - val_accuracy: 0.9391\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 1s 170ms/step - loss: 1.4705 - accuracy: 0.9650 - val_loss: 1.4284 - val_accuracy: 0.9652\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 1s 181ms/step - loss: 1.4037 - accuracy: 0.9900 - val_loss: 1.3648 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 1.3403 - accuracy: 0.9900 - val_loss: 1.3070 - val_accuracy: 0.9739\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 0s 88ms/step - loss: 1.2781 - accuracy: 0.9900 - val_loss: 1.2547 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 1.2248 - accuracy: 0.9900 - val_loss: 1.1966 - val_accuracy: 1.0000\n",
      "Epoch 1/10\n",
      "4/4 [==============================] - 1s 208ms/step - loss: 1.1668 - accuracy: 0.9900 - val_loss: 1.1457 - val_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 1.1195 - accuracy: 0.9950 - val_loss: 1.1005 - val_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 1.0671 - accuracy: 0.9950 - val_loss: 1.0514 - val_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 1.0170 - accuracy: 0.9950 - val_loss: 1.0085 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.9720 - accuracy: 0.9950 - val_loss: 0.9577 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 1s 175ms/step - loss: 0.9271 - accuracy: 0.9950 - val_loss: 0.9122 - val_accuracy: 1.0000\n",
      "Epoch 1/10\n",
      "4/4 [==============================] - 1s 357ms/step - loss: 2.4285 - accuracy: 0.0600 - val_loss: 2.1064 - val_accuracy: 0.4000\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 1s 183ms/step - loss: 2.0730 - accuracy: 0.5500 - val_loss: 1.9582 - val_accuracy: 0.7652\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 1.9444 - accuracy: 0.7250 - val_loss: 1.8821 - val_accuracy: 0.7130\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 1.8676 - accuracy: 0.6950 - val_loss: 1.8104 - val_accuracy: 0.7739\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 1s 177ms/step - loss: 1.8034 - accuracy: 0.8350 - val_loss: 1.7585 - val_accuracy: 0.9478\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 1s 174ms/step - loss: 1.7518 - accuracy: 0.9100 - val_loss: 1.7100 - val_accuracy: 0.9739\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 1.6978 - accuracy: 0.9450 - val_loss: 1.6619 - val_accuracy: 0.9739\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 1.6495 - accuracy: 0.9750 - val_loss: 1.6241 - val_accuracy: 0.9652\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 1s 188ms/step - loss: 1.6111 - accuracy: 0.9800 - val_loss: 1.5825 - val_accuracy: 0.9826\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 1s 172ms/step - loss: 1.5735 - accuracy: 0.9900 - val_loss: 1.5447 - val_accuracy: 0.9913\n",
      "Epoch 1/10\n",
      "4/4 [==============================] - 1s 183ms/step - loss: 1.5369 - accuracy: 0.9900 - val_loss: 1.5108 - val_accuracy: 0.9826\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 1s 189ms/step - loss: 1.4994 - accuracy: 0.9900 - val_loss: 1.4782 - val_accuracy: 0.9913\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 1s 187ms/step - loss: 1.4623 - accuracy: 0.9950 - val_loss: 1.4433 - val_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 1.4292 - accuracy: 0.9950 - val_loss: 1.4110 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 0s 88ms/step - loss: 1.3956 - accuracy: 0.9950 - val_loss: 1.3773 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 1.3601 - accuracy: 0.9950 - val_loss: 1.3441 - val_accuracy: 0.9913\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 0s 89ms/step - loss: 1.3270 - accuracy: 0.9950 - val_loss: 1.3110 - val_accuracy: 0.9913\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 1s 173ms/step - loss: 1.2966 - accuracy: 0.9950 - val_loss: 1.2851 - val_accuracy: 1.0000\n",
      "Epoch 1/10\n",
      "4/4 [==============================] - 1s 339ms/step - loss: 2.4360 - accuracy: 0.1000 - val_loss: 2.1495 - val_accuracy: 0.4174\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 1s 186ms/step - loss: 2.1103 - accuracy: 0.4000 - val_loss: 1.9929 - val_accuracy: 0.4696\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 1s 176ms/step - loss: 1.9661 - accuracy: 0.5000 - val_loss: 1.8949 - val_accuracy: 0.6348\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 1s 181ms/step - loss: 1.8805 - accuracy: 0.6750 - val_loss: 1.8239 - val_accuracy: 0.7739\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 1s 181ms/step - loss: 1.8228 - accuracy: 0.7700 - val_loss: 1.7700 - val_accuracy: 0.8435\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 1s 175ms/step - loss: 1.7659 - accuracy: 0.8700 - val_loss: 1.7316 - val_accuracy: 0.8957\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 1s 181ms/step - loss: 1.7256 - accuracy: 0.9000 - val_loss: 1.6865 - val_accuracy: 0.9304\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 1s 182ms/step - loss: 1.6803 - accuracy: 0.9300 - val_loss: 1.6476 - val_accuracy: 0.9478\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 1s 170ms/step - loss: 1.6356 - accuracy: 0.9550 - val_loss: 1.6080 - val_accuracy: 0.9565\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 1s 179ms/step - loss: 1.5973 - accuracy: 0.9850 - val_loss: 1.5673 - val_accuracy: 0.9826\n",
      "Epoch 1/10\n",
      "4/4 [==============================] - 1s 179ms/step - loss: 1.5560 - accuracy: 0.9900 - val_loss: 1.5332 - val_accuracy: 0.9826\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 1s 179ms/step - loss: 1.5218 - accuracy: 0.9900 - val_loss: 1.4996 - val_accuracy: 0.9913\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 1s 185ms/step - loss: 1.4835 - accuracy: 0.9900 - val_loss: 1.4607 - val_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 1.4482 - accuracy: 0.9900 - val_loss: 1.4268 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 1.4147 - accuracy: 0.9900 - val_loss: 1.3982 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 1.3804 - accuracy: 0.9900 - val_loss: 1.3662 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 1.3466 - accuracy: 0.9950 - val_loss: 1.3281 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 1s 174ms/step - loss: 1.3076 - accuracy: 0.9950 - val_loss: 1.2959 - val_accuracy: 1.0000\n",
      "Epoch 1/10\n",
      "4/4 [==============================] - 1s 352ms/step - loss: 2.3234 - accuracy: 0.2250 - val_loss: 1.9557 - val_accuracy: 0.4783\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 1s 184ms/step - loss: 1.8904 - accuracy: 0.5400 - val_loss: 1.7635 - val_accuracy: 0.7391\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 1s 174ms/step - loss: 1.7209 - accuracy: 0.7950 - val_loss: 1.6264 - val_accuracy: 0.9652\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 1.6116 - accuracy: 0.9800 - val_loss: 1.5588 - val_accuracy: 0.9304\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 1.5351 - accuracy: 0.9850 - val_loss: 1.4994 - val_accuracy: 0.9565\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 1.4773 - accuracy: 0.9600 - val_loss: 1.4335 - val_accuracy: 0.9565\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 1.4164 - accuracy: 0.9650 - val_loss: 1.3853 - val_accuracy: 0.9478\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 1s 173ms/step - loss: 1.3684 - accuracy: 0.9650 - val_loss: 1.3470 - val_accuracy: 0.9391\n",
      "Epoch 1/10\n",
      "4/4 [==============================] - 1s 185ms/step - loss: 1.5893 - accuracy: 0.9900 - val_loss: 1.5326 - val_accuracy: 0.9739\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 1.5065 - accuracy: 0.9800 - val_loss: 1.4559 - val_accuracy: 0.9739\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 1.4229 - accuracy: 0.9900 - val_loss: 1.3882 - val_accuracy: 0.9739\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 1.3585 - accuracy: 0.9900 - val_loss: 1.3279 - val_accuracy: 0.9565\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 1.3016 - accuracy: 0.9900 - val_loss: 1.2802 - val_accuracy: 0.9565\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 1s 170ms/step - loss: 1.2522 - accuracy: 0.9900 - val_loss: 1.2296 - val_accuracy: 0.9739\n",
      "Epoch 1/10\n",
      "4/4 [==============================] - 1s 369ms/step - loss: 2.5100 - accuracy: 0.1000 - val_loss: 2.2473 - val_accuracy: 0.2696\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 2.1699 - accuracy: 0.2800 - val_loss: 2.1193 - val_accuracy: 0.2696\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 1s 178ms/step - loss: 2.0511 - accuracy: 0.3600 - val_loss: 2.0035 - val_accuracy: 0.5043\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 1s 174ms/step - loss: 1.9603 - accuracy: 0.5900 - val_loss: 1.9255 - val_accuracy: 0.7217\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 1s 215ms/step - loss: 1.9000 - accuracy: 0.8050 - val_loss: 1.8731 - val_accuracy: 0.8435\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 1s 178ms/step - loss: 1.8551 - accuracy: 0.9100 - val_loss: 1.8404 - val_accuracy: 0.9652\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 1.8211 - accuracy: 0.9850 - val_loss: 1.8069 - val_accuracy: 0.9565\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 1.7938 - accuracy: 0.9650 - val_loss: 1.7756 - val_accuracy: 0.9391\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 1.7596 - accuracy: 0.8750 - val_loss: 1.7438 - val_accuracy: 0.8696\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 1.7283 - accuracy: 0.9200 - val_loss: 1.7099 - val_accuracy: 0.9391\n",
      "Epoch 1/10\n",
      "4/4 [==============================] - 1s 209ms/step - loss: 1.6937 - accuracy: 0.9650 - val_loss: 1.6783 - val_accuracy: 0.9652\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 1.6623 - accuracy: 0.9700 - val_loss: 1.6556 - val_accuracy: 0.9652\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 1.6296 - accuracy: 0.9900 - val_loss: 1.6191 - val_accuracy: 0.9652\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 1s 179ms/step - loss: 1.5966 - accuracy: 0.9950 - val_loss: 1.5959 - val_accuracy: 0.9739\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 1.5725 - accuracy: 0.9150 - val_loss: 1.5681 - val_accuracy: 0.8696\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 1.5394 - accuracy: 0.8950 - val_loss: 1.5413 - val_accuracy: 0.9565\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 1s 198ms/step - loss: 1.5069 - accuracy: 0.9950 - val_loss: 1.5090 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 1.4782 - accuracy: 0.9950 - val_loss: 1.4737 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 0s 88ms/step - loss: 1.4449 - accuracy: 0.9950 - val_loss: 1.4434 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 0s 86ms/step - loss: 1.4207 - accuracy: 0.9950 - val_loss: 1.4136 - val_accuracy: 1.0000\n",
      "Epoch 1/10\n",
      "4/4 [==============================] - 1s 372ms/step - loss: 2.4120 - accuracy: 0.0900 - val_loss: 2.0516 - val_accuracy: 0.5391\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 1s 173ms/step - loss: 2.0122 - accuracy: 0.5150 - val_loss: 1.9214 - val_accuracy: 0.6522\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 1s 179ms/step - loss: 1.8889 - accuracy: 0.7000 - val_loss: 1.8311 - val_accuracy: 0.7652\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 1s 169ms/step - loss: 1.8167 - accuracy: 0.7750 - val_loss: 1.7855 - val_accuracy: 0.8087\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 1s 179ms/step - loss: 1.7582 - accuracy: 0.8200 - val_loss: 1.7231 - val_accuracy: 0.9130\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 1s 175ms/step - loss: 1.7034 - accuracy: 0.9550 - val_loss: 1.6822 - val_accuracy: 0.9652\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 1s 173ms/step - loss: 1.6580 - accuracy: 0.9650 - val_loss: 1.6349 - val_accuracy: 0.9739\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 0s 87ms/step - loss: 1.6101 - accuracy: 0.9850 - val_loss: 1.5925 - val_accuracy: 0.9739\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 1s 183ms/step - loss: 1.5717 - accuracy: 0.9850 - val_loss: 1.5600 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 1.5352 - accuracy: 0.9900 - val_loss: 1.5224 - val_accuracy: 0.9826\n",
      "Epoch 1/10\n",
      "4/4 [==============================] - 1s 181ms/step - loss: 1.5000 - accuracy: 0.9850 - val_loss: 1.4890 - val_accuracy: 0.9826\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 1s 178ms/step - loss: 1.4656 - accuracy: 0.9950 - val_loss: 1.4533 - val_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 1.4311 - accuracy: 0.9950 - val_loss: 1.4193 - val_accuracy: 0.9913\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 1.3962 - accuracy: 0.9950 - val_loss: 1.3865 - val_accuracy: 0.9913\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 0s 109ms/step - loss: 1.3594 - accuracy: 0.9950 - val_loss: 1.3511 - val_accuracy: 0.9913\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 1.3262 - accuracy: 0.9950 - val_loss: 1.3226 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 1s 169ms/step - loss: 1.2932 - accuracy: 0.9950 - val_loss: 1.2884 - val_accuracy: 0.9913\n",
      "Epoch 1/10\n",
      "4/4 [==============================] - 1s 335ms/step - loss: 2.2954 - accuracy: 0.2850 - val_loss: 1.9499 - val_accuracy: 0.7739\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 1s 179ms/step - loss: 1.8868 - accuracy: 0.7700 - val_loss: 1.7596 - val_accuracy: 0.8087\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 1.7276 - accuracy: 0.7900 - val_loss: 1.6602 - val_accuracy: 0.8087\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 1s 180ms/step - loss: 1.6252 - accuracy: 0.8850 - val_loss: 1.5763 - val_accuracy: 0.8957\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 1s 174ms/step - loss: 1.5428 - accuracy: 0.9400 - val_loss: 1.5096 - val_accuracy: 0.9478\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 1.4727 - accuracy: 0.9550 - val_loss: 1.4397 - val_accuracy: 0.9478\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 1s 185ms/step - loss: 1.4070 - accuracy: 0.9550 - val_loss: 1.3818 - val_accuracy: 0.9565\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 0s 87ms/step - loss: 1.3492 - accuracy: 0.9650 - val_loss: 1.3367 - val_accuracy: 0.9565\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 1s 185ms/step - loss: 1.2960 - accuracy: 0.9800 - val_loss: 1.2768 - val_accuracy: 0.9826\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 1.2404 - accuracy: 0.9850 - val_loss: 1.2249 - val_accuracy: 0.9739\n",
      "Epoch 1/10\n",
      "4/4 [==============================] - 1s 192ms/step - loss: 1.1887 - accuracy: 0.9900 - val_loss: 1.1781 - val_accuracy: 0.9739\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 1s 186ms/step - loss: 1.1403 - accuracy: 0.9950 - val_loss: 1.1283 - val_accuracy: 0.9826\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 1.0927 - accuracy: 0.9950 - val_loss: 1.0852 - val_accuracy: 0.9826\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 1.0461 - accuracy: 0.9950 - val_loss: 1.0389 - val_accuracy: 0.9826\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 1.0000 - accuracy: 0.9950 - val_loss: 1.0004 - val_accuracy: 0.9826\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 1s 174ms/step - loss: 0.9570 - accuracy: 0.9950 - val_loss: 0.9565 - val_accuracy: 0.9913\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 0.9151 - accuracy: 0.9950 - val_loss: 0.9190 - val_accuracy: 0.9913\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 0.8786 - accuracy: 0.9950 - val_loss: 0.8848 - val_accuracy: 0.9913\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 0.8396 - accuracy: 0.9950 - val_loss: 0.8454 - val_accuracy: 0.9913\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 1s 220ms/step - loss: 0.8019 - accuracy: 0.9950 - val_loss: 0.8081 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "high_acc = 0\n",
    "for run in range(0,10):\n",
    "    # feature extraction layers\n",
    "    resnet_model = ResNet50(input_shape=(224, 224,3), include_top=False, weights=\"imagenet\")\n",
    "    for layer in resnet_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    d = resnet_model.output.shape[-1] # dimension of last layer\n",
    "\n",
    "\n",
    "    ###################### model 2 ###################### \n",
    "    layer_2_0 = tf.keras.layers.Dense(d,name=\"weight_2\")(resnet_model.output) #times weight before flatten\n",
    "    layer_2_1 = tf.keras.layers.Flatten(name='flatten_2')(layer_2_0)\n",
    "\n",
    "    Dense_2_1 = tf.keras.layers.Dense(shape_2_1, activation=actv_fun_2_1,name='fc2_1')\n",
    "    layer_2_2  = Dense_2_1(layer_2_1)\n",
    "    Dense_2_2 = tf.keras.layers.Dense(shape_2_2, activation=actv_fun_2_2,name='fc2_2')\n",
    "    layer_2_3  = Dense_2_2(layer_2_2)\n",
    "\n",
    "    Dense_2_3 = tf.keras.layers.Dense(10, activation='softmax',name='command_output')\n",
    "    out_layer_2 = Dense_2_3(layer_2_3)\n",
    "\n",
    "\n",
    "    resnet_model = tf.keras.Model(resnet_model.input, out_layer_2)\n",
    "\n",
    "\n",
    "    # resnet_model.summary() \n",
    "\n",
    "\n",
    "    ##################### training ############################\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "    callbacks = [EarlyStopping(monitor = 'val_accuracy', patience=5,restore_best_weights=True)]\n",
    "    resnet_model.compile(optimizer=opt, loss=\"categorical_crossentropy\",metrics=['accuracy'])\n",
    "\n",
    "    \n",
    "    start = timeit.default_timer()\n",
    "       \n",
    "    history1 = resnet_model.fit(Train_Inputs,Train_command_class,\n",
    "                                validation_data=(Val_Inputs,Val_command_class),\n",
    "                                callbacks=callbacks,\n",
    "                                batch_size=64,\n",
    "                                epochs=10)\n",
    "    \n",
    "    for layer in resnet_model.layers[0:175]:\n",
    "        layer.trainable = True\n",
    "        \n",
    "    history2 = resnet_model.fit(Train_Inputs,Train_command_class,\n",
    "                            validation_data=(Val_Inputs,Val_command_class), \n",
    "                           callbacks=callbacks,\n",
    "                           batch_size=64,\n",
    "                           epochs=10)\n",
    "\n",
    "    stop = timeit.default_timer()\n",
    "    run_time = stop - start\n",
    "    \n",
    "    ##################### test performance ############################\n",
    "    predictions = resnet_model.predict(Test_Inputs)\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    true_classes = test_unit_command_class\n",
    "    acc_p15_c = metrics.accuracy_score(true_classes, predicted_classes).round(4)\n",
    "\n",
    "\n",
    "    # test on p1\n",
    "    ## command classification\n",
    "    predictions = resnet_model.predict(Test_Inputs_1)\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    true_classes = np.argmax(Test_command_class_1, axis=-1)\n",
    "    acc_p1_c = metrics.accuracy_score(true_classes, predicted_classes).round(4)   \n",
    "\n",
    "    # test on p2\n",
    "    ## command classification\n",
    "    predictions = resnet_model.predict(Test_Inputs_2)\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    true_classes = np.argmax(Test_command_class_2, axis=-1)\n",
    "    acc_p2_c = metrics.accuracy_score(true_classes, predicted_classes).round(4)   \n",
    "\n",
    "    # test on p3 \n",
    "    ## command classification\n",
    "    predictions = resnet_model.predict(Test_Inputs_3)\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    true_classes = np.argmax(Test_command_class_3, axis=-1)\n",
    "    acc_p3_c = metrics.accuracy_score(true_classes, predicted_classes).round(4)   \n",
    "\n",
    "    # test on p4\n",
    "    ## command classification\n",
    "    predictions = resnet_model.predict(Test_Inputs_4)\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    true_classes = np.argmax(Test_command_class_4, axis=-1)\n",
    "    acc_p4_c = metrics.accuracy_score(true_classes, predicted_classes).round(4)   \n",
    "\n",
    "    # test on p5\n",
    "\n",
    "    ## command classification\n",
    "    predictions = resnet_model.predict(Test_Inputs_5)\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    true_classes = np.argmax(Test_command_class_5, axis=-1)\n",
    "    acc_p5_c = metrics.accuracy_score(true_classes, predicted_classes).round(4)   \n",
    "\n",
    "    # test on p6 \n",
    "    ## command classification\n",
    "    predictions = resnet_model.predict(Test_Inputs_6)\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    true_classes = test_unit_command_class_6\n",
    "    acc_p6 = metrics.accuracy_score(true_classes, predicted_classes).round(4)                \n",
    "\n",
    "    # test on p7 \n",
    "    ## command classification\n",
    "    predictions = resnet_model.predict(Test_Inputs_7)\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    true_classes = test_unit_command_class_7\n",
    "    acc_p7 = metrics.accuracy_score(true_classes, predicted_classes).round(4)    \n",
    "\n",
    "    # test on p8 \n",
    "    ## command classification\n",
    "    predictions = resnet_model.predict(Test_Inputs_8)\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    true_classes = test_unit_command_class_8\n",
    "    acc_p8 = metrics.accuracy_score(true_classes, predicted_classes).round(4)    \n",
    "\n",
    "    Perfomance = Perfomance.append({'Model': \"Subjet_3\",'Size':'20','Time':run_time,'Command_Acc_p15':acc_p15_c,\n",
    "                                    'Command_Acc_p1':acc_p1_c,'Command_Acc_p2':acc_p2_c,\n",
    "                                    'Command_Acc_p3':acc_p3_c,'Command_Acc_p4':acc_p4_c,'Command_Acc_p5':acc_p5_c,\n",
    "                                    'Acc_p6':acc_p6,'Acc_p7':acc_p7,'Acc_p8':acc_p8}, ignore_index=True)\n",
    "\n",
    "\n",
    "    if high_acc < acc_p15_c :\n",
    "        resnet_model.save('Initial_subject_3_model_size20_0608.h5')\n",
    "        high_acc = acc_p15_c \n",
    "        best_index = run\n",
    "        pd.DataFrame.from_dict(history1.history).to_csv('subject_3_size20_history1_0608.csv',index=False)\n",
    "        pd.DataFrame.from_dict(history2.history).to_csv('subject_3_size20_history2_0608.csv',index=False)\n",
    "        \n",
    "    del resnet_model\n",
    "    run = run + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "0.4444\n"
     ]
    }
   ],
   "source": [
    "resnet_model = tf.keras.models.load_model('Initial_subject_3_model_size20_0608.h5')\n",
    "predictions = resnet_model.predict(Test_Inputs_2)\n",
    "predicted_classes =  np.argmax(predictions, axis=1)\n",
    "acc_c = round(sum(x == y for x, y in zip(np.argmax(Test_command_class_2, axis=1), predicted_classes)) / len(np.argmax(Test_command_class_2, axis=1)),4)\n",
    "print(acc_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Time</th>\n",
       "      <th>Command_Acc_p15</th>\n",
       "      <th>Command_Acc_p1</th>\n",
       "      <th>Command_Acc_p2</th>\n",
       "      <th>Command_Acc_p3</th>\n",
       "      <th>Command_Acc_p4</th>\n",
       "      <th>Command_Acc_p5</th>\n",
       "      <th>Acc_p6</th>\n",
       "      <th>Acc_p7</th>\n",
       "      <th>Acc_p8</th>\n",
       "      <th>Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Subjet_1</td>\n",
       "      <td>15.269878</td>\n",
       "      <td>0.6243</td>\n",
       "      <td>0.9369</td>\n",
       "      <td>0.3889</td>\n",
       "      <td>0.5391</td>\n",
       "      <td>0.6239</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.384</td>\n",
       "      <td>0.2673</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Subjet_1</td>\n",
       "      <td>12.062418</td>\n",
       "      <td>0.5709</td>\n",
       "      <td>0.9189</td>\n",
       "      <td>0.3148</td>\n",
       "      <td>0.4696</td>\n",
       "      <td>0.5413</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.2673</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Subjet_1</td>\n",
       "      <td>13.520935</td>\n",
       "      <td>0.6335</td>\n",
       "      <td>0.9550</td>\n",
       "      <td>0.3889</td>\n",
       "      <td>0.5478</td>\n",
       "      <td>0.6514</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.384</td>\n",
       "      <td>0.2475</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Subjet_1</td>\n",
       "      <td>14.664869</td>\n",
       "      <td>0.6225</td>\n",
       "      <td>0.9550</td>\n",
       "      <td>0.2685</td>\n",
       "      <td>0.5217</td>\n",
       "      <td>0.6789</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.456</td>\n",
       "      <td>0.2970</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Subjet_1</td>\n",
       "      <td>13.347304</td>\n",
       "      <td>0.6188</td>\n",
       "      <td>0.9279</td>\n",
       "      <td>0.3796</td>\n",
       "      <td>0.5652</td>\n",
       "      <td>0.5780</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.416</td>\n",
       "      <td>0.2574</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Subjet_3</td>\n",
       "      <td>15.910140</td>\n",
       "      <td>0.6593</td>\n",
       "      <td>0.4955</td>\n",
       "      <td>0.3611</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.7156</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.384</td>\n",
       "      <td>0.3267</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Subjet_3</td>\n",
       "      <td>11.082789</td>\n",
       "      <td>0.5838</td>\n",
       "      <td>0.3964</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.9739</td>\n",
       "      <td>0.6697</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.2475</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Subjet_3</td>\n",
       "      <td>14.793002</td>\n",
       "      <td>0.6427</td>\n",
       "      <td>0.4775</td>\n",
       "      <td>0.3889</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.6697</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.448</td>\n",
       "      <td>0.3267</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Subjet_3</td>\n",
       "      <td>14.358196</td>\n",
       "      <td>0.6409</td>\n",
       "      <td>0.5135</td>\n",
       "      <td>0.3611</td>\n",
       "      <td>0.9826</td>\n",
       "      <td>0.6972</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.408</td>\n",
       "      <td>0.2475</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Subjet_3</td>\n",
       "      <td>15.263640</td>\n",
       "      <td>0.6483</td>\n",
       "      <td>0.4775</td>\n",
       "      <td>0.4074</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.6422</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.432</td>\n",
       "      <td>0.2376</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows  12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Model       Time  Command_Acc_p15  Command_Acc_p1  Command_Acc_p2  \\\n",
       "0   Subjet_1  15.269878           0.6243          0.9369          0.3889   \n",
       "1   Subjet_1  12.062418           0.5709          0.9189          0.3148   \n",
       "2   Subjet_1  13.520935           0.6335          0.9550          0.3889   \n",
       "3   Subjet_1  14.664869           0.6225          0.9550          0.2685   \n",
       "4   Subjet_1  13.347304           0.6188          0.9279          0.3796   \n",
       "..       ...        ...              ...             ...             ...   \n",
       "75  Subjet_3  15.910140           0.6593          0.4955          0.3611   \n",
       "76  Subjet_3  11.082789           0.5838          0.3964          0.3333   \n",
       "77  Subjet_3  14.793002           0.6427          0.4775          0.3889   \n",
       "78  Subjet_3  14.358196           0.6409          0.5135          0.3611   \n",
       "79  Subjet_3  15.263640           0.6483          0.4775          0.4074   \n",
       "\n",
       "    Command_Acc_p3  Command_Acc_p4  Command_Acc_p5  Acc_p6  Acc_p7  Acc_p8  \\\n",
       "0           0.5391          0.6239            0.63    0.38   0.384  0.2673   \n",
       "1           0.4696          0.5413            0.61    0.33   0.320  0.2673   \n",
       "2           0.5478          0.6514            0.62    0.48   0.384  0.2475   \n",
       "3           0.5217          0.6789            0.69    0.26   0.456  0.2970   \n",
       "4           0.5652          0.5780            0.64    0.39   0.416  0.2574   \n",
       "..             ...             ...             ...     ...     ...     ...   \n",
       "75          0.9913          0.7156            0.72    0.32   0.384  0.3267   \n",
       "76          0.9739          0.6697            0.52    0.41   0.400  0.2475   \n",
       "77          0.9913          0.6697            0.67    0.36   0.448  0.3267   \n",
       "78          0.9826          0.6972            0.63    0.40   0.408  0.2475   \n",
       "79          1.0000          0.6422            0.70    0.46   0.432  0.2376   \n",
       "\n",
       "   Size  \n",
       "0    10  \n",
       "1    10  \n",
       "2    10  \n",
       "3    10  \n",
       "4    10  \n",
       "..  ...  \n",
       "75   20  \n",
       "76   20  \n",
       "77   20  \n",
       "78   20  \n",
       "79   20  \n",
       "\n",
       "[80 rows x 12 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Perfomance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single model size:30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = 3\n",
    "train_image = 30 #10:20%, 20: 40%, 30:60%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([30., 30., 30., 30., 30., 30., 30., 30., 30., 30.], dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_indexs_train = (image_no<train_image)&(ALL_participant_class==subject)\n",
    "Train_Inputs = All_Inputs[select_indexs_train]\n",
    "Train_command_class = All_command_class[select_indexs_train]\n",
    "sum(Train_command_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5/5 [==============================] - 2s 332ms/step - loss: 2.1817 - accuracy: 0.2433 - val_loss: 1.8347 - val_accuracy: 0.6696\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 1s 191ms/step - loss: 1.7330 - accuracy: 0.8800 - val_loss: 1.6100 - val_accuracy: 0.9739\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 1.5523 - accuracy: 0.9867 - val_loss: 1.4779 - val_accuracy: 0.9652\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 1.4353 - accuracy: 0.9900 - val_loss: 1.3795 - val_accuracy: 0.9739\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 1.3419 - accuracy: 0.9867 - val_loss: 1.2988 - val_accuracy: 0.9652\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 1.2599 - accuracy: 0.9933 - val_loss: 1.2226 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 1s 112ms/step - loss: 1.1842 - accuracy: 0.9933 - val_loss: 1.1496 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 1.1123 - accuracy: 0.9933 - val_loss: 1.0789 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 1.0395 - accuracy: 0.9967 - val_loss: 1.0102 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.9742 - accuracy: 0.9967 - val_loss: 0.9490 - val_accuracy: 1.0000\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.9123 - accuracy: 0.9967 - val_loss: 0.8905 - val_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.8545 - accuracy: 0.9967 - val_loss: 0.8355 - val_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.8004 - accuracy: 0.9967 - val_loss: 0.7807 - val_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 0.7461 - accuracy: 0.9967 - val_loss: 0.7326 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 0.6975 - accuracy: 0.9967 - val_loss: 0.6845 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 1s 158ms/step - loss: 0.6518 - accuracy: 0.9967 - val_loss: 0.6423 - val_accuracy: 1.0000\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 1s 290ms/step - loss: 2.2599 - accuracy: 0.2200 - val_loss: 1.9556 - val_accuracy: 0.5217\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 1.8030 - accuracy: 0.6967 - val_loss: 1.6901 - val_accuracy: 0.7478\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 1.6010 - accuracy: 0.8267 - val_loss: 1.5373 - val_accuracy: 0.8783\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 1.4694 - accuracy: 0.9600 - val_loss: 1.4253 - val_accuracy: 0.9826\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 1s 163ms/step - loss: 1.3737 - accuracy: 0.9900 - val_loss: 1.3318 - val_accuracy: 0.9913\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 1s 155ms/step - loss: 1.2909 - accuracy: 0.9933 - val_loss: 1.2535 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 1.2129 - accuracy: 0.9967 - val_loss: 1.1841 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 1.1407 - accuracy: 0.9967 - val_loss: 1.1168 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 1.0740 - accuracy: 0.9967 - val_loss: 1.0514 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 1.0101 - accuracy: 0.9933 - val_loss: 0.9937 - val_accuracy: 1.0000\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.9501 - accuracy: 0.9967 - val_loss: 0.9333 - val_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 99ms/step - loss: 0.8902 - accuracy: 0.9967 - val_loss: 0.8778 - val_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.8352 - accuracy: 0.9967 - val_loss: 0.8256 - val_accuracy: 0.9913\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 99ms/step - loss: 0.7836 - accuracy: 0.9967 - val_loss: 0.7744 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 1s 105ms/step - loss: 0.7346 - accuracy: 0.9967 - val_loss: 0.7290 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 1s 163ms/step - loss: 0.6896 - accuracy: 0.9967 - val_loss: 0.6830 - val_accuracy: 1.0000\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 2s 325ms/step - loss: 2.3273 - accuracy: 0.1600 - val_loss: 2.0282 - val_accuracy: 0.4696\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 1.9670 - accuracy: 0.5567 - val_loss: 1.8785 - val_accuracy: 0.7739\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 1s 162ms/step - loss: 1.8499 - accuracy: 0.8300 - val_loss: 1.8041 - val_accuracy: 0.9043\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 1s 163ms/step - loss: 1.7781 - accuracy: 0.9667 - val_loss: 1.7384 - val_accuracy: 0.9739\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 1s 122ms/step - loss: 1.7164 - accuracy: 0.9900 - val_loss: 1.6843 - val_accuracy: 0.9739\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 1.6580 - accuracy: 0.9900 - val_loss: 1.6311 - val_accuracy: 0.9739\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 1.6041 - accuracy: 0.9933 - val_loss: 1.5785 - val_accuracy: 0.9739\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 1s 167ms/step - loss: 1.5512 - accuracy: 0.9933 - val_loss: 1.5286 - val_accuracy: 0.9913\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 1.5016 - accuracy: 0.9933 - val_loss: 1.4765 - val_accuracy: 0.9826\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 1.4519 - accuracy: 0.9933 - val_loss: 1.4295 - val_accuracy: 0.9826\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 1s 173ms/step - loss: 1.4028 - accuracy: 0.9933 - val_loss: 1.3818 - val_accuracy: 0.9826\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 1s 170ms/step - loss: 1.3554 - accuracy: 0.9933 - val_loss: 1.3359 - val_accuracy: 0.9913\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 1.3083 - accuracy: 0.9933 - val_loss: 1.2895 - val_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 1.2618 - accuracy: 0.9967 - val_loss: 1.2442 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 1.2161 - accuracy: 0.9967 - val_loss: 1.2012 - val_accuracy: 0.9913\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 1.1710 - accuracy: 0.9967 - val_loss: 1.1586 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 95ms/step - loss: 1.1256 - accuracy: 0.9967 - val_loss: 1.1130 - val_accuracy: 0.9913\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 1s 162ms/step - loss: 1.0813 - accuracy: 0.9967 - val_loss: 1.0714 - val_accuracy: 1.0000\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 2s 313ms/step - loss: 2.3894 - accuracy: 0.2267 - val_loss: 2.0454 - val_accuracy: 0.4522\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 1.9718 - accuracy: 0.5967 - val_loss: 1.8277 - val_accuracy: 0.7565\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 1.7914 - accuracy: 0.7700 - val_loss: 1.6942 - val_accuracy: 0.7913\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 1.6701 - accuracy: 0.8133 - val_loss: 1.6077 - val_accuracy: 0.8957\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 1s 174ms/step - loss: 1.5770 - accuracy: 0.9033 - val_loss: 1.5319 - val_accuracy: 0.9478\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 1s 158ms/step - loss: 1.4993 - accuracy: 0.9533 - val_loss: 1.4636 - val_accuracy: 0.9652\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 1.4324 - accuracy: 0.9800 - val_loss: 1.4028 - val_accuracy: 0.9652\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 85ms/step - loss: 1.3710 - accuracy: 0.9767 - val_loss: 1.3384 - val_accuracy: 0.9652\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 1.3101 - accuracy: 0.9900 - val_loss: 1.2786 - val_accuracy: 0.9652\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 85ms/step - loss: 1.2502 - accuracy: 0.9733 - val_loss: 1.2238 - val_accuracy: 0.9565\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 1s 157ms/step - loss: 1.1960 - accuracy: 0.9800 - val_loss: 1.1672 - val_accuracy: 0.9652\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 1.1382 - accuracy: 0.9967 - val_loss: 1.1110 - val_accuracy: 0.9652\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 1.0829 - accuracy: 0.9967 - val_loss: 1.0596 - val_accuracy: 0.9826\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 1s 162ms/step - loss: 1.0307 - accuracy: 0.9967 - val_loss: 1.0070 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 98ms/step - loss: 0.9812 - accuracy: 0.9967 - val_loss: 0.9593 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.9320 - accuracy: 0.9967 - val_loss: 0.9149 - val_accuracy: 0.9913\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.8853 - accuracy: 0.9967 - val_loss: 0.8686 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 0.8412 - accuracy: 0.9967 - val_loss: 0.8251 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 1s 155ms/step - loss: 0.7974 - accuracy: 0.9967 - val_loss: 0.7847 - val_accuracy: 1.0000\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 2s 330ms/step - loss: 2.2788 - accuracy: 0.2000 - val_loss: 1.9340 - val_accuracy: 0.6087\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 1.8440 - accuracy: 0.6800 - val_loss: 1.6891 - val_accuracy: 0.7826\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 1.6385 - accuracy: 0.8400 - val_loss: 1.5616 - val_accuracy: 0.9217\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 1.5251 - accuracy: 0.9467 - val_loss: 1.4779 - val_accuracy: 0.9739\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 81ms/step - loss: 1.4390 - accuracy: 0.9867 - val_loss: 1.3964 - val_accuracy: 0.9739\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 1.3604 - accuracy: 0.9933 - val_loss: 1.3271 - val_accuracy: 0.9913\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 1.2859 - accuracy: 0.9933 - val_loss: 1.2512 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 82ms/step - loss: 1.2134 - accuracy: 0.9967 - val_loss: 1.1852 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 85ms/step - loss: 1.1460 - accuracy: 0.9967 - val_loss: 1.1210 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 1s 119ms/step - loss: 1.0823 - accuracy: 0.9967 - val_loss: 1.0568 - val_accuracy: 1.0000\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 1.0223 - accuracy: 0.9967 - val_loss: 1.0019 - val_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.9638 - accuracy: 0.9967 - val_loss: 0.9465 - val_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.9092 - accuracy: 0.9967 - val_loss: 0.8968 - val_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 85ms/step - loss: 0.8584 - accuracy: 0.9967 - val_loss: 0.8468 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 0.8091 - accuracy: 0.9967 - val_loss: 0.7991 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 0.7632 - accuracy: 0.9967 - val_loss: 0.7544 - val_accuracy: 1.0000\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 2s 320ms/step - loss: 2.2164 - accuracy: 0.3400 - val_loss: 1.9149 - val_accuracy: 0.7304\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 1.8191 - accuracy: 0.7133 - val_loss: 1.7076 - val_accuracy: 0.8261\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 1s 163ms/step - loss: 1.6585 - accuracy: 0.8800 - val_loss: 1.5876 - val_accuracy: 0.9739\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 1s 162ms/step - loss: 1.5423 - accuracy: 0.9800 - val_loss: 1.4924 - val_accuracy: 0.9826\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 1.4550 - accuracy: 0.9867 - val_loss: 1.4136 - val_accuracy: 0.9739\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 1s 101ms/step - loss: 1.3814 - accuracy: 0.9933 - val_loss: 1.3405 - val_accuracy: 0.9739\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 1.3094 - accuracy: 0.9867 - val_loss: 1.2747 - val_accuracy: 0.9652\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 1.2440 - accuracy: 0.9967 - val_loss: 1.2139 - val_accuracy: 0.9913\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 1.1780 - accuracy: 0.9967 - val_loss: 1.1484 - val_accuracy: 0.9826\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 1.1158 - accuracy: 0.9933 - val_loss: 1.0879 - val_accuracy: 0.9913\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 1s 186ms/step - loss: 1.0534 - accuracy: 0.9933 - val_loss: 1.0288 - val_accuracy: 0.9913\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 0.9965 - accuracy: 0.9933 - val_loss: 0.9747 - val_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 0.9408 - accuracy: 0.9967 - val_loss: 0.9234 - val_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 0.8892 - accuracy: 0.9967 - val_loss: 0.8743 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 0.8417 - accuracy: 0.9967 - val_loss: 0.8287 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 1s 100ms/step - loss: 0.7956 - accuracy: 0.9967 - val_loss: 0.7841 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 1s 160ms/step - loss: 0.7530 - accuracy: 0.9967 - val_loss: 0.7418 - val_accuracy: 1.0000\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 1s 294ms/step - loss: 2.2310 - accuracy: 0.2967 - val_loss: 1.8784 - val_accuracy: 0.7304\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 1s 161ms/step - loss: 1.8087 - accuracy: 0.8067 - val_loss: 1.7060 - val_accuracy: 0.9739\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 1.6604 - accuracy: 0.9400 - val_loss: 1.5941 - val_accuracy: 0.9739\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 1.5622 - accuracy: 0.9933 - val_loss: 1.5105 - val_accuracy: 0.9913\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 1.4727 - accuracy: 0.9933 - val_loss: 1.4286 - val_accuracy: 0.9913\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 1.3932 - accuracy: 0.9967 - val_loss: 1.3541 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 1.3175 - accuracy: 0.9967 - val_loss: 1.2850 - val_accuracy: 0.9913\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 1.2481 - accuracy: 0.9967 - val_loss: 1.2188 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 1.1796 - accuracy: 0.9967 - val_loss: 1.1546 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 1s 104ms/step - loss: 1.1151 - accuracy: 0.9967 - val_loss: 1.0914 - val_accuracy: 1.0000\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 1s 163ms/step - loss: 1.0554 - accuracy: 0.9967 - val_loss: 1.0294 - val_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.9961 - accuracy: 0.9967 - val_loss: 0.9735 - val_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.9393 - accuracy: 0.9967 - val_loss: 0.9207 - val_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.8876 - accuracy: 0.9967 - val_loss: 0.8719 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 1s 141ms/step - loss: 0.8368 - accuracy: 0.9967 - val_loss: 0.8225 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 0.7883 - accuracy: 0.9967 - val_loss: 0.7765 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5/5 [==============================] - 1s 289ms/step - loss: 2.2539 - accuracy: 0.2433 - val_loss: 1.9319 - val_accuracy: 0.6000\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 1.8651 - accuracy: 0.6867 - val_loss: 1.7577 - val_accuracy: 0.7652\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 1s 162ms/step - loss: 1.7085 - accuracy: 0.8167 - val_loss: 1.6254 - val_accuracy: 0.9652\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 1.5948 - accuracy: 0.9833 - val_loss: 1.5470 - val_accuracy: 0.9565\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 1.5111 - accuracy: 0.9867 - val_loss: 1.4670 - val_accuracy: 0.9652\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 1.4297 - accuracy: 0.9867 - val_loss: 1.3978 - val_accuracy: 0.9739\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 1s 218ms/step - loss: 1.3568 - accuracy: 0.9967 - val_loss: 1.3232 - val_accuracy: 0.9913\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 1.2881 - accuracy: 0.9967 - val_loss: 1.2571 - val_accuracy: 0.9913\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 1.2200 - accuracy: 0.9967 - val_loss: 1.1965 - val_accuracy: 0.9913\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 1s 161ms/step - loss: 1.1554 - accuracy: 0.9967 - val_loss: 1.1318 - val_accuracy: 1.0000\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 1.0960 - accuracy: 0.9967 - val_loss: 1.0755 - val_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 1.0368 - accuracy: 0.9967 - val_loss: 1.0156 - val_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.9766 - accuracy: 0.9967 - val_loss: 0.9600 - val_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 85ms/step - loss: 0.9220 - accuracy: 0.9967 - val_loss: 0.9117 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.8728 - accuracy: 0.9967 - val_loss: 0.8611 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 1s 160ms/step - loss: 0.8233 - accuracy: 0.9967 - val_loss: 0.8142 - val_accuracy: 1.0000\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 2s 326ms/step - loss: 2.2533 - accuracy: 0.1967 - val_loss: 1.9605 - val_accuracy: 0.4870\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 1s 162ms/step - loss: 1.8784 - accuracy: 0.7000 - val_loss: 1.7852 - val_accuracy: 0.9739\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 1s 211ms/step - loss: 1.7437 - accuracy: 0.9667 - val_loss: 1.6813 - val_accuracy: 0.9826\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 1.6485 - accuracy: 0.9833 - val_loss: 1.6049 - val_accuracy: 0.9826\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 1.5720 - accuracy: 0.9933 - val_loss: 1.5375 - val_accuracy: 0.9913\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 1.5051 - accuracy: 0.9933 - val_loss: 1.4697 - val_accuracy: 0.9739\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 1.4370 - accuracy: 0.9933 - val_loss: 1.4036 - val_accuracy: 0.9913\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 1s 119ms/step - loss: 1.3730 - accuracy: 0.9933 - val_loss: 1.3449 - val_accuracy: 0.9913\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 1.3107 - accuracy: 0.9933 - val_loss: 1.2827 - val_accuracy: 0.9913\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 1s 161ms/step - loss: 1.2485 - accuracy: 0.9933 - val_loss: 1.2243 - val_accuracy: 0.9913\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 1s 173ms/step - loss: 1.5036 - accuracy: 0.9933 - val_loss: 1.4682 - val_accuracy: 0.9826\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 1.4346 - accuracy: 0.9933 - val_loss: 1.3989 - val_accuracy: 0.9913\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 1s 167ms/step - loss: 1.3584 - accuracy: 0.9933 - val_loss: 1.3319 - val_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 1.2921 - accuracy: 0.9933 - val_loss: 1.2645 - val_accuracy: 0.9913\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 1.2268 - accuracy: 0.9933 - val_loss: 1.2062 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 1.1677 - accuracy: 0.9967 - val_loss: 1.1483 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 1s 119ms/step - loss: 1.1119 - accuracy: 0.9967 - val_loss: 1.0942 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 1s 157ms/step - loss: 1.0583 - accuracy: 0.9967 - val_loss: 1.0433 - val_accuracy: 1.0000\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 1s 298ms/step - loss: 2.2434 - accuracy: 0.3267 - val_loss: 1.9134 - val_accuracy: 0.7826\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 1.8266 - accuracy: 0.7533 - val_loss: 1.6818 - val_accuracy: 0.7913\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 1s 175ms/step - loss: 1.6333 - accuracy: 0.8567 - val_loss: 1.5586 - val_accuracy: 0.9304\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 1s 170ms/step - loss: 1.5185 - accuracy: 0.9733 - val_loss: 1.4556 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 1s 127ms/step - loss: 1.4222 - accuracy: 0.9933 - val_loss: 1.3763 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 1.3416 - accuracy: 0.9900 - val_loss: 1.2968 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 1.2644 - accuracy: 0.9933 - val_loss: 1.2204 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 95ms/step - loss: 1.1899 - accuracy: 0.9933 - val_loss: 1.1502 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 1s 163ms/step - loss: 1.1184 - accuracy: 0.9967 - val_loss: 1.0857 - val_accuracy: 1.0000\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 1s 203ms/step - loss: 1.4143 - accuracy: 0.9933 - val_loss: 1.3665 - val_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 1.3252 - accuracy: 0.9933 - val_loss: 1.2760 - val_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 1.2397 - accuracy: 0.9967 - val_loss: 1.2003 - val_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 1.1661 - accuracy: 0.9967 - val_loss: 1.1359 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 1.0996 - accuracy: 0.9967 - val_loss: 1.0699 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 1s 160ms/step - loss: 1.0362 - accuracy: 0.9967 - val_loss: 1.0109 - val_accuracy: 0.9913\n"
     ]
    }
   ],
   "source": [
    "high_acc = 0\n",
    "for run in range(0,10):\n",
    "    # feature extraction layers\n",
    "    resnet_model = ResNet50(input_shape=(224, 224,3), include_top=False, weights=\"imagenet\")\n",
    "    for layer in resnet_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    d = resnet_model.output.shape[-1] # dimension of last layer\n",
    "\n",
    "\n",
    "    ###################### model 2 ###################### \n",
    "    layer_2_0 = tf.keras.layers.Dense(d,name=\"weight_2\")(resnet_model.output) #times weight before flatten\n",
    "    layer_2_1 = tf.keras.layers.Flatten(name='flatten_2')(layer_2_0)\n",
    "\n",
    "    Dense_2_1 = tf.keras.layers.Dense(shape_2_1, activation=actv_fun_2_1,name='fc2_1')\n",
    "    layer_2_2  = Dense_2_1(layer_2_1)\n",
    "    Dense_2_2 = tf.keras.layers.Dense(shape_2_2, activation=actv_fun_2_2,name='fc2_2')\n",
    "    layer_2_3  = Dense_2_2(layer_2_2)\n",
    "\n",
    "    Dense_2_3 = tf.keras.layers.Dense(10, activation='softmax',name='command_output')\n",
    "    out_layer_2 = Dense_2_3(layer_2_3)\n",
    "\n",
    "\n",
    "    resnet_model = tf.keras.Model(resnet_model.input, out_layer_2)\n",
    "\n",
    "\n",
    "    # resnet_model.summary() \n",
    "\n",
    "\n",
    "    ##################### training ############################\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "    callbacks = [EarlyStopping(monitor = 'val_accuracy', patience=5,restore_best_weights=True)]\n",
    "    resnet_model.compile(optimizer=opt, loss=\"categorical_crossentropy\",metrics=['accuracy'])\n",
    "\n",
    "    \n",
    "    start = timeit.default_timer()\n",
    "       \n",
    "    history1 = resnet_model.fit(Train_Inputs,Train_command_class,\n",
    "                                validation_data=(Val_Inputs,Val_command_class),\n",
    "                                callbacks=callbacks,\n",
    "                                batch_size=64,\n",
    "                                epochs=10)\n",
    "    \n",
    "    for layer in resnet_model.layers[0:175]:\n",
    "        layer.trainable = True\n",
    "        \n",
    "    history2 = resnet_model.fit(Train_Inputs,Train_command_class,\n",
    "                            validation_data=(Val_Inputs,Val_command_class), \n",
    "                           callbacks=callbacks,\n",
    "                           batch_size=64,\n",
    "                           epochs=10)\n",
    "\n",
    "    stop = timeit.default_timer()\n",
    "    run_time = stop - start\n",
    "    \n",
    "    ##################### test performance ############################\n",
    "    predictions = resnet_model.predict(Test_Inputs)\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    true_classes = test_unit_command_class\n",
    "    acc_p15_c = metrics.accuracy_score(true_classes, predicted_classes).round(4)\n",
    "\n",
    "\n",
    "    # test on p1\n",
    "    ## command classification\n",
    "    predictions = resnet_model.predict(Test_Inputs_1)\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    true_classes = np.argmax(Test_command_class_1, axis=-1)\n",
    "    acc_p1_c = metrics.accuracy_score(true_classes, predicted_classes).round(4)   \n",
    "\n",
    "    # test on p2\n",
    "    ## command classification\n",
    "    predictions = resnet_model.predict(Test_Inputs_2)\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    true_classes = np.argmax(Test_command_class_2, axis=-1)\n",
    "    acc_p2_c = metrics.accuracy_score(true_classes, predicted_classes).round(4)   \n",
    "\n",
    "    # test on p3 \n",
    "    ## command classification\n",
    "    predictions = resnet_model.predict(Test_Inputs_3)\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    true_classes = np.argmax(Test_command_class_3, axis=-1)\n",
    "    acc_p3_c = metrics.accuracy_score(true_classes, predicted_classes).round(4)   \n",
    "\n",
    "    # test on p4\n",
    "    ## command classification\n",
    "    predictions = resnet_model.predict(Test_Inputs_4)\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    true_classes = np.argmax(Test_command_class_4, axis=-1)\n",
    "    acc_p4_c = metrics.accuracy_score(true_classes, predicted_classes).round(4)   \n",
    "\n",
    "    # test on p5\n",
    "\n",
    "    ## command classification\n",
    "    predictions = resnet_model.predict(Test_Inputs_5)\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    true_classes = np.argmax(Test_command_class_5, axis=-1)\n",
    "    acc_p5_c = metrics.accuracy_score(true_classes, predicted_classes).round(4)   \n",
    "\n",
    "    # test on p6 \n",
    "    ## command classification\n",
    "    predictions = resnet_model.predict(Test_Inputs_6)\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    true_classes = test_unit_command_class_6\n",
    "    acc_p6 = metrics.accuracy_score(true_classes, predicted_classes).round(4)                \n",
    "\n",
    "    # test on p7 \n",
    "    ## command classification\n",
    "    predictions = resnet_model.predict(Test_Inputs_7)\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    true_classes = test_unit_command_class_7\n",
    "    acc_p7 = metrics.accuracy_score(true_classes, predicted_classes).round(4)    \n",
    "\n",
    "    # test on p8 \n",
    "    ## command classification\n",
    "    predictions = resnet_model.predict(Test_Inputs_8)\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    true_classes = test_unit_command_class_8\n",
    "    acc_p8 = metrics.accuracy_score(true_classes, predicted_classes).round(4)    \n",
    "\n",
    "    Perfomance = Perfomance.append({'Model': \"Subjet_3\",'Size':'30','Time':run_time,'Command_Acc_p15':acc_p15_c,\n",
    "                                    'Command_Acc_p1':acc_p1_c,'Command_Acc_p2':acc_p2_c,\n",
    "                                    'Command_Acc_p3':acc_p3_c,'Command_Acc_p4':acc_p4_c,'Command_Acc_p5':acc_p5_c,\n",
    "                                    'Acc_p6':acc_p6,'Acc_p7':acc_p7,'Acc_p8':acc_p8}, ignore_index=True)\n",
    "\n",
    "\n",
    "    if high_acc < acc_p15_c :\n",
    "        resnet_model.save('Initial_subject_3_model_size30_0608.h5')\n",
    "        high_acc = acc_p15_c \n",
    "        best_index = run\n",
    "        pd.DataFrame.from_dict(history1.history).to_csv('subject_3_size30_history1_0608.csv',index=False)\n",
    "        pd.DataFrame.from_dict(history2.history).to_csv('subject_3_size30_history2_0608.csv',index=False)\n",
    "        \n",
    "    del resnet_model\n",
    "    run = run + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "0.9913\n"
     ]
    }
   ],
   "source": [
    "resnet_model = tf.keras.models.load_model('Initial_subject_3_model_size30_0608.h5')\n",
    "predictions = resnet_model.predict(Test_Inputs_3)\n",
    "predicted_classes =  np.argmax(predictions, axis=1)\n",
    "acc_c = round(sum(x == y for x, y in zip(np.argmax(Test_command_class_3, axis=1), predicted_classes)) / len(np.argmax(Test_command_class_3, axis=1)),4)\n",
    "print(acc_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Time</th>\n",
       "      <th>Command_Acc_p15</th>\n",
       "      <th>Command_Acc_p1</th>\n",
       "      <th>Command_Acc_p2</th>\n",
       "      <th>Command_Acc_p3</th>\n",
       "      <th>Command_Acc_p4</th>\n",
       "      <th>Command_Acc_p5</th>\n",
       "      <th>Acc_p6</th>\n",
       "      <th>Acc_p7</th>\n",
       "      <th>Acc_p8</th>\n",
       "      <th>Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Subjet_1</td>\n",
       "      <td>15.269878</td>\n",
       "      <td>0.6243</td>\n",
       "      <td>0.9369</td>\n",
       "      <td>0.3889</td>\n",
       "      <td>0.5391</td>\n",
       "      <td>0.6239</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.384</td>\n",
       "      <td>0.2673</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Subjet_1</td>\n",
       "      <td>12.062418</td>\n",
       "      <td>0.5709</td>\n",
       "      <td>0.9189</td>\n",
       "      <td>0.3148</td>\n",
       "      <td>0.4696</td>\n",
       "      <td>0.5413</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.2673</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Subjet_1</td>\n",
       "      <td>13.520935</td>\n",
       "      <td>0.6335</td>\n",
       "      <td>0.9550</td>\n",
       "      <td>0.3889</td>\n",
       "      <td>0.5478</td>\n",
       "      <td>0.6514</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.384</td>\n",
       "      <td>0.2475</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Subjet_1</td>\n",
       "      <td>14.664869</td>\n",
       "      <td>0.6225</td>\n",
       "      <td>0.9550</td>\n",
       "      <td>0.2685</td>\n",
       "      <td>0.5217</td>\n",
       "      <td>0.6789</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.456</td>\n",
       "      <td>0.2970</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Subjet_1</td>\n",
       "      <td>13.347304</td>\n",
       "      <td>0.6188</td>\n",
       "      <td>0.9279</td>\n",
       "      <td>0.3796</td>\n",
       "      <td>0.5652</td>\n",
       "      <td>0.5780</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.416</td>\n",
       "      <td>0.2574</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>Subjet_3</td>\n",
       "      <td>15.712269</td>\n",
       "      <td>0.6427</td>\n",
       "      <td>0.4865</td>\n",
       "      <td>0.3704</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.6972</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.408</td>\n",
       "      <td>0.3168</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Subjet_3</td>\n",
       "      <td>15.409171</td>\n",
       "      <td>0.6519</td>\n",
       "      <td>0.5315</td>\n",
       "      <td>0.3704</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.6972</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.408</td>\n",
       "      <td>0.2277</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>Subjet_3</td>\n",
       "      <td>14.525968</td>\n",
       "      <td>0.6427</td>\n",
       "      <td>0.4865</td>\n",
       "      <td>0.3519</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.6881</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.312</td>\n",
       "      <td>0.2574</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>Subjet_3</td>\n",
       "      <td>17.149453</td>\n",
       "      <td>0.6280</td>\n",
       "      <td>0.5225</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.6422</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.424</td>\n",
       "      <td>0.2475</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>Subjet_3</td>\n",
       "      <td>14.352271</td>\n",
       "      <td>0.5856</td>\n",
       "      <td>0.4595</td>\n",
       "      <td>0.3056</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.6239</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.376</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows  12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Model       Time  Command_Acc_p15  Command_Acc_p1  Command_Acc_p2  \\\n",
       "0   Subjet_1  15.269878           0.6243          0.9369          0.3889   \n",
       "1   Subjet_1  12.062418           0.5709          0.9189          0.3148   \n",
       "2   Subjet_1  13.520935           0.6335          0.9550          0.3889   \n",
       "3   Subjet_1  14.664869           0.6225          0.9550          0.2685   \n",
       "4   Subjet_1  13.347304           0.6188          0.9279          0.3796   \n",
       "..       ...        ...              ...             ...             ...   \n",
       "85  Subjet_3  15.712269           0.6427          0.4865          0.3704   \n",
       "86  Subjet_3  15.409171           0.6519          0.5315          0.3704   \n",
       "87  Subjet_3  14.525968           0.6427          0.4865          0.3519   \n",
       "88  Subjet_3  17.149453           0.6280          0.5225          0.3333   \n",
       "89  Subjet_3  14.352271           0.5856          0.4595          0.3056   \n",
       "\n",
       "    Command_Acc_p3  Command_Acc_p4  Command_Acc_p5  Acc_p6  Acc_p7  Acc_p8  \\\n",
       "0           0.5391          0.6239            0.63    0.38   0.384  0.2673   \n",
       "1           0.4696          0.5413            0.61    0.33   0.320  0.2673   \n",
       "2           0.5478          0.6514            0.62    0.48   0.384  0.2475   \n",
       "3           0.5217          0.6789            0.69    0.26   0.456  0.2970   \n",
       "4           0.5652          0.5780            0.64    0.39   0.416  0.2574   \n",
       "..             ...             ...             ...     ...     ...     ...   \n",
       "85          0.9913          0.6972            0.65    0.31   0.408  0.3168   \n",
       "86          0.9913          0.6972            0.65    0.35   0.408  0.2277   \n",
       "87          0.9913          0.6881            0.68    0.37   0.312  0.2574   \n",
       "88          0.9913          0.6422            0.63    0.34   0.424  0.2475   \n",
       "89          0.9913          0.6239            0.52    0.39   0.376  0.1980   \n",
       "\n",
       "   Size  \n",
       "0    10  \n",
       "1    10  \n",
       "2    10  \n",
       "3    10  \n",
       "4    10  \n",
       "..  ...  \n",
       "85   30  \n",
       "86   30  \n",
       "87   30  \n",
       "88   30  \n",
       "89   30  \n",
       "\n",
       "[90 rows x 12 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Perfomance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "Perfomance.to_csv('Performance_0608_single_model.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
