{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"   #(xxxx is your specific GPU ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.layers import Activation, Dense, Flatten, GlobalAveragePooling2D\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Sequential\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from MyEarlyStopping import MyEarlyStopping\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "# from keras.optimizers import adam\n",
    "\n",
    "import timeit\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.preprocessing import LabelEncoder  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_number = 5\n",
    "train_image = 30 #10:20%, 20: 40%, 30:60%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training dataset (40%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1714 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "train_generator = train_data.flow_from_directory('/data/home/cou/yuli5/semg/Audio_MEL_Data/train',\n",
    "                                                batch_size=1,\n",
    "                                                target_size=(224,224),\n",
    "                                                class_mode='categorical',\n",
    "                                               shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_names = train_generator.filenames\n",
    "image_no = [i.split(\"/\")[1].split(\"_\")[2].split(\".\")[0] for i in image_names]\n",
    "image_no = np.array(list(map(int, image_no)))\n",
    "ALL_participant_class = [i.split(\"/\")[1].split(\"_\")[1] for i in image_names]\n",
    "ALL_participant_class = np.array(list(map(int, ALL_participant_class)))\n",
    "command_class = train_generator.classes\n",
    "All_participant_class = tf.keras.utils.to_categorical(ALL_participant_class-1, num_classes=train_number)\n",
    "All_command_class = tf.keras.utils.to_categorical(command_class, num_classes=10)\n",
    "All_command_uniform = All_command_class*0+1/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "All_Inputs = [next(train_generator)[0][0] for _ in range(len(train_generator))]\n",
    "All_Inputs = np.array(All_Inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "select_indexs_train = image_no<train_image\n",
    "Train_Inputs = All_Inputs[select_indexs_train]\n",
    "Train_participant_class = All_participant_class[select_indexs_train]\n",
    "Train_participant_uniform = Train_participant_class*0+1/train_number\n",
    "Train_command_class = All_command_class[select_indexs_train]\n",
    "Train_command_uniform = Train_command_class*0+1/10\n",
    "#sum(Train_command_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation dataset (20%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 543 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "val_data = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "val_generator = val_data.flow_from_directory('/data/home/cou/yuli5/semg/Audio_MEL_Data/validation',\n",
    "                                                batch_size=1,\n",
    "                                                target_size=(224,224),\n",
    "                                                class_mode='categorical',\n",
    "                                               shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_names = val_generator.filenames\n",
    "participant_class = [i.split(\"/\", 1)[1].split(\"_\")[1] for i in image_names]\n",
    "participant_class = np.array(list(map(int, participant_class)))\n",
    "command_class = val_generator.classes\n",
    "Val_participant_class = tf.keras.utils.to_categorical(participant_class-1, num_classes=train_number)\n",
    "Val_participant_uniform = Val_participant_class*0+1/train_number\n",
    "Val_command_class = tf.keras.utils.to_categorical(command_class, num_classes=10)\n",
    "Val_command_uniform = Val_command_class*0+1/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Val_Inputs = [next(val_generator)[0][0] for _ in range(len(val_generator))]\n",
    "Val_Inputs = np.array(Val_Inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test dataset (20%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 543 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "test_data = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "test_generator = test_data.flow_from_directory('/data/home/cou/yuli5/semg/Audio_MEL_Data/test',\n",
    "                                                batch_size=1,\n",
    "                                                target_size=(224,224),\n",
    "                                                class_mode='categorical',\n",
    "                                                shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_names = test_generator.filenames\n",
    "participant_class = [i.split(\"/\", 1)[1].split(\"_\")[1] for i in image_names]\n",
    "test_unit_participant_class = np.array(list(map(int, participant_class)))\n",
    "test_unit_command_class = test_generator.classes\n",
    "Test_participant_class = tf.keras.utils.to_categorical(test_unit_participant_class-1, num_classes=train_number)\n",
    "Test_participant_uniform = Test_participant_class*0+1/train_number\n",
    "Test_command_class = tf.keras.utils.to_categorical(test_unit_command_class, num_classes=10)\n",
    "Test_command_uniform = Test_command_class*0+1/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_Inputs = [next(test_generator)[0][0] for _ in range(len(test_generator))]\n",
    "Test_Inputs = np.array(Test_Inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_Inputs_1 = Test_Inputs[np.where(test_unit_participant_class == 1)]\n",
    "Test_command_class_1 = Test_command_class[np.where(test_unit_participant_class == 1)]\n",
    "Test_Inputs_2 = Test_Inputs[np.where(test_unit_participant_class == 2)]\n",
    "Test_command_class_2 = Test_command_class[np.where(test_unit_participant_class == 2)]\n",
    "Test_Inputs_3 = Test_Inputs[np.where(test_unit_participant_class == 3)]\n",
    "Test_command_class_3 = Test_command_class[np.where(test_unit_participant_class == 3)]\n",
    "Test_Inputs_4 = Test_Inputs[np.where(test_unit_participant_class == 4)]\n",
    "Test_command_class_4 = Test_command_class[np.where(test_unit_participant_class == 4)]\n",
    "Test_Inputs_5 = Test_Inputs[np.where(test_unit_participant_class == 5)]\n",
    "Test_command_class_5 = Test_command_class[np.where(test_unit_participant_class == 5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speaker 6 Test dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "test_data_6 = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "test_generator_6 = test_data_6.flow_from_directory('/data/home/cou/yuli5/semg/Audio_MEL_subject/p_6_split/test',\n",
    "                                                batch_size=1,\n",
    "                                                target_size=(224,224),\n",
    "                                                class_mode='categorical',\n",
    "                                                shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_names = test_generator_6.filenames\n",
    "command_class = [i.split(\"/\", 1)[0]for i in image_names]\n",
    "le = LabelEncoder()\n",
    "test_unit_command_class_6 = le.fit_transform(command_class)\n",
    "Test_command_class_6 = tf.keras.utils.to_categorical(test_unit_command_class_6, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_Inputs_6 = [next(test_generator_6)[0][0] for _ in range(len(test_generator_6))]\n",
    "Test_Inputs_6 = np.array(Test_Inputs_6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speaker 7 Test dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 125 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "test_data_7 = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "test_generator_7 = test_data_6.flow_from_directory('/data/home/cou/yuli5/semg/Audio_MEL_subject/p_7_split/test',\n",
    "                                                batch_size=1,\n",
    "                                                target_size=(224,224),\n",
    "                                                class_mode='categorical',\n",
    "                                                shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_names = test_generator_7.filenames\n",
    "command_class = [i.split(\"/\", 1)[0]for i in image_names]\n",
    "le = LabelEncoder()\n",
    "test_unit_command_class_7 = le.fit_transform(command_class)\n",
    "Test_command_class_7 = tf.keras.utils.to_categorical(test_unit_command_class_7, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_Inputs_7 = [next(test_generator_7)[0][0] for _ in range(len(test_generator_7))]\n",
    "Test_Inputs_7 = np.array(Test_Inputs_7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speaker 8 Test dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 101 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "test_data_8 = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "test_generator_8 = test_data_6.flow_from_directory('/data/home/cou/yuli5/semg/Audio_MEL_subject/p_8_split/test',\n",
    "                                                batch_size=1,\n",
    "                                                target_size=(224,224),\n",
    "                                                class_mode='categorical',\n",
    "                                                shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_names = test_generator_8.filenames\n",
    "command_class = [i.split(\"/\", 1)[0]for i in image_names]\n",
    "le = LabelEncoder()\n",
    "test_unit_command_class_8 = le.fit_transform(command_class)\n",
    "Test_command_class_8 = tf.keras.utils.to_categorical(test_unit_command_class_8, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_Inputs_8 = [next(test_generator_8)[0][0] for _ in range(len(test_generator_8))]\n",
    "Test_Inputs_8 = np.array(Test_Inputs_8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pd file store performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Size</th>\n",
       "      <th>Time</th>\n",
       "      <th>Partcp_Acc_p15</th>\n",
       "      <th>Command_Acc_p15</th>\n",
       "      <th>Partcp_Acc_p1</th>\n",
       "      <th>Command_Acc_p1</th>\n",
       "      <th>Partcp_Acc_p2</th>\n",
       "      <th>Command_Acc_p2</th>\n",
       "      <th>Partcp_Acc_p3</th>\n",
       "      <th>Command_Acc_p3</th>\n",
       "      <th>Partcp_Acc_p4</th>\n",
       "      <th>Command_Acc_p4</th>\n",
       "      <th>Partcp_Acc_p5</th>\n",
       "      <th>Command_Acc_p5</th>\n",
       "      <th>Acc_p6</th>\n",
       "      <th>Acc_p7</th>\n",
       "      <th>Acc_p8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Group</td>\n",
       "      <td>20%</td>\n",
       "      <td>47.540156</td>\n",
       "      <td>0.9724</td>\n",
       "      <td>0.9484</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.9550</td>\n",
       "      <td>0.9259</td>\n",
       "      <td>0.8796</td>\n",
       "      <td>0.9652</td>\n",
       "      <td>0.9565</td>\n",
       "      <td>0.9817</td>\n",
       "      <td>0.9633</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.528</td>\n",
       "      <td>0.3366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Group</td>\n",
       "      <td>20%</td>\n",
       "      <td>48.307249</td>\n",
       "      <td>0.9779</td>\n",
       "      <td>0.9521</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.9369</td>\n",
       "      <td>0.9352</td>\n",
       "      <td>0.8796</td>\n",
       "      <td>0.9739</td>\n",
       "      <td>0.9652</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.528</td>\n",
       "      <td>0.2970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Group</td>\n",
       "      <td>20%</td>\n",
       "      <td>46.201615</td>\n",
       "      <td>0.9613</td>\n",
       "      <td>0.9448</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.9369</td>\n",
       "      <td>0.9074</td>\n",
       "      <td>0.8611</td>\n",
       "      <td>0.9826</td>\n",
       "      <td>0.9652</td>\n",
       "      <td>0.9358</td>\n",
       "      <td>0.9725</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.432</td>\n",
       "      <td>0.2673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Group</td>\n",
       "      <td>20%</td>\n",
       "      <td>43.692362</td>\n",
       "      <td>0.9650</td>\n",
       "      <td>0.9521</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.9459</td>\n",
       "      <td>0.9074</td>\n",
       "      <td>0.8704</td>\n",
       "      <td>0.9826</td>\n",
       "      <td>0.9652</td>\n",
       "      <td>0.9358</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.504</td>\n",
       "      <td>0.2673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Group</td>\n",
       "      <td>20%</td>\n",
       "      <td>44.504580</td>\n",
       "      <td>0.9687</td>\n",
       "      <td>0.9484</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.9550</td>\n",
       "      <td>0.9259</td>\n",
       "      <td>0.8796</td>\n",
       "      <td>0.9739</td>\n",
       "      <td>0.9652</td>\n",
       "      <td>0.9541</td>\n",
       "      <td>0.9541</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.472</td>\n",
       "      <td>0.3267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Group</td>\n",
       "      <td>20%</td>\n",
       "      <td>44.229166</td>\n",
       "      <td>0.9705</td>\n",
       "      <td>0.9521</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.9550</td>\n",
       "      <td>0.9074</td>\n",
       "      <td>0.8796</td>\n",
       "      <td>0.9826</td>\n",
       "      <td>0.9739</td>\n",
       "      <td>0.9633</td>\n",
       "      <td>0.9633</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.456</td>\n",
       "      <td>0.3069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Group</td>\n",
       "      <td>20%</td>\n",
       "      <td>44.535541</td>\n",
       "      <td>0.9632</td>\n",
       "      <td>0.9540</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.9369</td>\n",
       "      <td>0.9259</td>\n",
       "      <td>0.8981</td>\n",
       "      <td>0.9565</td>\n",
       "      <td>0.9652</td>\n",
       "      <td>0.9541</td>\n",
       "      <td>0.9817</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.496</td>\n",
       "      <td>0.3267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Group</td>\n",
       "      <td>20%</td>\n",
       "      <td>42.948731</td>\n",
       "      <td>0.9724</td>\n",
       "      <td>0.9595</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.9550</td>\n",
       "      <td>0.9074</td>\n",
       "      <td>0.8889</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9739</td>\n",
       "      <td>0.9633</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.496</td>\n",
       "      <td>0.2574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Group</td>\n",
       "      <td>20%</td>\n",
       "      <td>45.444911</td>\n",
       "      <td>0.9724</td>\n",
       "      <td>0.9503</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.9459</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>0.8796</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9652</td>\n",
       "      <td>0.9633</td>\n",
       "      <td>0.9725</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.552</td>\n",
       "      <td>0.2673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Group</td>\n",
       "      <td>20%</td>\n",
       "      <td>42.707019</td>\n",
       "      <td>0.9669</td>\n",
       "      <td>0.9540</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.9459</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>0.8704</td>\n",
       "      <td>0.9739</td>\n",
       "      <td>0.9652</td>\n",
       "      <td>0.9541</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.480</td>\n",
       "      <td>0.4059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Group</td>\n",
       "      <td>40%</td>\n",
       "      <td>67.289367</td>\n",
       "      <td>0.9945</td>\n",
       "      <td>0.9761</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.9640</td>\n",
       "      <td>0.9907</td>\n",
       "      <td>0.9352</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.472</td>\n",
       "      <td>0.2772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Group</td>\n",
       "      <td>40%</td>\n",
       "      <td>64.328163</td>\n",
       "      <td>0.9890</td>\n",
       "      <td>0.9761</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.9730</td>\n",
       "      <td>0.9815</td>\n",
       "      <td>0.9259</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.480</td>\n",
       "      <td>0.2871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Group</td>\n",
       "      <td>40%</td>\n",
       "      <td>61.978212</td>\n",
       "      <td>0.9926</td>\n",
       "      <td>0.9797</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.9730</td>\n",
       "      <td>0.9907</td>\n",
       "      <td>0.9444</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.3168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Group</td>\n",
       "      <td>40%</td>\n",
       "      <td>60.036626</td>\n",
       "      <td>0.9926</td>\n",
       "      <td>0.9779</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.9730</td>\n",
       "      <td>0.9907</td>\n",
       "      <td>0.9352</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.456</td>\n",
       "      <td>0.3267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Group</td>\n",
       "      <td>40%</td>\n",
       "      <td>58.215136</td>\n",
       "      <td>0.9890</td>\n",
       "      <td>0.9761</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.9730</td>\n",
       "      <td>0.9815</td>\n",
       "      <td>0.9352</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9826</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.448</td>\n",
       "      <td>0.2871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Group</td>\n",
       "      <td>40%</td>\n",
       "      <td>49.347837</td>\n",
       "      <td>0.9871</td>\n",
       "      <td>0.9761</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.9730</td>\n",
       "      <td>0.9815</td>\n",
       "      <td>0.9352</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9817</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.472</td>\n",
       "      <td>0.2772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Group</td>\n",
       "      <td>40%</td>\n",
       "      <td>59.879732</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.9779</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.9730</td>\n",
       "      <td>0.9815</td>\n",
       "      <td>0.9444</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9826</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.3366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Group</td>\n",
       "      <td>40%</td>\n",
       "      <td>57.413757</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.9761</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.9640</td>\n",
       "      <td>0.9815</td>\n",
       "      <td>0.9444</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9826</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.3168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Group</td>\n",
       "      <td>40%</td>\n",
       "      <td>50.219540</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.9761</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.9730</td>\n",
       "      <td>0.9815</td>\n",
       "      <td>0.9352</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.456</td>\n",
       "      <td>0.2772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Group</td>\n",
       "      <td>40%</td>\n",
       "      <td>53.871787</td>\n",
       "      <td>0.9945</td>\n",
       "      <td>0.9742</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.9730</td>\n",
       "      <td>0.9907</td>\n",
       "      <td>0.9259</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.9817</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.424</td>\n",
       "      <td>0.2673</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Model Size       Time  Partcp_Acc_p15  Command_Acc_p15  Partcp_Acc_p1  \\\n",
       "0   Group  20%  47.540156          0.9724           0.9484          0.991   \n",
       "1   Group  20%  48.307249          0.9779           0.9521          1.000   \n",
       "2   Group  20%  46.201615          0.9613           0.9448          0.991   \n",
       "3   Group  20%  43.692362          0.9650           0.9521          1.000   \n",
       "4   Group  20%  44.504580          0.9687           0.9484          0.991   \n",
       "5   Group  20%  44.229166          0.9705           0.9521          1.000   \n",
       "6   Group  20%  44.535541          0.9632           0.9540          0.991   \n",
       "7   Group  20%  42.948731          0.9724           0.9595          1.000   \n",
       "8   Group  20%  45.444911          0.9724           0.9503          0.991   \n",
       "9   Group  20%  42.707019          0.9669           0.9540          0.991   \n",
       "10  Group  40%  67.289367          0.9945           0.9761          0.991   \n",
       "11  Group  40%  64.328163          0.9890           0.9761          0.982   \n",
       "12  Group  40%  61.978212          0.9926           0.9797          0.991   \n",
       "13  Group  40%  60.036626          0.9926           0.9779          0.991   \n",
       "14  Group  40%  58.215136          0.9890           0.9761          0.982   \n",
       "15  Group  40%  49.347837          0.9871           0.9761          0.982   \n",
       "16  Group  40%  59.879732          0.9908           0.9779          0.991   \n",
       "17  Group  40%  57.413757          0.9908           0.9761          0.991   \n",
       "18  Group  40%  50.219540          0.9908           0.9761          0.991   \n",
       "19  Group  40%  53.871787          0.9945           0.9742          1.000   \n",
       "\n",
       "    Command_Acc_p1  Partcp_Acc_p2  Command_Acc_p2  Partcp_Acc_p3  \\\n",
       "0           0.9550         0.9259          0.8796         0.9652   \n",
       "1           0.9369         0.9352          0.8796         0.9739   \n",
       "2           0.9369         0.9074          0.8611         0.9826   \n",
       "3           0.9459         0.9074          0.8704         0.9826   \n",
       "4           0.9550         0.9259          0.8796         0.9739   \n",
       "5           0.9550         0.9074          0.8796         0.9826   \n",
       "6           0.9369         0.9259          0.8981         0.9565   \n",
       "7           0.9550         0.9074          0.8889         0.9913   \n",
       "8           0.9459         0.9167          0.8796         0.9913   \n",
       "9           0.9459         0.9167          0.8704         0.9739   \n",
       "10          0.9640         0.9907          0.9352         1.0000   \n",
       "11          0.9730         0.9815          0.9259         0.9913   \n",
       "12          0.9730         0.9907          0.9444         0.9913   \n",
       "13          0.9730         0.9907          0.9352         0.9913   \n",
       "14          0.9730         0.9815          0.9352         0.9913   \n",
       "15          0.9730         0.9815          0.9352         0.9913   \n",
       "16          0.9730         0.9815          0.9444         0.9913   \n",
       "17          0.9640         0.9815          0.9444         0.9913   \n",
       "18          0.9730         0.9815          0.9352         0.9913   \n",
       "19          0.9730         0.9907          0.9259         0.9913   \n",
       "\n",
       "    Command_Acc_p3  Partcp_Acc_p4  Command_Acc_p4  Partcp_Acc_p5  \\\n",
       "0           0.9565         0.9817          0.9633           1.00   \n",
       "1           0.9652         0.9908          0.9908           0.99   \n",
       "2           0.9652         0.9358          0.9725           0.99   \n",
       "3           0.9652         0.9358          0.9908           1.00   \n",
       "4           0.9652         0.9541          0.9541           1.00   \n",
       "5           0.9739         0.9633          0.9633           1.00   \n",
       "6           0.9652         0.9541          0.9817           0.99   \n",
       "7           0.9739         0.9633          0.9908           1.00   \n",
       "8           0.9652         0.9633          0.9725           1.00   \n",
       "9           0.9652         0.9541          0.9908           1.00   \n",
       "10          0.9913         0.9908          0.9908           1.00   \n",
       "11          0.9913         0.9908          0.9908           1.00   \n",
       "12          0.9913         0.9908          0.9908           1.00   \n",
       "13          0.9913         0.9908          0.9908           1.00   \n",
       "14          0.9826         0.9908          0.9908           1.00   \n",
       "15          0.9913         0.9817          0.9908           1.00   \n",
       "16          0.9826         0.9908          0.9908           1.00   \n",
       "17          0.9826         0.9908          0.9908           1.00   \n",
       "18          0.9913         0.9908          0.9908           1.00   \n",
       "19          0.9913         0.9908          0.9817           1.00   \n",
       "\n",
       "    Command_Acc_p5  Acc_p6  Acc_p7  Acc_p8  \n",
       "0             0.99    0.67   0.528  0.3366  \n",
       "1             0.99    0.59   0.528  0.2970  \n",
       "2             0.99    0.67   0.432  0.2673  \n",
       "3             0.99    0.62   0.504  0.2673  \n",
       "4             0.99    0.59   0.472  0.3267  \n",
       "5             0.99    0.62   0.456  0.3069  \n",
       "6             0.99    0.67   0.496  0.3267  \n",
       "7             0.99    0.67   0.496  0.2574  \n",
       "8             0.99    0.60   0.552  0.2673  \n",
       "9             1.00    0.66   0.480  0.4059  \n",
       "10            1.00    0.65   0.472  0.2772  \n",
       "11            1.00    0.63   0.480  0.2871  \n",
       "12            1.00    0.69   0.400  0.3168  \n",
       "13            1.00    0.70   0.456  0.3267  \n",
       "14            1.00    0.70   0.448  0.2871  \n",
       "15            0.99    0.70   0.472  0.2772  \n",
       "16            1.00    0.70   0.440  0.3366  \n",
       "17            1.00    0.67   0.440  0.3168  \n",
       "18            0.99    0.63   0.456  0.2772  \n",
       "19            1.00    0.65   0.424  0.2673  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pd file store performance\n",
    "# Perfomance = pd.DataFrame(columns = ['Model','Time','Partcp_Acc_p15','Command_Acc_p15','Partcp_Acc_p1','Command_Acc_p1',\n",
    "#                                       'Partcp_Acc_p2','Command_Acc_p2','Partcp_Acc_p3','Command_Acc_p3',\n",
    "#                                       'Partcp_Acc_p4','Command_Acc_p4','Partcp_Acc_p5','Command_Acc_p5','Acc_p6','Acc_p7','Acc_p8'])\n",
    "\n",
    "Perfomance = pd.read_csv('Performance_0608_training_Data_Size.csv')\n",
    "# Perfomance\n",
    "Perfomance                                                        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "actv_fun_1_1 = \"relu\" \n",
    "actv_fun_1_2 = \"sigmoid\"\n",
    "shape_1_1 = 128\n",
    "shape_1_2 = 256\n",
    "actv_fun_2_1 = \"sigmoid\" \n",
    "actv_fun_2_2 = \"sigmoid\"\n",
    "shape_2_1 = 512\n",
    "shape_2_2 = 512\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "24/24 [==============================] - 6s 231ms/step - loss: 3.3345 - participant_output_loss: 1.1946 - command_output_loss: 2.1360 - command_output_1_loss: 8.8785e-04 - participant_output_1_loss: 0.0030 - participant_output_accuracy: 0.6107 - command_output_accuracy: 0.4127 - command_output_1_accuracy: 0.1365 - participant_output_1_accuracy: 0.1692 - val_loss: 2.7598 - val_participant_output_loss: 0.8086 - val_command_output_loss: 1.9508 - val_command_output_1_loss: 3.9016e-04 - val_participant_output_1_loss: 6.3677e-05 - val_participant_output_accuracy: 0.8508 - val_command_output_accuracy: 0.6777 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.2192\n",
      "Epoch 2/10\n",
      "24/24 [==============================] - 4s 165ms/step - loss: 2.4697 - participant_output_loss: 0.6195 - command_output_loss: 1.8500 - command_output_1_loss: 1.6620e-04 - participant_output_1_loss: 5.2210e-05 - participant_output_accuracy: 0.9084 - command_output_accuracy: 0.8094 - command_output_1_accuracy: 0.1746 - participant_output_1_accuracy: 0.2890 - val_loss: 2.2093 - val_participant_output_loss: 0.4659 - val_command_output_loss: 1.7432 - val_command_output_1_loss: 1.6964e-04 - val_participant_output_1_loss: 4.5081e-05 - val_participant_output_accuracy: 0.9448 - val_command_output_accuracy: 0.8527 - val_command_output_1_accuracy: 0.2947 - val_participant_output_1_accuracy: 0.2155\n",
      "Epoch 3/10\n",
      "24/24 [==============================] - 4s 173ms/step - loss: 2.0053 - participant_output_loss: 0.3606 - command_output_loss: 1.6445 - command_output_1_loss: 1.5106e-04 - participant_output_1_loss: 3.4346e-05 - participant_output_accuracy: 0.9746 - command_output_accuracy: 0.9351 - command_output_1_accuracy: 0.0281 - participant_output_1_accuracy: 0.2609 - val_loss: 1.8621 - val_participant_output_loss: 0.3151 - val_command_output_loss: 1.5469 - val_command_output_1_loss: 9.0936e-05 - val_participant_output_1_loss: 2.9584e-05 - val_participant_output_accuracy: 0.9613 - val_command_output_accuracy: 0.9411 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.2781\n",
      "Epoch 4/10\n",
      "24/24 [==============================] - 4s 165ms/step - loss: 1.6926 - participant_output_loss: 0.2463 - command_output_loss: 1.4462 - command_output_1_loss: 1.0029e-04 - participant_output_1_loss: 2.7142e-05 - participant_output_accuracy: 0.9866 - command_output_accuracy: 0.9545 - command_output_1_accuracy: 0.1050 - participant_output_1_accuracy: 0.2870 - val_loss: 1.6056 - val_participant_output_loss: 0.2486 - val_command_output_loss: 1.3568 - val_command_output_1_loss: 1.1920e-04 - val_participant_output_1_loss: 2.7399e-05 - val_participant_output_accuracy: 0.9742 - val_command_output_accuracy: 0.9632 - val_command_output_1_accuracy: 0.3867 - val_participant_output_1_accuracy: 0.2210\n",
      "Epoch 5/10\n",
      "24/24 [==============================] - 4s 164ms/step - loss: 1.4321 - participant_output_loss: 0.1796 - command_output_loss: 1.2524 - command_output_1_loss: 6.5731e-05 - participant_output_1_loss: 2.5333e-05 - participant_output_accuracy: 0.9933 - command_output_accuracy: 0.9773 - command_output_1_accuracy: 0.0528 - participant_output_1_accuracy: 0.2702 - val_loss: 1.3603 - val_participant_output_loss: 0.1866 - val_command_output_loss: 1.1737 - val_command_output_1_loss: 5.4934e-05 - val_participant_output_1_loss: 2.6759e-05 - val_participant_output_accuracy: 0.9853 - val_command_output_accuracy: 0.9797 - val_command_output_1_accuracy: 0.1621 - val_participant_output_1_accuracy: 0.2947\n",
      "Epoch 6/10\n",
      "24/24 [==============================] - 4s 164ms/step - loss: 1.2011 - participant_output_loss: 0.1309 - command_output_loss: 1.0701 - command_output_1_loss: 4.7106e-05 - participant_output_1_loss: 2.4691e-05 - participant_output_accuracy: 0.9973 - command_output_accuracy: 0.9860 - command_output_1_accuracy: 0.2174 - participant_output_1_accuracy: 0.2421 - val_loss: 1.1596 - val_participant_output_loss: 0.1526 - val_command_output_loss: 1.0070 - val_command_output_1_loss: 5.9827e-05 - val_participant_output_1_loss: 2.5972e-05 - val_participant_output_accuracy: 0.9871 - val_command_output_accuracy: 0.9834 - val_command_output_1_accuracy: 0.0902 - val_participant_output_1_accuracy: 0.3002\n",
      "Epoch 7/10\n",
      "24/24 [==============================] - 3s 145ms/step - loss: 1.0047 - participant_output_loss: 0.0994 - command_output_loss: 0.9053 - command_output_1_loss: 6.0965e-05 - participant_output_1_loss: 2.4195e-05 - participant_output_accuracy: 0.9987 - command_output_accuracy: 0.9926 - command_output_1_accuracy: 0.2863 - participant_output_1_accuracy: 0.2388 - val_loss: 0.9951 - val_participant_output_loss: 0.1303 - val_command_output_loss: 0.8647 - val_command_output_1_loss: 3.6374e-05 - val_participant_output_1_loss: 2.6206e-05 - val_participant_output_accuracy: 0.9816 - val_command_output_accuracy: 0.9834 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.2928\n",
      "Epoch 8/10\n",
      "24/24 [==============================] - 3s 139ms/step - loss: 0.8387 - participant_output_loss: 0.0787 - command_output_loss: 0.7600 - command_output_1_loss: 5.0595e-05 - participant_output_1_loss: 2.4734e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9940 - command_output_1_accuracy: 0.0033 - participant_output_1_accuracy: 0.2502 - val_loss: 0.8351 - val_participant_output_loss: 0.1113 - val_command_output_loss: 0.7237 - val_command_output_1_loss: 5.6822e-05 - val_participant_output_1_loss: 2.6885e-05 - val_participant_output_accuracy: 0.9834 - val_command_output_accuracy: 0.9853 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.1805\n",
      "Epoch 9/10\n",
      "24/24 [==============================] - 3s 137ms/step - loss: 0.6949 - participant_output_loss: 0.0658 - command_output_loss: 0.6290 - command_output_1_loss: 4.6024e-05 - participant_output_1_loss: 2.3536e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9967 - command_output_1_accuracy: 0.1779 - participant_output_1_accuracy: 0.2421 - val_loss: 0.7163 - val_participant_output_loss: 0.1066 - val_command_output_loss: 0.6097 - val_command_output_1_loss: 3.5498e-05 - val_participant_output_1_loss: 2.6262e-05 - val_participant_output_accuracy: 0.9816 - val_command_output_accuracy: 0.9834 - val_command_output_1_accuracy: 0.0055 - val_participant_output_1_accuracy: 0.2726\n",
      "Epoch 10/10\n",
      "24/24 [==============================] - 4s 155ms/step - loss: 0.5773 - participant_output_loss: 0.0575 - command_output_loss: 0.5197 - command_output_1_loss: 3.6301e-05 - participant_output_1_loss: 2.2877e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9987 - command_output_1_accuracy: 0.0334 - participant_output_1_accuracy: 0.2428 - val_loss: 0.6061 - val_participant_output_loss: 0.0902 - val_command_output_loss: 0.5159 - val_command_output_1_loss: 1.9419e-05 - val_participant_output_1_loss: 2.6183e-05 - val_participant_output_accuracy: 0.9890 - val_command_output_accuracy: 0.9853 - val_command_output_1_accuracy: 0.0460 - val_participant_output_1_accuracy: 0.2910\n",
      "Epoch 1/10\n",
      "24/24 [==============================] - 4s 168ms/step - loss: 0.4805 - participant_output_loss: 0.0488 - command_output_loss: 0.4317 - command_output_1_loss: 2.9467e-05 - participant_output_1_loss: 2.1824e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9993 - command_output_1_accuracy: 0.0421 - participant_output_1_accuracy: 0.2181 - val_loss: 0.5267 - val_participant_output_loss: 0.0853 - val_command_output_loss: 0.4414 - val_command_output_1_loss: 2.4827e-05 - val_participant_output_1_loss: 2.5714e-05 - val_participant_output_accuracy: 0.9871 - val_command_output_accuracy: 0.9834 - val_command_output_1_accuracy: 0.0018 - val_participant_output_1_accuracy: 0.2726\n",
      "Epoch 2/10\n",
      "24/24 [==============================] - 3s 140ms/step - loss: 0.4016 - participant_output_loss: 0.0442 - command_output_loss: 0.3573 - command_output_1_loss: 3.0408e-05 - participant_output_1_loss: 2.0301e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9993 - command_output_1_accuracy: 6.6890e-04 - participant_output_1_accuracy: 0.2395 - val_loss: 0.4517 - val_participant_output_loss: 0.0801 - val_command_output_loss: 0.3716 - val_command_output_1_loss: 1.9967e-05 - val_participant_output_1_loss: 2.4808e-05 - val_participant_output_accuracy: 0.9908 - val_command_output_accuracy: 0.9816 - val_command_output_1_accuracy: 0.0110 - val_participant_output_1_accuracy: 0.1657\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10\n",
      "24/24 [==============================] - 3s 145ms/step - loss: 0.3347 - participant_output_loss: 0.0395 - command_output_loss: 0.2952 - command_output_1_loss: 2.5499e-05 - participant_output_1_loss: 1.9334e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9993 - command_output_1_accuracy: 0.0569 - participant_output_1_accuracy: 0.2381 - val_loss: 0.3980 - val_participant_output_loss: 0.0799 - val_command_output_loss: 0.3181 - val_command_output_1_loss: 1.8560e-05 - val_participant_output_1_loss: 2.3351e-05 - val_participant_output_accuracy: 0.9853 - val_command_output_accuracy: 0.9853 - val_command_output_1_accuracy: 0.4862 - val_participant_output_1_accuracy: 0.2302\n",
      "Epoch 4/10\n",
      "24/24 [==============================] - 4s 163ms/step - loss: 0.2819 - participant_output_loss: 0.0358 - command_output_loss: 0.2461 - command_output_1_loss: 1.7049e-05 - participant_output_1_loss: 1.7563e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9993 - command_output_1_accuracy: 0.4936 - participant_output_1_accuracy: 0.2241 - val_loss: 0.3442 - val_participant_output_loss: 0.0691 - val_command_output_loss: 0.2751 - val_command_output_1_loss: 1.5474e-05 - val_participant_output_1_loss: 2.2482e-05 - val_participant_output_accuracy: 0.9926 - val_command_output_accuracy: 0.9853 - val_command_output_1_accuracy: 0.0258 - val_participant_output_1_accuracy: 0.2505\n",
      "Epoch 5/10\n",
      "24/24 [==============================] - 3s 141ms/step - loss: 0.2397 - participant_output_loss: 0.0323 - command_output_loss: 0.2074 - command_output_1_loss: 1.9504e-05 - participant_output_1_loss: 1.6870e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9993 - command_output_1_accuracy: 0.0013 - participant_output_1_accuracy: 0.2314 - val_loss: 0.3084 - val_participant_output_loss: 0.0696 - val_command_output_loss: 0.2387 - val_command_output_1_loss: 2.1651e-05 - val_participant_output_1_loss: 2.1775e-05 - val_participant_output_accuracy: 0.9871 - val_command_output_accuracy: 0.9853 - val_command_output_1_accuracy: 0.0442 - val_participant_output_1_accuracy: 0.2339\n",
      "Epoch 6/10\n",
      "24/24 [==============================] - 3s 139ms/step - loss: 0.2033 - participant_output_loss: 0.0290 - command_output_loss: 0.1743 - command_output_1_loss: 1.8076e-05 - participant_output_1_loss: 1.5800e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9993 - command_output_1_accuracy: 0.0321 - participant_output_1_accuracy: 0.2114 - val_loss: 0.2738 - val_participant_output_loss: 0.0635 - val_command_output_loss: 0.2103 - val_command_output_1_loss: 7.4611e-06 - val_participant_output_1_loss: 2.1482e-05 - val_participant_output_accuracy: 0.9890 - val_command_output_accuracy: 0.9834 - val_command_output_1_accuracy: 0.0221 - val_participant_output_1_accuracy: 0.2762\n",
      "Epoch 7/10\n",
      "24/24 [==============================] - 3s 137ms/step - loss: 0.1747 - participant_output_loss: 0.0265 - command_output_loss: 0.1481 - command_output_1_loss: 1.8911e-05 - participant_output_1_loss: 1.4881e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9993 - command_output_1_accuracy: 0.0047 - participant_output_1_accuracy: 0.2201 - val_loss: 0.2479 - val_participant_output_loss: 0.0640 - val_command_output_loss: 0.1839 - val_command_output_1_loss: 7.7511e-06 - val_participant_output_1_loss: 2.0623e-05 - val_participant_output_accuracy: 0.9871 - val_command_output_accuracy: 0.9853 - val_command_output_1_accuracy: 0.1713 - val_participant_output_1_accuracy: 0.2762\n",
      "Epoch 8/10\n",
      "24/24 [==============================] - 3s 136ms/step - loss: 0.1517 - participant_output_loss: 0.0246 - command_output_loss: 0.1271 - command_output_1_loss: 1.1525e-05 - participant_output_1_loss: 1.3809e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9993 - command_output_1_accuracy: 0.1632 - participant_output_1_accuracy: 0.2308 - val_loss: 0.2252 - val_participant_output_loss: 0.0576 - val_command_output_loss: 0.1676 - val_command_output_1_loss: 9.3463e-06 - val_participant_output_1_loss: 2.0164e-05 - val_participant_output_accuracy: 0.9908 - val_command_output_accuracy: 0.9853 - val_command_output_1_accuracy: 0.3076 - val_participant_output_1_accuracy: 0.1934\n",
      "Epoch 9/10\n",
      "24/24 [==============================] - 4s 159ms/step - loss: 0.1337 - participant_output_loss: 0.0228 - command_output_loss: 0.1109 - command_output_1_loss: 1.0329e-05 - participant_output_1_loss: 1.3029e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9993 - command_output_1_accuracy: 0.0321 - participant_output_1_accuracy: 0.2301 - val_loss: 0.2074 - val_participant_output_loss: 0.0565 - val_command_output_loss: 0.1509 - val_command_output_1_loss: 8.5227e-06 - val_participant_output_1_loss: 1.9187e-05 - val_participant_output_accuracy: 0.9890 - val_command_output_accuracy: 0.9853 - val_command_output_1_accuracy: 0.0110 - val_participant_output_1_accuracy: 0.2265\n",
      "Epoch 1/10\n",
      "24/24 [==============================] - 5s 214ms/step - loss: 3.5417 - participant_output_loss: 1.3227 - command_output_loss: 2.2142 - command_output_1_loss: 9.6934e-04 - participant_output_1_loss: 0.0039 - participant_output_accuracy: 0.5144 - command_output_accuracy: 0.4294 - command_output_1_accuracy: 0.0709 - participant_output_1_accuracy: 0.2395 - val_loss: 3.0480 - val_participant_output_loss: 0.9839 - val_command_output_loss: 2.0638 - val_command_output_1_loss: 1.9487e-04 - val_participant_output_1_loss: 9.3071e-05 - val_participant_output_accuracy: 0.7624 - val_command_output_accuracy: 0.6446 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.0313\n",
      "Epoch 2/10\n",
      "24/24 [==============================] - 3s 145ms/step - loss: 2.7551 - participant_output_loss: 0.7518 - command_output_loss: 2.0030 - command_output_1_loss: 1.8028e-04 - participant_output_1_loss: 7.6858e-05 - participant_output_accuracy: 0.8662 - command_output_accuracy: 0.6970 - command_output_1_accuracy: 0.0000e+00 - participant_output_1_accuracy: 0.1478 - val_loss: 2.5251 - val_participant_output_loss: 0.5941 - val_command_output_loss: 1.9309 - val_command_output_1_loss: 8.0965e-05 - val_participant_output_1_loss: 4.1386e-05 - val_participant_output_accuracy: 0.9116 - val_command_output_accuracy: 0.8195 - val_command_output_1_accuracy: 0.0129 - val_participant_output_1_accuracy: 0.1160\n",
      "Epoch 3/10\n",
      "24/24 [==============================] - 4s 154ms/step - loss: 2.3635 - participant_output_loss: 0.5066 - command_output_loss: 1.8568 - command_output_1_loss: 6.7818e-05 - participant_output_1_loss: 3.4477e-05 - participant_output_accuracy: 0.9485 - command_output_accuracy: 0.8321 - command_output_1_accuracy: 0.0716 - participant_output_1_accuracy: 0.1839 - val_loss: 2.2664 - val_participant_output_loss: 0.4697 - val_command_output_loss: 1.7966 - val_command_output_1_loss: 8.3340e-05 - val_participant_output_1_loss: 2.9726e-05 - val_participant_output_accuracy: 0.9540 - val_command_output_accuracy: 0.8508 - val_command_output_1_accuracy: 0.1179 - val_participant_output_1_accuracy: 0.1731\n",
      "Epoch 4/10\n",
      "24/24 [==============================] - 4s 166ms/step - loss: 2.0855 - participant_output_loss: 0.3687 - command_output_loss: 1.7168 - command_output_1_loss: 6.9379e-05 - participant_output_1_loss: 2.8215e-05 - participant_output_accuracy: 0.9779 - command_output_accuracy: 0.9164 - command_output_1_accuracy: 0.1839 - participant_output_1_accuracy: 0.1993 - val_loss: 2.0033 - val_participant_output_loss: 0.3474 - val_command_output_loss: 1.6558 - val_command_output_1_loss: 4.3314e-05 - val_participant_output_1_loss: 2.6490e-05 - val_participant_output_accuracy: 0.9650 - val_command_output_accuracy: 0.9190 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.1436\n",
      "Epoch 5/10\n",
      "24/24 [==============================] - 4s 163ms/step - loss: 1.8438 - participant_output_loss: 0.2715 - command_output_loss: 1.5721 - command_output_1_loss: 1.0246e-04 - participant_output_1_loss: 2.6147e-05 - participant_output_accuracy: 0.9900 - command_output_accuracy: 0.9666 - command_output_1_accuracy: 0.0000e+00 - participant_output_1_accuracy: 0.1839 - val_loss: 1.7973 - val_participant_output_loss: 0.2878 - val_command_output_loss: 1.5094 - val_command_output_1_loss: 8.6085e-05 - val_participant_output_1_loss: 2.5467e-05 - val_participant_output_accuracy: 0.9761 - val_command_output_accuracy: 0.9650 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.1713\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10\n",
      "24/24 [==============================] - 4s 163ms/step - loss: 1.6346 - participant_output_loss: 0.2167 - command_output_loss: 1.4178 - command_output_1_loss: 5.6779e-05 - participant_output_1_loss: 2.4713e-05 - participant_output_accuracy: 0.9953 - command_output_accuracy: 0.9853 - command_output_1_accuracy: 0.0575 - participant_output_1_accuracy: 0.1799 - val_loss: 1.6024 - val_participant_output_loss: 0.2381 - val_command_output_loss: 1.3642 - val_command_output_1_loss: 4.5399e-05 - val_participant_output_1_loss: 2.4649e-05 - val_participant_output_accuracy: 0.9797 - val_command_output_accuracy: 0.9705 - val_command_output_1_accuracy: 0.5028 - val_participant_output_1_accuracy: 0.1602\n",
      "Epoch 7/10\n",
      "24/24 [==============================] - 4s 161ms/step - loss: 1.4474 - participant_output_loss: 0.1753 - command_output_loss: 1.2720 - command_output_1_loss: 6.1507e-05 - participant_output_1_loss: 2.3533e-05 - participant_output_accuracy: 0.9973 - command_output_accuracy: 0.9906 - command_output_1_accuracy: 0.3525 - participant_output_1_accuracy: 0.2013 - val_loss: 1.4320 - val_participant_output_loss: 0.1992 - val_command_output_loss: 1.2327 - val_command_output_1_loss: 6.5135e-05 - val_participant_output_1_loss: 2.5403e-05 - val_participant_output_accuracy: 0.9834 - val_command_output_accuracy: 0.9742 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.1363\n",
      "Epoch 8/10\n",
      "24/24 [==============================] - 4s 158ms/step - loss: 1.2839 - participant_output_loss: 0.1464 - command_output_loss: 1.1373 - command_output_1_loss: 1.0052e-04 - participant_output_1_loss: 2.3329e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9953 - command_output_1_accuracy: 0.0656 - participant_output_1_accuracy: 0.1813 - val_loss: 1.2784 - val_participant_output_loss: 0.1807 - val_command_output_loss: 1.0977 - val_command_output_1_loss: 6.6166e-05 - val_participant_output_1_loss: 2.5054e-05 - val_participant_output_accuracy: 0.9816 - val_command_output_accuracy: 0.9797 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.1436\n",
      "Epoch 9/10\n",
      "24/24 [==============================] - 4s 165ms/step - loss: 1.1230 - participant_output_loss: 0.1237 - command_output_loss: 0.9991 - command_output_1_loss: 7.4914e-05 - participant_output_1_loss: 2.3605e-05 - participant_output_accuracy: 0.9987 - command_output_accuracy: 0.9953 - command_output_1_accuracy: 0.1351 - participant_output_1_accuracy: 0.1993 - val_loss: 1.1290 - val_participant_output_loss: 0.1569 - val_command_output_loss: 0.9720 - val_command_output_1_loss: 4.3320e-05 - val_participant_output_1_loss: 2.4670e-05 - val_participant_output_accuracy: 0.9871 - val_command_output_accuracy: 0.9816 - val_command_output_1_accuracy: 0.4622 - val_participant_output_1_accuracy: 0.2689\n",
      "Epoch 10/10\n",
      "24/24 [==============================] - 4s 160ms/step - loss: 0.9785 - participant_output_loss: 0.1042 - command_output_loss: 0.8742 - command_output_1_loss: 5.8172e-05 - participant_output_1_loss: 2.2690e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9973 - command_output_1_accuracy: 0.0201 - participant_output_1_accuracy: 0.1799 - val_loss: 0.9983 - val_participant_output_loss: 0.1414 - val_command_output_loss: 0.8568 - val_command_output_1_loss: 6.1438e-05 - val_participant_output_1_loss: 2.5426e-05 - val_participant_output_accuracy: 0.9871 - val_command_output_accuracy: 0.9834 - val_command_output_1_accuracy: 0.0074 - val_participant_output_1_accuracy: 0.1418\n",
      "Epoch 1/10\n",
      "24/24 [==============================] - 4s 175ms/step - loss: 0.8443 - participant_output_loss: 0.0883 - command_output_loss: 0.7559 - command_output_1_loss: 5.7436e-05 - participant_output_1_loss: 2.2833e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9980 - command_output_1_accuracy: 0.2488 - participant_output_1_accuracy: 0.1926 - val_loss: 0.8844 - val_participant_output_loss: 0.1235 - val_command_output_loss: 0.7608 - val_command_output_1_loss: 4.1508e-05 - val_participant_output_1_loss: 2.5936e-05 - val_participant_output_accuracy: 0.9890 - val_command_output_accuracy: 0.9779 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.1234\n",
      "Epoch 2/10\n",
      "24/24 [==============================] - 3s 136ms/step - loss: 0.7314 - participant_output_loss: 0.0739 - command_output_loss: 0.6574 - command_output_1_loss: 4.1306e-05 - participant_output_1_loss: 2.2893e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9987 - command_output_1_accuracy: 0.0000e+00 - participant_output_1_accuracy: 0.1906 - val_loss: 0.7685 - val_participant_output_loss: 0.1095 - val_command_output_loss: 0.6590 - val_command_output_1_loss: 4.0174e-05 - val_participant_output_1_loss: 2.7304e-05 - val_participant_output_accuracy: 0.9908 - val_command_output_accuracy: 0.9834 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.1842\n",
      "Epoch 3/10\n",
      "24/24 [==============================] - 3s 141ms/step - loss: 0.6207 - participant_output_loss: 0.0641 - command_output_loss: 0.5565 - command_output_1_loss: 4.3187e-05 - participant_output_1_loss: 2.3257e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9987 - command_output_1_accuracy: 0.0482 - participant_output_1_accuracy: 0.1853 - val_loss: 0.6641 - val_participant_output_loss: 0.1018 - val_command_output_loss: 0.5622 - val_command_output_1_loss: 1.9334e-05 - val_participant_output_1_loss: 2.7699e-05 - val_participant_output_accuracy: 0.9908 - val_command_output_accuracy: 0.9816 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.2357\n",
      "Epoch 4/10\n",
      "24/24 [==============================] - 4s 167ms/step - loss: 0.5229 - participant_output_loss: 0.0577 - command_output_loss: 0.4652 - command_output_1_loss: 3.3858e-05 - participant_output_1_loss: 2.2674e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9987 - command_output_1_accuracy: 0.0722 - participant_output_1_accuracy: 0.2161 - val_loss: 0.5711 - val_participant_output_loss: 0.0952 - val_command_output_loss: 0.4758 - val_command_output_1_loss: 4.3684e-05 - val_participant_output_1_loss: 2.7045e-05 - val_participant_output_accuracy: 0.9908 - val_command_output_accuracy: 0.9853 - val_command_output_1_accuracy: 0.2597 - val_participant_output_1_accuracy: 0.1400\n",
      "Epoch 5/10\n",
      "24/24 [==============================] - 3s 140ms/step - loss: 0.4366 - participant_output_loss: 0.0518 - command_output_loss: 0.3847 - command_output_1_loss: 4.3181e-05 - participant_output_1_loss: 2.0972e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9993 - command_output_1_accuracy: 0.0776 - participant_output_1_accuracy: 0.1826 - val_loss: 0.4924 - val_participant_output_loss: 0.0914 - val_command_output_loss: 0.4009 - val_command_output_1_loss: 2.1796e-05 - val_participant_output_1_loss: 2.5809e-05 - val_participant_output_accuracy: 0.9908 - val_command_output_accuracy: 0.9834 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.2118\n",
      "Epoch 6/10\n",
      "24/24 [==============================] - 3s 132ms/step - loss: 0.3640 - participant_output_loss: 0.0472 - command_output_loss: 0.3167 - command_output_1_loss: 2.3995e-05 - participant_output_1_loss: 1.9513e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9993 - command_output_1_accuracy: 0.0441 - participant_output_1_accuracy: 0.1933 - val_loss: 0.4248 - val_participant_output_loss: 0.0842 - val_command_output_loss: 0.3406 - val_command_output_1_loss: 1.3400e-05 - val_participant_output_1_loss: 2.4021e-05 - val_participant_output_accuracy: 0.9890 - val_command_output_accuracy: 0.9853 - val_command_output_1_accuracy: 0.0074 - val_participant_output_1_accuracy: 0.1897\n",
      "Epoch 7/10\n",
      "24/24 [==============================] - 3s 119ms/step - loss: 0.3047 - participant_output_loss: 0.0433 - command_output_loss: 0.2614 - command_output_1_loss: 1.8110e-05 - participant_output_1_loss: 1.7852e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9993 - command_output_1_accuracy: 0.0000e+00 - participant_output_1_accuracy: 0.1967 - val_loss: 0.3672 - val_participant_output_loss: 0.0784 - val_command_output_loss: 0.2887 - val_command_output_1_loss: 1.8543e-05 - val_participant_output_1_loss: 2.3246e-05 - val_participant_output_accuracy: 0.9908 - val_command_output_accuracy: 0.9834 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.1750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10\n",
      "24/24 [==============================] - 3s 128ms/step - loss: 0.2575 - participant_output_loss: 0.0402 - command_output_loss: 0.2173 - command_output_1_loss: 1.5175e-05 - participant_output_1_loss: 1.6910e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9993 - command_output_1_accuracy: 0.0334 - participant_output_1_accuracy: 0.1926 - val_loss: 0.3290 - val_participant_output_loss: 0.0781 - val_command_output_loss: 0.2509 - val_command_output_1_loss: 1.6532e-05 - val_participant_output_1_loss: 2.2314e-05 - val_participant_output_accuracy: 0.9926 - val_command_output_accuracy: 0.9834 - val_command_output_1_accuracy: 0.0074 - val_participant_output_1_accuracy: 0.1842\n",
      "Epoch 9/10\n",
      "24/24 [==============================] - 4s 154ms/step - loss: 0.2199 - participant_output_loss: 0.0371 - command_output_loss: 0.1827 - command_output_1_loss: 1.0659e-05 - participant_output_1_loss: 1.5979e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9993 - command_output_1_accuracy: 0.0916 - participant_output_1_accuracy: 0.2100 - val_loss: 0.2955 - val_participant_output_loss: 0.0751 - val_command_output_loss: 0.2204 - val_command_output_1_loss: 6.5373e-06 - val_participant_output_1_loss: 2.1470e-05 - val_participant_output_accuracy: 0.9908 - val_command_output_accuracy: 0.9853 - val_command_output_1_accuracy: 0.3333 - val_participant_output_1_accuracy: 0.2081\n",
      "Epoch 1/10\n",
      "24/24 [==============================] - 5s 216ms/step - loss: 3.2761 - participant_output_loss: 1.3336 - command_output_loss: 1.9400 - command_output_1_loss: 5.2602e-04 - participant_output_1_loss: 0.0020 - participant_output_accuracy: 0.5619 - command_output_accuracy: 0.6060 - command_output_1_accuracy: 0.0154 - participant_output_1_accuracy: 0.1712 - val_loss: 2.7075 - val_participant_output_loss: 1.0358 - val_command_output_loss: 1.6715 - val_command_output_1_loss: 1.0973e-04 - val_participant_output_1_loss: 1.1018e-04 - val_participant_output_accuracy: 0.7182 - val_command_output_accuracy: 0.8564 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.0534\n",
      "Epoch 2/10\n",
      "24/24 [==============================] - 4s 153ms/step - loss: 2.3744 - participant_output_loss: 0.8526 - command_output_loss: 1.5216 - command_output_1_loss: 1.2405e-04 - participant_output_1_loss: 6.7051e-05 - participant_output_accuracy: 0.8522 - command_output_accuracy: 0.8997 - command_output_1_accuracy: 0.1151 - participant_output_1_accuracy: 0.1371 - val_loss: 2.1157 - val_participant_output_loss: 0.7419 - val_command_output_loss: 1.3736 - val_command_output_1_loss: 1.9653e-04 - val_participant_output_1_loss: 4.2168e-05 - val_participant_output_accuracy: 0.8932 - val_command_output_accuracy: 0.8987 - val_command_output_1_accuracy: 0.0847 - val_participant_output_1_accuracy: 0.1971\n",
      "Epoch 3/10\n",
      "24/24 [==============================] - 4s 168ms/step - loss: 1.8365 - participant_output_loss: 0.6060 - command_output_loss: 1.2304 - command_output_1_loss: 9.2471e-05 - participant_output_1_loss: 3.5032e-05 - participant_output_accuracy: 0.9478 - command_output_accuracy: 0.9518 - command_output_1_accuracy: 0.0535 - participant_output_1_accuracy: 0.2234 - val_loss: 1.6565 - val_participant_output_loss: 0.5342 - val_command_output_loss: 1.1222 - val_command_output_1_loss: 7.5980e-05 - val_participant_output_1_loss: 3.4425e-05 - val_participant_output_accuracy: 0.9503 - val_command_output_accuracy: 0.9540 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.1363\n",
      "Epoch 4/10\n",
      "24/24 [==============================] - 4s 167ms/step - loss: 1.4284 - participant_output_loss: 0.4532 - command_output_loss: 0.9751 - command_output_1_loss: 7.1899e-05 - participant_output_1_loss: 3.3597e-05 - participant_output_accuracy: 0.9786 - command_output_accuracy: 0.9786 - command_output_1_accuracy: 0.2241 - participant_output_1_accuracy: 0.2154 - val_loss: 1.3145 - val_participant_output_loss: 0.4210 - val_command_output_loss: 0.8933 - val_command_output_1_loss: 1.0561e-04 - val_participant_output_1_loss: 3.4388e-05 - val_participant_output_accuracy: 0.9687 - val_command_output_accuracy: 0.9576 - val_command_output_1_accuracy: 0.1013 - val_participant_output_1_accuracy: 0.1381\n",
      "Epoch 5/10\n",
      "24/24 [==============================] - 4s 166ms/step - loss: 1.1100 - participant_output_loss: 0.3561 - command_output_loss: 0.7538 - command_output_1_loss: 6.0265e-05 - participant_output_1_loss: 3.2521e-05 - participant_output_accuracy: 0.9846 - command_output_accuracy: 0.9893 - command_output_1_accuracy: 0.0462 - participant_output_1_accuracy: 0.2007 - val_loss: 1.0429 - val_participant_output_loss: 0.3507 - val_command_output_loss: 0.6920 - val_command_output_1_loss: 5.6301e-05 - val_participant_output_1_loss: 3.5105e-05 - val_participant_output_accuracy: 0.9669 - val_command_output_accuracy: 0.9816 - val_command_output_1_accuracy: 0.2781 - val_participant_output_1_accuracy: 0.1381\n",
      "Epoch 6/10\n",
      "24/24 [==============================] - 4s 157ms/step - loss: 0.8576 - participant_output_loss: 0.2828 - command_output_loss: 0.5746 - command_output_1_loss: 5.2959e-05 - participant_output_1_loss: 3.1892e-05 - participant_output_accuracy: 0.9926 - command_output_accuracy: 0.9933 - command_output_1_accuracy: 0.1003 - participant_output_1_accuracy: 0.1813 - val_loss: 0.8436 - val_participant_output_loss: 0.2996 - val_command_output_loss: 0.5439 - val_command_output_1_loss: 4.8796e-05 - val_participant_output_1_loss: 3.4529e-05 - val_participant_output_accuracy: 0.9797 - val_command_output_accuracy: 0.9797 - val_command_output_1_accuracy: 0.0092 - val_participant_output_1_accuracy: 0.2578\n",
      "Epoch 7/10\n",
      "24/24 [==============================] - 4s 159ms/step - loss: 0.6743 - participant_output_loss: 0.2315 - command_output_loss: 0.4427 - command_output_1_loss: 4.3179e-05 - participant_output_1_loss: 3.2238e-05 - participant_output_accuracy: 0.9960 - command_output_accuracy: 0.9953 - command_output_1_accuracy: 0.1465 - participant_output_1_accuracy: 0.1886 - val_loss: 0.6807 - val_participant_output_loss: 0.2484 - val_command_output_loss: 0.4322 - val_command_output_1_loss: 5.8781e-05 - val_participant_output_1_loss: 3.5480e-05 - val_participant_output_accuracy: 0.9816 - val_command_output_accuracy: 0.9816 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.2873\n",
      "Epoch 8/10\n",
      "24/24 [==============================] - 4s 156ms/step - loss: 0.5269 - participant_output_loss: 0.1892 - command_output_loss: 0.3377 - command_output_1_loss: 4.9220e-05 - participant_output_1_loss: 3.1510e-05 - participant_output_accuracy: 0.9973 - command_output_accuracy: 0.9980 - command_output_1_accuracy: 0.1130 - participant_output_1_accuracy: 0.1980 - val_loss: 0.5605 - val_participant_output_loss: 0.2165 - val_command_output_loss: 0.3439 - val_command_output_1_loss: 6.3513e-05 - val_participant_output_1_loss: 3.4714e-05 - val_participant_output_accuracy: 0.9871 - val_command_output_accuracy: 0.9816 - val_command_output_1_accuracy: 0.2744 - val_participant_output_1_accuracy: 0.1473\n",
      "Epoch 9/10\n",
      "24/24 [==============================] - 4s 158ms/step - loss: 0.4234 - participant_output_loss: 0.1626 - command_output_loss: 0.2607 - command_output_1_loss: 4.5798e-05 - participant_output_1_loss: 2.9677e-05 - participant_output_accuracy: 0.9987 - command_output_accuracy: 0.9987 - command_output_1_accuracy: 0.0829 - participant_output_1_accuracy: 0.2000 - val_loss: 0.4709 - val_participant_output_loss: 0.1867 - val_command_output_loss: 0.2842 - val_command_output_1_loss: 2.6037e-05 - val_participant_output_1_loss: 3.2276e-05 - val_participant_output_accuracy: 0.9908 - val_command_output_accuracy: 0.9797 - val_command_output_1_accuracy: 0.0037 - val_participant_output_1_accuracy: 0.2007\n",
      "Epoch 10/10\n",
      "24/24 [==============================] - 3s 118ms/step - loss: 0.3382 - participant_output_loss: 0.1348 - command_output_loss: 0.2034 - command_output_1_loss: 2.3310e-05 - participant_output_1_loss: 2.7891e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9993 - command_output_1_accuracy: 0.0107 - participant_output_1_accuracy: 0.1893 - val_loss: 0.4037 - val_participant_output_loss: 0.1640 - val_command_output_loss: 0.2396 - val_command_output_1_loss: 2.6735e-05 - val_participant_output_1_loss: 3.1080e-05 - val_participant_output_accuracy: 0.9853 - val_command_output_accuracy: 0.9834 - val_command_output_1_accuracy: 0.0829 - val_participant_output_1_accuracy: 0.2026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "24/24 [==============================] - 4s 172ms/step - loss: 0.2728 - participant_output_loss: 0.1103 - command_output_loss: 0.1625 - command_output_1_loss: 2.5638e-05 - participant_output_1_loss: 2.6295e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9993 - command_output_1_accuracy: 0.1592 - participant_output_1_accuracy: 0.1880 - val_loss: 0.3377 - val_participant_output_loss: 0.1408 - val_command_output_loss: 0.1969 - val_command_output_1_loss: 1.8733e-05 - val_participant_output_1_loss: 2.9919e-05 - val_participant_output_accuracy: 0.9871 - val_command_output_accuracy: 0.9890 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.2173\n",
      "Epoch 2/10\n",
      "24/24 [==============================] - 3s 125ms/step - loss: 0.2247 - participant_output_loss: 0.0921 - command_output_loss: 0.1325 - command_output_1_loss: 1.9374e-05 - participant_output_1_loss: 2.4177e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9993 - command_output_1_accuracy: 0.0328 - participant_output_1_accuracy: 0.1967 - val_loss: 0.2987 - val_participant_output_loss: 0.1265 - val_command_output_loss: 0.1721 - val_command_output_1_loss: 1.5387e-05 - val_participant_output_1_loss: 2.8820e-05 - val_participant_output_accuracy: 0.9871 - val_command_output_accuracy: 0.9853 - val_command_output_1_accuracy: 0.0239 - val_participant_output_1_accuracy: 0.1878\n",
      "Epoch 3/10\n",
      "24/24 [==============================] - 3s 119ms/step - loss: 0.1887 - participant_output_loss: 0.0790 - command_output_loss: 0.1097 - command_output_1_loss: 1.5337e-05 - participant_output_1_loss: 2.2659e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9993 - command_output_1_accuracy: 0.0649 - participant_output_1_accuracy: 0.1960 - val_loss: 0.2672 - val_participant_output_loss: 0.1147 - val_command_output_loss: 0.1525 - val_command_output_1_loss: 1.4625e-05 - val_participant_output_1_loss: 2.7636e-05 - val_participant_output_accuracy: 0.9871 - val_command_output_accuracy: 0.9853 - val_command_output_1_accuracy: 0.4678 - val_participant_output_1_accuracy: 0.2413\n",
      "Epoch 4/10\n",
      "24/24 [==============================] - 3s 143ms/step - loss: 0.1617 - participant_output_loss: 0.0701 - command_output_loss: 0.0915 - command_output_1_loss: 1.3430e-05 - participant_output_1_loss: 2.1306e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9993 - command_output_1_accuracy: 0.2181 - participant_output_1_accuracy: 0.1926 - val_loss: 0.2397 - val_participant_output_loss: 0.1070 - val_command_output_loss: 0.1327 - val_command_output_1_loss: 1.0901e-05 - val_participant_output_1_loss: 2.6733e-05 - val_participant_output_accuracy: 0.9890 - val_command_output_accuracy: 0.9890 - val_command_output_1_accuracy: 0.0792 - val_participant_output_1_accuracy: 0.2560\n",
      "Epoch 5/10\n",
      "24/24 [==============================] - 4s 146ms/step - loss: 0.1402 - participant_output_loss: 0.0628 - command_output_loss: 0.0774 - command_output_1_loss: 9.0728e-06 - participant_output_1_loss: 1.9850e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9993 - command_output_1_accuracy: 0.1786 - participant_output_1_accuracy: 0.1980 - val_loss: 0.2261 - val_participant_output_loss: 0.1041 - val_command_output_loss: 0.1220 - val_command_output_1_loss: 1.1294e-05 - val_participant_output_1_loss: 2.5583e-05 - val_participant_output_accuracy: 0.9871 - val_command_output_accuracy: 0.9853 - val_command_output_1_accuracy: 0.0737 - val_participant_output_1_accuracy: 0.1952\n",
      "Epoch 6/10\n",
      "24/24 [==============================] - 4s 147ms/step - loss: 0.1235 - participant_output_loss: 0.0572 - command_output_loss: 0.0663 - command_output_1_loss: 1.0084e-05 - participant_output_1_loss: 1.8370e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9993 - command_output_1_accuracy: 0.0635 - participant_output_1_accuracy: 0.2094 - val_loss: 0.2024 - val_participant_output_loss: 0.0933 - val_command_output_loss: 0.1091 - val_command_output_1_loss: 8.7596e-06 - val_participant_output_1_loss: 2.5134e-05 - val_participant_output_accuracy: 0.9908 - val_command_output_accuracy: 0.9871 - val_command_output_1_accuracy: 0.1455 - val_participant_output_1_accuracy: 0.2007\n",
      "Epoch 7/10\n",
      "24/24 [==============================] - 3s 138ms/step - loss: 0.1089 - participant_output_loss: 0.0514 - command_output_loss: 0.0574 - command_output_1_loss: 7.3320e-06 - participant_output_1_loss: 1.7214e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9993 - command_output_1_accuracy: 0.0863 - participant_output_1_accuracy: 0.2047 - val_loss: 0.1894 - val_participant_output_loss: 0.0877 - val_command_output_loss: 0.1017 - val_command_output_1_loss: 7.2139e-06 - val_participant_output_1_loss: 2.4000e-05 - val_participant_output_accuracy: 0.9890 - val_command_output_accuracy: 0.9871 - val_command_output_1_accuracy: 0.3039 - val_participant_output_1_accuracy: 0.1584\n",
      "Epoch 8/10\n",
      "24/24 [==============================] - 3s 139ms/step - loss: 0.0966 - participant_output_loss: 0.0464 - command_output_loss: 0.0502 - command_output_1_loss: 5.6922e-06 - participant_output_1_loss: 1.5922e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9993 - command_output_1_accuracy: 0.2314 - participant_output_1_accuracy: 0.1946 - val_loss: 0.1764 - val_participant_output_loss: 0.0846 - val_command_output_loss: 0.0918 - val_command_output_1_loss: 5.2447e-06 - val_participant_output_1_loss: 2.3089e-05 - val_participant_output_accuracy: 0.9853 - val_command_output_accuracy: 0.9908 - val_command_output_1_accuracy: 0.0166 - val_participant_output_1_accuracy: 0.2947\n",
      "Epoch 9/10\n",
      "24/24 [==============================] - 3s 138ms/step - loss: 0.0862 - participant_output_loss: 0.0419 - command_output_loss: 0.0443 - command_output_1_loss: 4.5419e-06 - participant_output_1_loss: 1.5229e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9993 - command_output_1_accuracy: 0.1258 - participant_output_1_accuracy: 0.2120 - val_loss: 0.1651 - val_participant_output_loss: 0.0781 - val_command_output_loss: 0.0870 - val_command_output_1_loss: 4.4479e-06 - val_participant_output_1_loss: 2.1621e-05 - val_participant_output_accuracy: 0.9871 - val_command_output_accuracy: 0.9908 - val_command_output_1_accuracy: 0.3223 - val_participant_output_1_accuracy: 0.1676\n",
      "Epoch 10/10\n",
      "24/24 [==============================] - 3s 119ms/step - loss: 0.0774 - participant_output_loss: 0.0379 - command_output_loss: 0.0395 - command_output_1_loss: 4.7417e-06 - participant_output_1_loss: 1.4174e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9993 - command_output_1_accuracy: 0.0676 - participant_output_1_accuracy: 0.1973 - val_loss: 0.1548 - val_participant_output_loss: 0.0720 - val_command_output_loss: 0.0829 - val_command_output_1_loss: 3.6830e-06 - val_participant_output_1_loss: 2.0887e-05 - val_participant_output_accuracy: 0.9908 - val_command_output_accuracy: 0.9871 - val_command_output_1_accuracy: 0.1621 - val_participant_output_1_accuracy: 0.1971\n",
      "Epoch 1/10\n",
      "24/24 [==============================] - 5s 211ms/step - loss: 3.3231 - participant_output_loss: 1.2868 - command_output_loss: 2.0342 - command_output_1_loss: 6.1966e-04 - participant_output_1_loss: 0.0015 - participant_output_accuracy: 0.5699 - command_output_accuracy: 0.5291 - command_output_1_accuracy: 0.3030 - participant_output_1_accuracy: 0.2468 - val_loss: 2.7147 - val_participant_output_loss: 0.9142 - val_command_output_loss: 1.8001 - val_command_output_1_loss: 2.8279e-04 - val_participant_output_1_loss: 7.7964e-05 - val_participant_output_accuracy: 0.8287 - val_command_output_accuracy: 0.7735 - val_command_output_1_accuracy: 0.9650 - val_participant_output_1_accuracy: 0.0110\n",
      "Epoch 2/10\n",
      "24/24 [==============================] - 3s 135ms/step - loss: 2.3810 - participant_output_loss: 0.7302 - command_output_loss: 1.6506 - command_output_1_loss: 1.3483e-04 - participant_output_1_loss: 5.3600e-05 - participant_output_accuracy: 0.8977 - command_output_accuracy: 0.8722 - command_output_1_accuracy: 0.3411 - participant_output_1_accuracy: 0.2769 - val_loss: 2.0746 - val_participant_output_loss: 0.5605 - val_command_output_loss: 1.5140 - val_command_output_1_loss: 6.6014e-05 - val_participant_output_1_loss: 3.0693e-05 - val_participant_output_accuracy: 0.9319 - val_command_output_accuracy: 0.9171 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.1473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10\n",
      "24/24 [==============================] - 3s 135ms/step - loss: 1.8136 - participant_output_loss: 0.4366 - command_output_loss: 1.3769 - command_output_1_loss: 5.4122e-05 - participant_output_1_loss: 2.7314e-05 - participant_output_accuracy: 0.9652 - command_output_accuracy: 0.9438 - command_output_1_accuracy: 0.0000e+00 - participant_output_1_accuracy: 0.2054 - val_loss: 1.6245 - val_participant_output_loss: 0.3707 - val_command_output_loss: 1.2538 - val_command_output_1_loss: 4.4707e-05 - val_participant_output_1_loss: 2.6236e-05 - val_participant_output_accuracy: 0.9632 - val_command_output_accuracy: 0.9576 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.2228\n",
      "Epoch 4/10\n",
      "24/24 [==============================] - 3s 141ms/step - loss: 1.4033 - participant_output_loss: 0.2782 - command_output_loss: 1.1250 - command_output_1_loss: 6.1068e-05 - participant_output_1_loss: 2.3042e-05 - participant_output_accuracy: 0.9826 - command_output_accuracy: 0.9699 - command_output_1_accuracy: 0.0067 - participant_output_1_accuracy: 0.1866 - val_loss: 1.2832 - val_participant_output_loss: 0.2550 - val_command_output_loss: 1.0281 - val_command_output_1_loss: 7.6687e-05 - val_participant_output_1_loss: 2.5162e-05 - val_participant_output_accuracy: 0.9650 - val_command_output_accuracy: 0.9761 - val_command_output_1_accuracy: 0.0276 - val_participant_output_1_accuracy: 0.1344\n",
      "Epoch 5/10\n",
      "24/24 [==============================] - 3s 142ms/step - loss: 1.1002 - participant_output_loss: 0.1971 - command_output_loss: 0.9030 - command_output_1_loss: 7.1721e-05 - participant_output_1_loss: 2.1679e-05 - participant_output_accuracy: 0.9913 - command_output_accuracy: 0.9853 - command_output_1_accuracy: 0.0609 - participant_output_1_accuracy: 0.1452 - val_loss: 1.0438 - val_participant_output_loss: 0.2020 - val_command_output_loss: 0.8418 - val_command_output_1_loss: 7.2009e-05 - val_participant_output_1_loss: 2.3913e-05 - val_participant_output_accuracy: 0.9779 - val_command_output_accuracy: 0.9687 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.1805\n",
      "Epoch 6/10\n",
      "24/24 [==============================] - 3s 139ms/step - loss: 0.8567 - participant_output_loss: 0.1403 - command_output_loss: 0.7164 - command_output_1_loss: 5.9368e-05 - participant_output_1_loss: 2.1009e-05 - participant_output_accuracy: 0.9940 - command_output_accuracy: 0.9906 - command_output_1_accuracy: 0.0421 - participant_output_1_accuracy: 0.1632 - val_loss: 0.8269 - val_participant_output_loss: 0.1583 - val_command_output_loss: 0.6685 - val_command_output_1_loss: 9.1212e-05 - val_participant_output_1_loss: 2.4312e-05 - val_participant_output_accuracy: 0.9797 - val_command_output_accuracy: 0.9834 - val_command_output_1_accuracy: 0.3757 - val_participant_output_1_accuracy: 0.1529\n",
      "Epoch 7/10\n",
      "24/24 [==============================] - 3s 135ms/step - loss: 0.6615 - participant_output_loss: 0.1022 - command_output_loss: 0.5593 - command_output_1_loss: 6.3042e-05 - participant_output_1_loss: 2.0145e-05 - participant_output_accuracy: 0.9980 - command_output_accuracy: 0.9960 - command_output_1_accuracy: 0.4020 - participant_output_1_accuracy: 0.1425 - val_loss: 0.6696 - val_participant_output_loss: 0.1293 - val_command_output_loss: 0.5402 - val_command_output_1_loss: 5.4239e-05 - val_participant_output_1_loss: 2.3630e-05 - val_participant_output_accuracy: 0.9779 - val_command_output_accuracy: 0.9853 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.2063\n",
      "Epoch 8/10\n",
      "24/24 [==============================] - 4s 156ms/step - loss: 0.5221 - participant_output_loss: 0.0814 - command_output_loss: 0.4405 - command_output_1_loss: 6.4358e-05 - participant_output_1_loss: 1.9311e-05 - participant_output_accuracy: 0.9993 - command_output_accuracy: 0.9980 - command_output_1_accuracy: 0.0013 - participant_output_1_accuracy: 0.1712 - val_loss: 0.5478 - val_participant_output_loss: 0.1110 - val_command_output_loss: 0.4367 - val_command_output_1_loss: 3.2461e-05 - val_participant_output_1_loss: 2.2415e-05 - val_participant_output_accuracy: 0.9834 - val_command_output_accuracy: 0.9834 - val_command_output_1_accuracy: 0.0221 - val_participant_output_1_accuracy: 0.2026\n",
      "Epoch 9/10\n",
      "24/24 [==============================] - 4s 154ms/step - loss: 0.4069 - participant_output_loss: 0.0616 - command_output_loss: 0.3453 - command_output_1_loss: 3.6797e-05 - participant_output_1_loss: 1.7601e-05 - participant_output_accuracy: 0.9993 - command_output_accuracy: 0.9980 - command_output_1_accuracy: 0.2395 - participant_output_1_accuracy: 0.1605 - val_loss: 0.4540 - val_participant_output_loss: 0.0960 - val_command_output_loss: 0.3580 - val_command_output_1_loss: 3.3982e-05 - val_participant_output_1_loss: 2.1462e-05 - val_participant_output_accuracy: 0.9890 - val_command_output_accuracy: 0.9816 - val_command_output_1_accuracy: 0.0239 - val_participant_output_1_accuracy: 0.1418\n",
      "Epoch 10/10\n",
      "24/24 [==============================] - 4s 150ms/step - loss: 0.3222 - participant_output_loss: 0.0510 - command_output_loss: 0.2711 - command_output_1_loss: 3.5936e-05 - participant_output_1_loss: 1.6296e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9993 - command_output_1_accuracy: 0.0074 - participant_output_1_accuracy: 0.1706 - val_loss: 0.3829 - val_participant_output_loss: 0.0882 - val_command_output_loss: 0.2946 - val_command_output_1_loss: 2.3720e-05 - val_participant_output_1_loss: 1.9692e-05 - val_participant_output_accuracy: 0.9890 - val_command_output_accuracy: 0.9853 - val_command_output_1_accuracy: 0.0239 - val_participant_output_1_accuracy: 0.1694\n",
      "Epoch 1/10\n",
      "24/24 [==============================] - 4s 174ms/step - loss: 0.2590 - participant_output_loss: 0.0443 - command_output_loss: 0.2147 - command_output_1_loss: 2.0152e-05 - participant_output_1_loss: 1.4841e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9993 - command_output_1_accuracy: 0.0876 - participant_output_1_accuracy: 0.1659 - val_loss: 0.3238 - val_participant_output_loss: 0.0780 - val_command_output_loss: 0.2458 - val_command_output_1_loss: 1.6500e-05 - val_participant_output_1_loss: 1.8441e-05 - val_participant_output_accuracy: 0.9926 - val_command_output_accuracy: 0.9853 - val_command_output_1_accuracy: 0.0092 - val_participant_output_1_accuracy: 0.2081\n",
      "Epoch 2/10\n",
      "24/24 [==============================] - 3s 145ms/step - loss: 0.2120 - participant_output_loss: 0.0391 - command_output_loss: 0.1729 - command_output_1_loss: 1.4704e-05 - participant_output_1_loss: 1.3604e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9993 - command_output_1_accuracy: 0.0247 - participant_output_1_accuracy: 0.1612 - val_loss: 0.2813 - val_participant_output_loss: 0.0760 - val_command_output_loss: 0.2053 - val_command_output_1_loss: 1.4529e-05 - val_participant_output_1_loss: 1.7591e-05 - val_participant_output_accuracy: 0.9908 - val_command_output_accuracy: 0.9834 - val_command_output_1_accuracy: 0.0221 - val_participant_output_1_accuracy: 0.1621\n",
      "Epoch 3/10\n",
      "24/24 [==============================] - 4s 148ms/step - loss: 0.1758 - participant_output_loss: 0.0336 - command_output_loss: 0.1422 - command_output_1_loss: 1.8199e-05 - participant_output_1_loss: 1.2354e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9993 - command_output_1_accuracy: 0.0040 - participant_output_1_accuracy: 0.1632 - val_loss: 0.2484 - val_participant_output_loss: 0.0688 - val_command_output_loss: 0.1796 - val_command_output_1_loss: 9.8909e-06 - val_participant_output_1_loss: 1.6771e-05 - val_participant_output_accuracy: 0.9926 - val_command_output_accuracy: 0.9853 - val_command_output_1_accuracy: 0.0074 - val_participant_output_1_accuracy: 0.1492\n",
      "Epoch 4/10\n",
      "24/24 [==============================] - 3s 131ms/step - loss: 0.1497 - participant_output_loss: 0.0301 - command_output_loss: 0.1196 - command_output_1_loss: 1.0485e-05 - participant_output_1_loss: 1.1214e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9993 - command_output_1_accuracy: 0.1010 - participant_output_1_accuracy: 0.1726 - val_loss: 0.2258 - val_participant_output_loss: 0.0659 - val_command_output_loss: 0.1599 - val_command_output_1_loss: 7.7356e-06 - val_participant_output_1_loss: 1.5474e-05 - val_participant_output_accuracy: 0.9908 - val_command_output_accuracy: 0.9853 - val_command_output_1_accuracy: 0.0313 - val_participant_output_1_accuracy: 0.1934\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10\n",
      "24/24 [==============================] - 3s 141ms/step - loss: 0.1290 - participant_output_loss: 0.0271 - command_output_loss: 0.1019 - command_output_1_loss: 8.0483e-06 - participant_output_1_loss: 1.0295e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9993 - command_output_1_accuracy: 0.0207 - participant_output_1_accuracy: 0.1652 - val_loss: 0.2052 - val_participant_output_loss: 0.0629 - val_command_output_loss: 0.1422 - val_command_output_1_loss: 6.8113e-06 - val_participant_output_1_loss: 1.4608e-05 - val_participant_output_accuracy: 0.9926 - val_command_output_accuracy: 0.9853 - val_command_output_1_accuracy: 0.0552 - val_participant_output_1_accuracy: 0.1897\n",
      "Epoch 6/10\n",
      "24/24 [==============================] - 3s 145ms/step - loss: 0.1122 - participant_output_loss: 0.0247 - command_output_loss: 0.0875 - command_output_1_loss: 9.0446e-06 - participant_output_1_loss: 9.4083e-06 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9993 - command_output_1_accuracy: 0.0702 - participant_output_1_accuracy: 0.1679 - val_loss: 0.1884 - val_participant_output_loss: 0.0596 - val_command_output_loss: 0.1288 - val_command_output_1_loss: 5.1672e-06 - val_participant_output_1_loss: 1.3839e-05 - val_participant_output_accuracy: 0.9926 - val_command_output_accuracy: 0.9834 - val_command_output_1_accuracy: 0.0331 - val_participant_output_1_accuracy: 0.1657\n",
      "Epoch 1/10\n",
      "24/24 [==============================] - 5s 225ms/step - loss: 3.3764 - participant_output_loss: 1.2107 - command_output_loss: 2.1630 - command_output_1_loss: 3.7007e-04 - participant_output_1_loss: 0.0024 - participant_output_accuracy: 0.5853 - command_output_accuracy: 0.4435 - command_output_1_accuracy: 0.0114 - participant_output_1_accuracy: 0.2027 - val_loss: 2.7918 - val_participant_output_loss: 0.8321 - val_command_output_loss: 1.9594 - val_command_output_1_loss: 1.8204e-04 - val_participant_output_1_loss: 1.0418e-04 - val_participant_output_accuracy: 0.8435 - val_command_output_accuracy: 0.7164 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.1934\n",
      "Epoch 2/10\n",
      "24/24 [==============================] - 3s 140ms/step - loss: 2.5327 - participant_output_loss: 0.6610 - command_output_loss: 1.8714 - command_output_1_loss: 1.3681e-04 - participant_output_1_loss: 7.4833e-05 - participant_output_accuracy: 0.8783 - command_output_accuracy: 0.7425 - command_output_1_accuracy: 0.0575 - participant_output_1_accuracy: 0.2268 - val_loss: 2.3142 - val_participant_output_loss: 0.5388 - val_command_output_loss: 1.7752 - val_command_output_1_loss: 7.4831e-05 - val_participant_output_1_loss: 4.6479e-05 - val_participant_output_accuracy: 0.9208 - val_command_output_accuracy: 0.8932 - val_command_output_1_accuracy: 0.3738 - val_participant_output_1_accuracy: 0.0976\n",
      "Epoch 3/10\n",
      "24/24 [==============================] - 3s 145ms/step - loss: 2.1022 - participant_output_loss: 0.4186 - command_output_loss: 1.6835 - command_output_1_loss: 1.2193e-04 - participant_output_1_loss: 3.7245e-05 - participant_output_accuracy: 0.9672 - command_output_accuracy: 0.8856 - command_output_1_accuracy: 0.1920 - participant_output_1_accuracy: 0.1405 - val_loss: 1.9536 - val_participant_output_loss: 0.3542 - val_command_output_loss: 1.5992 - val_command_output_1_loss: 7.9707e-05 - val_participant_output_1_loss: 3.5780e-05 - val_participant_output_accuracy: 0.9558 - val_command_output_accuracy: 0.9245 - val_command_output_1_accuracy: 0.6059 - val_participant_output_1_accuracy: 0.1492\n",
      "Epoch 4/10\n",
      "24/24 [==============================] - 4s 161ms/step - loss: 1.7810 - participant_output_loss: 0.2795 - command_output_loss: 1.5013 - command_output_1_loss: 5.7364e-05 - participant_output_1_loss: 3.2606e-05 - participant_output_accuracy: 0.9799 - command_output_accuracy: 0.9411 - command_output_1_accuracy: 0.0515 - participant_output_1_accuracy: 0.1953 - val_loss: 1.7012 - val_participant_output_loss: 0.2738 - val_command_output_loss: 1.4272 - val_command_output_1_loss: 9.5172e-05 - val_participant_output_1_loss: 3.4416e-05 - val_participant_output_accuracy: 0.9687 - val_command_output_accuracy: 0.9558 - val_command_output_1_accuracy: 0.0018 - val_participant_output_1_accuracy: 0.1160\n",
      "Epoch 5/10\n",
      "24/24 [==============================] - 4s 155ms/step - loss: 1.5185 - participant_output_loss: 0.1980 - command_output_loss: 1.3204 - command_output_1_loss: 8.0861e-05 - participant_output_1_loss: 3.1404e-05 - participant_output_accuracy: 0.9886 - command_output_accuracy: 0.9726 - command_output_1_accuracy: 0.1264 - participant_output_1_accuracy: 0.2221 - val_loss: 1.4545 - val_participant_output_loss: 0.2056 - val_command_output_loss: 1.2487 - val_command_output_1_loss: 9.4798e-05 - val_participant_output_1_loss: 3.3390e-05 - val_participant_output_accuracy: 0.9761 - val_command_output_accuracy: 0.9613 - val_command_output_1_accuracy: 0.2339 - val_participant_output_1_accuracy: 0.1786\n",
      "Epoch 6/10\n",
      "24/24 [==============================] - 4s 159ms/step - loss: 1.2878 - participant_output_loss: 0.1476 - command_output_loss: 1.1402 - command_output_1_loss: 5.3569e-05 - participant_output_1_loss: 2.9982e-05 - participant_output_accuracy: 0.9940 - command_output_accuracy: 0.9853 - command_output_1_accuracy: 0.0642 - participant_output_1_accuracy: 0.2254 - val_loss: 1.2401 - val_participant_output_loss: 0.1714 - val_command_output_loss: 1.0686 - val_command_output_1_loss: 2.2368e-05 - val_participant_output_1_loss: 3.1226e-05 - val_participant_output_accuracy: 0.9816 - val_command_output_accuracy: 0.9742 - val_command_output_1_accuracy: 0.1031 - val_participant_output_1_accuracy: 0.1878\n",
      "Epoch 7/10\n",
      "24/24 [==============================] - 4s 147ms/step - loss: 1.0784 - participant_output_loss: 0.1156 - command_output_loss: 0.9628 - command_output_1_loss: 4.2946e-05 - participant_output_1_loss: 2.9152e-05 - participant_output_accuracy: 0.9967 - command_output_accuracy: 0.9886 - command_output_1_accuracy: 0.0595 - participant_output_1_accuracy: 0.2094 - val_loss: 1.0504 - val_participant_output_loss: 0.1447 - val_command_output_loss: 0.9056 - val_command_output_1_loss: 6.0454e-05 - val_participant_output_1_loss: 3.3309e-05 - val_participant_output_accuracy: 0.9853 - val_command_output_accuracy: 0.9705 - val_command_output_1_accuracy: 0.0166 - val_participant_output_1_accuracy: 0.1234\n",
      "Epoch 8/10\n",
      "24/24 [==============================] - 4s 149ms/step - loss: 0.8903 - participant_output_loss: 0.0923 - command_output_loss: 0.7979 - command_output_1_loss: 4.3079e-05 - participant_output_1_loss: 3.0495e-05 - participant_output_accuracy: 0.9967 - command_output_accuracy: 0.9953 - command_output_1_accuracy: 0.0040 - participant_output_1_accuracy: 0.2134 - val_loss: 0.8782 - val_participant_output_loss: 0.1206 - val_command_output_loss: 0.7575 - val_command_output_1_loss: 3.9849e-05 - val_participant_output_1_loss: 3.4498e-05 - val_participant_output_accuracy: 0.9871 - val_command_output_accuracy: 0.9779 - val_command_output_1_accuracy: 0.0037 - val_participant_output_1_accuracy: 0.2026\n",
      "Epoch 9/10\n",
      "24/24 [==============================] - 3s 116ms/step - loss: 0.7280 - participant_output_loss: 0.0713 - command_output_loss: 0.6566 - command_output_1_loss: 3.9179e-05 - participant_output_1_loss: 2.9715e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9960 - command_output_1_accuracy: 0.1472 - participant_output_1_accuracy: 0.2107 - val_loss: 0.7401 - val_participant_output_loss: 0.1082 - val_command_output_loss: 0.6318 - val_command_output_1_loss: 5.3778e-05 - val_participant_output_1_loss: 3.1631e-05 - val_participant_output_accuracy: 0.9853 - val_command_output_accuracy: 0.9742 - val_command_output_1_accuracy: 0.1989 - val_participant_output_1_accuracy: 0.1934\n",
      "Epoch 10/10\n",
      "24/24 [==============================] - 3s 146ms/step - loss: 0.5909 - participant_output_loss: 0.0578 - command_output_loss: 0.5330 - command_output_1_loss: 4.8256e-05 - participant_output_1_loss: 2.7498e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9973 - command_output_1_accuracy: 0.0161 - participant_output_1_accuracy: 0.1987 - val_loss: 0.6183 - val_participant_output_loss: 0.0981 - val_command_output_loss: 0.5202 - val_command_output_1_loss: 4.8502e-05 - val_participant_output_1_loss: 3.1057e-05 - val_participant_output_accuracy: 0.9871 - val_command_output_accuracy: 0.9816 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.2192\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "24/24 [==============================] - 4s 170ms/step - loss: 0.4733 - participant_output_loss: 0.0498 - command_output_loss: 0.4234 - command_output_1_loss: 3.2276e-05 - participant_output_1_loss: 2.7205e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9993 - command_output_1_accuracy: 0.1645 - participant_output_1_accuracy: 0.1946 - val_loss: 0.5100 - val_participant_output_loss: 0.0856 - val_command_output_loss: 0.4244 - val_command_output_1_loss: 2.9759e-05 - val_participant_output_1_loss: 3.2427e-05 - val_participant_output_accuracy: 0.9890 - val_command_output_accuracy: 0.9779 - val_command_output_1_accuracy: 0.0074 - val_participant_output_1_accuracy: 0.1252\n",
      "Epoch 2/10\n",
      "24/24 [==============================] - 3s 138ms/step - loss: 0.3779 - participant_output_loss: 0.0426 - command_output_loss: 0.3352 - command_output_1_loss: 3.1820e-05 - participant_output_1_loss: 2.5645e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9993 - command_output_1_accuracy: 0.0020 - participant_output_1_accuracy: 0.2020 - val_loss: 0.4276 - val_participant_output_loss: 0.0809 - val_command_output_loss: 0.3466 - val_command_output_1_loss: 2.7887e-05 - val_participant_output_1_loss: 2.8984e-05 - val_participant_output_accuracy: 0.9890 - val_command_output_accuracy: 0.9797 - val_command_output_1_accuracy: 0.0663 - val_participant_output_1_accuracy: 0.2247\n",
      "Epoch 3/10\n",
      "24/24 [==============================] - 3s 127ms/step - loss: 0.3020 - participant_output_loss: 0.0380 - command_output_loss: 0.2640 - command_output_1_loss: 3.3718e-05 - participant_output_1_loss: 2.3438e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9993 - command_output_1_accuracy: 0.3579 - participant_output_1_accuracy: 0.2107 - val_loss: 0.3633 - val_participant_output_loss: 0.0779 - val_command_output_loss: 0.2854 - val_command_output_1_loss: 1.5354e-05 - val_participant_output_1_loss: 2.8665e-05 - val_participant_output_accuracy: 0.9890 - val_command_output_accuracy: 0.9761 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.1731\n",
      "Epoch 4/10\n",
      "24/24 [==============================] - 3s 142ms/step - loss: 0.2426 - participant_output_loss: 0.0338 - command_output_loss: 0.2088 - command_output_1_loss: 2.2299e-05 - participant_output_1_loss: 2.1652e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9993 - command_output_1_accuracy: 0.0000e+00 - participant_output_1_accuracy: 0.2054 - val_loss: 0.3113 - val_participant_output_loss: 0.0726 - val_command_output_loss: 0.2387 - val_command_output_1_loss: 1.2659e-05 - val_participant_output_1_loss: 2.6718e-05 - val_participant_output_accuracy: 0.9890 - val_command_output_accuracy: 0.9834 - val_command_output_1_accuracy: 0.0147 - val_participant_output_1_accuracy: 0.2063\n",
      "Epoch 5/10\n",
      "24/24 [==============================] - 3s 142ms/step - loss: 0.1973 - participant_output_loss: 0.0298 - command_output_loss: 0.1675 - command_output_1_loss: 1.3853e-05 - participant_output_1_loss: 1.9453e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9993 - command_output_1_accuracy: 0.5398 - participant_output_1_accuracy: 0.2147 - val_loss: 0.2726 - val_participant_output_loss: 0.0714 - val_command_output_loss: 0.2012 - val_command_output_1_loss: 1.2488e-05 - val_participant_output_1_loss: 2.4840e-05 - val_participant_output_accuracy: 0.9871 - val_command_output_accuracy: 0.9871 - val_command_output_1_accuracy: 0.0295 - val_participant_output_1_accuracy: 0.1621\n",
      "Epoch 6/10\n",
      "24/24 [==============================] - 4s 159ms/step - loss: 0.1644 - participant_output_loss: 0.0274 - command_output_loss: 0.1370 - command_output_1_loss: 1.6100e-05 - participant_output_1_loss: 1.7850e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9993 - command_output_1_accuracy: 0.0027 - participant_output_1_accuracy: 0.2100 - val_loss: 0.2380 - val_participant_output_loss: 0.0648 - val_command_output_loss: 0.1731 - val_command_output_1_loss: 6.7154e-06 - val_participant_output_1_loss: 2.3766e-05 - val_participant_output_accuracy: 0.9890 - val_command_output_accuracy: 0.9890 - val_command_output_1_accuracy: 0.0055 - val_participant_output_1_accuracy: 0.1657\n",
      "Epoch 7/10\n",
      "24/24 [==============================] - 4s 158ms/step - loss: 0.1384 - participant_output_loss: 0.0249 - command_output_loss: 0.1135 - command_output_1_loss: 6.7774e-06 - participant_output_1_loss: 1.6626e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9993 - command_output_1_accuracy: 0.0080 - participant_output_1_accuracy: 0.2261 - val_loss: 0.2165 - val_participant_output_loss: 0.0634 - val_command_output_loss: 0.1531 - val_command_output_1_loss: 5.8515e-06 - val_participant_output_1_loss: 2.2800e-05 - val_participant_output_accuracy: 0.9890 - val_command_output_accuracy: 0.9908 - val_command_output_1_accuracy: 0.0018 - val_participant_output_1_accuracy: 0.1547\n",
      "Epoch 8/10\n",
      "24/24 [==============================] - 3s 135ms/step - loss: 0.1194 - participant_output_loss: 0.0229 - command_output_loss: 0.0964 - command_output_1_loss: 9.5616e-06 - participant_output_1_loss: 1.5216e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9993 - command_output_1_accuracy: 0.0047 - participant_output_1_accuracy: 0.2241 - val_loss: 0.1955 - val_participant_output_loss: 0.0600 - val_command_output_loss: 0.1355 - val_command_output_1_loss: 9.9056e-06 - val_participant_output_1_loss: 2.1398e-05 - val_participant_output_accuracy: 0.9890 - val_command_output_accuracy: 0.9890 - val_command_output_1_accuracy: 0.0074 - val_participant_output_1_accuracy: 0.1768\n",
      "Epoch 9/10\n",
      "24/24 [==============================] - 3s 138ms/step - loss: 0.1041 - participant_output_loss: 0.0212 - command_output_loss: 0.0829 - command_output_1_loss: 8.5994e-06 - participant_output_1_loss: 1.4285e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9993 - command_output_1_accuracy: 0.0047 - participant_output_1_accuracy: 0.2201 - val_loss: 0.1819 - val_participant_output_loss: 0.0577 - val_command_output_loss: 0.1242 - val_command_output_1_loss: 4.7093e-06 - val_participant_output_1_loss: 2.0810e-05 - val_participant_output_accuracy: 0.9890 - val_command_output_accuracy: 0.9890 - val_command_output_1_accuracy: 0.0018 - val_participant_output_1_accuracy: 0.1676\n",
      "Epoch 10/10\n",
      "24/24 [==============================] - 3s 135ms/step - loss: 0.0916 - participant_output_loss: 0.0196 - command_output_loss: 0.0720 - command_output_1_loss: 5.3279e-06 - participant_output_1_loss: 1.3060e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9993 - command_output_1_accuracy: 0.0789 - participant_output_1_accuracy: 0.2207 - val_loss: 0.1681 - val_participant_output_loss: 0.0558 - val_command_output_loss: 0.1123 - val_command_output_1_loss: 5.5626e-06 - val_participant_output_1_loss: 1.9957e-05 - val_participant_output_accuracy: 0.9890 - val_command_output_accuracy: 0.9908 - val_command_output_1_accuracy: 0.0147 - val_participant_output_1_accuracy: 0.2081\n",
      "Epoch 1/10\n",
      "24/24 [==============================] - 5s 210ms/step - loss: 3.2887 - participant_output_loss: 1.3201 - command_output_loss: 1.9662 - command_output_1_loss: 1.8189e-04 - participant_output_1_loss: 0.0021 - participant_output_accuracy: 0.5565 - command_output_accuracy: 0.5324 - command_output_1_accuracy: 0.0348 - participant_output_1_accuracy: 0.3365 - val_loss: 2.5987 - val_participant_output_loss: 0.9108 - val_command_output_loss: 1.6877 - val_command_output_1_loss: 6.9850e-05 - val_participant_output_1_loss: 1.1514e-04 - val_participant_output_accuracy: 0.8103 - val_command_output_accuracy: 0.7624 - val_command_output_1_accuracy: 0.0166 - val_participant_output_1_accuracy: 0.1031\n",
      "Epoch 2/10\n",
      "24/24 [==============================] - 4s 148ms/step - loss: 2.2645 - participant_output_loss: 0.7405 - command_output_loss: 1.5238 - command_output_1_loss: 8.1774e-05 - participant_output_1_loss: 8.7260e-05 - participant_output_accuracy: 0.8783 - command_output_accuracy: 0.8528 - command_output_1_accuracy: 0.1017 - participant_output_1_accuracy: 0.1385 - val_loss: 1.9392 - val_participant_output_loss: 0.5729 - val_command_output_loss: 1.3660 - val_command_output_1_loss: 2.4148e-04 - val_participant_output_1_loss: 7.8472e-05 - val_participant_output_accuracy: 0.9208 - val_command_output_accuracy: 0.9061 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.1418\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10\n",
      "24/24 [==============================] - 4s 163ms/step - loss: 1.6971 - participant_output_loss: 0.4673 - command_output_loss: 1.2296 - command_output_1_loss: 1.4017e-04 - participant_output_1_loss: 6.0214e-05 - participant_output_accuracy: 0.9525 - command_output_accuracy: 0.9405 - command_output_1_accuracy: 0.0595 - participant_output_1_accuracy: 0.1799 - val_loss: 1.5300 - val_participant_output_loss: 0.4154 - val_command_output_loss: 1.1145 - val_command_output_1_loss: 5.8881e-05 - val_participant_output_1_loss: 5.5433e-05 - val_participant_output_accuracy: 0.9540 - val_command_output_accuracy: 0.9576 - val_command_output_1_accuracy: 0.1068 - val_participant_output_1_accuracy: 0.1878\n",
      "Epoch 4/10\n",
      "24/24 [==============================] - 4s 159ms/step - loss: 1.2823 - participant_output_loss: 0.3132 - command_output_loss: 0.9689 - command_output_1_loss: 8.0079e-05 - participant_output_1_loss: 5.3649e-05 - participant_output_accuracy: 0.9773 - command_output_accuracy: 0.9753 - command_output_1_accuracy: 0.0796 - participant_output_1_accuracy: 0.2140 - val_loss: 1.1697 - val_participant_output_loss: 0.2907 - val_command_output_loss: 0.8789 - val_command_output_1_loss: 6.7493e-05 - val_participant_output_1_loss: 5.3777e-05 - val_participant_output_accuracy: 0.9705 - val_command_output_accuracy: 0.9724 - val_command_output_1_accuracy: 0.1878 - val_participant_output_1_accuracy: 0.2523\n",
      "Epoch 5/10\n",
      "24/24 [==============================] - 4s 156ms/step - loss: 0.9633 - participant_output_loss: 0.2085 - command_output_loss: 0.7547 - command_output_1_loss: 7.1309e-05 - participant_output_1_loss: 5.2190e-05 - participant_output_accuracy: 0.9913 - command_output_accuracy: 0.9819 - command_output_1_accuracy: 0.0555 - participant_output_1_accuracy: 0.1639 - val_loss: 0.8996 - val_participant_output_loss: 0.2111 - val_command_output_loss: 0.6884 - val_command_output_1_loss: 5.0370e-05 - val_participant_output_1_loss: 5.3570e-05 - val_participant_output_accuracy: 0.9797 - val_command_output_accuracy: 0.9797 - val_command_output_1_accuracy: 0.0147 - val_participant_output_1_accuracy: 0.1878\n",
      "Epoch 6/10\n",
      "24/24 [==============================] - 4s 149ms/step - loss: 0.7338 - participant_output_loss: 0.1567 - command_output_loss: 0.5770 - command_output_1_loss: 6.5121e-05 - participant_output_1_loss: 5.2470e-05 - participant_output_accuracy: 0.9953 - command_output_accuracy: 0.9913 - command_output_1_accuracy: 0.0756 - participant_output_1_accuracy: 0.1565 - val_loss: 0.7170 - val_participant_output_loss: 0.1802 - val_command_output_loss: 0.5367 - val_command_output_1_loss: 6.2725e-05 - val_participant_output_1_loss: 5.5935e-05 - val_participant_output_accuracy: 0.9834 - val_command_output_accuracy: 0.9761 - val_command_output_1_accuracy: 0.0350 - val_participant_output_1_accuracy: 0.2505\n",
      "Epoch 7/10\n",
      "24/24 [==============================] - 3s 140ms/step - loss: 0.5565 - participant_output_loss: 0.1263 - command_output_loss: 0.4302 - command_output_1_loss: 4.0722e-05 - participant_output_1_loss: 5.3467e-05 - participant_output_accuracy: 0.9987 - command_output_accuracy: 0.9967 - command_output_1_accuracy: 0.0562 - participant_output_1_accuracy: 0.1632 - val_loss: 0.5662 - val_participant_output_loss: 0.1487 - val_command_output_loss: 0.4173 - val_command_output_1_loss: 3.3315e-05 - val_participant_output_1_loss: 5.4829e-05 - val_participant_output_accuracy: 0.9890 - val_command_output_accuracy: 0.9779 - val_command_output_1_accuracy: 0.0884 - val_participant_output_1_accuracy: 0.1786\n",
      "Epoch 8/10\n",
      "24/24 [==============================] - 3s 130ms/step - loss: 0.4293 - participant_output_loss: 0.0996 - command_output_loss: 0.3296 - command_output_1_loss: 3.3247e-05 - participant_output_1_loss: 5.1701e-05 - participant_output_accuracy: 0.9987 - command_output_accuracy: 0.9973 - command_output_1_accuracy: 0.0395 - participant_output_1_accuracy: 0.1532 - val_loss: 0.4758 - val_participant_output_loss: 0.1328 - val_command_output_loss: 0.3430 - val_command_output_1_loss: 3.4405e-05 - val_participant_output_1_loss: 5.5135e-05 - val_participant_output_accuracy: 0.9834 - val_command_output_accuracy: 0.9779 - val_command_output_1_accuracy: 0.0442 - val_participant_output_1_accuracy: 0.1492\n",
      "Epoch 9/10\n",
      "24/24 [==============================] - 3s 137ms/step - loss: 0.3369 - participant_output_loss: 0.0835 - command_output_loss: 0.2534 - command_output_1_loss: 2.4978e-05 - participant_output_1_loss: 5.0529e-05 - participant_output_accuracy: 0.9993 - command_output_accuracy: 0.9993 - command_output_1_accuracy: 0.0970 - participant_output_1_accuracy: 0.1284 - val_loss: 0.3881 - val_participant_output_loss: 0.1159 - val_command_output_loss: 0.2721 - val_command_output_1_loss: 1.8313e-05 - val_participant_output_1_loss: 5.5049e-05 - val_participant_output_accuracy: 0.9871 - val_command_output_accuracy: 0.9797 - val_command_output_1_accuracy: 0.0055 - val_participant_output_1_accuracy: 0.1750\n",
      "Epoch 10/10\n",
      "24/24 [==============================] - 4s 160ms/step - loss: 0.2656 - participant_output_loss: 0.0677 - command_output_loss: 0.1978 - command_output_1_loss: 1.8913e-05 - participant_output_1_loss: 4.7007e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9993 - command_output_1_accuracy: 0.0789 - participant_output_1_accuracy: 0.1645 - val_loss: 0.3358 - val_participant_output_loss: 0.1063 - val_command_output_loss: 0.2294 - val_command_output_1_loss: 1.7537e-05 - val_participant_output_1_loss: 5.1376e-05 - val_participant_output_accuracy: 0.9871 - val_command_output_accuracy: 0.9853 - val_command_output_1_accuracy: 0.0792 - val_participant_output_1_accuracy: 0.1529\n",
      "Epoch 1/10\n",
      "24/24 [==============================] - 4s 175ms/step - loss: 0.2160 - participant_output_loss: 0.0571 - command_output_loss: 0.1588 - command_output_1_loss: 1.9235e-05 - participant_output_1_loss: 4.3286e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9993 - command_output_1_accuracy: 0.1391 - participant_output_1_accuracy: 0.1552 - val_loss: 0.2867 - val_participant_output_loss: 0.0920 - val_command_output_loss: 0.1947 - val_command_output_1_loss: 1.9354e-05 - val_participant_output_1_loss: 4.7258e-05 - val_participant_output_accuracy: 0.9890 - val_command_output_accuracy: 0.9853 - val_command_output_1_accuracy: 0.0147 - val_participant_output_1_accuracy: 0.1823\n",
      "Epoch 2/10\n",
      "24/24 [==============================] - 3s 117ms/step - loss: 0.1798 - participant_output_loss: 0.0486 - command_output_loss: 0.1312 - command_output_1_loss: 1.7325e-05 - participant_output_1_loss: 3.9648e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9993 - command_output_1_accuracy: 0.0381 - participant_output_1_accuracy: 0.1625 - val_loss: 0.2594 - val_participant_output_loss: 0.0845 - val_command_output_loss: 0.1748 - val_command_output_1_loss: 1.5001e-05 - val_participant_output_1_loss: 4.4735e-05 - val_participant_output_accuracy: 0.9926 - val_command_output_accuracy: 0.9797 - val_command_output_1_accuracy: 0.0110 - val_participant_output_1_accuracy: 0.1823\n",
      "Epoch 3/10\n",
      "24/24 [==============================] - 3s 140ms/step - loss: 0.1524 - participant_output_loss: 0.0430 - command_output_loss: 0.1094 - command_output_1_loss: 1.6089e-05 - participant_output_1_loss: 3.7045e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9993 - command_output_1_accuracy: 0.0288 - participant_output_1_accuracy: 0.1592 - val_loss: 0.2327 - val_participant_output_loss: 0.0807 - val_command_output_loss: 0.1520 - val_command_output_1_loss: 1.3752e-05 - val_participant_output_1_loss: 4.4018e-05 - val_participant_output_accuracy: 0.9908 - val_command_output_accuracy: 0.9871 - val_command_output_1_accuracy: 0.0129 - val_participant_output_1_accuracy: 0.1492\n",
      "Epoch 4/10\n",
      "24/24 [==============================] - 3s 138ms/step - loss: 0.1316 - participant_output_loss: 0.0386 - command_output_loss: 0.0929 - command_output_1_loss: 1.4983e-05 - participant_output_1_loss: 3.3804e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9993 - command_output_1_accuracy: 0.0254 - participant_output_1_accuracy: 0.1632 - val_loss: 0.2121 - val_participant_output_loss: 0.0759 - val_command_output_loss: 0.1361 - val_command_output_1_loss: 8.6875e-06 - val_participant_output_1_loss: 3.9926e-05 - val_participant_output_accuracy: 0.9890 - val_command_output_accuracy: 0.9871 - val_command_output_1_accuracy: 0.1234 - val_participant_output_1_accuracy: 0.1860\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10\n",
      "24/24 [==============================] - 3s 136ms/step - loss: 0.1146 - participant_output_loss: 0.0350 - command_output_loss: 0.0795 - command_output_1_loss: 9.2645e-06 - participant_output_1_loss: 3.1241e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9993 - command_output_1_accuracy: 0.0816 - participant_output_1_accuracy: 0.1726 - val_loss: 0.1933 - val_participant_output_loss: 0.0705 - val_command_output_loss: 0.1228 - val_command_output_1_loss: 6.5314e-06 - val_participant_output_1_loss: 3.7787e-05 - val_participant_output_accuracy: 0.9908 - val_command_output_accuracy: 0.9853 - val_command_output_1_accuracy: 0.0221 - val_participant_output_1_accuracy: 0.1750\n",
      "Epoch 6/10\n",
      "24/24 [==============================] - 3s 139ms/step - loss: 0.1008 - participant_output_loss: 0.0316 - command_output_loss: 0.0692 - command_output_1_loss: 7.5361e-06 - participant_output_1_loss: 2.9543e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9993 - command_output_1_accuracy: 0.0415 - participant_output_1_accuracy: 0.1645 - val_loss: 0.1795 - val_participant_output_loss: 0.0668 - val_command_output_loss: 0.1127 - val_command_output_1_loss: 5.5860e-06 - val_participant_output_1_loss: 3.6819e-05 - val_participant_output_accuracy: 0.9926 - val_command_output_accuracy: 0.9853 - val_command_output_1_accuracy: 0.0516 - val_participant_output_1_accuracy: 0.1989\n",
      "Epoch 7/10\n",
      "24/24 [==============================] - 3s 131ms/step - loss: 0.0892 - participant_output_loss: 0.0286 - command_output_loss: 0.0606 - command_output_1_loss: 7.5331e-06 - participant_output_1_loss: 2.6871e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9993 - command_output_1_accuracy: 0.0508 - participant_output_1_accuracy: 0.1666 - val_loss: 0.1681 - val_participant_output_loss: 0.0624 - val_command_output_loss: 0.1057 - val_command_output_1_loss: 6.1608e-06 - val_participant_output_1_loss: 3.4875e-05 - val_participant_output_accuracy: 0.9926 - val_command_output_accuracy: 0.9816 - val_command_output_1_accuracy: 0.1105 - val_participant_output_1_accuracy: 0.1897\n",
      "Epoch 8/10\n",
      "24/24 [==============================] - 3s 143ms/step - loss: 0.0797 - participant_output_loss: 0.0262 - command_output_loss: 0.0534 - command_output_1_loss: 6.7343e-06 - participant_output_1_loss: 2.4745e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9993 - command_output_1_accuracy: 0.0729 - participant_output_1_accuracy: 0.1913 - val_loss: 0.1601 - val_participant_output_loss: 0.0642 - val_command_output_loss: 0.0959 - val_command_output_1_loss: 5.7683e-06 - val_participant_output_1_loss: 3.3048e-05 - val_participant_output_accuracy: 0.9890 - val_command_output_accuracy: 0.9890 - val_command_output_1_accuracy: 0.2136 - val_participant_output_1_accuracy: 0.1786\n",
      "Epoch 1/10\n",
      "24/24 [==============================] - 5s 214ms/step - loss: 3.0684 - participant_output_loss: 1.1894 - command_output_loss: 1.8774 - command_output_1_loss: 4.5624e-04 - participant_output_1_loss: 0.0011 - participant_output_accuracy: 0.6174 - command_output_accuracy: 0.6020 - command_output_1_accuracy: 0.0535 - participant_output_1_accuracy: 0.2000 - val_loss: 2.3962 - val_participant_output_loss: 0.8019 - val_command_output_loss: 1.5941 - val_command_output_1_loss: 5.0437e-05 - val_participant_output_1_loss: 1.1943e-04 - val_participant_output_accuracy: 0.8471 - val_command_output_accuracy: 0.8637 - val_command_output_1_accuracy: 0.1400 - val_participant_output_1_accuracy: 0.4972\n",
      "Epoch 2/10\n",
      "24/24 [==============================] - 4s 157ms/step - loss: 2.0477 - participant_output_loss: 0.6298 - command_output_loss: 1.4177 - command_output_1_loss: 1.0205e-04 - participant_output_1_loss: 9.1705e-05 - participant_output_accuracy: 0.9057 - command_output_accuracy: 0.9043 - command_output_1_accuracy: 0.0181 - participant_output_1_accuracy: 0.2729 - val_loss: 1.7528 - val_participant_output_loss: 0.4956 - val_command_output_loss: 1.2571 - val_command_output_1_loss: 7.1558e-05 - val_participant_output_1_loss: 7.0042e-05 - val_participant_output_accuracy: 0.9282 - val_command_output_accuracy: 0.9319 - val_command_output_1_accuracy: 0.0129 - val_participant_output_1_accuracy: 0.1529\n",
      "Epoch 3/10\n",
      "24/24 [==============================] - 4s 164ms/step - loss: 1.5138 - participant_output_loss: 0.4002 - command_output_loss: 1.1134 - command_output_1_loss: 8.8030e-05 - participant_output_1_loss: 5.8790e-05 - participant_output_accuracy: 0.9645 - command_output_accuracy: 0.9552 - command_output_1_accuracy: 0.2221 - participant_output_1_accuracy: 0.2027 - val_loss: 1.3737 - val_participant_output_loss: 0.3769 - val_command_output_loss: 0.9967 - val_command_output_1_loss: 1.1833e-04 - val_participant_output_1_loss: 5.2349e-05 - val_participant_output_accuracy: 0.9521 - val_command_output_accuracy: 0.9613 - val_command_output_1_accuracy: 0.0018 - val_participant_output_1_accuracy: 0.2302\n",
      "Epoch 4/10\n",
      "24/24 [==============================] - 4s 165ms/step - loss: 1.1587 - participant_output_loss: 0.2970 - command_output_loss: 0.8616 - command_output_1_loss: 9.6937e-05 - participant_output_1_loss: 4.7274e-05 - participant_output_accuracy: 0.9846 - command_output_accuracy: 0.9759 - command_output_1_accuracy: 0.1371 - participant_output_1_accuracy: 0.1993 - val_loss: 1.0491 - val_participant_output_loss: 0.2811 - val_command_output_loss: 0.7679 - val_command_output_1_loss: 7.9302e-05 - val_participant_output_1_loss: 5.0655e-05 - val_participant_output_accuracy: 0.9669 - val_command_output_accuracy: 0.9761 - val_command_output_1_accuracy: 0.0055 - val_participant_output_1_accuracy: 0.1786\n",
      "Epoch 5/10\n",
      "24/24 [==============================] - 4s 155ms/step - loss: 0.8656 - participant_output_loss: 0.2177 - command_output_loss: 0.6478 - command_output_1_loss: 6.9053e-05 - participant_output_1_loss: 4.2122e-05 - participant_output_accuracy: 0.9866 - command_output_accuracy: 0.9893 - command_output_1_accuracy: 0.0395 - participant_output_1_accuracy: 0.1773 - val_loss: 0.8286 - val_participant_output_loss: 0.2283 - val_command_output_loss: 0.6002 - val_command_output_1_loss: 4.8370e-05 - val_participant_output_1_loss: 4.6447e-05 - val_participant_output_accuracy: 0.9871 - val_command_output_accuracy: 0.9742 - val_command_output_1_accuracy: 0.0571 - val_participant_output_1_accuracy: 0.1786\n",
      "Epoch 6/10\n",
      "24/24 [==============================] - 3s 140ms/step - loss: 0.6529 - participant_output_loss: 0.1618 - command_output_loss: 0.4910 - command_output_1_loss: 4.5549e-05 - participant_output_1_loss: 3.8732e-05 - participant_output_accuracy: 0.9926 - command_output_accuracy: 0.9946 - command_output_1_accuracy: 0.0635 - participant_output_1_accuracy: 0.1946 - val_loss: 0.6422 - val_participant_output_loss: 0.1713 - val_command_output_loss: 0.4708 - val_command_output_1_loss: 5.0798e-05 - val_participant_output_1_loss: 4.5351e-05 - val_participant_output_accuracy: 0.9853 - val_command_output_accuracy: 0.9779 - val_command_output_1_accuracy: 0.2044 - val_participant_output_1_accuracy: 0.1492\n",
      "Epoch 7/10\n",
      "24/24 [==============================] - 3s 137ms/step - loss: 0.4910 - participant_output_loss: 0.1196 - command_output_loss: 0.3713 - command_output_1_loss: 5.7528e-05 - participant_output_1_loss: 3.6005e-05 - participant_output_accuracy: 0.9953 - command_output_accuracy: 0.9973 - command_output_1_accuracy: 0.1398 - participant_output_1_accuracy: 0.1973 - val_loss: 0.5174 - val_participant_output_loss: 0.1472 - val_command_output_loss: 0.3700 - val_command_output_1_loss: 6.3454e-05 - val_participant_output_1_loss: 4.3559e-05 - val_participant_output_accuracy: 0.9834 - val_command_output_accuracy: 0.9834 - val_command_output_1_accuracy: 0.0018 - val_participant_output_1_accuracy: 0.2357\n",
      "Epoch 8/10\n",
      "24/24 [==============================] - 3s 117ms/step - loss: 0.3741 - participant_output_loss: 0.0937 - command_output_loss: 0.2803 - command_output_1_loss: 3.7562e-05 - participant_output_1_loss: 3.3340e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9980 - command_output_1_accuracy: 0.1137 - participant_output_1_accuracy: 0.2067 - val_loss: 0.4274 - val_participant_output_loss: 0.1268 - val_command_output_loss: 0.3005 - val_command_output_1_loss: 3.9773e-05 - val_participant_output_1_loss: 4.1405e-05 - val_participant_output_accuracy: 0.9834 - val_command_output_accuracy: 0.9779 - val_command_output_1_accuracy: 0.1179 - val_participant_output_1_accuracy: 0.2615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10\n",
      "24/24 [==============================] - 3s 129ms/step - loss: 0.2958 - participant_output_loss: 0.0758 - command_output_loss: 0.2198 - command_output_1_loss: 3.3648e-05 - participant_output_1_loss: 3.0633e-05 - participant_output_accuracy: 0.9993 - command_output_accuracy: 0.9980 - command_output_1_accuracy: 0.1057 - participant_output_1_accuracy: 0.2000 - val_loss: 0.3634 - val_participant_output_loss: 0.1097 - val_command_output_loss: 0.2536 - val_command_output_1_loss: 2.8747e-05 - val_participant_output_1_loss: 3.8962e-05 - val_participant_output_accuracy: 0.9871 - val_command_output_accuracy: 0.9797 - val_command_output_1_accuracy: 0.2486 - val_participant_output_1_accuracy: 0.2044\n",
      "Epoch 10/10\n",
      "24/24 [==============================] - 3s 132ms/step - loss: 0.2390 - participant_output_loss: 0.0640 - command_output_loss: 0.1750 - command_output_1_loss: 1.9915e-05 - participant_output_1_loss: 2.7498e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9993 - command_output_1_accuracy: 0.0783 - participant_output_1_accuracy: 0.2261 - val_loss: 0.3076 - val_participant_output_loss: 0.0955 - val_command_output_loss: 0.2121 - val_command_output_1_loss: 1.7571e-05 - val_participant_output_1_loss: 3.7476e-05 - val_participant_output_accuracy: 0.9871 - val_command_output_accuracy: 0.9779 - val_command_output_1_accuracy: 0.0092 - val_participant_output_1_accuracy: 0.1878\n",
      "Epoch 1/10\n",
      "24/24 [==============================] - 4s 171ms/step - loss: 0.1941 - participant_output_loss: 0.0523 - command_output_loss: 0.1418 - command_output_1_loss: 1.7420e-05 - participant_output_1_loss: 2.5432e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9993 - command_output_1_accuracy: 0.0174 - participant_output_1_accuracy: 0.2161 - val_loss: 0.2718 - val_participant_output_loss: 0.0898 - val_command_output_loss: 0.1820 - val_command_output_1_loss: 1.3176e-05 - val_participant_output_1_loss: 3.4234e-05 - val_participant_output_accuracy: 0.9871 - val_command_output_accuracy: 0.9871 - val_command_output_1_accuracy: 0.0829 - val_participant_output_1_accuracy: 0.2376\n",
      "Epoch 2/10\n",
      "24/24 [==============================] - 3s 119ms/step - loss: 0.1610 - participant_output_loss: 0.0437 - command_output_loss: 0.1172 - command_output_1_loss: 1.4988e-05 - participant_output_1_loss: 2.3468e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9993 - command_output_1_accuracy: 0.0990 - participant_output_1_accuracy: 0.2381 - val_loss: 0.2397 - val_participant_output_loss: 0.0807 - val_command_output_loss: 0.1590 - val_command_output_1_loss: 1.2543e-05 - val_participant_output_1_loss: 3.3722e-05 - val_participant_output_accuracy: 0.9871 - val_command_output_accuracy: 0.9797 - val_command_output_1_accuracy: 0.0313 - val_participant_output_1_accuracy: 0.1676\n",
      "Epoch 3/10\n",
      "24/24 [==============================] - 3s 121ms/step - loss: 0.1361 - participant_output_loss: 0.0390 - command_output_loss: 0.0971 - command_output_1_loss: 1.0034e-05 - participant_output_1_loss: 2.2002e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9993 - command_output_1_accuracy: 0.0348 - participant_output_1_accuracy: 0.2234 - val_loss: 0.2158 - val_participant_output_loss: 0.0755 - val_command_output_loss: 0.1402 - val_command_output_1_loss: 9.9962e-06 - val_participant_output_1_loss: 3.2003e-05 - val_participant_output_accuracy: 0.9871 - val_command_output_accuracy: 0.9779 - val_command_output_1_accuracy: 0.0092 - val_participant_output_1_accuracy: 0.2431\n",
      "Epoch 4/10\n",
      "24/24 [==============================] - 3s 117ms/step - loss: 0.1164 - participant_output_loss: 0.0349 - command_output_loss: 0.0815 - command_output_1_loss: 9.0900e-06 - participant_output_1_loss: 2.0005e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9993 - command_output_1_accuracy: 0.1023 - participant_output_1_accuracy: 0.2341 - val_loss: 0.2003 - val_participant_output_loss: 0.0744 - val_command_output_loss: 0.1258 - val_command_output_1_loss: 8.0208e-06 - val_participant_output_1_loss: 2.9735e-05 - val_participant_output_accuracy: 0.9853 - val_command_output_accuracy: 0.9816 - val_command_output_1_accuracy: 0.0958 - val_participant_output_1_accuracy: 0.1915\n",
      "Epoch 5/10\n",
      "24/24 [==============================] - 3s 144ms/step - loss: 0.1015 - participant_output_loss: 0.0317 - command_output_loss: 0.0698 - command_output_1_loss: 7.4704e-06 - participant_output_1_loss: 1.8214e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9993 - command_output_1_accuracy: 0.0294 - participant_output_1_accuracy: 0.2241 - val_loss: 0.1790 - val_participant_output_loss: 0.0667 - val_command_output_loss: 0.1122 - val_command_output_1_loss: 6.7640e-06 - val_participant_output_1_loss: 2.7639e-05 - val_participant_output_accuracy: 0.9908 - val_command_output_accuracy: 0.9834 - val_command_output_1_accuracy: 0.0221 - val_participant_output_1_accuracy: 0.1934\n",
      "Epoch 6/10\n",
      "24/24 [==============================] - 3s 133ms/step - loss: 0.0884 - participant_output_loss: 0.0287 - command_output_loss: 0.0597 - command_output_1_loss: 7.4915e-06 - participant_output_1_loss: 1.6720e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9993 - command_output_1_accuracy: 0.1291 - participant_output_1_accuracy: 0.2247 - val_loss: 0.1661 - val_participant_output_loss: 0.0645 - val_command_output_loss: 0.1016 - val_command_output_1_loss: 6.1971e-06 - val_participant_output_1_loss: 2.6515e-05 - val_participant_output_accuracy: 0.9871 - val_command_output_accuracy: 0.9853 - val_command_output_1_accuracy: 0.0221 - val_participant_output_1_accuracy: 0.2339\n",
      "Epoch 7/10\n",
      "24/24 [==============================] - 3s 138ms/step - loss: 0.0777 - participant_output_loss: 0.0261 - command_output_loss: 0.0515 - command_output_1_loss: 7.9631e-06 - participant_output_1_loss: 1.5578e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9993 - command_output_1_accuracy: 0.0100 - participant_output_1_accuracy: 0.2348 - val_loss: 0.1561 - val_participant_output_loss: 0.0620 - val_command_output_loss: 0.0940 - val_command_output_1_loss: 6.4379e-06 - val_participant_output_1_loss: 2.5520e-05 - val_participant_output_accuracy: 0.9871 - val_command_output_accuracy: 0.9834 - val_command_output_1_accuracy: 0.0258 - val_participant_output_1_accuracy: 0.2099\n",
      "Epoch 8/10\n",
      "24/24 [==============================] - 3s 133ms/step - loss: 0.0690 - participant_output_loss: 0.0240 - command_output_loss: 0.0450 - command_output_1_loss: 8.2143e-06 - participant_output_1_loss: 1.4596e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9993 - command_output_1_accuracy: 0.0542 - participant_output_1_accuracy: 0.2127 - val_loss: 0.1463 - val_participant_output_loss: 0.0583 - val_command_output_loss: 0.0879 - val_command_output_1_loss: 6.3943e-06 - val_participant_output_1_loss: 2.4199e-05 - val_participant_output_accuracy: 0.9890 - val_command_output_accuracy: 0.9834 - val_command_output_1_accuracy: 0.0884 - val_participant_output_1_accuracy: 0.2265\n",
      "Epoch 9/10\n",
      "24/24 [==============================] - 3s 138ms/step - loss: 0.0611 - participant_output_loss: 0.0213 - command_output_loss: 0.0397 - command_output_1_loss: 6.2138e-06 - participant_output_1_loss: 1.3609e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9993 - command_output_1_accuracy: 0.1224 - participant_output_1_accuracy: 0.2462 - val_loss: 0.1389 - val_participant_output_loss: 0.0558 - val_command_output_loss: 0.0831 - val_command_output_1_loss: 5.0140e-06 - val_participant_output_1_loss: 2.3232e-05 - val_participant_output_accuracy: 0.9890 - val_command_output_accuracy: 0.9816 - val_command_output_1_accuracy: 0.0737 - val_participant_output_1_accuracy: 0.1934\n",
      "Epoch 10/10\n",
      "24/24 [==============================] - 3s 137ms/step - loss: 0.0554 - participant_output_loss: 0.0197 - command_output_loss: 0.0356 - command_output_1_loss: 5.6101e-06 - participant_output_1_loss: 1.2731e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9993 - command_output_1_accuracy: 0.0134 - participant_output_1_accuracy: 0.2147 - val_loss: 0.1339 - val_participant_output_loss: 0.0556 - val_command_output_loss: 0.0783 - val_command_output_1_loss: 4.3118e-06 - val_participant_output_1_loss: 2.2283e-05 - val_participant_output_accuracy: 0.9871 - val_command_output_accuracy: 0.9871 - val_command_output_1_accuracy: 0.0994 - val_participant_output_1_accuracy: 0.2762\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "24/24 [==============================] - 5s 212ms/step - loss: 3.2493 - participant_output_loss: 1.2595 - command_output_loss: 1.9839 - command_output_1_loss: 3.1476e-04 - participant_output_1_loss: 0.0056 - participant_output_accuracy: 0.6114 - command_output_accuracy: 0.5043 - command_output_1_accuracy: 0.0903 - participant_output_1_accuracy: 0.3405 - val_loss: 2.6710 - val_participant_output_loss: 0.9303 - val_command_output_loss: 1.7404 - val_command_output_1_loss: 1.3416e-04 - val_participant_output_1_loss: 1.0160e-04 - val_participant_output_accuracy: 0.7993 - val_command_output_accuracy: 0.7716 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.0129\n",
      "Epoch 2/10\n",
      "24/24 [==============================] - 4s 165ms/step - loss: 2.3587 - participant_output_loss: 0.7777 - command_output_loss: 1.5807 - command_output_1_loss: 1.1870e-04 - participant_output_1_loss: 1.2188e-04 - participant_output_accuracy: 0.8769 - command_output_accuracy: 0.8602 - command_output_1_accuracy: 6.6890e-04 - participant_output_1_accuracy: 0.1953 - val_loss: 2.0935 - val_participant_output_loss: 0.6631 - val_command_output_loss: 1.4301 - val_command_output_1_loss: 2.2906e-04 - val_participant_output_1_loss: 5.5211e-05 - val_participant_output_accuracy: 0.9190 - val_command_output_accuracy: 0.9263 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.5672\n",
      "Epoch 3/10\n",
      "24/24 [==============================] - 4s 146ms/step - loss: 1.8278 - participant_output_loss: 0.5399 - command_output_loss: 1.2877 - command_output_1_loss: 1.2543e-04 - participant_output_1_loss: 4.9806e-05 - participant_output_accuracy: 0.9625 - command_output_accuracy: 0.9538 - command_output_1_accuracy: 0.0716 - participant_output_1_accuracy: 0.1746 - val_loss: 1.6439 - val_participant_output_loss: 0.4644 - val_command_output_loss: 1.1794 - val_command_output_1_loss: 5.7411e-05 - val_participant_output_1_loss: 4.2624e-05 - val_participant_output_accuracy: 0.9521 - val_command_output_accuracy: 0.9521 - val_command_output_1_accuracy: 0.0147 - val_participant_output_1_accuracy: 0.1013\n",
      "Epoch 4/10\n",
      "24/24 [==============================] - 3s 142ms/step - loss: 1.4120 - participant_output_loss: 0.3775 - command_output_loss: 1.0345 - command_output_1_loss: 4.5655e-05 - participant_output_1_loss: 4.0221e-05 - participant_output_accuracy: 0.9813 - command_output_accuracy: 0.9753 - command_output_1_accuracy: 0.0716 - participant_output_1_accuracy: 0.1599 - val_loss: 1.2966 - val_participant_output_loss: 0.3528 - val_command_output_loss: 0.9437 - val_command_output_1_loss: 6.3532e-05 - val_participant_output_1_loss: 4.2202e-05 - val_participant_output_accuracy: 0.9705 - val_command_output_accuracy: 0.9742 - val_command_output_1_accuracy: 0.0184 - val_participant_output_1_accuracy: 0.1400\n",
      "Epoch 5/10\n",
      "24/24 [==============================] - 4s 151ms/step - loss: 1.0839 - participant_output_loss: 0.2722 - command_output_loss: 0.8116 - command_output_1_loss: 7.6817e-05 - participant_output_1_loss: 4.3141e-05 - participant_output_accuracy: 0.9880 - command_output_accuracy: 0.9880 - command_output_1_accuracy: 0.0308 - participant_output_1_accuracy: 0.1799 - val_loss: 1.0013 - val_participant_output_loss: 0.2637 - val_command_output_loss: 0.7376 - val_command_output_1_loss: 5.9653e-05 - val_participant_output_1_loss: 4.6726e-05 - val_participant_output_accuracy: 0.9779 - val_command_output_accuracy: 0.9816 - val_command_output_1_accuracy: 0.0773 - val_participant_output_1_accuracy: 0.1436\n",
      "Epoch 6/10\n",
      "24/24 [==============================] - 3s 125ms/step - loss: 0.8149 - participant_output_loss: 0.1948 - command_output_loss: 0.6200 - command_output_1_loss: 4.4279e-05 - participant_output_1_loss: 4.4499e-05 - participant_output_accuracy: 0.9953 - command_output_accuracy: 0.9926 - command_output_1_accuracy: 0.0783 - participant_output_1_accuracy: 0.2047 - val_loss: 0.8028 - val_participant_output_loss: 0.2172 - val_command_output_loss: 0.5855 - val_command_output_1_loss: 4.2594e-05 - val_participant_output_1_loss: 4.9392e-05 - val_participant_output_accuracy: 0.9761 - val_command_output_accuracy: 0.9779 - val_command_output_1_accuracy: 0.2983 - val_participant_output_1_accuracy: 0.1492\n",
      "Epoch 7/10\n",
      "24/24 [==============================] - 4s 152ms/step - loss: 0.6226 - participant_output_loss: 0.1533 - command_output_loss: 0.4692 - command_output_1_loss: 3.4415e-05 - participant_output_1_loss: 4.4123e-05 - participant_output_accuracy: 0.9973 - command_output_accuracy: 0.9973 - command_output_1_accuracy: 0.1023 - participant_output_1_accuracy: 0.2013 - val_loss: 0.6415 - val_participant_output_loss: 0.1873 - val_command_output_loss: 0.4541 - val_command_output_1_loss: 3.9683e-05 - val_participant_output_1_loss: 5.0156e-05 - val_participant_output_accuracy: 0.9797 - val_command_output_accuracy: 0.9816 - val_command_output_1_accuracy: 0.2063 - val_participant_output_1_accuracy: 0.2431\n",
      "Epoch 8/10\n",
      "24/24 [==============================] - 4s 164ms/step - loss: 0.4801 - participant_output_loss: 0.1238 - command_output_loss: 0.3563 - command_output_1_loss: 2.9718e-05 - participant_output_1_loss: 4.4503e-05 - participant_output_accuracy: 0.9980 - command_output_accuracy: 0.9973 - command_output_1_accuracy: 0.0709 - participant_output_1_accuracy: 0.2361 - val_loss: 0.5253 - val_participant_output_loss: 0.1607 - val_command_output_loss: 0.3646 - val_command_output_1_loss: 2.2217e-05 - val_participant_output_1_loss: 5.0580e-05 - val_participant_output_accuracy: 0.9816 - val_command_output_accuracy: 0.9816 - val_command_output_1_accuracy: 0.1418 - val_participant_output_1_accuracy: 0.2707\n",
      "Epoch 9/10\n",
      "24/24 [==============================] - 4s 155ms/step - loss: 0.3767 - participant_output_loss: 0.1037 - command_output_loss: 0.2729 - command_output_1_loss: 2.6034e-05 - participant_output_1_loss: 4.3489e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9993 - command_output_1_accuracy: 0.1559 - participant_output_1_accuracy: 0.2254 - val_loss: 0.4334 - val_participant_output_loss: 0.1405 - val_command_output_loss: 0.2928 - val_command_output_1_loss: 4.0027e-05 - val_participant_output_1_loss: 5.0712e-05 - val_participant_output_accuracy: 0.9834 - val_command_output_accuracy: 0.9816 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.1473\n",
      "Epoch 10/10\n",
      "24/24 [==============================] - 4s 154ms/step - loss: 0.3021 - participant_output_loss: 0.0884 - command_output_loss: 0.2137 - command_output_1_loss: 2.2803e-05 - participant_output_1_loss: 4.0472e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9993 - command_output_1_accuracy: 0.0615 - participant_output_1_accuracy: 0.2234 - val_loss: 0.3686 - val_participant_output_loss: 0.1240 - val_command_output_loss: 0.2446 - val_command_output_1_loss: 2.1673e-05 - val_participant_output_1_loss: 4.8021e-05 - val_participant_output_accuracy: 0.9890 - val_command_output_accuracy: 0.9834 - val_command_output_1_accuracy: 0.3020 - val_participant_output_1_accuracy: 0.2081\n",
      "Epoch 1/10\n",
      "24/24 [==============================] - 4s 176ms/step - loss: 0.2451 - participant_output_loss: 0.0742 - command_output_loss: 0.1709 - command_output_1_loss: 2.1612e-05 - participant_output_1_loss: 3.7834e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9993 - command_output_1_accuracy: 0.0863 - participant_output_1_accuracy: 0.2281 - val_loss: 0.3197 - val_participant_output_loss: 0.1112 - val_command_output_loss: 0.2084 - val_command_output_1_loss: 2.4303e-05 - val_participant_output_1_loss: 4.5358e-05 - val_participant_output_accuracy: 0.9871 - val_command_output_accuracy: 0.9834 - val_command_output_1_accuracy: 0.4236 - val_participant_output_1_accuracy: 0.2173\n",
      "Epoch 2/10\n",
      "24/24 [==============================] - 3s 137ms/step - loss: 0.2038 - participant_output_loss: 0.0648 - command_output_loss: 0.1389 - command_output_1_loss: 2.2301e-05 - participant_output_1_loss: 3.5433e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9993 - command_output_1_accuracy: 0.3351 - participant_output_1_accuracy: 0.2214 - val_loss: 0.2819 - val_participant_output_loss: 0.1067 - val_command_output_loss: 0.1751 - val_command_output_1_loss: 8.8969e-06 - val_participant_output_1_loss: 4.2743e-05 - val_participant_output_accuracy: 0.9834 - val_command_output_accuracy: 0.9890 - val_command_output_1_accuracy: 0.0829 - val_participant_output_1_accuracy: 0.1952\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10\n",
      "24/24 [==============================] - 3s 145ms/step - loss: 0.1733 - participant_output_loss: 0.0581 - command_output_loss: 0.1152 - command_output_1_loss: 1.3100e-05 - participant_output_1_loss: 3.2686e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9993 - command_output_1_accuracy: 0.0161 - participant_output_1_accuracy: 0.2221 - val_loss: 0.2546 - val_participant_output_loss: 0.0987 - val_command_output_loss: 0.1559 - val_command_output_1_loss: 8.5519e-06 - val_participant_output_1_loss: 4.1245e-05 - val_participant_output_accuracy: 0.9945 - val_command_output_accuracy: 0.9853 - val_command_output_1_accuracy: 0.0129 - val_participant_output_1_accuracy: 0.2431\n",
      "Epoch 4/10\n",
      "24/24 [==============================] - 3s 145ms/step - loss: 0.1503 - participant_output_loss: 0.0527 - command_output_loss: 0.0975 - command_output_1_loss: 1.2785e-05 - participant_output_1_loss: 3.0095e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9993 - command_output_1_accuracy: 0.0234 - participant_output_1_accuracy: 0.2348 - val_loss: 0.2336 - val_participant_output_loss: 0.0921 - val_command_output_loss: 0.1415 - val_command_output_1_loss: 5.9272e-06 - val_participant_output_1_loss: 3.7710e-05 - val_participant_output_accuracy: 0.9853 - val_command_output_accuracy: 0.9871 - val_command_output_1_accuracy: 0.5009 - val_participant_output_1_accuracy: 0.2394\n",
      "Epoch 5/10\n",
      "24/24 [==============================] - 3s 138ms/step - loss: 0.1316 - participant_output_loss: 0.0476 - command_output_loss: 0.0841 - command_output_1_loss: 8.6291e-06 - participant_output_1_loss: 2.7698e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9993 - command_output_1_accuracy: 0.6214 - participant_output_1_accuracy: 0.2435 - val_loss: 0.2153 - val_participant_output_loss: 0.0887 - val_command_output_loss: 0.1266 - val_command_output_1_loss: 6.5830e-06 - val_participant_output_1_loss: 3.5481e-05 - val_participant_output_accuracy: 0.9871 - val_command_output_accuracy: 0.9871 - val_command_output_1_accuracy: 0.2560 - val_participant_output_1_accuracy: 0.2063\n",
      "Epoch 6/10\n",
      "24/24 [==============================] - 3s 132ms/step - loss: 0.1159 - participant_output_loss: 0.0429 - command_output_loss: 0.0730 - command_output_1_loss: 7.2148e-06 - participant_output_1_loss: 2.5559e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9993 - command_output_1_accuracy: 0.0288 - participant_output_1_accuracy: 0.2368 - val_loss: 0.1955 - val_participant_output_loss: 0.0806 - val_command_output_loss: 0.1150 - val_command_output_1_loss: 5.1055e-06 - val_participant_output_1_loss: 3.4032e-05 - val_participant_output_accuracy: 0.9908 - val_command_output_accuracy: 0.9890 - val_command_output_1_accuracy: 0.0571 - val_participant_output_1_accuracy: 0.1694\n",
      "Epoch 7/10\n",
      "24/24 [==============================] - 3s 120ms/step - loss: 0.1035 - participant_output_loss: 0.0397 - command_output_loss: 0.0638 - command_output_1_loss: 6.9056e-06 - participant_output_1_loss: 2.4002e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.1538 - participant_output_1_accuracy: 0.2508 - val_loss: 0.1897 - val_participant_output_loss: 0.0812 - val_command_output_loss: 0.1085 - val_command_output_1_loss: 4.4578e-06 - val_participant_output_1_loss: 3.1942e-05 - val_participant_output_accuracy: 0.9871 - val_command_output_accuracy: 0.9853 - val_command_output_1_accuracy: 0.0976 - val_participant_output_1_accuracy: 0.2063\n",
      "Epoch 8/10\n",
      "24/24 [==============================] - 3s 134ms/step - loss: 0.0932 - participant_output_loss: 0.0367 - command_output_loss: 0.0564 - command_output_1_loss: 6.1230e-06 - participant_output_1_loss: 2.2564e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.1706 - participant_output_1_accuracy: 0.2435 - val_loss: 0.1736 - val_participant_output_loss: 0.0746 - val_command_output_loss: 0.0989 - val_command_output_1_loss: 4.2390e-06 - val_participant_output_1_loss: 3.0923e-05 - val_participant_output_accuracy: 0.9890 - val_command_output_accuracy: 0.9890 - val_command_output_1_accuracy: 0.0203 - val_participant_output_1_accuracy: 0.2007\n",
      "Epoch 1/10\n",
      "24/24 [==============================] - 5s 207ms/step - loss: 3.3782 - participant_output_loss: 1.3819 - command_output_loss: 1.9933 - command_output_1_loss: 4.8766e-04 - participant_output_1_loss: 0.0026 - participant_output_accuracy: 0.5378 - command_output_accuracy: 0.5512 - command_output_1_accuracy: 0.2475 - participant_output_1_accuracy: 0.2241 - val_loss: 2.7774 - val_participant_output_loss: 1.0247 - val_command_output_loss: 1.7525 - val_command_output_1_loss: 8.9574e-05 - val_participant_output_1_loss: 1.5784e-04 - val_participant_output_accuracy: 0.7827 - val_command_output_accuracy: 0.8232 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.6390\n",
      "Epoch 2/10\n",
      "24/24 [==============================] - 3s 139ms/step - loss: 2.4839 - participant_output_loss: 0.8628 - command_output_loss: 1.6210 - command_output_1_loss: 1.0468e-04 - participant_output_1_loss: 6.9972e-05 - participant_output_accuracy: 0.8836 - command_output_accuracy: 0.8736 - command_output_1_accuracy: 0.1117 - participant_output_1_accuracy: 0.1304 - val_loss: 2.1988 - val_participant_output_loss: 0.7008 - val_command_output_loss: 1.4977 - val_command_output_1_loss: 1.8334e-04 - val_participant_output_1_loss: 4.5656e-05 - val_participant_output_accuracy: 0.9282 - val_command_output_accuracy: 0.9006 - val_command_output_1_accuracy: 0.8969 - val_participant_output_1_accuracy: 0.2689\n",
      "Epoch 3/10\n",
      "24/24 [==============================] - 3s 142ms/step - loss: 1.9617 - participant_output_loss: 0.5962 - command_output_loss: 1.3653 - command_output_1_loss: 1.4442e-04 - participant_output_1_loss: 3.8278e-05 - participant_output_accuracy: 0.9518 - command_output_accuracy: 0.9344 - command_output_1_accuracy: 0.4348 - participant_output_1_accuracy: 0.1057 - val_loss: 1.7677 - val_participant_output_loss: 0.5228 - val_command_output_loss: 1.2447 - val_command_output_1_loss: 1.3070e-04 - val_participant_output_1_loss: 3.4573e-05 - val_participant_output_accuracy: 0.9503 - val_command_output_accuracy: 0.9613 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.1308\n",
      "Epoch 4/10\n",
      "24/24 [==============================] - 3s 136ms/step - loss: 1.5517 - participant_output_loss: 0.4339 - command_output_loss: 1.1177 - command_output_1_loss: 7.0815e-05 - participant_output_1_loss: 3.1263e-05 - participant_output_accuracy: 0.9786 - command_output_accuracy: 0.9706 - command_output_1_accuracy: 0.0368 - participant_output_1_accuracy: 0.1251 - val_loss: 1.4599 - val_participant_output_loss: 0.4292 - val_command_output_loss: 1.0306 - val_command_output_1_loss: 7.0718e-05 - val_participant_output_1_loss: 3.3749e-05 - val_participant_output_accuracy: 0.9540 - val_command_output_accuracy: 0.9724 - val_command_output_1_accuracy: 0.0773 - val_participant_output_1_accuracy: 0.0773\n",
      "Epoch 5/10\n",
      "24/24 [==============================] - 3s 139ms/step - loss: 1.2522 - participant_output_loss: 0.3488 - command_output_loss: 0.9033 - command_output_1_loss: 6.0636e-05 - participant_output_1_loss: 2.9862e-05 - participant_output_accuracy: 0.9839 - command_output_accuracy: 0.9860 - command_output_1_accuracy: 0.0569 - participant_output_1_accuracy: 0.1043 - val_loss: 1.2055 - val_participant_output_loss: 0.3671 - val_command_output_loss: 0.8384 - val_command_output_1_loss: 5.8366e-05 - val_participant_output_1_loss: 3.3085e-05 - val_participant_output_accuracy: 0.9669 - val_command_output_accuracy: 0.9761 - val_command_output_1_accuracy: 0.0258 - val_participant_output_1_accuracy: 0.0424\n",
      "Epoch 6/10\n",
      "24/24 [==============================] - 3s 139ms/step - loss: 0.9918 - participant_output_loss: 0.2738 - command_output_loss: 0.7179 - command_output_1_loss: 6.2561e-05 - participant_output_1_loss: 2.8687e-05 - participant_output_accuracy: 0.9906 - command_output_accuracy: 0.9886 - command_output_1_accuracy: 0.0696 - participant_output_1_accuracy: 0.1151 - val_loss: 0.9420 - val_participant_output_loss: 0.2753 - val_command_output_loss: 0.6666 - val_command_output_1_loss: 8.9895e-05 - val_participant_output_1_loss: 3.2739e-05 - val_participant_output_accuracy: 0.9816 - val_command_output_accuracy: 0.9816 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.1050\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10\n",
      "24/24 [==============================] - 3s 117ms/step - loss: 0.7777 - participant_output_loss: 0.2154 - command_output_loss: 0.5623 - command_output_1_loss: 4.5034e-05 - participant_output_1_loss: 2.8243e-05 - participant_output_accuracy: 0.9920 - command_output_accuracy: 0.9953 - command_output_1_accuracy: 0.1672 - participant_output_1_accuracy: 0.1171 - val_loss: 0.8022 - val_participant_output_loss: 0.2477 - val_command_output_loss: 0.5544 - val_command_output_1_loss: 4.2629e-05 - val_participant_output_1_loss: 3.2310e-05 - val_participant_output_accuracy: 0.9779 - val_command_output_accuracy: 0.9797 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.1989\n",
      "Epoch 8/10\n",
      "24/24 [==============================] - 3s 142ms/step - loss: 0.6212 - participant_output_loss: 0.1829 - command_output_loss: 0.4382 - command_output_1_loss: 4.1881e-05 - participant_output_1_loss: 2.7903e-05 - participant_output_accuracy: 0.9953 - command_output_accuracy: 0.9973 - command_output_1_accuracy: 0.0776 - participant_output_1_accuracy: 0.1378 - val_loss: 0.6469 - val_participant_output_loss: 0.2119 - val_command_output_loss: 0.4350 - val_command_output_1_loss: 2.7053e-05 - val_participant_output_1_loss: 3.3100e-05 - val_participant_output_accuracy: 0.9797 - val_command_output_accuracy: 0.9834 - val_command_output_1_accuracy: 0.4770 - val_participant_output_1_accuracy: 0.1215\n",
      "Epoch 9/10\n",
      "24/24 [==============================] - 3s 134ms/step - loss: 0.4901 - participant_output_loss: 0.1562 - command_output_loss: 0.3338 - command_output_1_loss: 1.8644e-05 - participant_output_1_loss: 2.8755e-05 - participant_output_accuracy: 0.9967 - command_output_accuracy: 0.9980 - command_output_1_accuracy: 0.3003 - participant_output_1_accuracy: 0.1197 - val_loss: 0.5304 - val_participant_output_loss: 0.1877 - val_command_output_loss: 0.3426 - val_command_output_1_loss: 1.4828e-05 - val_participant_output_1_loss: 3.4464e-05 - val_participant_output_accuracy: 0.9853 - val_command_output_accuracy: 0.9853 - val_command_output_1_accuracy: 0.3076 - val_participant_output_1_accuracy: 0.1510\n",
      "Epoch 10/10\n",
      "24/24 [==============================] - 3s 116ms/step - loss: 0.3867 - participant_output_loss: 0.1306 - command_output_loss: 0.2560 - command_output_1_loss: 1.7252e-05 - participant_output_1_loss: 2.6337e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9987 - command_output_1_accuracy: 0.0729 - participant_output_1_accuracy: 0.1378 - val_loss: 0.4472 - val_participant_output_loss: 0.1691 - val_command_output_loss: 0.2780 - val_command_output_1_loss: 1.7774e-05 - val_participant_output_1_loss: 3.0567e-05 - val_participant_output_accuracy: 0.9816 - val_command_output_accuracy: 0.9779 - val_command_output_1_accuracy: 0.0442 - val_participant_output_1_accuracy: 0.1750\n",
      "Epoch 1/10\n",
      "24/24 [==============================] - 4s 169ms/step - loss: 0.3131 - participant_output_loss: 0.1141 - command_output_loss: 0.1989 - command_output_1_loss: 1.7737e-05 - participant_output_1_loss: 2.3908e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9993 - command_output_1_accuracy: 0.0843 - participant_output_1_accuracy: 0.1565 - val_loss: 0.3894 - val_participant_output_loss: 0.1528 - val_command_output_loss: 0.2366 - val_command_output_1_loss: 2.7018e-05 - val_participant_output_1_loss: 2.9444e-05 - val_participant_output_accuracy: 0.9853 - val_command_output_accuracy: 0.9834 - val_command_output_1_accuracy: 0.0368 - val_participant_output_1_accuracy: 0.1750\n",
      "Epoch 2/10\n",
      "24/24 [==============================] - 3s 128ms/step - loss: 0.2579 - participant_output_loss: 0.1002 - command_output_loss: 0.1576 - command_output_1_loss: 2.3782e-05 - participant_output_1_loss: 2.1771e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9993 - command_output_1_accuracy: 0.0676 - participant_output_1_accuracy: 0.1438 - val_loss: 0.3345 - val_participant_output_loss: 0.1405 - val_command_output_loss: 0.1939 - val_command_output_1_loss: 1.6447e-05 - val_participant_output_1_loss: 2.7767e-05 - val_participant_output_accuracy: 0.9834 - val_command_output_accuracy: 0.9853 - val_command_output_1_accuracy: 0.0166 - val_participant_output_1_accuracy: 0.1731\n",
      "Epoch 3/10\n",
      "24/24 [==============================] - 3s 134ms/step - loss: 0.2133 - participant_output_loss: 0.0859 - command_output_loss: 0.1274 - command_output_1_loss: 1.6683e-05 - participant_output_1_loss: 2.0016e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9993 - command_output_1_accuracy: 0.0482 - participant_output_1_accuracy: 0.1632 - val_loss: 0.2973 - val_participant_output_loss: 0.1301 - val_command_output_loss: 0.1671 - val_command_output_1_loss: 1.5206e-05 - val_participant_output_1_loss: 2.6799e-05 - val_participant_output_accuracy: 0.9816 - val_command_output_accuracy: 0.9834 - val_command_output_1_accuracy: 0.0110 - val_participant_output_1_accuracy: 0.1344\n",
      "Epoch 4/10\n",
      "24/24 [==============================] - 3s 141ms/step - loss: 0.1802 - participant_output_loss: 0.0756 - command_output_loss: 0.1046 - command_output_1_loss: 1.2715e-05 - participant_output_1_loss: 1.8429e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9993 - command_output_1_accuracy: 0.0087 - participant_output_1_accuracy: 0.1545 - val_loss: 0.2646 - val_participant_output_loss: 0.1185 - val_command_output_loss: 0.1460 - val_command_output_1_loss: 1.0194e-05 - val_participant_output_1_loss: 2.4680e-05 - val_participant_output_accuracy: 0.9853 - val_command_output_accuracy: 0.9853 - val_command_output_1_accuracy: 0.0424 - val_participant_output_1_accuracy: 0.1326\n",
      "Epoch 5/10\n",
      "24/24 [==============================] - 4s 153ms/step - loss: 0.1554 - participant_output_loss: 0.0680 - command_output_loss: 0.0874 - command_output_1_loss: 8.9273e-06 - participant_output_1_loss: 1.6520e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9993 - command_output_1_accuracy: 0.3853 - participant_output_1_accuracy: 0.1706 - val_loss: 0.2414 - val_participant_output_loss: 0.1109 - val_command_output_loss: 0.1305 - val_command_output_1_loss: 7.7826e-06 - val_participant_output_1_loss: 2.3228e-05 - val_participant_output_accuracy: 0.9853 - val_command_output_accuracy: 0.9871 - val_command_output_1_accuracy: 0.0203 - val_participant_output_1_accuracy: 0.1252\n",
      "Epoch 6/10\n",
      "24/24 [==============================] - 3s 139ms/step - loss: 0.1365 - participant_output_loss: 0.0628 - command_output_loss: 0.0737 - command_output_1_loss: 7.3141e-06 - participant_output_1_loss: 1.5057e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9993 - command_output_1_accuracy: 0.0074 - participant_output_1_accuracy: 0.1692 - val_loss: 0.2223 - val_participant_output_loss: 0.1035 - val_command_output_loss: 0.1187 - val_command_output_1_loss: 5.8216e-06 - val_participant_output_1_loss: 2.2568e-05 - val_participant_output_accuracy: 0.9871 - val_command_output_accuracy: 0.9871 - val_command_output_1_accuracy: 0.1381 - val_participant_output_1_accuracy: 0.1234\n",
      "Epoch 7/10\n",
      "24/24 [==============================] - 3s 138ms/step - loss: 0.1218 - participant_output_loss: 0.0586 - command_output_loss: 0.0632 - command_output_1_loss: 5.9052e-06 - participant_output_1_loss: 1.3987e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9993 - command_output_1_accuracy: 0.3425 - participant_output_1_accuracy: 0.1532 - val_loss: 0.2072 - val_participant_output_loss: 0.0996 - val_command_output_loss: 0.1076 - val_command_output_1_loss: 4.8225e-06 - val_participant_output_1_loss: 2.1976e-05 - val_participant_output_accuracy: 0.9890 - val_command_output_accuracy: 0.9890 - val_command_output_1_accuracy: 0.0847 - val_participant_output_1_accuracy: 0.1676\n",
      "Epoch 8/10\n",
      "24/24 [==============================] - 3s 138ms/step - loss: 0.1084 - participant_output_loss: 0.0539 - command_output_loss: 0.0546 - command_output_1_loss: 5.2773e-06 - participant_output_1_loss: 1.2897e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9993 - command_output_1_accuracy: 0.0890 - participant_output_1_accuracy: 0.1645 - val_loss: 0.1918 - val_participant_output_loss: 0.0937 - val_command_output_loss: 0.0981 - val_command_output_1_loss: 3.7192e-06 - val_participant_output_1_loss: 2.0692e-05 - val_participant_output_accuracy: 0.9890 - val_command_output_accuracy: 0.9908 - val_command_output_1_accuracy: 0.0424 - val_participant_output_1_accuracy: 0.1436\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10\n",
      "24/24 [==============================] - 3s 119ms/step - loss: 0.0955 - participant_output_loss: 0.0481 - command_output_loss: 0.0473 - command_output_1_loss: 4.8062e-06 - participant_output_1_loss: 1.1951e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9993 - command_output_1_accuracy: 0.0462 - participant_output_1_accuracy: 0.1612 - val_loss: 0.1811 - val_participant_output_loss: 0.0901 - val_command_output_loss: 0.0910 - val_command_output_1_loss: 3.2504e-06 - val_participant_output_1_loss: 1.9710e-05 - val_participant_output_accuracy: 0.9853 - val_command_output_accuracy: 0.9890 - val_command_output_1_accuracy: 0.1694 - val_participant_output_1_accuracy: 0.1308\n",
      "Epoch 10/10\n",
      "24/24 [==============================] - 3s 117ms/step - loss: 0.0859 - participant_output_loss: 0.0441 - command_output_loss: 0.0418 - command_output_1_loss: 3.3120e-06 - participant_output_1_loss: 1.0922e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9993 - command_output_1_accuracy: 0.1425 - participant_output_1_accuracy: 0.1559 - val_loss: 0.1703 - val_participant_output_loss: 0.0842 - val_command_output_loss: 0.0860 - val_command_output_1_loss: 3.0509e-06 - val_participant_output_1_loss: 1.9039e-05 - val_participant_output_accuracy: 0.9853 - val_command_output_accuracy: 0.9890 - val_command_output_1_accuracy: 0.2357 - val_participant_output_1_accuracy: 0.1308\n",
      "Epoch 1/10\n",
      "24/24 [==============================] - 5s 209ms/step - loss: 3.5343 - participant_output_loss: 1.4373 - command_output_loss: 2.0942 - command_output_1_loss: 7.4279e-04 - participant_output_1_loss: 0.0020 - participant_output_accuracy: 0.4916 - command_output_accuracy: 0.5117 - command_output_1_accuracy: 0.2314 - participant_output_1_accuracy: 0.3197 - val_loss: 3.0111 - val_participant_output_loss: 1.1271 - val_command_output_loss: 1.8836 - val_command_output_1_loss: 2.3378e-04 - val_participant_output_1_loss: 1.5557e-04 - val_participant_output_accuracy: 0.7587 - val_command_output_accuracy: 0.8269 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.0074\n",
      "Epoch 2/10\n",
      "24/24 [==============================] - 3s 142ms/step - loss: 2.7078 - participant_output_loss: 0.9267 - command_output_loss: 1.7809 - command_output_1_loss: 1.0365e-04 - participant_output_1_loss: 6.9074e-05 - participant_output_accuracy: 0.8575 - command_output_accuracy: 0.8936 - command_output_1_accuracy: 0.0000e+00 - participant_output_1_accuracy: 0.2067 - val_loss: 2.4207 - val_participant_output_loss: 0.7499 - val_command_output_loss: 1.6708 - val_command_output_1_loss: 4.7064e-05 - val_participant_output_1_loss: 3.9295e-05 - val_participant_output_accuracy: 0.9006 - val_command_output_accuracy: 0.9300 - val_command_output_1_accuracy: 0.0350 - val_participant_output_1_accuracy: 0.1308\n",
      "Epoch 3/10\n",
      "24/24 [==============================] - 4s 148ms/step - loss: 2.1769 - participant_output_loss: 0.6112 - command_output_loss: 1.5656 - command_output_1_loss: 8.2427e-05 - participant_output_1_loss: 3.2228e-05 - participant_output_accuracy: 0.9452 - command_output_accuracy: 0.9264 - command_output_1_accuracy: 0.4274 - participant_output_1_accuracy: 0.2134 - val_loss: 1.9828 - val_participant_output_loss: 0.5169 - val_command_output_loss: 1.4658 - val_command_output_1_loss: 4.9505e-05 - val_participant_output_1_loss: 3.0398e-05 - val_participant_output_accuracy: 0.9448 - val_command_output_accuracy: 0.9540 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.2376\n",
      "Epoch 4/10\n",
      "24/24 [==============================] - 3s 144ms/step - loss: 1.7782 - participant_output_loss: 0.4150 - command_output_loss: 1.3631 - command_output_1_loss: 6.8668e-05 - participant_output_1_loss: 2.7083e-05 - participant_output_accuracy: 0.9739 - command_output_accuracy: 0.9726 - command_output_1_accuracy: 0.0535 - participant_output_1_accuracy: 0.2167 - val_loss: 1.6558 - val_participant_output_loss: 0.3799 - val_command_output_loss: 1.2757 - val_command_output_1_loss: 1.0278e-04 - val_participant_output_1_loss: 2.6720e-05 - val_participant_output_accuracy: 0.9632 - val_command_output_accuracy: 0.9687 - val_command_output_1_accuracy: 0.1215 - val_participant_output_1_accuracy: 0.2523\n",
      "Epoch 5/10\n",
      "24/24 [==============================] - 3s 138ms/step - loss: 1.4579 - participant_output_loss: 0.2958 - command_output_loss: 1.1620 - command_output_1_loss: 1.0798e-04 - participant_output_1_loss: 2.5222e-05 - participant_output_accuracy: 0.9880 - command_output_accuracy: 0.9853 - command_output_1_accuracy: 0.0435 - participant_output_1_accuracy: 0.2381 - val_loss: 1.3668 - val_participant_output_loss: 0.2831 - val_command_output_loss: 1.0835 - val_command_output_1_loss: 1.1874e-04 - val_participant_output_1_loss: 2.5546e-05 - val_participant_output_accuracy: 0.9761 - val_command_output_accuracy: 0.9687 - val_command_output_1_accuracy: 0.0110 - val_participant_output_1_accuracy: 0.2357\n",
      "Epoch 6/10\n",
      "24/24 [==============================] - 3s 137ms/step - loss: 1.1839 - participant_output_loss: 0.2177 - command_output_loss: 0.9661 - command_output_1_loss: 7.9408e-05 - participant_output_1_loss: 2.4098e-05 - participant_output_accuracy: 0.9913 - command_output_accuracy: 0.9906 - command_output_1_accuracy: 0.0027 - participant_output_1_accuracy: 0.2154 - val_loss: 1.1382 - val_participant_output_loss: 0.2272 - val_command_output_loss: 0.9110 - val_command_output_1_loss: 4.0723e-05 - val_participant_output_1_loss: 2.6379e-05 - val_participant_output_accuracy: 0.9797 - val_command_output_accuracy: 0.9761 - val_command_output_1_accuracy: 0.0681 - val_participant_output_1_accuracy: 0.1971\n",
      "Epoch 7/10\n",
      "24/24 [==============================] - 3s 146ms/step - loss: 0.9582 - participant_output_loss: 0.1632 - command_output_loss: 0.7950 - command_output_1_loss: 5.4127e-05 - participant_output_1_loss: 2.4379e-05 - participant_output_accuracy: 0.9946 - command_output_accuracy: 0.9926 - command_output_1_accuracy: 0.0716 - participant_output_1_accuracy: 0.2214 - val_loss: 0.9321 - val_participant_output_loss: 0.1811 - val_command_output_loss: 0.7510 - val_command_output_1_loss: 3.4047e-05 - val_participant_output_1_loss: 2.7224e-05 - val_participant_output_accuracy: 0.9871 - val_command_output_accuracy: 0.9816 - val_command_output_1_accuracy: 0.0037 - val_participant_output_1_accuracy: 0.2081\n",
      "Epoch 8/10\n",
      "24/24 [==============================] - 3s 116ms/step - loss: 0.7721 - participant_output_loss: 0.1253 - command_output_loss: 0.6467 - command_output_1_loss: 3.6632e-05 - participant_output_1_loss: 2.5127e-05 - participant_output_accuracy: 0.9967 - command_output_accuracy: 0.9973 - command_output_1_accuracy: 0.0080 - participant_output_1_accuracy: 0.2234 - val_loss: 0.7841 - val_participant_output_loss: 0.1548 - val_command_output_loss: 0.6292 - val_command_output_1_loss: 2.1493e-05 - val_participant_output_1_loss: 2.8772e-05 - val_participant_output_accuracy: 0.9853 - val_command_output_accuracy: 0.9797 - val_command_output_1_accuracy: 0.0037 - val_participant_output_1_accuracy: 0.1713\n",
      "Epoch 9/10\n",
      "24/24 [==============================] - 3s 140ms/step - loss: 0.6287 - participant_output_loss: 0.0987 - command_output_loss: 0.5299 - command_output_1_loss: 2.7214e-05 - participant_output_1_loss: 2.5285e-05 - participant_output_accuracy: 0.9980 - command_output_accuracy: 0.9980 - command_output_1_accuracy: 0.0722 - participant_output_1_accuracy: 0.2214 - val_loss: 0.6552 - val_participant_output_loss: 0.1326 - val_command_output_loss: 0.5225 - val_command_output_1_loss: 2.7687e-05 - val_participant_output_1_loss: 2.8619e-05 - val_participant_output_accuracy: 0.9871 - val_command_output_accuracy: 0.9853 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.1989\n",
      "Epoch 10/10\n",
      "24/24 [==============================] - 3s 131ms/step - loss: 0.5131 - participant_output_loss: 0.0817 - command_output_loss: 0.4313 - command_output_1_loss: 3.9943e-05 - participant_output_1_loss: 2.4261e-05 - participant_output_accuracy: 0.9993 - command_output_accuracy: 0.9993 - command_output_1_accuracy: 0.2321 - participant_output_1_accuracy: 0.2067 - val_loss: 0.5609 - val_participant_output_loss: 0.1195 - val_command_output_loss: 0.4412 - val_command_output_1_loss: 6.8947e-05 - val_participant_output_1_loss: 2.8071e-05 - val_participant_output_accuracy: 0.9853 - val_command_output_accuracy: 0.9816 - val_command_output_1_accuracy: 0.9503 - val_participant_output_1_accuracy: 0.2173\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "24/24 [==============================] - 4s 167ms/step - loss: 0.4160 - participant_output_loss: 0.0655 - command_output_loss: 0.3505 - command_output_1_loss: 4.4850e-05 - participant_output_1_loss: 2.3884e-05 - participant_output_accuracy: 0.9993 - command_output_accuracy: 0.9993 - command_output_1_accuracy: 0.4007 - participant_output_1_accuracy: 0.2033 - val_loss: 0.4677 - val_participant_output_loss: 0.1037 - val_command_output_loss: 0.3640 - val_command_output_1_loss: 2.3908e-05 - val_participant_output_1_loss: 2.9432e-05 - val_participant_output_accuracy: 0.9853 - val_command_output_accuracy: 0.9908 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.3168\n",
      "Epoch 2/10\n",
      "24/24 [==============================] - 3s 120ms/step - loss: 0.3391 - participant_output_loss: 0.0540 - command_output_loss: 0.2851 - command_output_1_loss: 2.4974e-05 - participant_output_1_loss: 2.3209e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9993 - command_output_1_accuracy: 0.1157 - participant_output_1_accuracy: 0.2381 - val_loss: 0.3990 - val_participant_output_loss: 0.0923 - val_command_output_loss: 0.3066 - val_command_output_1_loss: 2.1408e-05 - val_participant_output_1_loss: 2.7423e-05 - val_participant_output_accuracy: 0.9853 - val_command_output_accuracy: 0.9890 - val_command_output_1_accuracy: 0.0018 - val_participant_output_1_accuracy: 0.1529\n",
      "Epoch 3/10\n",
      "24/24 [==============================] - 3s 120ms/step - loss: 0.2773 - participant_output_loss: 0.0455 - command_output_loss: 0.2317 - command_output_1_loss: 1.7125e-05 - participant_output_1_loss: 2.1219e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9993 - command_output_1_accuracy: 0.0207 - participant_output_1_accuracy: 0.1987 - val_loss: 0.3451 - val_participant_output_loss: 0.0854 - val_command_output_loss: 0.2596 - val_command_output_1_loss: 1.7524e-05 - val_participant_output_1_loss: 2.5489e-05 - val_participant_output_accuracy: 0.9853 - val_command_output_accuracy: 0.9890 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.2265\n",
      "Epoch 4/10\n",
      "24/24 [==============================] - 3s 123ms/step - loss: 0.2309 - participant_output_loss: 0.0398 - command_output_loss: 0.1911 - command_output_1_loss: 1.1578e-05 - participant_output_1_loss: 1.9555e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9993 - command_output_1_accuracy: 0.1532 - participant_output_1_accuracy: 0.1926 - val_loss: 0.3015 - val_participant_output_loss: 0.0793 - val_command_output_loss: 0.2221 - val_command_output_1_loss: 1.9796e-05 - val_participant_output_1_loss: 2.4164e-05 - val_participant_output_accuracy: 0.9871 - val_command_output_accuracy: 0.9890 - val_command_output_1_accuracy: 0.5820 - val_participant_output_1_accuracy: 0.1657\n",
      "Epoch 5/10\n",
      "24/24 [==============================] - 3s 120ms/step - loss: 0.1950 - participant_output_loss: 0.0360 - command_output_loss: 0.1589 - command_output_1_loss: 2.5830e-05 - participant_output_1_loss: 1.7787e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9993 - command_output_1_accuracy: 0.1512 - participant_output_1_accuracy: 0.2060 - val_loss: 0.2687 - val_participant_output_loss: 0.0752 - val_command_output_loss: 0.1935 - val_command_output_1_loss: 2.3632e-05 - val_participant_output_1_loss: 2.3172e-05 - val_participant_output_accuracy: 0.9853 - val_command_output_accuracy: 0.9908 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.2007\n",
      "Epoch 6/10\n",
      "24/24 [==============================] - 3s 139ms/step - loss: 0.1666 - participant_output_loss: 0.0322 - command_output_loss: 0.1344 - command_output_1_loss: 1.6462e-05 - participant_output_1_loss: 1.6625e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9993 - command_output_1_accuracy: 0.0334 - participant_output_1_accuracy: 0.2027 - val_loss: 0.2419 - val_participant_output_loss: 0.0707 - val_command_output_loss: 0.1712 - val_command_output_1_loss: 1.0879e-05 - val_participant_output_1_loss: 2.2426e-05 - val_participant_output_accuracy: 0.9871 - val_command_output_accuracy: 0.9908 - val_command_output_1_accuracy: 0.2228 - val_participant_output_1_accuracy: 0.1694\n",
      "Epoch 7/10\n",
      "24/24 [==============================] - 3s 116ms/step - loss: 0.1447 - participant_output_loss: 0.0293 - command_output_loss: 0.1154 - command_output_1_loss: 8.6410e-06 - participant_output_1_loss: 1.5746e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9993 - command_output_1_accuracy: 0.2783 - participant_output_1_accuracy: 0.1913 - val_loss: 0.2235 - val_participant_output_loss: 0.0691 - val_command_output_loss: 0.1544 - val_command_output_1_loss: 6.4741e-06 - val_participant_output_1_loss: 2.1149e-05 - val_participant_output_accuracy: 0.9871 - val_command_output_accuracy: 0.9871 - val_command_output_1_accuracy: 0.2836 - val_participant_output_1_accuracy: 0.1842\n",
      "Epoch 8/10\n",
      "24/24 [==============================] - 3s 125ms/step - loss: 0.1269 - participant_output_loss: 0.0267 - command_output_loss: 0.1002 - command_output_1_loss: 5.5613e-06 - participant_output_1_loss: 1.4885e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9993 - command_output_1_accuracy: 0.1452 - participant_output_1_accuracy: 0.2020 - val_loss: 0.2038 - val_participant_output_loss: 0.0662 - val_command_output_loss: 0.1376 - val_command_output_1_loss: 4.8891e-06 - val_participant_output_1_loss: 2.0123e-05 - val_participant_output_accuracy: 0.9853 - val_command_output_accuracy: 0.9890 - val_command_output_1_accuracy: 0.0018 - val_participant_output_1_accuracy: 0.1657\n",
      "Epoch 9/10\n",
      "24/24 [==============================] - 3s 119ms/step - loss: 0.1120 - participant_output_loss: 0.0245 - command_output_loss: 0.0875 - command_output_1_loss: 6.0967e-06 - participant_output_1_loss: 1.4013e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9993 - command_output_1_accuracy: 0.0114 - participant_output_1_accuracy: 0.1880 - val_loss: 0.1875 - val_participant_output_loss: 0.0623 - val_command_output_loss: 0.1252 - val_command_output_1_loss: 5.1859e-06 - val_participant_output_1_loss: 1.9653e-05 - val_participant_output_accuracy: 0.9871 - val_command_output_accuracy: 0.9908 - val_command_output_1_accuracy: 0.2634 - val_participant_output_1_accuracy: 0.2597\n",
      "Epoch 10/10\n",
      "24/24 [==============================] - 3s 126ms/step - loss: 0.0995 - participant_output_loss: 0.0228 - command_output_loss: 0.0767 - command_output_1_loss: 6.7701e-06 - participant_output_1_loss: 1.3020e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9993 - command_output_1_accuracy: 0.3465 - participant_output_1_accuracy: 0.1920 - val_loss: 0.1785 - val_participant_output_loss: 0.0632 - val_command_output_loss: 0.1153 - val_command_output_1_loss: 5.8045e-06 - val_participant_output_1_loss: 1.8728e-05 - val_participant_output_accuracy: 0.9871 - val_command_output_accuracy: 0.9908 - val_command_output_1_accuracy: 0.5912 - val_participant_output_1_accuracy: 0.1915\n"
     ]
    }
   ],
   "source": [
    "high_acc = 0\n",
    "for run in range(0,10):\n",
    "    # feature extraction layers\n",
    "    resnet_model = ResNet50(input_shape=(224, 224,3), include_top=False, weights=\"imagenet\")\n",
    "    for layer in resnet_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    d = resnet_model.output.shape[-1] # dimension of last layer\n",
    "\n",
    "    ###################### model 1 ###################### \n",
    "    layer_1_0 = tf.keras.layers.Dense(d,name=\"weight_1\")(resnet_model.output) #times weight before flatten\n",
    "    layer_1_1 = tf.keras.layers.Flatten(name='flatten_1')(layer_1_0)\n",
    "\n",
    "    Dense_1_1 = tf.keras.layers.Dense(shape_1_1, activation=actv_fun_1_1,name='fc1_1')\n",
    "    layer_1_2 = Dense_1_1(layer_1_1)\n",
    "    Dense_1_2 = tf.keras.layers.Dense(shape_1_2, activation=actv_fun_1_2,name='fc1_2')\n",
    "    layer_1_3 = Dense_1_2(layer_1_2)\n",
    "\n",
    "    Dense_1_3 = tf.keras.layers.Dense(train_number, activation='softmax' ,name='participant_output')\n",
    "    out_layer_1 = Dense_1_3(layer_1_3)\n",
    "\n",
    "    ###################### model 2 ###################### \n",
    "    layer_2_0 = tf.keras.layers.Dense(d,name=\"weight_2\")(resnet_model.output) #times weight before flatten\n",
    "    layer_2_1 = tf.keras.layers.Flatten(name='flatten_2')(layer_2_0)\n",
    "\n",
    "    Dense_2_1 = tf.keras.layers.Dense(shape_2_1, activation=actv_fun_2_1,name='fc2_1')\n",
    "    layer_2_2  = Dense_2_1(layer_2_1)\n",
    "    Dense_2_2 = tf.keras.layers.Dense(shape_2_2, activation=actv_fun_2_2,name='fc2_2')\n",
    "    layer_2_3  = Dense_2_2(layer_2_2)\n",
    "\n",
    "    Dense_2_3 = tf.keras.layers.Dense(10, activation='softmax',name='command_output')\n",
    "    out_layer_2 = Dense_2_3(layer_2_3)\n",
    "\n",
    "    ###################### model 1' ###################### \n",
    "    layer_1_2_  = Dense_2_1(layer_1_1)\n",
    "    layer_1_3_  = Dense_2_2(layer_1_2_)\n",
    "    out_layer_1_ = Dense_2_3(layer_1_3_)\n",
    "\n",
    "    ###################### model 1' ###################### \n",
    "    layer_2_2_  = Dense_1_1(layer_2_1)\n",
    "    layer_2_3_  = Dense_1_2(layer_2_2_)\n",
    "    out_layer_2_ = Dense_1_3(layer_2_3_)\n",
    "\n",
    "    resnet_model = tf.keras.Model(resnet_model.input, [out_layer_1,out_layer_2,out_layer_1_,out_layer_2_])\n",
    "\n",
    "\n",
    "    # resnet_model.summary() \n",
    "\n",
    "    w_1, w_2, w_1_, w_2_ = 1,1,1,1\n",
    "    ##################### training ############################\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "    callbacks = [MyEarlyStopping(monitor1 = 'val_' + resnet_model.layers[-1].name+'_accuracy',\n",
    "                                  monitor2 = 'val_' + resnet_model.layers[-2].name+'_accuracy',\n",
    "                                  patience=5,restore_best_weights=True)]\n",
    "    resnet_model.compile(optimizer=opt, loss=[\"categorical_crossentropy\",\"categorical_crossentropy\",\"mse\",\"mse\"],\n",
    "                         loss_weights=[w_1, w_2, w_1_, w_2_], metrics=['accuracy'])\n",
    "\n",
    "    \n",
    "    start = timeit.default_timer()\n",
    "       \n",
    "    history1 = resnet_model.fit(Train_Inputs, \n",
    "                           {resnet_model.layers[-2].name:Train_participant_class, \n",
    "                            resnet_model.layers[-1].name:Train_command_class,\n",
    "                            resnet_model.layers[-1].name+\"_1\":Train_command_uniform, \n",
    "                            resnet_model.layers[-2].name+\"_1\":Train_participant_uniform}, \n",
    "                            validation_data=(Val_Inputs,\n",
    "                                             {resnet_model.layers[-2].name:Val_participant_class,\n",
    "                                              resnet_model.layers[-1].name:Val_command_class,\n",
    "                                              resnet_model.layers[-1].name+\"_1\":Val_command_uniform,\n",
    "                                              resnet_model.layers[-2].name+\"_1\":Val_participant_uniform}), \n",
    "                           callbacks=callbacks,\n",
    "                           batch_size=64,\n",
    "                           epochs=10)\n",
    "    \n",
    "    for layer in resnet_model.layers[0:175]:\n",
    "        layer.trainable = True\n",
    "        \n",
    "    history2 = resnet_model.fit(Train_Inputs, \n",
    "                               {resnet_model.layers[-2].name:Train_participant_class, \n",
    "                                resnet_model.layers[-1].name:Train_command_class,\n",
    "                                resnet_model.layers[-1].name+\"_1\":Train_command_uniform, \n",
    "                                resnet_model.layers[-2].name+\"_1\":Train_participant_uniform}, \n",
    "                                validation_data=(Val_Inputs,\n",
    "                                                 {resnet_model.layers[-2].name:Val_participant_class,\n",
    "                                                  resnet_model.layers[-1].name:Val_command_class,\n",
    "                                                  resnet_model.layers[-1].name+\"_1\":Val_command_uniform,\n",
    "                                                  resnet_model.layers[-2].name+\"_1\":Val_participant_uniform}), \n",
    "                               callbacks=callbacks,\n",
    "                               batch_size=64,\n",
    "                               epochs=10)\n",
    "\n",
    "    stop = timeit.default_timer()\n",
    "    run_time = stop - start\n",
    "    \n",
    "    ##################### test performance ############################\n",
    "    predictions = resnet_model.predict(Test_Inputs)[0]\n",
    "    predicted_classes = np.argmax(predictions, axis=1)+1\n",
    "    true_classes = test_unit_participant_class\n",
    "    acc_p15_s = metrics.accuracy_score(true_classes, predicted_classes).round(4)\n",
    "\n",
    "    predictions = resnet_model.predict(Test_Inputs)[1]\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    true_classes = test_unit_command_class\n",
    "    acc_p15_c = metrics.accuracy_score(true_classes, predicted_classes).round(4)\n",
    "\n",
    "\n",
    "    # test on p1\n",
    "    ## speaker classification\n",
    "    predictions = resnet_model.predict(Test_Inputs_1)[0]\n",
    "    predicted_classes = np.argmax(predictions, axis=1)+1\n",
    "    true_classes = np.array([1]*len(predicted_classes))\n",
    "    acc_p1_s = metrics.accuracy_score(true_classes, predicted_classes).round(4)   \n",
    "    ## command classification\n",
    "    predictions = resnet_model.predict(Test_Inputs_1)[1]\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    true_classes = np.argmax(Test_command_class_1, axis=-1)\n",
    "    acc_p1_c = metrics.accuracy_score(true_classes, predicted_classes).round(4)   \n",
    "\n",
    "    # test on p2\n",
    "    ## speaker classification\n",
    "    predictions = resnet_model.predict(Test_Inputs_2)[0]\n",
    "    predicted_classes = np.argmax(predictions, axis=1)+1\n",
    "    true_classes = np.array([2]*len(predicted_classes))\n",
    "    acc_p2_s = metrics.accuracy_score(true_classes, predicted_classes).round(4)   \n",
    "    ## command classification\n",
    "    predictions = resnet_model.predict(Test_Inputs_2)[1]\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    true_classes = np.argmax(Test_command_class_2, axis=-1)\n",
    "    acc_p2_c = metrics.accuracy_score(true_classes, predicted_classes).round(4)   \n",
    "\n",
    "    # test on p3\n",
    "    ## speaker classification\n",
    "    predictions = resnet_model.predict(Test_Inputs_3)[0]\n",
    "    predicted_classes = np.argmax(predictions, axis=1)+1\n",
    "    true_classes = np.array([3]*len(predicted_classes))\n",
    "    acc_p3_s = metrics.accuracy_score(true_classes, predicted_classes).round(4)   \n",
    "    ## command classification\n",
    "    predictions = resnet_model.predict(Test_Inputs_3)[1]\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    true_classes = np.argmax(Test_command_class_3, axis=-1)\n",
    "    acc_p3_c = metrics.accuracy_score(true_classes, predicted_classes).round(4)   \n",
    "\n",
    "    # test on p4\n",
    "    ## speaker classification\n",
    "    predictions = resnet_model.predict(Test_Inputs_4)[0]\n",
    "    predicted_classes = np.argmax(predictions, axis=1)+1\n",
    "    true_classes = np.array([4]*len(predicted_classes))\n",
    "    acc_p4_s = metrics.accuracy_score(true_classes, predicted_classes).round(4)   \n",
    "    ## command classification\n",
    "    predictions = resnet_model.predict(Test_Inputs_4)[1]\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    true_classes = np.argmax(Test_command_class_4, axis=-1)\n",
    "    acc_p4_c = metrics.accuracy_score(true_classes, predicted_classes).round(4)   \n",
    "\n",
    "    # test on p5\n",
    "    ## speaker classification\n",
    "    predictions = resnet_model.predict(Test_Inputs_5)[0]\n",
    "    predicted_classes = np.argmax(predictions, axis=1)+1\n",
    "    true_classes = np.array([5]*len(predicted_classes))\n",
    "    acc_p5_s = metrics.accuracy_score(true_classes, predicted_classes).round(4)   \n",
    "    ## command classification\n",
    "    predictions = resnet_model.predict(Test_Inputs_5)[1]\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    true_classes = np.argmax(Test_command_class_5, axis=-1)\n",
    "    acc_p5_c = metrics.accuracy_score(true_classes, predicted_classes).round(4)   \n",
    "\n",
    "    # test on p6 \n",
    "    ## command classification\n",
    "    predictions = resnet_model.predict(Test_Inputs_6)[1]\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    true_classes = test_unit_command_class_6\n",
    "    acc_p6 = metrics.accuracy_score(true_classes, predicted_classes).round(4)                \n",
    "\n",
    "    # test on p7 \n",
    "    ## command classification\n",
    "    predictions = resnet_model.predict(Test_Inputs_7)[1]\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    true_classes = test_unit_command_class_7\n",
    "    acc_p7 = metrics.accuracy_score(true_classes, predicted_classes).round(4)    \n",
    "\n",
    "    # test on p8 \n",
    "    ## command classification\n",
    "    predictions = resnet_model.predict(Test_Inputs_8)[1]\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    true_classes = test_unit_command_class_8\n",
    "    acc_p8 = metrics.accuracy_score(true_classes, predicted_classes).round(4)    \n",
    "\n",
    "    Perfomance = Perfomance.append({'Model': \"Group\",'Size':'60%','Time':run_time,\n",
    "                                    'Partcp_Acc_p15':acc_p15_s,'Command_Acc_p15':acc_p15_c,'Partcp_Acc_p1':acc_p1_s,\n",
    "                                    'Command_Acc_p1':acc_p1_c,'Partcp_Acc_p2':acc_p2_s,'Command_Acc_p2':acc_p2_c,\n",
    "                                    'Partcp_Acc_p3':acc_p3_s,'Command_Acc_p3':acc_p3_c,'Partcp_Acc_p4':acc_p4_s,\n",
    "                                    'Command_Acc_p4':acc_p4_c,'Partcp_Acc_p5':acc_p5_s,'Command_Acc_p5':acc_p5_c,\n",
    "                                    'Acc_p6':acc_p6,'Acc_p7':acc_p7,'Acc_p8':acc_p8}, ignore_index=True)\n",
    "\n",
    "\n",
    "    if high_acc < acc_p15_c + acc_p15_s:\n",
    "        resnet_model.save('Initial_group_model_60p_0608.h5')\n",
    "        high_acc = acc_p15_c + acc_p15_s\n",
    "        best_index = run\n",
    "        pd.DataFrame.from_dict(history1.history).to_csv('60p_history1_0608.csv',index=False)\n",
    "        pd.DataFrame.from_dict(history2.history).to_csv('60p_history2_0608.csv',index=False)\n",
    "        \n",
    "    del resnet_model\n",
    "    run = run + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "0.9945 0.989\n"
     ]
    }
   ],
   "source": [
    "resnet_model = tf.keras.models.load_model('Initial_group_model_60p_0608.h5')\n",
    "predictions = resnet_model.predict(Test_Inputs)[0]\n",
    "predicted_classes = np.argmax(predictions, axis=1)+1\n",
    "acc_c = round(sum(x == y for x, y in zip(test_unit_participant_class, predicted_classes)) / len(test_unit_participant_class),4)\n",
    "\n",
    "predictions = resnet_model.predict(Test_Inputs)[1]\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "acc_s = round(sum(x == y for x, y in zip(test_unit_command_class, predicted_classes)) / len(test_unit_command_class),4)\n",
    "overall_acc = acc_c + acc_s\n",
    "print(acc_c,acc_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Size</th>\n",
       "      <th>Time</th>\n",
       "      <th>Partcp_Acc_p15</th>\n",
       "      <th>Command_Acc_p15</th>\n",
       "      <th>Partcp_Acc_p1</th>\n",
       "      <th>Command_Acc_p1</th>\n",
       "      <th>Partcp_Acc_p2</th>\n",
       "      <th>Command_Acc_p2</th>\n",
       "      <th>Partcp_Acc_p3</th>\n",
       "      <th>Command_Acc_p3</th>\n",
       "      <th>Partcp_Acc_p4</th>\n",
       "      <th>Command_Acc_p4</th>\n",
       "      <th>Partcp_Acc_p5</th>\n",
       "      <th>Command_Acc_p5</th>\n",
       "      <th>Acc_p6</th>\n",
       "      <th>Acc_p7</th>\n",
       "      <th>Acc_p8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Group</td>\n",
       "      <td>20%</td>\n",
       "      <td>47.540156</td>\n",
       "      <td>0.9724</td>\n",
       "      <td>0.9484</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.9550</td>\n",
       "      <td>0.9259</td>\n",
       "      <td>0.8796</td>\n",
       "      <td>0.9652</td>\n",
       "      <td>0.9565</td>\n",
       "      <td>0.9817</td>\n",
       "      <td>0.9633</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.528</td>\n",
       "      <td>0.3366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Group</td>\n",
       "      <td>20%</td>\n",
       "      <td>48.307249</td>\n",
       "      <td>0.9779</td>\n",
       "      <td>0.9521</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.9369</td>\n",
       "      <td>0.9352</td>\n",
       "      <td>0.8796</td>\n",
       "      <td>0.9739</td>\n",
       "      <td>0.9652</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.528</td>\n",
       "      <td>0.2970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Group</td>\n",
       "      <td>20%</td>\n",
       "      <td>46.201615</td>\n",
       "      <td>0.9613</td>\n",
       "      <td>0.9448</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.9369</td>\n",
       "      <td>0.9074</td>\n",
       "      <td>0.8611</td>\n",
       "      <td>0.9826</td>\n",
       "      <td>0.9652</td>\n",
       "      <td>0.9358</td>\n",
       "      <td>0.9725</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.432</td>\n",
       "      <td>0.2673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Group</td>\n",
       "      <td>20%</td>\n",
       "      <td>43.692362</td>\n",
       "      <td>0.9650</td>\n",
       "      <td>0.9521</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.9459</td>\n",
       "      <td>0.9074</td>\n",
       "      <td>0.8704</td>\n",
       "      <td>0.9826</td>\n",
       "      <td>0.9652</td>\n",
       "      <td>0.9358</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.504</td>\n",
       "      <td>0.2673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Group</td>\n",
       "      <td>20%</td>\n",
       "      <td>44.504580</td>\n",
       "      <td>0.9687</td>\n",
       "      <td>0.9484</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.9550</td>\n",
       "      <td>0.9259</td>\n",
       "      <td>0.8796</td>\n",
       "      <td>0.9739</td>\n",
       "      <td>0.9652</td>\n",
       "      <td>0.9541</td>\n",
       "      <td>0.9541</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.472</td>\n",
       "      <td>0.3267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Group</td>\n",
       "      <td>20%</td>\n",
       "      <td>44.229166</td>\n",
       "      <td>0.9705</td>\n",
       "      <td>0.9521</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.9550</td>\n",
       "      <td>0.9074</td>\n",
       "      <td>0.8796</td>\n",
       "      <td>0.9826</td>\n",
       "      <td>0.9739</td>\n",
       "      <td>0.9633</td>\n",
       "      <td>0.9633</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.456</td>\n",
       "      <td>0.3069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Group</td>\n",
       "      <td>20%</td>\n",
       "      <td>44.535541</td>\n",
       "      <td>0.9632</td>\n",
       "      <td>0.9540</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.9369</td>\n",
       "      <td>0.9259</td>\n",
       "      <td>0.8981</td>\n",
       "      <td>0.9565</td>\n",
       "      <td>0.9652</td>\n",
       "      <td>0.9541</td>\n",
       "      <td>0.9817</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.496</td>\n",
       "      <td>0.3267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Group</td>\n",
       "      <td>20%</td>\n",
       "      <td>42.948731</td>\n",
       "      <td>0.9724</td>\n",
       "      <td>0.9595</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.9550</td>\n",
       "      <td>0.9074</td>\n",
       "      <td>0.8889</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9739</td>\n",
       "      <td>0.9633</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.496</td>\n",
       "      <td>0.2574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Group</td>\n",
       "      <td>20%</td>\n",
       "      <td>45.444911</td>\n",
       "      <td>0.9724</td>\n",
       "      <td>0.9503</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.9459</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>0.8796</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9652</td>\n",
       "      <td>0.9633</td>\n",
       "      <td>0.9725</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.552</td>\n",
       "      <td>0.2673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Group</td>\n",
       "      <td>20%</td>\n",
       "      <td>42.707019</td>\n",
       "      <td>0.9669</td>\n",
       "      <td>0.9540</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.9459</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>0.8704</td>\n",
       "      <td>0.9739</td>\n",
       "      <td>0.9652</td>\n",
       "      <td>0.9541</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.480</td>\n",
       "      <td>0.4059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Group</td>\n",
       "      <td>40%</td>\n",
       "      <td>67.289367</td>\n",
       "      <td>0.9945</td>\n",
       "      <td>0.9761</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.9640</td>\n",
       "      <td>0.9907</td>\n",
       "      <td>0.9352</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.472</td>\n",
       "      <td>0.2772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Group</td>\n",
       "      <td>40%</td>\n",
       "      <td>64.328163</td>\n",
       "      <td>0.9890</td>\n",
       "      <td>0.9761</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.9730</td>\n",
       "      <td>0.9815</td>\n",
       "      <td>0.9259</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.480</td>\n",
       "      <td>0.2871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Group</td>\n",
       "      <td>40%</td>\n",
       "      <td>61.978212</td>\n",
       "      <td>0.9926</td>\n",
       "      <td>0.9797</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.9730</td>\n",
       "      <td>0.9907</td>\n",
       "      <td>0.9444</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.3168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Group</td>\n",
       "      <td>40%</td>\n",
       "      <td>60.036626</td>\n",
       "      <td>0.9926</td>\n",
       "      <td>0.9779</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.9730</td>\n",
       "      <td>0.9907</td>\n",
       "      <td>0.9352</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.456</td>\n",
       "      <td>0.3267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Group</td>\n",
       "      <td>40%</td>\n",
       "      <td>58.215136</td>\n",
       "      <td>0.9890</td>\n",
       "      <td>0.9761</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.9730</td>\n",
       "      <td>0.9815</td>\n",
       "      <td>0.9352</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9826</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.448</td>\n",
       "      <td>0.2871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Group</td>\n",
       "      <td>40%</td>\n",
       "      <td>49.347837</td>\n",
       "      <td>0.9871</td>\n",
       "      <td>0.9761</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.9730</td>\n",
       "      <td>0.9815</td>\n",
       "      <td>0.9352</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9817</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.472</td>\n",
       "      <td>0.2772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Group</td>\n",
       "      <td>40%</td>\n",
       "      <td>59.879732</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.9779</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.9730</td>\n",
       "      <td>0.9815</td>\n",
       "      <td>0.9444</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9826</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.3366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Group</td>\n",
       "      <td>40%</td>\n",
       "      <td>57.413757</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.9761</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.9640</td>\n",
       "      <td>0.9815</td>\n",
       "      <td>0.9444</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9826</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.3168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Group</td>\n",
       "      <td>40%</td>\n",
       "      <td>50.219540</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.9761</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.9730</td>\n",
       "      <td>0.9815</td>\n",
       "      <td>0.9352</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.456</td>\n",
       "      <td>0.2772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Group</td>\n",
       "      <td>40%</td>\n",
       "      <td>53.871787</td>\n",
       "      <td>0.9945</td>\n",
       "      <td>0.9742</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.9730</td>\n",
       "      <td>0.9907</td>\n",
       "      <td>0.9259</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.9817</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.424</td>\n",
       "      <td>0.2673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Group</td>\n",
       "      <td>60%</td>\n",
       "      <td>80.966223</td>\n",
       "      <td>0.9926</td>\n",
       "      <td>0.9871</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.9820</td>\n",
       "      <td>0.9815</td>\n",
       "      <td>0.9722</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.2772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Group</td>\n",
       "      <td>60%</td>\n",
       "      <td>77.376384</td>\n",
       "      <td>0.9926</td>\n",
       "      <td>0.9797</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.9820</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9537</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9826</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.9817</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.456</td>\n",
       "      <td>0.2178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Group</td>\n",
       "      <td>60%</td>\n",
       "      <td>79.340686</td>\n",
       "      <td>0.9945</td>\n",
       "      <td>0.9816</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.9820</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9444</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.2970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Group</td>\n",
       "      <td>60%</td>\n",
       "      <td>63.791425</td>\n",
       "      <td>0.9890</td>\n",
       "      <td>0.9871</td>\n",
       "      <td>0.973</td>\n",
       "      <td>0.9910</td>\n",
       "      <td>0.9815</td>\n",
       "      <td>0.9630</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.424</td>\n",
       "      <td>0.3069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Group</td>\n",
       "      <td>60%</td>\n",
       "      <td>78.678261</td>\n",
       "      <td>0.9926</td>\n",
       "      <td>0.9797</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.9820</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9537</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9826</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.9817</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.424</td>\n",
       "      <td>0.2376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Group</td>\n",
       "      <td>60%</td>\n",
       "      <td>71.382334</td>\n",
       "      <td>0.9945</td>\n",
       "      <td>0.9834</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.9820</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9537</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.408</td>\n",
       "      <td>0.2475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Group</td>\n",
       "      <td>60%</td>\n",
       "      <td>76.130331</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.9853</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.9910</td>\n",
       "      <td>0.9907</td>\n",
       "      <td>0.9537</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.416</td>\n",
       "      <td>0.2673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Group</td>\n",
       "      <td>60%</td>\n",
       "      <td>70.832085</td>\n",
       "      <td>0.9945</td>\n",
       "      <td>0.9871</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.9820</td>\n",
       "      <td>0.9907</td>\n",
       "      <td>0.9722</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.2673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Group</td>\n",
       "      <td>60%</td>\n",
       "      <td>73.439023</td>\n",
       "      <td>0.9945</td>\n",
       "      <td>0.9890</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.9910</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9722</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.424</td>\n",
       "      <td>0.2277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Group</td>\n",
       "      <td>60%</td>\n",
       "      <td>72.148432</td>\n",
       "      <td>0.9945</td>\n",
       "      <td>0.9834</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.9910</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9444</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.416</td>\n",
       "      <td>0.2772</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Model Size       Time  Partcp_Acc_p15  Command_Acc_p15  Partcp_Acc_p1  \\\n",
       "0   Group  20%  47.540156          0.9724           0.9484          0.991   \n",
       "1   Group  20%  48.307249          0.9779           0.9521          1.000   \n",
       "2   Group  20%  46.201615          0.9613           0.9448          0.991   \n",
       "3   Group  20%  43.692362          0.9650           0.9521          1.000   \n",
       "4   Group  20%  44.504580          0.9687           0.9484          0.991   \n",
       "5   Group  20%  44.229166          0.9705           0.9521          1.000   \n",
       "6   Group  20%  44.535541          0.9632           0.9540          0.991   \n",
       "7   Group  20%  42.948731          0.9724           0.9595          1.000   \n",
       "8   Group  20%  45.444911          0.9724           0.9503          0.991   \n",
       "9   Group  20%  42.707019          0.9669           0.9540          0.991   \n",
       "10  Group  40%  67.289367          0.9945           0.9761          0.991   \n",
       "11  Group  40%  64.328163          0.9890           0.9761          0.982   \n",
       "12  Group  40%  61.978212          0.9926           0.9797          0.991   \n",
       "13  Group  40%  60.036626          0.9926           0.9779          0.991   \n",
       "14  Group  40%  58.215136          0.9890           0.9761          0.982   \n",
       "15  Group  40%  49.347837          0.9871           0.9761          0.982   \n",
       "16  Group  40%  59.879732          0.9908           0.9779          0.991   \n",
       "17  Group  40%  57.413757          0.9908           0.9761          0.991   \n",
       "18  Group  40%  50.219540          0.9908           0.9761          0.991   \n",
       "19  Group  40%  53.871787          0.9945           0.9742          1.000   \n",
       "20  Group  60%  80.966223          0.9926           0.9871          0.991   \n",
       "21  Group  60%  77.376384          0.9926           0.9797          0.982   \n",
       "22  Group  60%  79.340686          0.9945           0.9816          0.982   \n",
       "23  Group  60%  63.791425          0.9890           0.9871          0.973   \n",
       "24  Group  60%  78.678261          0.9926           0.9797          0.982   \n",
       "25  Group  60%  71.382334          0.9945           0.9834          0.982   \n",
       "26  Group  60%  76.130331          0.9908           0.9853          0.982   \n",
       "27  Group  60%  70.832085          0.9945           0.9871          0.991   \n",
       "28  Group  60%  73.439023          0.9945           0.9890          0.982   \n",
       "29  Group  60%  72.148432          0.9945           0.9834          0.982   \n",
       "\n",
       "    Command_Acc_p1  Partcp_Acc_p2  Command_Acc_p2  Partcp_Acc_p3  \\\n",
       "0           0.9550         0.9259          0.8796         0.9652   \n",
       "1           0.9369         0.9352          0.8796         0.9739   \n",
       "2           0.9369         0.9074          0.8611         0.9826   \n",
       "3           0.9459         0.9074          0.8704         0.9826   \n",
       "4           0.9550         0.9259          0.8796         0.9739   \n",
       "5           0.9550         0.9074          0.8796         0.9826   \n",
       "6           0.9369         0.9259          0.8981         0.9565   \n",
       "7           0.9550         0.9074          0.8889         0.9913   \n",
       "8           0.9459         0.9167          0.8796         0.9913   \n",
       "9           0.9459         0.9167          0.8704         0.9739   \n",
       "10          0.9640         0.9907          0.9352         1.0000   \n",
       "11          0.9730         0.9815          0.9259         0.9913   \n",
       "12          0.9730         0.9907          0.9444         0.9913   \n",
       "13          0.9730         0.9907          0.9352         0.9913   \n",
       "14          0.9730         0.9815          0.9352         0.9913   \n",
       "15          0.9730         0.9815          0.9352         0.9913   \n",
       "16          0.9730         0.9815          0.9444         0.9913   \n",
       "17          0.9640         0.9815          0.9444         0.9913   \n",
       "18          0.9730         0.9815          0.9352         0.9913   \n",
       "19          0.9730         0.9907          0.9259         0.9913   \n",
       "20          0.9820         0.9815          0.9722         1.0000   \n",
       "21          0.9820         1.0000          0.9537         0.9913   \n",
       "22          0.9820         1.0000          0.9444         1.0000   \n",
       "23          0.9910         0.9815          0.9630         1.0000   \n",
       "24          0.9820         1.0000          0.9537         0.9913   \n",
       "25          0.9820         1.0000          0.9537         1.0000   \n",
       "26          0.9910         0.9907          0.9537         0.9913   \n",
       "27          0.9820         0.9907          0.9722         1.0000   \n",
       "28          0.9910         1.0000          0.9722         1.0000   \n",
       "29          0.9910         1.0000          0.9444         1.0000   \n",
       "\n",
       "    Command_Acc_p3  Partcp_Acc_p4  Command_Acc_p4  Partcp_Acc_p5  \\\n",
       "0           0.9565         0.9817          0.9633           1.00   \n",
       "1           0.9652         0.9908          0.9908           0.99   \n",
       "2           0.9652         0.9358          0.9725           0.99   \n",
       "3           0.9652         0.9358          0.9908           1.00   \n",
       "4           0.9652         0.9541          0.9541           1.00   \n",
       "5           0.9739         0.9633          0.9633           1.00   \n",
       "6           0.9652         0.9541          0.9817           0.99   \n",
       "7           0.9739         0.9633          0.9908           1.00   \n",
       "8           0.9652         0.9633          0.9725           1.00   \n",
       "9           0.9652         0.9541          0.9908           1.00   \n",
       "10          0.9913         0.9908          0.9908           1.00   \n",
       "11          0.9913         0.9908          0.9908           1.00   \n",
       "12          0.9913         0.9908          0.9908           1.00   \n",
       "13          0.9913         0.9908          0.9908           1.00   \n",
       "14          0.9826         0.9908          0.9908           1.00   \n",
       "15          0.9913         0.9817          0.9908           1.00   \n",
       "16          0.9826         0.9908          0.9908           1.00   \n",
       "17          0.9826         0.9908          0.9908           1.00   \n",
       "18          0.9913         0.9908          0.9908           1.00   \n",
       "19          0.9913         0.9908          0.9817           1.00   \n",
       "20          0.9913         0.9908          0.9908           1.00   \n",
       "21          0.9826         0.9908          0.9817           1.00   \n",
       "22          0.9913         0.9908          0.9908           1.00   \n",
       "23          0.9913         0.9908          0.9908           1.00   \n",
       "24          0.9826         0.9908          0.9817           1.00   \n",
       "25          0.9913         0.9908          0.9908           1.00   \n",
       "26          0.9913         0.9908          0.9908           1.00   \n",
       "27          0.9913         0.9908          0.9908           1.00   \n",
       "28          0.9913         0.9908          0.9908           1.00   \n",
       "29          0.9913         0.9908          0.9908           1.00   \n",
       "\n",
       "    Command_Acc_p5  Acc_p6  Acc_p7  Acc_p8  \n",
       "0             0.99    0.67   0.528  0.3366  \n",
       "1             0.99    0.59   0.528  0.2970  \n",
       "2             0.99    0.67   0.432  0.2673  \n",
       "3             0.99    0.62   0.504  0.2673  \n",
       "4             0.99    0.59   0.472  0.3267  \n",
       "5             0.99    0.62   0.456  0.3069  \n",
       "6             0.99    0.67   0.496  0.3267  \n",
       "7             0.99    0.67   0.496  0.2574  \n",
       "8             0.99    0.60   0.552  0.2673  \n",
       "9             1.00    0.66   0.480  0.4059  \n",
       "10            1.00    0.65   0.472  0.2772  \n",
       "11            1.00    0.63   0.480  0.2871  \n",
       "12            1.00    0.69   0.400  0.3168  \n",
       "13            1.00    0.70   0.456  0.3267  \n",
       "14            1.00    0.70   0.448  0.2871  \n",
       "15            0.99    0.70   0.472  0.2772  \n",
       "16            1.00    0.70   0.440  0.3366  \n",
       "17            1.00    0.67   0.440  0.3168  \n",
       "18            0.99    0.63   0.456  0.2772  \n",
       "19            1.00    0.65   0.424  0.2673  \n",
       "20            1.00    0.69   0.440  0.2772  \n",
       "21            1.00    0.72   0.456  0.2178  \n",
       "22            1.00    0.68   0.440  0.2970  \n",
       "23            1.00    0.68   0.424  0.3069  \n",
       "24            1.00    0.68   0.424  0.2376  \n",
       "25            1.00    0.66   0.408  0.2475  \n",
       "26            1.00    0.73   0.416  0.2673  \n",
       "27            1.00    0.70   0.440  0.2673  \n",
       "28            1.00    0.70   0.424  0.2277  \n",
       "29            1.00    0.70   0.416  0.2772  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Perfomance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "Perfomance.to_csv('Performance_0608_training_Data_Size.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
