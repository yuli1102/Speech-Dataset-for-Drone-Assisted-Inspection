{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"   #(xxxx is your specific GPU ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.layers import Activation, Dense, Flatten, GlobalAveragePooling2D\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Sequential\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from MyEarlyStopping import MyEarlyStopping\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "# from keras.optimizers import adam\n",
    "\n",
    "import timeit\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.preprocessing import LabelEncoder  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_number = 5\n",
    "train_image = 10 #10:20%, 20: 40%, 30:60%\n",
    "train_image_s2 = 20 #10:20%, 20: 40%, 30:60%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training dataset (40%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1714 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "train_generator = train_data.flow_from_directory('/data/home/cou/yuli5/semg/Audio_MEL_Data/train',\n",
    "                                                batch_size=1,\n",
    "                                                target_size=(224,224),\n",
    "                                                class_mode='categorical',\n",
    "                                               shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_names = train_generator.filenames\n",
    "image_no = [i.split(\"/\")[1].split(\"_\")[2].split(\".\")[0] for i in image_names]\n",
    "image_no = np.array(list(map(int, image_no)))\n",
    "ALL_participant_class = [i.split(\"/\")[1].split(\"_\")[1] for i in image_names]\n",
    "ALL_participant_class = np.array(list(map(int, ALL_participant_class)))\n",
    "command_class = train_generator.classes\n",
    "All_participant_class = tf.keras.utils.to_categorical(ALL_participant_class-1, num_classes=train_number)\n",
    "All_command_class = tf.keras.utils.to_categorical(command_class, num_classes=10)\n",
    "All_command_uniform = All_command_class*0+1/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "All_Inputs = [next(train_generator)[0][0] for _ in range(len(train_generator))]\n",
    "All_Inputs = np.array(All_Inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_indexs_train = ((image_no<train_image)&(ALL_participant_class!=2))|((image_no<train_image_s2)&(ALL_participant_class==2))\n",
    "Train_Inputs = All_Inputs[select_indexs_train]\n",
    "Train_participant_class = All_participant_class[select_indexs_train]\n",
    "Train_participant_uniform = Train_participant_class*0+1/train_number\n",
    "Train_command_class = All_command_class[select_indexs_train]\n",
    "Train_command_uniform = Train_command_class*0+1/10\n",
    "# sum(Train_participant_class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation dataset (20%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 543 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "val_data = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "val_generator = val_data.flow_from_directory('/data/home/cou/yuli5/semg/Audio_MEL_Data/validation',\n",
    "                                                batch_size=1,\n",
    "                                                target_size=(224,224),\n",
    "                                                class_mode='categorical',\n",
    "                                               shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_names = val_generator.filenames\n",
    "participant_class = [i.split(\"/\", 1)[1].split(\"_\")[1] for i in image_names]\n",
    "participant_class = np.array(list(map(int, participant_class)))\n",
    "command_class = val_generator.classes\n",
    "Val_participant_class = tf.keras.utils.to_categorical(participant_class-1, num_classes=train_number)\n",
    "Val_participant_uniform = Val_participant_class*0+1/train_number\n",
    "Val_command_class = tf.keras.utils.to_categorical(command_class, num_classes=10)\n",
    "Val_command_uniform = Val_command_class*0+1/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Val_Inputs = [next(val_generator)[0][0] for _ in range(len(val_generator))]\n",
    "Val_Inputs = np.array(Val_Inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test dataset (20%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 543 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "test_data = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "test_generator = test_data.flow_from_directory('/data/home/cou/yuli5/semg/Audio_MEL_Data/test',\n",
    "                                                batch_size=1,\n",
    "                                                target_size=(224,224),\n",
    "                                                class_mode='categorical',\n",
    "                                                shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_names = test_generator.filenames\n",
    "participant_class = [i.split(\"/\", 1)[1].split(\"_\")[1] for i in image_names]\n",
    "test_unit_participant_class = np.array(list(map(int, participant_class)))\n",
    "test_unit_command_class = test_generator.classes\n",
    "Test_participant_class = tf.keras.utils.to_categorical(test_unit_participant_class-1, num_classes=train_number)\n",
    "Test_participant_uniform = Test_participant_class*0+1/train_number\n",
    "Test_command_class = tf.keras.utils.to_categorical(test_unit_command_class, num_classes=10)\n",
    "Test_command_uniform = Test_command_class*0+1/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_Inputs = [next(test_generator)[0][0] for _ in range(len(test_generator))]\n",
    "Test_Inputs = np.array(Test_Inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_Inputs_1 = Test_Inputs[np.where(test_unit_participant_class == 1)]\n",
    "Test_command_class_1 = Test_command_class[np.where(test_unit_participant_class == 1)]\n",
    "Test_Inputs_2 = Test_Inputs[np.where(test_unit_participant_class == 2)]\n",
    "Test_command_class_2 = Test_command_class[np.where(test_unit_participant_class == 2)]\n",
    "Test_Inputs_3 = Test_Inputs[np.where(test_unit_participant_class == 3)]\n",
    "Test_command_class_3 = Test_command_class[np.where(test_unit_participant_class == 3)]\n",
    "Test_Inputs_4 = Test_Inputs[np.where(test_unit_participant_class == 4)]\n",
    "Test_command_class_4 = Test_command_class[np.where(test_unit_participant_class == 4)]\n",
    "Test_Inputs_5 = Test_Inputs[np.where(test_unit_participant_class == 5)]\n",
    "Test_command_class_5 = Test_command_class[np.where(test_unit_participant_class == 5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speaker 6 Test dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "test_data_6 = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "test_generator_6 = test_data_6.flow_from_directory('/data/home/cou/yuli5/semg/Audio_MEL_subject/p_6_split/test',\n",
    "                                                batch_size=1,\n",
    "                                                target_size=(224,224),\n",
    "                                                class_mode='categorical',\n",
    "                                                shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_names = test_generator_6.filenames\n",
    "command_class = [i.split(\"/\", 1)[0]for i in image_names]\n",
    "le = LabelEncoder()\n",
    "test_unit_command_class_6 = le.fit_transform(command_class)\n",
    "Test_command_class_6 = tf.keras.utils.to_categorical(test_unit_command_class_6, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_Inputs_6 = [next(test_generator_6)[0][0] for _ in range(len(test_generator_6))]\n",
    "Test_Inputs_6 = np.array(Test_Inputs_6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speaker 7 Test dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 125 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "test_data_7 = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "test_generator_7 = test_data_6.flow_from_directory('/data/home/cou/yuli5/semg/Audio_MEL_subject/p_7_split/test',\n",
    "                                                batch_size=1,\n",
    "                                                target_size=(224,224),\n",
    "                                                class_mode='categorical',\n",
    "                                                shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_names = test_generator_7.filenames\n",
    "command_class = [i.split(\"/\", 1)[0]for i in image_names]\n",
    "le = LabelEncoder()\n",
    "test_unit_command_class_7 = le.fit_transform(command_class)\n",
    "Test_command_class_7 = tf.keras.utils.to_categorical(test_unit_command_class_7, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_Inputs_7 = [next(test_generator_7)[0][0] for _ in range(len(test_generator_7))]\n",
    "Test_Inputs_7 = np.array(Test_Inputs_7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speaker 8 Test dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 101 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "test_data_8 = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "test_generator_8 = test_data_6.flow_from_directory('/data/home/cou/yuli5/semg/Audio_MEL_subject/p_8_split/test',\n",
    "                                                batch_size=1,\n",
    "                                                target_size=(224,224),\n",
    "                                                class_mode='categorical',\n",
    "                                                shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_names = test_generator_8.filenames\n",
    "command_class = [i.split(\"/\", 1)[0]for i in image_names]\n",
    "le = LabelEncoder()\n",
    "test_unit_command_class_8 = le.fit_transform(command_class)\n",
    "Test_command_class_8 = tf.keras.utils.to_categorical(test_unit_command_class_8, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_Inputs_8 = [next(test_generator_8)[0][0] for _ in range(len(test_generator_8))]\n",
    "Test_Inputs_8 = np.array(Test_Inputs_8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pd file store performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Size</th>\n",
       "      <th>Time</th>\n",
       "      <th>Partcp_Acc_p15</th>\n",
       "      <th>Command_Acc_p15</th>\n",
       "      <th>Partcp_Acc_p1</th>\n",
       "      <th>Command_Acc_p1</th>\n",
       "      <th>Partcp_Acc_p2</th>\n",
       "      <th>Command_Acc_p2</th>\n",
       "      <th>Partcp_Acc_p3</th>\n",
       "      <th>Command_Acc_p3</th>\n",
       "      <th>Partcp_Acc_p4</th>\n",
       "      <th>Command_Acc_p4</th>\n",
       "      <th>Partcp_Acc_p5</th>\n",
       "      <th>Command_Acc_p5</th>\n",
       "      <th>Acc_p6</th>\n",
       "      <th>Acc_p7</th>\n",
       "      <th>Acc_p8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Group</td>\n",
       "      <td>20%</td>\n",
       "      <td>47.540156</td>\n",
       "      <td>0.9724</td>\n",
       "      <td>0.9484</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.9550</td>\n",
       "      <td>0.9259</td>\n",
       "      <td>0.8796</td>\n",
       "      <td>0.9652</td>\n",
       "      <td>0.9565</td>\n",
       "      <td>0.9817</td>\n",
       "      <td>0.9633</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.528</td>\n",
       "      <td>0.3366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Group</td>\n",
       "      <td>20%</td>\n",
       "      <td>48.307249</td>\n",
       "      <td>0.9779</td>\n",
       "      <td>0.9521</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.9369</td>\n",
       "      <td>0.9352</td>\n",
       "      <td>0.8796</td>\n",
       "      <td>0.9739</td>\n",
       "      <td>0.9652</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.528</td>\n",
       "      <td>0.2970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Group</td>\n",
       "      <td>20%</td>\n",
       "      <td>46.201615</td>\n",
       "      <td>0.9613</td>\n",
       "      <td>0.9448</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.9369</td>\n",
       "      <td>0.9074</td>\n",
       "      <td>0.8611</td>\n",
       "      <td>0.9826</td>\n",
       "      <td>0.9652</td>\n",
       "      <td>0.9358</td>\n",
       "      <td>0.9725</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.432</td>\n",
       "      <td>0.2673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Group</td>\n",
       "      <td>20%</td>\n",
       "      <td>43.692362</td>\n",
       "      <td>0.9650</td>\n",
       "      <td>0.9521</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.9459</td>\n",
       "      <td>0.9074</td>\n",
       "      <td>0.8704</td>\n",
       "      <td>0.9826</td>\n",
       "      <td>0.9652</td>\n",
       "      <td>0.9358</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.504</td>\n",
       "      <td>0.2673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Group</td>\n",
       "      <td>20%</td>\n",
       "      <td>44.504580</td>\n",
       "      <td>0.9687</td>\n",
       "      <td>0.9484</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.9550</td>\n",
       "      <td>0.9259</td>\n",
       "      <td>0.8796</td>\n",
       "      <td>0.9739</td>\n",
       "      <td>0.9652</td>\n",
       "      <td>0.9541</td>\n",
       "      <td>0.9541</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.472</td>\n",
       "      <td>0.3267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Group</td>\n",
       "      <td>20%</td>\n",
       "      <td>44.229166</td>\n",
       "      <td>0.9705</td>\n",
       "      <td>0.9521</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.9550</td>\n",
       "      <td>0.9074</td>\n",
       "      <td>0.8796</td>\n",
       "      <td>0.9826</td>\n",
       "      <td>0.9739</td>\n",
       "      <td>0.9633</td>\n",
       "      <td>0.9633</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.456</td>\n",
       "      <td>0.3069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Group</td>\n",
       "      <td>20%</td>\n",
       "      <td>44.535541</td>\n",
       "      <td>0.9632</td>\n",
       "      <td>0.9540</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.9369</td>\n",
       "      <td>0.9259</td>\n",
       "      <td>0.8981</td>\n",
       "      <td>0.9565</td>\n",
       "      <td>0.9652</td>\n",
       "      <td>0.9541</td>\n",
       "      <td>0.9817</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.496</td>\n",
       "      <td>0.3267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Group</td>\n",
       "      <td>20%</td>\n",
       "      <td>42.948731</td>\n",
       "      <td>0.9724</td>\n",
       "      <td>0.9595</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.9550</td>\n",
       "      <td>0.9074</td>\n",
       "      <td>0.8889</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9739</td>\n",
       "      <td>0.9633</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.496</td>\n",
       "      <td>0.2574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Group</td>\n",
       "      <td>20%</td>\n",
       "      <td>45.444911</td>\n",
       "      <td>0.9724</td>\n",
       "      <td>0.9503</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.9459</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>0.8796</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9652</td>\n",
       "      <td>0.9633</td>\n",
       "      <td>0.9725</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.552</td>\n",
       "      <td>0.2673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Group</td>\n",
       "      <td>20%</td>\n",
       "      <td>42.707019</td>\n",
       "      <td>0.9669</td>\n",
       "      <td>0.9540</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.9459</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>0.8704</td>\n",
       "      <td>0.9739</td>\n",
       "      <td>0.9652</td>\n",
       "      <td>0.9541</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.480</td>\n",
       "      <td>0.4059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Group</td>\n",
       "      <td>40%</td>\n",
       "      <td>67.289367</td>\n",
       "      <td>0.9945</td>\n",
       "      <td>0.9761</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.9640</td>\n",
       "      <td>0.9907</td>\n",
       "      <td>0.9352</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.472</td>\n",
       "      <td>0.2772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Group</td>\n",
       "      <td>40%</td>\n",
       "      <td>64.328163</td>\n",
       "      <td>0.9890</td>\n",
       "      <td>0.9761</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.9730</td>\n",
       "      <td>0.9815</td>\n",
       "      <td>0.9259</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.480</td>\n",
       "      <td>0.2871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Group</td>\n",
       "      <td>40%</td>\n",
       "      <td>61.978212</td>\n",
       "      <td>0.9926</td>\n",
       "      <td>0.9797</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.9730</td>\n",
       "      <td>0.9907</td>\n",
       "      <td>0.9444</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.3168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Group</td>\n",
       "      <td>40%</td>\n",
       "      <td>60.036626</td>\n",
       "      <td>0.9926</td>\n",
       "      <td>0.9779</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.9730</td>\n",
       "      <td>0.9907</td>\n",
       "      <td>0.9352</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.456</td>\n",
       "      <td>0.3267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Group</td>\n",
       "      <td>40%</td>\n",
       "      <td>58.215136</td>\n",
       "      <td>0.9890</td>\n",
       "      <td>0.9761</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.9730</td>\n",
       "      <td>0.9815</td>\n",
       "      <td>0.9352</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9826</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.448</td>\n",
       "      <td>0.2871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Group</td>\n",
       "      <td>40%</td>\n",
       "      <td>49.347837</td>\n",
       "      <td>0.9871</td>\n",
       "      <td>0.9761</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.9730</td>\n",
       "      <td>0.9815</td>\n",
       "      <td>0.9352</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9817</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.472</td>\n",
       "      <td>0.2772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Group</td>\n",
       "      <td>40%</td>\n",
       "      <td>59.879732</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.9779</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.9730</td>\n",
       "      <td>0.9815</td>\n",
       "      <td>0.9444</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9826</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.3366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Group</td>\n",
       "      <td>40%</td>\n",
       "      <td>57.413757</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.9761</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.9640</td>\n",
       "      <td>0.9815</td>\n",
       "      <td>0.9444</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9826</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.3168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Group</td>\n",
       "      <td>40%</td>\n",
       "      <td>50.219540</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.9761</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.9730</td>\n",
       "      <td>0.9815</td>\n",
       "      <td>0.9352</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.456</td>\n",
       "      <td>0.2772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Group</td>\n",
       "      <td>40%</td>\n",
       "      <td>53.871787</td>\n",
       "      <td>0.9945</td>\n",
       "      <td>0.9742</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.9730</td>\n",
       "      <td>0.9907</td>\n",
       "      <td>0.9259</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.9817</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.424</td>\n",
       "      <td>0.2673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Group</td>\n",
       "      <td>60%</td>\n",
       "      <td>80.966223</td>\n",
       "      <td>0.9926</td>\n",
       "      <td>0.9871</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.9820</td>\n",
       "      <td>0.9815</td>\n",
       "      <td>0.9722</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.2772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Group</td>\n",
       "      <td>60%</td>\n",
       "      <td>77.376384</td>\n",
       "      <td>0.9926</td>\n",
       "      <td>0.9797</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.9820</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9537</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9826</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.9817</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.456</td>\n",
       "      <td>0.2178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Group</td>\n",
       "      <td>60%</td>\n",
       "      <td>79.340686</td>\n",
       "      <td>0.9945</td>\n",
       "      <td>0.9816</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.9820</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9444</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.2970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Group</td>\n",
       "      <td>60%</td>\n",
       "      <td>63.791425</td>\n",
       "      <td>0.9890</td>\n",
       "      <td>0.9871</td>\n",
       "      <td>0.973</td>\n",
       "      <td>0.9910</td>\n",
       "      <td>0.9815</td>\n",
       "      <td>0.9630</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.424</td>\n",
       "      <td>0.3069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Group</td>\n",
       "      <td>60%</td>\n",
       "      <td>78.678261</td>\n",
       "      <td>0.9926</td>\n",
       "      <td>0.9797</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.9820</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9537</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9826</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.9817</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.424</td>\n",
       "      <td>0.2376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Group</td>\n",
       "      <td>60%</td>\n",
       "      <td>71.382334</td>\n",
       "      <td>0.9945</td>\n",
       "      <td>0.9834</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.9820</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9537</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.408</td>\n",
       "      <td>0.2475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Group</td>\n",
       "      <td>60%</td>\n",
       "      <td>76.130331</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.9853</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.9910</td>\n",
       "      <td>0.9907</td>\n",
       "      <td>0.9537</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.416</td>\n",
       "      <td>0.2673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Group</td>\n",
       "      <td>60%</td>\n",
       "      <td>70.832085</td>\n",
       "      <td>0.9945</td>\n",
       "      <td>0.9871</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.9820</td>\n",
       "      <td>0.9907</td>\n",
       "      <td>0.9722</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.2673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Group</td>\n",
       "      <td>60%</td>\n",
       "      <td>73.439023</td>\n",
       "      <td>0.9945</td>\n",
       "      <td>0.9890</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.9910</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9722</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.424</td>\n",
       "      <td>0.2277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Group</td>\n",
       "      <td>60%</td>\n",
       "      <td>72.148432</td>\n",
       "      <td>0.9945</td>\n",
       "      <td>0.9834</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.9910</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9444</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.416</td>\n",
       "      <td>0.2772</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Model Size       Time  Partcp_Acc_p15  Command_Acc_p15  Partcp_Acc_p1  \\\n",
       "0   Group  20%  47.540156          0.9724           0.9484          0.991   \n",
       "1   Group  20%  48.307249          0.9779           0.9521          1.000   \n",
       "2   Group  20%  46.201615          0.9613           0.9448          0.991   \n",
       "3   Group  20%  43.692362          0.9650           0.9521          1.000   \n",
       "4   Group  20%  44.504580          0.9687           0.9484          0.991   \n",
       "5   Group  20%  44.229166          0.9705           0.9521          1.000   \n",
       "6   Group  20%  44.535541          0.9632           0.9540          0.991   \n",
       "7   Group  20%  42.948731          0.9724           0.9595          1.000   \n",
       "8   Group  20%  45.444911          0.9724           0.9503          0.991   \n",
       "9   Group  20%  42.707019          0.9669           0.9540          0.991   \n",
       "10  Group  40%  67.289367          0.9945           0.9761          0.991   \n",
       "11  Group  40%  64.328163          0.9890           0.9761          0.982   \n",
       "12  Group  40%  61.978212          0.9926           0.9797          0.991   \n",
       "13  Group  40%  60.036626          0.9926           0.9779          0.991   \n",
       "14  Group  40%  58.215136          0.9890           0.9761          0.982   \n",
       "15  Group  40%  49.347837          0.9871           0.9761          0.982   \n",
       "16  Group  40%  59.879732          0.9908           0.9779          0.991   \n",
       "17  Group  40%  57.413757          0.9908           0.9761          0.991   \n",
       "18  Group  40%  50.219540          0.9908           0.9761          0.991   \n",
       "19  Group  40%  53.871787          0.9945           0.9742          1.000   \n",
       "20  Group  60%  80.966223          0.9926           0.9871          0.991   \n",
       "21  Group  60%  77.376384          0.9926           0.9797          0.982   \n",
       "22  Group  60%  79.340686          0.9945           0.9816          0.982   \n",
       "23  Group  60%  63.791425          0.9890           0.9871          0.973   \n",
       "24  Group  60%  78.678261          0.9926           0.9797          0.982   \n",
       "25  Group  60%  71.382334          0.9945           0.9834          0.982   \n",
       "26  Group  60%  76.130331          0.9908           0.9853          0.982   \n",
       "27  Group  60%  70.832085          0.9945           0.9871          0.991   \n",
       "28  Group  60%  73.439023          0.9945           0.9890          0.982   \n",
       "29  Group  60%  72.148432          0.9945           0.9834          0.982   \n",
       "\n",
       "    Command_Acc_p1  Partcp_Acc_p2  Command_Acc_p2  Partcp_Acc_p3  \\\n",
       "0           0.9550         0.9259          0.8796         0.9652   \n",
       "1           0.9369         0.9352          0.8796         0.9739   \n",
       "2           0.9369         0.9074          0.8611         0.9826   \n",
       "3           0.9459         0.9074          0.8704         0.9826   \n",
       "4           0.9550         0.9259          0.8796         0.9739   \n",
       "5           0.9550         0.9074          0.8796         0.9826   \n",
       "6           0.9369         0.9259          0.8981         0.9565   \n",
       "7           0.9550         0.9074          0.8889         0.9913   \n",
       "8           0.9459         0.9167          0.8796         0.9913   \n",
       "9           0.9459         0.9167          0.8704         0.9739   \n",
       "10          0.9640         0.9907          0.9352         1.0000   \n",
       "11          0.9730         0.9815          0.9259         0.9913   \n",
       "12          0.9730         0.9907          0.9444         0.9913   \n",
       "13          0.9730         0.9907          0.9352         0.9913   \n",
       "14          0.9730         0.9815          0.9352         0.9913   \n",
       "15          0.9730         0.9815          0.9352         0.9913   \n",
       "16          0.9730         0.9815          0.9444         0.9913   \n",
       "17          0.9640         0.9815          0.9444         0.9913   \n",
       "18          0.9730         0.9815          0.9352         0.9913   \n",
       "19          0.9730         0.9907          0.9259         0.9913   \n",
       "20          0.9820         0.9815          0.9722         1.0000   \n",
       "21          0.9820         1.0000          0.9537         0.9913   \n",
       "22          0.9820         1.0000          0.9444         1.0000   \n",
       "23          0.9910         0.9815          0.9630         1.0000   \n",
       "24          0.9820         1.0000          0.9537         0.9913   \n",
       "25          0.9820         1.0000          0.9537         1.0000   \n",
       "26          0.9910         0.9907          0.9537         0.9913   \n",
       "27          0.9820         0.9907          0.9722         1.0000   \n",
       "28          0.9910         1.0000          0.9722         1.0000   \n",
       "29          0.9910         1.0000          0.9444         1.0000   \n",
       "\n",
       "    Command_Acc_p3  Partcp_Acc_p4  Command_Acc_p4  Partcp_Acc_p5  \\\n",
       "0           0.9565         0.9817          0.9633           1.00   \n",
       "1           0.9652         0.9908          0.9908           0.99   \n",
       "2           0.9652         0.9358          0.9725           0.99   \n",
       "3           0.9652         0.9358          0.9908           1.00   \n",
       "4           0.9652         0.9541          0.9541           1.00   \n",
       "5           0.9739         0.9633          0.9633           1.00   \n",
       "6           0.9652         0.9541          0.9817           0.99   \n",
       "7           0.9739         0.9633          0.9908           1.00   \n",
       "8           0.9652         0.9633          0.9725           1.00   \n",
       "9           0.9652         0.9541          0.9908           1.00   \n",
       "10          0.9913         0.9908          0.9908           1.00   \n",
       "11          0.9913         0.9908          0.9908           1.00   \n",
       "12          0.9913         0.9908          0.9908           1.00   \n",
       "13          0.9913         0.9908          0.9908           1.00   \n",
       "14          0.9826         0.9908          0.9908           1.00   \n",
       "15          0.9913         0.9817          0.9908           1.00   \n",
       "16          0.9826         0.9908          0.9908           1.00   \n",
       "17          0.9826         0.9908          0.9908           1.00   \n",
       "18          0.9913         0.9908          0.9908           1.00   \n",
       "19          0.9913         0.9908          0.9817           1.00   \n",
       "20          0.9913         0.9908          0.9908           1.00   \n",
       "21          0.9826         0.9908          0.9817           1.00   \n",
       "22          0.9913         0.9908          0.9908           1.00   \n",
       "23          0.9913         0.9908          0.9908           1.00   \n",
       "24          0.9826         0.9908          0.9817           1.00   \n",
       "25          0.9913         0.9908          0.9908           1.00   \n",
       "26          0.9913         0.9908          0.9908           1.00   \n",
       "27          0.9913         0.9908          0.9908           1.00   \n",
       "28          0.9913         0.9908          0.9908           1.00   \n",
       "29          0.9913         0.9908          0.9908           1.00   \n",
       "\n",
       "    Command_Acc_p5  Acc_p6  Acc_p7  Acc_p8  \n",
       "0             0.99    0.67   0.528  0.3366  \n",
       "1             0.99    0.59   0.528  0.2970  \n",
       "2             0.99    0.67   0.432  0.2673  \n",
       "3             0.99    0.62   0.504  0.2673  \n",
       "4             0.99    0.59   0.472  0.3267  \n",
       "5             0.99    0.62   0.456  0.3069  \n",
       "6             0.99    0.67   0.496  0.3267  \n",
       "7             0.99    0.67   0.496  0.2574  \n",
       "8             0.99    0.60   0.552  0.2673  \n",
       "9             1.00    0.66   0.480  0.4059  \n",
       "10            1.00    0.65   0.472  0.2772  \n",
       "11            1.00    0.63   0.480  0.2871  \n",
       "12            1.00    0.69   0.400  0.3168  \n",
       "13            1.00    0.70   0.456  0.3267  \n",
       "14            1.00    0.70   0.448  0.2871  \n",
       "15            0.99    0.70   0.472  0.2772  \n",
       "16            1.00    0.70   0.440  0.3366  \n",
       "17            1.00    0.67   0.440  0.3168  \n",
       "18            0.99    0.63   0.456  0.2772  \n",
       "19            1.00    0.65   0.424  0.2673  \n",
       "20            1.00    0.69   0.440  0.2772  \n",
       "21            1.00    0.72   0.456  0.2178  \n",
       "22            1.00    0.68   0.440  0.2970  \n",
       "23            1.00    0.68   0.424  0.3069  \n",
       "24            1.00    0.68   0.424  0.2376  \n",
       "25            1.00    0.66   0.408  0.2475  \n",
       "26            1.00    0.73   0.416  0.2673  \n",
       "27            1.00    0.70   0.440  0.2673  \n",
       "28            1.00    0.70   0.424  0.2277  \n",
       "29            1.00    0.70   0.416  0.2772  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pd file store performance\n",
    "# Perfomance = pd.DataFrame(columns = ['Model','Time','Partcp_Acc_p15','Command_Acc_p15','Partcp_Acc_p1','Command_Acc_p1',\n",
    "#                                       'Partcp_Acc_p2','Command_Acc_p2','Partcp_Acc_p3','Command_Acc_p3',\n",
    "#                                       'Partcp_Acc_p4','Command_Acc_p4','Partcp_Acc_p5','Command_Acc_p5','Acc_p6','Acc_p7','Acc_p8'])\n",
    "\n",
    "Perfomance = pd.read_csv('Performance_0608_training_Data_Size.csv')\n",
    "# Perfomance\n",
    "Perfomance                                                        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "actv_fun_1_1 = \"relu\" \n",
    "actv_fun_1_2 = \"sigmoid\"\n",
    "shape_1_1 = 128\n",
    "shape_1_2 = 256\n",
    "actv_fun_2_1 = \"sigmoid\" \n",
    "actv_fun_2_2 = \"sigmoid\"\n",
    "shape_2_1 = 512\n",
    "shape_2_2 = 512\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10/10 [==============================] - 4s 416ms/step - loss: 3.7580 - participant_output_loss: 1.5107 - command_output_loss: 2.2426 - command_output_1_loss: 7.2169e-04 - participant_output_1_loss: 0.0040 - participant_output_accuracy: 0.3850 - command_output_accuracy: 0.2717 - command_output_1_accuracy: 0.0033 - participant_output_1_accuracy: 0.1500 - val_loss: 3.3565 - val_participant_output_loss: 1.3232 - val_command_output_loss: 2.0329 - val_command_output_1_loss: 1.5829e-04 - val_participant_output_1_loss: 1.8299e-04 - val_participant_output_accuracy: 0.5028 - val_command_output_accuracy: 0.4567 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.2302\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 2s 189ms/step - loss: 3.0626 - participant_output_loss: 1.1257 - command_output_loss: 1.9367 - command_output_1_loss: 9.6669e-05 - participant_output_1_loss: 1.2350e-04 - participant_output_accuracy: 0.6417 - command_output_accuracy: 0.6217 - command_output_1_accuracy: 0.0000e+00 - participant_output_1_accuracy: 0.1083 - val_loss: 2.9481 - val_participant_output_loss: 1.0699 - val_command_output_loss: 1.8781 - val_command_output_1_loss: 7.1506e-05 - val_participant_output_1_loss: 7.9972e-05 - val_participant_output_accuracy: 0.7017 - val_command_output_accuracy: 0.7403 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.1694\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 2s 197ms/step - loss: 2.7098 - participant_output_loss: 0.8943 - command_output_loss: 1.8154 - command_output_1_loss: 9.0651e-05 - participant_output_1_loss: 6.3721e-05 - participant_output_accuracy: 0.7917 - command_output_accuracy: 0.8067 - command_output_1_accuracy: 0.0000e+00 - participant_output_1_accuracy: 0.2883 - val_loss: 2.6569 - val_participant_output_loss: 0.8792 - val_command_output_loss: 1.7776 - val_command_output_1_loss: 5.9831e-05 - val_participant_output_1_loss: 4.9160e-05 - val_participant_output_accuracy: 0.7974 - val_command_output_accuracy: 0.8066 - val_command_output_1_accuracy: 0.0018 - val_participant_output_1_accuracy: 0.2578\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 2s 187ms/step - loss: 2.4115 - participant_output_loss: 0.7056 - command_output_loss: 1.7057 - command_output_1_loss: 3.9450e-05 - participant_output_1_loss: 4.5716e-05 - participant_output_accuracy: 0.8950 - command_output_accuracy: 0.9100 - command_output_1_accuracy: 0.0583 - participant_output_1_accuracy: 0.2050 - val_loss: 2.4205 - val_participant_output_loss: 0.7395 - val_command_output_loss: 1.6809 - val_command_output_1_loss: 2.8683e-05 - val_participant_output_1_loss: 4.2370e-05 - val_participant_output_accuracy: 0.8785 - val_command_output_accuracy: 0.8656 - val_command_output_1_accuracy: 0.3076 - val_participant_output_1_accuracy: 0.3315\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 2s 200ms/step - loss: 2.1683 - participant_output_loss: 0.5669 - command_output_loss: 1.6013 - command_output_1_loss: 5.0401e-05 - participant_output_1_loss: 3.5146e-05 - participant_output_accuracy: 0.9400 - command_output_accuracy: 0.9300 - command_output_1_accuracy: 0.2450 - participant_output_1_accuracy: 0.2300 - val_loss: 2.2101 - val_participant_output_loss: 0.6205 - val_command_output_loss: 1.5895 - val_command_output_1_loss: 8.2189e-05 - val_participant_output_1_loss: 3.3110e-05 - val_participant_output_accuracy: 0.9171 - val_command_output_accuracy: 0.8674 - val_command_output_1_accuracy: 0.0939 - val_participant_output_1_accuracy: 0.2228\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 2s 188ms/step - loss: 1.9728 - participant_output_loss: 0.4707 - command_output_loss: 1.5020 - command_output_1_loss: 1.0507e-04 - participant_output_1_loss: 2.9734e-05 - participant_output_accuracy: 0.9633 - command_output_accuracy: 0.9350 - command_output_1_accuracy: 0.0433 - participant_output_1_accuracy: 0.2550 - val_loss: 2.0203 - val_participant_output_loss: 0.5254 - val_command_output_loss: 1.4948 - val_command_output_1_loss: 9.4278e-05 - val_participant_output_1_loss: 3.0294e-05 - val_participant_output_accuracy: 0.9411 - val_command_output_accuracy: 0.9171 - val_command_output_1_accuracy: 0.0055 - val_participant_output_1_accuracy: 0.3002\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 2s 191ms/step - loss: 1.7897 - participant_output_loss: 0.3878 - command_output_loss: 1.4019 - command_output_1_loss: 7.6558e-05 - participant_output_1_loss: 2.6310e-05 - participant_output_accuracy: 0.9783 - command_output_accuracy: 0.9567 - command_output_1_accuracy: 0.0033 - participant_output_1_accuracy: 0.2550 - val_loss: 1.8781 - val_participant_output_loss: 0.4763 - val_command_output_loss: 1.4017 - val_command_output_1_loss: 4.8525e-05 - val_participant_output_1_loss: 2.8884e-05 - val_participant_output_accuracy: 0.9355 - val_command_output_accuracy: 0.9337 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.2431\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 2s 185ms/step - loss: 1.6313 - participant_output_loss: 0.3263 - command_output_loss: 1.3048 - command_output_1_loss: 5.1779e-05 - participant_output_1_loss: 2.4360e-05 - participant_output_accuracy: 0.9833 - command_output_accuracy: 0.9800 - command_output_1_accuracy: 0.2050 - participant_output_1_accuracy: 0.2367 - val_loss: 1.7372 - val_participant_output_loss: 0.4211 - val_command_output_loss: 1.3161 - val_command_output_1_loss: 5.2170e-05 - val_participant_output_1_loss: 2.7244e-05 - val_participant_output_accuracy: 0.9484 - val_command_output_accuracy: 0.9429 - val_command_output_1_accuracy: 0.7145 - val_participant_output_1_accuracy: 0.2597\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 2s 194ms/step - loss: 1.4869 - participant_output_loss: 0.2744 - command_output_loss: 1.2125 - command_output_1_loss: 4.5004e-05 - participant_output_1_loss: 2.3231e-05 - participant_output_accuracy: 0.9917 - command_output_accuracy: 0.9900 - command_output_1_accuracy: 0.3317 - participant_output_1_accuracy: 0.2217 - val_loss: 1.6023 - val_participant_output_loss: 0.3691 - val_command_output_loss: 1.2331 - val_command_output_1_loss: 3.8822e-05 - val_participant_output_1_loss: 2.6546e-05 - val_participant_output_accuracy: 0.9669 - val_command_output_accuracy: 0.9540 - val_command_output_1_accuracy: 0.0184 - val_participant_output_1_accuracy: 0.3002\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 2s 161ms/step - loss: 1.3638 - participant_output_loss: 0.2417 - command_output_loss: 1.1221 - command_output_1_loss: 3.7498e-05 - participant_output_1_loss: 2.1909e-05 - participant_output_accuracy: 0.9967 - command_output_accuracy: 0.9917 - command_output_1_accuracy: 0.0083 - participant_output_1_accuracy: 0.2283 - val_loss: 1.4774 - val_participant_output_loss: 0.3258 - val_command_output_loss: 1.1516 - val_command_output_1_loss: 4.0203e-05 - val_participant_output_1_loss: 2.6254e-05 - val_participant_output_accuracy: 0.9650 - val_command_output_accuracy: 0.9540 - val_command_output_1_accuracy: 0.0074 - val_participant_output_1_accuracy: 0.2449\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 3s 259ms/step - loss: 1.2478 - participant_output_loss: 0.2138 - command_output_loss: 1.0339 - command_output_1_loss: 4.3802e-05 - participant_output_1_loss: 2.1087e-05 - participant_output_accuracy: 0.9983 - command_output_accuracy: 0.9933 - command_output_1_accuracy: 0.0150 - participant_output_1_accuracy: 0.1917 - val_loss: 1.3784 - val_participant_output_loss: 0.3057 - val_command_output_loss: 1.0726 - val_command_output_1_loss: 4.0562e-05 - val_participant_output_1_loss: 2.6060e-05 - val_participant_output_accuracy: 0.9595 - val_command_output_accuracy: 0.9595 - val_command_output_1_accuracy: 0.0258 - val_participant_output_1_accuracy: 0.3370\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 1s 145ms/step - loss: 1.1312 - participant_output_loss: 0.1811 - command_output_loss: 0.9501 - command_output_1_loss: 4.3060e-05 - participant_output_1_loss: 2.0466e-05 - participant_output_accuracy: 0.9983 - command_output_accuracy: 0.9967 - command_output_1_accuracy: 0.0717 - participant_output_1_accuracy: 0.2333 - val_loss: 1.2641 - val_participant_output_loss: 0.2683 - val_command_output_loss: 0.9957 - val_command_output_1_loss: 5.4226e-05 - val_participant_output_1_loss: 2.5825e-05 - val_participant_output_accuracy: 0.9613 - val_command_output_accuracy: 0.9576 - val_command_output_1_accuracy: 0.1400 - val_participant_output_1_accuracy: 0.2818\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10\n",
      "10/10 [==============================] - 1s 146ms/step - loss: 1.0215 - participant_output_loss: 0.1523 - command_output_loss: 0.8691 - command_output_1_loss: 4.5990e-05 - participant_output_1_loss: 1.9762e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9967 - command_output_1_accuracy: 0.1250 - participant_output_1_accuracy: 0.2133 - val_loss: 1.1791 - val_participant_output_loss: 0.2515 - val_command_output_loss: 0.9275 - val_command_output_1_loss: 3.7399e-05 - val_participant_output_1_loss: 2.4843e-05 - val_participant_output_accuracy: 0.9613 - val_command_output_accuracy: 0.9576 - val_command_output_1_accuracy: 0.1123 - val_participant_output_1_accuracy: 0.2192\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 2s 193ms/step - loss: 0.9326 - participant_output_loss: 0.1346 - command_output_loss: 0.7979 - command_output_1_loss: 3.7155e-05 - participant_output_1_loss: 1.8767e-05 - participant_output_accuracy: 0.9983 - command_output_accuracy: 0.9967 - command_output_1_accuracy: 0.0417 - participant_output_1_accuracy: 0.2067 - val_loss: 1.1040 - val_participant_output_loss: 0.2396 - val_command_output_loss: 0.8644 - val_command_output_1_loss: 4.0290e-05 - val_participant_output_1_loss: 2.5101e-05 - val_participant_output_accuracy: 0.9613 - val_command_output_accuracy: 0.9632 - val_command_output_1_accuracy: 0.0368 - val_participant_output_1_accuracy: 0.2818\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 2s 203ms/step - loss: 0.8494 - participant_output_loss: 0.1175 - command_output_loss: 0.7319 - command_output_1_loss: 5.7422e-05 - participant_output_1_loss: 1.8226e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9983 - command_output_1_accuracy: 0.0183 - participant_output_1_accuracy: 0.2217 - val_loss: 1.0279 - val_participant_output_loss: 0.2225 - val_command_output_loss: 0.8054 - val_command_output_1_loss: 4.8470e-05 - val_participant_output_1_loss: 2.5678e-05 - val_participant_output_accuracy: 0.9650 - val_command_output_accuracy: 0.9632 - val_command_output_1_accuracy: 0.1657 - val_participant_output_1_accuracy: 0.1565\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 2s 208ms/step - loss: 0.7680 - participant_output_loss: 0.1046 - command_output_loss: 0.6634 - command_output_1_loss: 4.7690e-05 - participant_output_1_loss: 1.7882e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9983 - command_output_1_accuracy: 0.0783 - participant_output_1_accuracy: 0.2233 - val_loss: 0.9468 - val_participant_output_loss: 0.2013 - val_command_output_loss: 0.7455 - val_command_output_1_loss: 5.2348e-05 - val_participant_output_1_loss: 2.5286e-05 - val_participant_output_accuracy: 0.9705 - val_command_output_accuracy: 0.9632 - val_command_output_1_accuracy: 0.0589 - val_participant_output_1_accuracy: 0.1915\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 2s 186ms/step - loss: 0.6998 - participant_output_loss: 0.0930 - command_output_loss: 0.6067 - command_output_1_loss: 5.2946e-05 - participant_output_1_loss: 1.7184e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9983 - command_output_1_accuracy: 0.0850 - participant_output_1_accuracy: 0.2117 - val_loss: 0.8868 - val_participant_output_loss: 0.1948 - val_command_output_loss: 0.6920 - val_command_output_1_loss: 4.7185e-05 - val_participant_output_1_loss: 2.5807e-05 - val_participant_output_accuracy: 0.9632 - val_command_output_accuracy: 0.9669 - val_command_output_1_accuracy: 0.1068 - val_participant_output_1_accuracy: 0.1915\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 2s 168ms/step - loss: 0.6354 - participant_output_loss: 0.0833 - command_output_loss: 0.5520 - command_output_1_loss: 4.8479e-05 - participant_output_1_loss: 1.6767e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9983 - command_output_1_accuracy: 0.0650 - participant_output_1_accuracy: 0.2183 - val_loss: 0.8257 - val_participant_output_loss: 0.1812 - val_command_output_loss: 0.6445 - val_command_output_1_loss: 3.1562e-05 - val_participant_output_1_loss: 2.5087e-05 - val_participant_output_accuracy: 0.9687 - val_command_output_accuracy: 0.9650 - val_command_output_1_accuracy: 0.0147 - val_participant_output_1_accuracy: 0.1823\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 2s 158ms/step - loss: 0.5781 - participant_output_loss: 0.0755 - command_output_loss: 0.5026 - command_output_1_loss: 3.3105e-05 - participant_output_1_loss: 1.6130e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0033 - participant_output_1_accuracy: 0.2017 - val_loss: 0.7762 - val_participant_output_loss: 0.1756 - val_command_output_loss: 0.6005 - val_command_output_1_loss: 2.9194e-05 - val_participant_output_1_loss: 2.4913e-05 - val_participant_output_accuracy: 0.9687 - val_command_output_accuracy: 0.9650 - val_command_output_1_accuracy: 0.0110 - val_participant_output_1_accuracy: 0.2210\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 2s 207ms/step - loss: 0.5272 - participant_output_loss: 0.0694 - command_output_loss: 0.4577 - command_output_1_loss: 2.7345e-05 - participant_output_1_loss: 1.5759e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0033 - participant_output_1_accuracy: 0.2233 - val_loss: 0.7209 - val_participant_output_loss: 0.1673 - val_command_output_loss: 0.5536 - val_command_output_1_loss: 2.2700e-05 - val_participant_output_1_loss: 2.4504e-05 - val_participant_output_accuracy: 0.9705 - val_command_output_accuracy: 0.9687 - val_command_output_1_accuracy: 0.0534 - val_participant_output_1_accuracy: 0.2394\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 4s 384ms/step - loss: 3.6518 - participant_output_loss: 1.3957 - command_output_loss: 2.2497 - command_output_1_loss: 0.0012 - participant_output_1_loss: 0.0053 - participant_output_accuracy: 0.3983 - command_output_accuracy: 0.2517 - command_output_1_accuracy: 0.0000e+00 - participant_output_1_accuracy: 0.3333 - val_loss: 3.4501 - val_participant_output_loss: 1.3766 - val_command_output_loss: 2.0731 - val_command_output_1_loss: 1.8406e-04 - val_participant_output_1_loss: 2.2775e-04 - val_participant_output_accuracy: 0.4162 - val_command_output_accuracy: 0.4199 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 2s 204ms/step - loss: 3.0675 - participant_output_loss: 1.0705 - command_output_loss: 1.9967 - command_output_1_loss: 1.8270e-04 - participant_output_1_loss: 1.9618e-04 - participant_output_accuracy: 0.6717 - command_output_accuracy: 0.5567 - command_output_1_accuracy: 0.0000e+00 - participant_output_1_accuracy: 0.1833 - val_loss: 2.9677 - val_participant_output_loss: 1.0259 - val_command_output_loss: 1.9415 - val_command_output_1_loss: 1.7925e-04 - val_participant_output_1_loss: 1.4191e-04 - val_participant_output_accuracy: 0.6759 - val_command_output_accuracy: 0.7403 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.1768\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 2s 190ms/step - loss: 2.7025 - participant_output_loss: 0.8163 - command_output_loss: 1.8859 - command_output_1_loss: 1.5651e-04 - participant_output_1_loss: 8.5644e-05 - participant_output_accuracy: 0.7950 - command_output_accuracy: 0.7950 - command_output_1_accuracy: 0.0000e+00 - participant_output_1_accuracy: 0.1233 - val_loss: 2.6766 - val_participant_output_loss: 0.8233 - val_command_output_loss: 1.8532 - val_command_output_1_loss: 9.1493e-05 - val_participant_output_1_loss: 6.4721e-05 - val_participant_output_accuracy: 0.8103 - val_command_output_accuracy: 0.7606 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.1989\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 2s 204ms/step - loss: 2.4541 - participant_output_loss: 0.6585 - command_output_loss: 1.7955 - command_output_1_loss: 5.7517e-05 - participant_output_1_loss: 5.7668e-05 - participant_output_accuracy: 0.8917 - command_output_accuracy: 0.8517 - command_output_1_accuracy: 0.0067 - participant_output_1_accuracy: 0.2433 - val_loss: 2.4522 - val_participant_output_loss: 0.6851 - val_command_output_loss: 1.7671 - val_command_output_1_loss: 2.5245e-05 - val_participant_output_1_loss: 5.1970e-05 - val_participant_output_accuracy: 0.8987 - val_command_output_accuracy: 0.8564 - val_command_output_1_accuracy: 0.1731 - val_participant_output_1_accuracy: 0.0976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10\n",
      "10/10 [==============================] - 2s 221ms/step - loss: 2.2568 - participant_output_loss: 0.5512 - command_output_loss: 1.7055 - command_output_1_loss: 3.5627e-05 - participant_output_1_loss: 4.0271e-05 - participant_output_accuracy: 0.9300 - command_output_accuracy: 0.9033 - command_output_1_accuracy: 0.4717 - participant_output_1_accuracy: 0.2283 - val_loss: 2.2963 - val_participant_output_loss: 0.6009 - val_command_output_loss: 1.6953 - val_command_output_1_loss: 6.1481e-05 - val_participant_output_1_loss: 3.8558e-05 - val_participant_output_accuracy: 0.9337 - val_command_output_accuracy: 0.8729 - val_command_output_1_accuracy: 0.5083 - val_participant_output_1_accuracy: 0.3315\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 2s 217ms/step - loss: 2.0815 - participant_output_loss: 0.4597 - command_output_loss: 1.6217 - command_output_1_loss: 9.5810e-05 - participant_output_1_loss: 3.1110e-05 - participant_output_accuracy: 0.9550 - command_output_accuracy: 0.9467 - command_output_1_accuracy: 0.5933 - participant_output_1_accuracy: 0.1983 - val_loss: 2.1438 - val_participant_output_loss: 0.5310 - val_command_output_loss: 1.6127 - val_command_output_1_loss: 9.9403e-05 - val_participant_output_1_loss: 3.3554e-05 - val_participant_output_accuracy: 0.9392 - val_command_output_accuracy: 0.9024 - val_command_output_1_accuracy: 0.2726 - val_participant_output_1_accuracy: 0.2689\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 2s 224ms/step - loss: 1.9071 - participant_output_loss: 0.3689 - command_output_loss: 1.5381 - command_output_1_loss: 7.4694e-05 - participant_output_1_loss: 2.6651e-05 - participant_output_accuracy: 0.9767 - command_output_accuracy: 0.9667 - command_output_1_accuracy: 0.1867 - participant_output_1_accuracy: 0.2233 - val_loss: 1.9812 - val_participant_output_loss: 0.4507 - val_command_output_loss: 1.5304 - val_command_output_1_loss: 4.0835e-05 - val_participant_output_1_loss: 3.1309e-05 - val_participant_output_accuracy: 0.9429 - val_command_output_accuracy: 0.9319 - val_command_output_1_accuracy: 0.0313 - val_participant_output_1_accuracy: 0.1842\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 2s 229ms/step - loss: 1.7622 - participant_output_loss: 0.3072 - command_output_loss: 1.4550 - command_output_1_loss: 3.2964e-05 - participant_output_1_loss: 2.4720e-05 - participant_output_accuracy: 0.9783 - command_output_accuracy: 0.9750 - command_output_1_accuracy: 0.0183 - participant_output_1_accuracy: 0.2117 - val_loss: 1.8492 - val_participant_output_loss: 0.3861 - val_command_output_loss: 1.4630 - val_command_output_1_loss: 2.9495e-05 - val_participant_output_1_loss: 3.0547e-05 - val_participant_output_accuracy: 0.9558 - val_command_output_accuracy: 0.9319 - val_command_output_1_accuracy: 0.0350 - val_participant_output_1_accuracy: 0.1400\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 2s 208ms/step - loss: 1.6325 - participant_output_loss: 0.2565 - command_output_loss: 1.3760 - command_output_1_loss: 3.9481e-05 - participant_output_1_loss: 2.3156e-05 - participant_output_accuracy: 0.9883 - command_output_accuracy: 0.9767 - command_output_1_accuracy: 0.3150 - participant_output_1_accuracy: 0.2333 - val_loss: 1.7270 - val_participant_output_loss: 0.3351 - val_command_output_loss: 1.3919 - val_command_output_1_loss: 5.0040e-05 - val_participant_output_1_loss: 3.0484e-05 - val_participant_output_accuracy: 0.9669 - val_command_output_accuracy: 0.9337 - val_command_output_1_accuracy: 0.5322 - val_participant_output_1_accuracy: 0.1252\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 2s 211ms/step - loss: 1.5098 - participant_output_loss: 0.2111 - command_output_loss: 1.2987 - command_output_1_loss: 5.3023e-05 - participant_output_1_loss: 2.2001e-05 - participant_output_accuracy: 0.9900 - command_output_accuracy: 0.9917 - command_output_1_accuracy: 0.3100 - participant_output_1_accuracy: 0.1933 - val_loss: 1.6234 - val_participant_output_loss: 0.2988 - val_command_output_loss: 1.3245 - val_command_output_1_loss: 5.5850e-05 - val_participant_output_1_loss: 2.9422e-05 - val_participant_output_accuracy: 0.9669 - val_command_output_accuracy: 0.9595 - val_command_output_1_accuracy: 0.0129 - val_participant_output_1_accuracy: 0.1657\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 3s 289ms/step - loss: 1.3993 - participant_output_loss: 0.1766 - command_output_loss: 1.2226 - command_output_1_loss: 4.8941e-05 - participant_output_1_loss: 2.1244e-05 - participant_output_accuracy: 0.9950 - command_output_accuracy: 0.9933 - command_output_1_accuracy: 0.0383 - participant_output_1_accuracy: 0.1900 - val_loss: 1.5217 - val_participant_output_loss: 0.2696 - val_command_output_loss: 1.2520 - val_command_output_1_loss: 4.9952e-05 - val_participant_output_1_loss: 2.9428e-05 - val_participant_output_accuracy: 0.9705 - val_command_output_accuracy: 0.9521 - val_command_output_1_accuracy: 0.0295 - val_participant_output_1_accuracy: 0.1676\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 2s 193ms/step - loss: 1.2984 - participant_output_loss: 0.1538 - command_output_loss: 1.1445 - command_output_1_loss: 3.7769e-05 - participant_output_1_loss: 2.0788e-05 - participant_output_accuracy: 0.9967 - command_output_accuracy: 0.9933 - command_output_1_accuracy: 0.1000 - participant_output_1_accuracy: 0.1833 - val_loss: 1.4407 - val_participant_output_loss: 0.2561 - val_command_output_loss: 1.1846 - val_command_output_1_loss: 3.4876e-05 - val_participant_output_1_loss: 2.8957e-05 - val_participant_output_accuracy: 0.9669 - val_command_output_accuracy: 0.9576 - val_command_output_1_accuracy: 0.0755 - val_participant_output_1_accuracy: 0.1786\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 2s 192ms/step - loss: 1.2106 - participant_output_loss: 0.1380 - command_output_loss: 1.0725 - command_output_1_loss: 4.0883e-05 - participant_output_1_loss: 2.0441e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9950 - command_output_1_accuracy: 0.0300 - participant_output_1_accuracy: 0.1917 - val_loss: 1.3781 - val_participant_output_loss: 0.2594 - val_command_output_loss: 1.1187 - val_command_output_1_loss: 3.0116e-05 - val_participant_output_1_loss: 2.8705e-05 - val_participant_output_accuracy: 0.9687 - val_command_output_accuracy: 0.9576 - val_command_output_1_accuracy: 0.0718 - val_participant_output_1_accuracy: 0.1529\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 2s 210ms/step - loss: 1.1353 - participant_output_loss: 0.1296 - command_output_loss: 1.0056 - command_output_1_loss: 6.0436e-05 - participant_output_1_loss: 1.8784e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9967 - command_output_1_accuracy: 0.0200 - participant_output_1_accuracy: 0.1750 - val_loss: 1.3183 - val_participant_output_loss: 0.2602 - val_command_output_loss: 1.0580 - val_command_output_1_loss: 4.3790e-05 - val_participant_output_1_loss: 2.8952e-05 - val_participant_output_accuracy: 0.9687 - val_command_output_accuracy: 0.9595 - val_command_output_1_accuracy: 0.0129 - val_participant_output_1_accuracy: 0.1602\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 2s 208ms/step - loss: 1.0556 - participant_output_loss: 0.1172 - command_output_loss: 0.9384 - command_output_1_loss: 3.6867e-05 - participant_output_1_loss: 1.7786e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9967 - command_output_1_accuracy: 0.2717 - participant_output_1_accuracy: 0.1750 - val_loss: 1.2189 - val_participant_output_loss: 0.2200 - val_command_output_loss: 0.9989 - val_command_output_1_loss: 2.9865e-05 - val_participant_output_1_loss: 2.8059e-05 - val_participant_output_accuracy: 0.9687 - val_command_output_accuracy: 0.9632 - val_command_output_1_accuracy: 0.3941 - val_participant_output_1_accuracy: 0.1676\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 2s 171ms/step - loss: 0.9747 - participant_output_loss: 0.1020 - command_output_loss: 0.8727 - command_output_1_loss: 3.8248e-05 - participant_output_1_loss: 1.6939e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9983 - command_output_1_accuracy: 0.2333 - participant_output_1_accuracy: 0.2067 - val_loss: 1.1476 - val_participant_output_loss: 0.2007 - val_command_output_loss: 0.9468 - val_command_output_1_loss: 4.9581e-05 - val_participant_output_1_loss: 2.6219e-05 - val_participant_output_accuracy: 0.9705 - val_command_output_accuracy: 0.9613 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.1565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10\n",
      "10/10 [==============================] - 2s 213ms/step - loss: 0.9067 - participant_output_loss: 0.0912 - command_output_loss: 0.8154 - command_output_1_loss: 6.7052e-05 - participant_output_1_loss: 1.5814e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9983 - command_output_1_accuracy: 0.0000e+00 - participant_output_1_accuracy: 0.2083 - val_loss: 1.0787 - val_participant_output_loss: 0.1868 - val_command_output_loss: 0.8918 - val_command_output_1_loss: 6.0846e-05 - val_participant_output_1_loss: 2.5813e-05 - val_participant_output_accuracy: 0.9687 - val_command_output_accuracy: 0.9650 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.1418\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 2s 216ms/step - loss: 0.8413 - participant_output_loss: 0.0828 - command_output_loss: 0.7584 - command_output_1_loss: 3.8235e-05 - participant_output_1_loss: 1.5057e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9983 - command_output_1_accuracy: 0.3900 - participant_output_1_accuracy: 0.1833 - val_loss: 1.0138 - val_participant_output_loss: 0.1765 - val_command_output_loss: 0.8372 - val_command_output_1_loss: 3.9715e-05 - val_participant_output_1_loss: 2.4701e-05 - val_participant_output_accuracy: 0.9742 - val_command_output_accuracy: 0.9632 - val_command_output_1_accuracy: 0.8361 - val_participant_output_1_accuracy: 0.1915\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 2s 230ms/step - loss: 0.7810 - participant_output_loss: 0.0760 - command_output_loss: 0.7049 - command_output_1_loss: 3.1358e-05 - participant_output_1_loss: 1.4299e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9983 - command_output_1_accuracy: 0.5617 - participant_output_1_accuracy: 0.2000 - val_loss: 0.9550 - val_participant_output_loss: 0.1652 - val_command_output_loss: 0.7897 - val_command_output_1_loss: 2.5381e-05 - val_participant_output_1_loss: 2.4442e-05 - val_participant_output_accuracy: 0.9816 - val_command_output_accuracy: 0.9632 - val_command_output_1_accuracy: 0.0018 - val_participant_output_1_accuracy: 0.1971\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 2s 164ms/step - loss: 0.7261 - participant_output_loss: 0.0700 - command_output_loss: 0.6560 - command_output_1_loss: 4.1681e-05 - participant_output_1_loss: 1.3748e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0017 - participant_output_1_accuracy: 0.1917 - val_loss: 0.9114 - val_participant_output_loss: 0.1654 - val_command_output_loss: 0.7459 - val_command_output_1_loss: 4.9898e-05 - val_participant_output_1_loss: 2.3728e-05 - val_participant_output_accuracy: 0.9742 - val_command_output_accuracy: 0.9632 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.2044\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 4s 359ms/step - loss: 3.7342 - participant_output_loss: 1.5068 - command_output_loss: 2.2211 - command_output_1_loss: 0.0013 - participant_output_1_loss: 0.0050 - participant_output_accuracy: 0.3650 - command_output_accuracy: 0.2050 - command_output_1_accuracy: 0.2583 - participant_output_1_accuracy: 0.1100 - val_loss: 3.3587 - val_participant_output_loss: 1.3252 - val_command_output_loss: 2.0323 - val_command_output_1_loss: 2.3796e-04 - val_participant_output_1_loss: 9.5623e-04 - val_participant_output_accuracy: 0.5433 - val_command_output_accuracy: 0.6041 - val_command_output_1_accuracy: 0.0055 - val_participant_output_1_accuracy: 0.3444\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 2s 188ms/step - loss: 3.0604 - participant_output_loss: 1.0948 - command_output_loss: 1.9649 - command_output_1_loss: 1.4366e-04 - participant_output_1_loss: 6.1893e-04 - participant_output_accuracy: 0.6483 - command_output_accuracy: 0.6267 - command_output_1_accuracy: 0.0500 - participant_output_1_accuracy: 0.2883 - val_loss: 2.9289 - val_participant_output_loss: 1.0092 - val_command_output_loss: 1.9191 - val_command_output_1_loss: 1.4760e-04 - val_participant_output_1_loss: 5.0602e-04 - val_participant_output_accuracy: 0.7366 - val_command_output_accuracy: 0.6593 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 2s 194ms/step - loss: 2.6844 - participant_output_loss: 0.8306 - command_output_loss: 1.8535 - command_output_1_loss: 1.0073e-04 - participant_output_1_loss: 2.3875e-04 - participant_output_accuracy: 0.8183 - command_output_accuracy: 0.7867 - command_output_1_accuracy: 0.0000e+00 - participant_output_1_accuracy: 0.3533 - val_loss: 2.6016 - val_participant_output_loss: 0.7843 - val_command_output_loss: 1.8171 - val_command_output_1_loss: 3.5915e-05 - val_participant_output_1_loss: 1.5188e-04 - val_participant_output_accuracy: 0.8379 - val_command_output_accuracy: 0.7661 - val_command_output_1_accuracy: 0.0295 - val_participant_output_1_accuracy: 0.3389\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 2s 185ms/step - loss: 2.4047 - participant_output_loss: 0.6528 - command_output_loss: 1.7518 - command_output_1_loss: 4.0800e-05 - participant_output_1_loss: 1.1045e-04 - participant_output_accuracy: 0.8700 - command_output_accuracy: 0.8700 - command_output_1_accuracy: 0.0150 - participant_output_1_accuracy: 0.1167 - val_loss: 2.3715 - val_participant_output_loss: 0.6426 - val_command_output_loss: 1.7288 - val_command_output_1_loss: 5.6366e-05 - val_participant_output_1_loss: 7.1344e-05 - val_participant_output_accuracy: 0.8785 - val_command_output_accuracy: 0.8379 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.1105\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 2s 188ms/step - loss: 2.1657 - participant_output_loss: 0.5079 - command_output_loss: 1.6577 - command_output_1_loss: 6.5197e-05 - participant_output_1_loss: 6.8700e-05 - participant_output_accuracy: 0.9217 - command_output_accuracy: 0.9183 - command_output_1_accuracy: 0.0017 - participant_output_1_accuracy: 0.2717 - val_loss: 2.1953 - val_participant_output_loss: 0.5541 - val_command_output_loss: 1.6411 - val_command_output_1_loss: 7.6210e-05 - val_participant_output_1_loss: 5.9930e-05 - val_participant_output_accuracy: 0.8674 - val_command_output_accuracy: 0.8692 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.3536\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 2s 201ms/step - loss: 1.9629 - participant_output_loss: 0.4007 - command_output_loss: 1.5621 - command_output_1_loss: 7.8646e-05 - participant_output_1_loss: 5.0849e-05 - participant_output_accuracy: 0.9500 - command_output_accuracy: 0.9317 - command_output_1_accuracy: 0.0000e+00 - participant_output_1_accuracy: 0.1767 - val_loss: 2.0023 - val_participant_output_loss: 0.4522 - val_command_output_loss: 1.5501 - val_command_output_1_loss: 5.8369e-05 - val_participant_output_1_loss: 5.1186e-05 - val_participant_output_accuracy: 0.9134 - val_command_output_accuracy: 0.8766 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.1400\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 2s 193ms/step - loss: 1.7757 - participant_output_loss: 0.3101 - command_output_loss: 1.4655 - command_output_1_loss: 6.4632e-05 - participant_output_1_loss: 4.3855e-05 - participant_output_accuracy: 0.9800 - command_output_accuracy: 0.9433 - command_output_1_accuracy: 0.1250 - participant_output_1_accuracy: 0.2667 - val_loss: 1.8432 - val_participant_output_loss: 0.3865 - val_command_output_loss: 1.4567 - val_command_output_1_loss: 5.9692e-05 - val_participant_output_1_loss: 4.9963e-05 - val_participant_output_accuracy: 0.9392 - val_command_output_accuracy: 0.8895 - val_command_output_1_accuracy: 0.1731 - val_participant_output_1_accuracy: 0.1363\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 2s 216ms/step - loss: 1.6173 - participant_output_loss: 0.2510 - command_output_loss: 1.3662 - command_output_1_loss: 5.3569e-05 - participant_output_1_loss: 4.0835e-05 - participant_output_accuracy: 0.9917 - command_output_accuracy: 0.9700 - command_output_1_accuracy: 0.1450 - participant_output_1_accuracy: 0.1800 - val_loss: 1.7096 - val_participant_output_loss: 0.3306 - val_command_output_loss: 1.3790 - val_command_output_1_loss: 5.2527e-05 - val_participant_output_1_loss: 4.6397e-05 - val_participant_output_accuracy: 0.9503 - val_command_output_accuracy: 0.9208 - val_command_output_1_accuracy: 0.0110 - val_participant_output_1_accuracy: 0.1363\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10\n",
      "10/10 [==============================] - 2s 212ms/step - loss: 1.4873 - participant_output_loss: 0.2100 - command_output_loss: 1.2772 - command_output_1_loss: 4.7651e-05 - participant_output_1_loss: 3.8226e-05 - participant_output_accuracy: 0.9933 - command_output_accuracy: 0.9833 - command_output_1_accuracy: 0.0033 - participant_output_1_accuracy: 0.2083 - val_loss: 1.5802 - val_participant_output_loss: 0.2901 - val_command_output_loss: 1.2900 - val_command_output_1_loss: 4.8229e-05 - val_participant_output_1_loss: 4.6182e-05 - val_participant_output_accuracy: 0.9705 - val_command_output_accuracy: 0.9411 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.1952\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 2s 211ms/step - loss: 1.3589 - participant_output_loss: 0.1753 - command_output_loss: 1.1835 - command_output_1_loss: 6.3262e-05 - participant_output_1_loss: 3.6822e-05 - participant_output_accuracy: 0.9950 - command_output_accuracy: 0.9883 - command_output_1_accuracy: 0.0000e+00 - participant_output_1_accuracy: 0.1883 - val_loss: 1.4632 - val_participant_output_loss: 0.2627 - val_command_output_loss: 1.2004 - val_command_output_1_loss: 6.0298e-05 - val_participant_output_1_loss: 4.6197e-05 - val_participant_output_accuracy: 0.9724 - val_command_output_accuracy: 0.9558 - val_command_output_1_accuracy: 0.0018 - val_participant_output_1_accuracy: 0.2044\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 3s 277ms/step - loss: 1.2439 - participant_output_loss: 0.1497 - command_output_loss: 1.0941 - command_output_1_loss: 4.8645e-05 - participant_output_1_loss: 3.6539e-05 - participant_output_accuracy: 0.9967 - command_output_accuracy: 0.9917 - command_output_1_accuracy: 0.0450 - participant_output_1_accuracy: 0.1900 - val_loss: 1.3608 - val_participant_output_loss: 0.2363 - val_command_output_loss: 1.1244 - val_command_output_1_loss: 4.5792e-05 - val_participant_output_1_loss: 4.6360e-05 - val_participant_output_accuracy: 0.9761 - val_command_output_accuracy: 0.9411 - val_command_output_1_accuracy: 0.1510 - val_participant_output_1_accuracy: 0.1878\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 2s 199ms/step - loss: 1.1412 - participant_output_loss: 0.1247 - command_output_loss: 1.0165 - command_output_1_loss: 5.3109e-05 - participant_output_1_loss: 3.5883e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9917 - command_output_1_accuracy: 0.0883 - participant_output_1_accuracy: 0.2467 - val_loss: 1.2608 - val_participant_output_loss: 0.2114 - val_command_output_loss: 1.0493 - val_command_output_1_loss: 5.3179e-05 - val_participant_output_1_loss: 4.7511e-05 - val_participant_output_accuracy: 0.9779 - val_command_output_accuracy: 0.9558 - val_command_output_1_accuracy: 0.1860 - val_participant_output_1_accuracy: 0.1547\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 1s 144ms/step - loss: 1.0320 - participant_output_loss: 0.1051 - command_output_loss: 0.9269 - command_output_1_loss: 4.0257e-05 - participant_output_1_loss: 3.6616e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9950 - command_output_1_accuracy: 0.1350 - participant_output_1_accuracy: 0.1933 - val_loss: 1.1737 - val_participant_output_loss: 0.1991 - val_command_output_loss: 0.9745 - val_command_output_1_loss: 4.4696e-05 - val_participant_output_1_loss: 4.7764e-05 - val_participant_output_accuracy: 0.9724 - val_command_output_accuracy: 0.9576 - val_command_output_1_accuracy: 0.0147 - val_participant_output_1_accuracy: 0.2173\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 2s 210ms/step - loss: 0.9387 - participant_output_loss: 0.0919 - command_output_loss: 0.8467 - command_output_1_loss: 4.5760e-05 - participant_output_1_loss: 3.6252e-05 - participant_output_accuracy: 0.9983 - command_output_accuracy: 0.9967 - command_output_1_accuracy: 0.0017 - participant_output_1_accuracy: 0.2583 - val_loss: 1.0743 - val_participant_output_loss: 0.1762 - val_command_output_loss: 0.8980 - val_command_output_1_loss: 4.1214e-05 - val_participant_output_1_loss: 4.9633e-05 - val_participant_output_accuracy: 0.9797 - val_command_output_accuracy: 0.9632 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.1363\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 1s 149ms/step - loss: 0.8489 - participant_output_loss: 0.0783 - command_output_loss: 0.7705 - command_output_1_loss: 4.1269e-05 - participant_output_1_loss: 3.6004e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9967 - command_output_1_accuracy: 0.0000e+00 - participant_output_1_accuracy: 0.2000 - val_loss: 0.9858 - val_participant_output_loss: 0.1546 - val_command_output_loss: 0.8310 - val_command_output_1_loss: 3.0755e-05 - val_participant_output_1_loss: 4.9058e-05 - val_participant_output_accuracy: 0.9797 - val_command_output_accuracy: 0.9558 - val_command_output_1_accuracy: 0.0055 - val_participant_output_1_accuracy: 0.2413\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 2s 178ms/step - loss: 0.7670 - participant_output_loss: 0.0666 - command_output_loss: 0.7003 - command_output_1_loss: 4.1066e-05 - participant_output_1_loss: 3.5137e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9967 - command_output_1_accuracy: 0.0067 - participant_output_1_accuracy: 0.2067 - val_loss: 0.9210 - val_participant_output_loss: 0.1508 - val_command_output_loss: 0.7701 - val_command_output_1_loss: 6.0437e-05 - val_participant_output_1_loss: 4.8929e-05 - val_participant_output_accuracy: 0.9724 - val_command_output_accuracy: 0.9558 - val_command_output_1_accuracy: 0.0755 - val_participant_output_1_accuracy: 0.2228\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 2s 167ms/step - loss: 0.6913 - participant_output_loss: 0.0592 - command_output_loss: 0.6319 - command_output_1_loss: 8.9753e-05 - participant_output_1_loss: 3.3217e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.5333 - participant_output_1_accuracy: 0.2317 - val_loss: 0.8487 - val_participant_output_loss: 0.1452 - val_command_output_loss: 0.7034 - val_command_output_1_loss: 7.8142e-05 - val_participant_output_1_loss: 4.9281e-05 - val_participant_output_accuracy: 0.9742 - val_command_output_accuracy: 0.9632 - val_command_output_1_accuracy: 0.4972 - val_participant_output_1_accuracy: 0.1934\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 2s 173ms/step - loss: 0.6201 - participant_output_loss: 0.0539 - command_output_loss: 0.5662 - command_output_1_loss: 4.3363e-05 - participant_output_1_loss: 3.2070e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.2833 - participant_output_1_accuracy: 0.2250 - val_loss: 0.7826 - val_participant_output_loss: 0.1395 - val_command_output_loss: 0.6430 - val_command_output_1_loss: 3.6683e-05 - val_participant_output_1_loss: 4.9402e-05 - val_participant_output_accuracy: 0.9742 - val_command_output_accuracy: 0.9650 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.1989\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 2s 208ms/step - loss: 0.5574 - participant_output_loss: 0.0496 - command_output_loss: 0.5077 - command_output_1_loss: 3.4830e-05 - participant_output_1_loss: 3.1143e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0000e+00 - participant_output_1_accuracy: 0.2233 - val_loss: 0.7225 - val_participant_output_loss: 0.1277 - val_command_output_loss: 0.5947 - val_command_output_1_loss: 3.1711e-05 - val_participant_output_1_loss: 4.8535e-05 - val_participant_output_accuracy: 0.9761 - val_command_output_accuracy: 0.9650 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.2136\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 4s 369ms/step - loss: 3.7225 - participant_output_loss: 1.4845 - command_output_loss: 2.2308 - command_output_1_loss: 0.0016 - participant_output_1_loss: 0.0056 - participant_output_accuracy: 0.3967 - command_output_accuracy: 0.3583 - command_output_1_accuracy: 0.0333 - participant_output_1_accuracy: 0.1033 - val_loss: 3.3246 - val_participant_output_loss: 1.3367 - val_command_output_loss: 1.9872 - val_command_output_1_loss: 3.3408e-04 - val_participant_output_1_loss: 4.0948e-04 - val_participant_output_accuracy: 0.4365 - val_command_output_accuracy: 0.6519 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.0313\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10\n",
      "10/10 [==============================] - 2s 190ms/step - loss: 3.0117 - participant_output_loss: 1.1041 - command_output_loss: 1.9071 - command_output_1_loss: 1.6568e-04 - participant_output_1_loss: 2.4171e-04 - participant_output_accuracy: 0.6417 - command_output_accuracy: 0.7450 - command_output_1_accuracy: 0.0133 - participant_output_1_accuracy: 0.5733 - val_loss: 2.9106 - val_participant_output_loss: 1.0725 - val_command_output_loss: 1.8379 - val_command_output_1_loss: 1.0509e-04 - val_participant_output_1_loss: 1.2499e-04 - val_participant_output_accuracy: 0.7385 - val_command_output_accuracy: 0.7606 - val_command_output_1_accuracy: 0.0295 - val_participant_output_1_accuracy: 0.2136\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 2s 210ms/step - loss: 2.6473 - participant_output_loss: 0.8819 - command_output_loss: 1.7652 - command_output_1_loss: 7.6028e-05 - participant_output_1_loss: 8.4083e-05 - participant_output_accuracy: 0.8200 - command_output_accuracy: 0.8600 - command_output_1_accuracy: 0.0467 - participant_output_1_accuracy: 0.2583 - val_loss: 2.5858 - val_participant_output_loss: 0.8673 - val_command_output_loss: 1.7184 - val_command_output_1_loss: 4.9269e-05 - val_participant_output_1_loss: 6.4646e-05 - val_participant_output_accuracy: 0.8361 - val_command_output_accuracy: 0.8398 - val_command_output_1_accuracy: 0.0902 - val_participant_output_1_accuracy: 0.4328\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 2s 208ms/step - loss: 2.3503 - participant_output_loss: 0.7056 - command_output_loss: 1.6446 - command_output_1_loss: 5.0194e-05 - participant_output_1_loss: 4.6884e-05 - participant_output_accuracy: 0.8917 - command_output_accuracy: 0.8900 - command_output_1_accuracy: 0.1300 - participant_output_1_accuracy: 0.1483 - val_loss: 2.3360 - val_participant_output_loss: 0.7292 - val_command_output_loss: 1.6067 - val_command_output_1_loss: 5.1119e-05 - val_participant_output_1_loss: 3.2616e-05 - val_participant_output_accuracy: 0.8785 - val_command_output_accuracy: 0.8729 - val_command_output_1_accuracy: 0.0994 - val_participant_output_1_accuracy: 0.0902\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 2s 210ms/step - loss: 2.0959 - participant_output_loss: 0.5665 - command_output_loss: 1.5294 - command_output_1_loss: 5.1822e-05 - participant_output_1_loss: 2.8588e-05 - participant_output_accuracy: 0.9400 - command_output_accuracy: 0.9383 - command_output_1_accuracy: 0.1117 - participant_output_1_accuracy: 0.2067 - val_loss: 2.1246 - val_participant_output_loss: 0.6185 - val_command_output_loss: 1.5060 - val_command_output_1_loss: 4.5266e-05 - val_participant_output_1_loss: 2.9991e-05 - val_participant_output_accuracy: 0.8932 - val_command_output_accuracy: 0.8969 - val_command_output_1_accuracy: 0.0221 - val_participant_output_1_accuracy: 0.3131\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 2s 210ms/step - loss: 1.8805 - participant_output_loss: 0.4609 - command_output_loss: 1.4195 - command_output_1_loss: 4.3584e-05 - participant_output_1_loss: 2.3607e-05 - participant_output_accuracy: 0.9600 - command_output_accuracy: 0.9583 - command_output_1_accuracy: 0.0050 - participant_output_1_accuracy: 0.3750 - val_loss: 1.9537 - val_participant_output_loss: 0.5424 - val_command_output_loss: 1.4113 - val_command_output_1_loss: 4.3338e-05 - val_participant_output_1_loss: 2.2070e-05 - val_participant_output_accuracy: 0.9227 - val_command_output_accuracy: 0.9300 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.2302\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 2s 207ms/step - loss: 1.6936 - participant_output_loss: 0.3784 - command_output_loss: 1.3151 - command_output_1_loss: 4.1445e-05 - participant_output_1_loss: 1.9488e-05 - participant_output_accuracy: 0.9733 - command_output_accuracy: 0.9683 - command_output_1_accuracy: 0.0133 - participant_output_1_accuracy: 0.2300 - val_loss: 1.7711 - val_participant_output_loss: 0.4569 - val_command_output_loss: 1.3142 - val_command_output_1_loss: 4.6803e-05 - val_participant_output_1_loss: 2.0763e-05 - val_participant_output_accuracy: 0.9540 - val_command_output_accuracy: 0.9355 - val_command_output_1_accuracy: 0.1344 - val_participant_output_1_accuracy: 0.2836\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 2s 209ms/step - loss: 1.5420 - participant_output_loss: 0.3226 - command_output_loss: 1.2193 - command_output_1_loss: 4.2883e-05 - participant_output_1_loss: 1.8511e-05 - participant_output_accuracy: 0.9800 - command_output_accuracy: 0.9750 - command_output_1_accuracy: 0.1383 - participant_output_1_accuracy: 0.2683 - val_loss: 1.6307 - val_participant_output_loss: 0.4094 - val_command_output_loss: 1.2212 - val_command_output_1_loss: 3.1616e-05 - val_participant_output_1_loss: 2.1846e-05 - val_participant_output_accuracy: 0.9558 - val_command_output_accuracy: 0.9466 - val_command_output_1_accuracy: 0.0589 - val_participant_output_1_accuracy: 0.1621\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 2s 244ms/step - loss: 1.3981 - participant_output_loss: 0.2806 - command_output_loss: 1.1174 - command_output_1_loss: 4.1984e-05 - participant_output_1_loss: 1.8268e-05 - participant_output_accuracy: 0.9883 - command_output_accuracy: 0.9850 - command_output_1_accuracy: 0.0833 - participant_output_1_accuracy: 0.2133 - val_loss: 1.5006 - val_participant_output_loss: 0.3644 - val_command_output_loss: 1.1361 - val_command_output_1_loss: 5.9334e-05 - val_participant_output_1_loss: 2.1294e-05 - val_participant_output_accuracy: 0.9613 - val_command_output_accuracy: 0.9503 - val_command_output_1_accuracy: 0.0129 - val_participant_output_1_accuracy: 0.2468\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 2s 170ms/step - loss: 1.2619 - participant_output_loss: 0.2392 - command_output_loss: 1.0226 - command_output_1_loss: 6.4589e-05 - participant_output_1_loss: 1.7614e-05 - participant_output_accuracy: 0.9917 - command_output_accuracy: 0.9867 - command_output_1_accuracy: 0.0200 - participant_output_1_accuracy: 0.2083 - val_loss: 1.3803 - val_participant_output_loss: 0.3286 - val_command_output_loss: 1.0517 - val_command_output_1_loss: 4.4675e-05 - val_participant_output_1_loss: 2.1357e-05 - val_participant_output_accuracy: 0.9576 - val_command_output_accuracy: 0.9521 - val_command_output_1_accuracy: 0.0608 - val_participant_output_1_accuracy: 0.2118\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 3s 270ms/step - loss: 1.1360 - participant_output_loss: 0.2032 - command_output_loss: 0.9328 - command_output_1_loss: 5.3740e-05 - participant_output_1_loss: 1.7407e-05 - participant_output_accuracy: 0.9967 - command_output_accuracy: 0.9900 - command_output_1_accuracy: 0.0183 - participant_output_1_accuracy: 0.2017 - val_loss: 1.2975 - val_participant_output_loss: 0.3249 - val_command_output_loss: 0.9725 - val_command_output_1_loss: 4.5450e-05 - val_participant_output_1_loss: 2.1250e-05 - val_participant_output_accuracy: 0.9558 - val_command_output_accuracy: 0.9521 - val_command_output_1_accuracy: 0.0018 - val_participant_output_1_accuracy: 0.2228\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 2s 197ms/step - loss: 1.0331 - participant_output_loss: 0.1790 - command_output_loss: 0.8541 - command_output_1_loss: 4.6359e-05 - participant_output_1_loss: 1.6807e-05 - participant_output_accuracy: 0.9967 - command_output_accuracy: 0.9950 - command_output_1_accuracy: 0.0017 - participant_output_1_accuracy: 0.1967 - val_loss: 1.1713 - val_participant_output_loss: 0.2654 - val_command_output_loss: 0.9058 - val_command_output_1_loss: 4.4941e-05 - val_participant_output_1_loss: 2.1238e-05 - val_participant_output_accuracy: 0.9761 - val_command_output_accuracy: 0.9466 - val_command_output_1_accuracy: 0.0166 - val_participant_output_1_accuracy: 0.1547\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 2s 187ms/step - loss: 0.9304 - participant_output_loss: 0.1554 - command_output_loss: 0.7750 - command_output_1_loss: 4.2320e-05 - participant_output_1_loss: 1.6032e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9983 - command_output_1_accuracy: 0.0183 - participant_output_1_accuracy: 0.2000 - val_loss: 1.0828 - val_participant_output_loss: 0.2453 - val_command_output_loss: 0.8374 - val_command_output_1_loss: 4.8253e-05 - val_participant_output_1_loss: 2.0547e-05 - val_participant_output_accuracy: 0.9742 - val_command_output_accuracy: 0.9540 - val_command_output_1_accuracy: 0.0295 - val_participant_output_1_accuracy: 0.2026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10\n",
      "10/10 [==============================] - 1s 146ms/step - loss: 0.8484 - participant_output_loss: 0.1395 - command_output_loss: 0.7088 - command_output_1_loss: 7.0759e-05 - participant_output_1_loss: 1.5681e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9983 - command_output_1_accuracy: 0.0383 - participant_output_1_accuracy: 0.1967 - val_loss: 1.0124 - val_participant_output_loss: 0.2313 - val_command_output_loss: 0.7810 - val_command_output_1_loss: 6.6827e-05 - val_participant_output_1_loss: 2.0618e-05 - val_participant_output_accuracy: 0.9742 - val_command_output_accuracy: 0.9466 - val_command_output_1_accuracy: 0.0424 - val_participant_output_1_accuracy: 0.1842\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 2s 186ms/step - loss: 0.7642 - participant_output_loss: 0.1260 - command_output_loss: 0.6382 - command_output_1_loss: 4.9498e-05 - participant_output_1_loss: 1.5570e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9983 - command_output_1_accuracy: 0.0067 - participant_output_1_accuracy: 0.2283 - val_loss: 0.9411 - val_participant_output_loss: 0.2241 - val_command_output_loss: 0.7169 - val_command_output_1_loss: 3.2217e-05 - val_participant_output_1_loss: 2.1111e-05 - val_participant_output_accuracy: 0.9742 - val_command_output_accuracy: 0.9576 - val_command_output_1_accuracy: 0.0018 - val_participant_output_1_accuracy: 0.1639\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 1s 146ms/step - loss: 0.6934 - participant_output_loss: 0.1152 - command_output_loss: 0.5781 - command_output_1_loss: 5.0393e-05 - participant_output_1_loss: 1.5361e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9983 - command_output_1_accuracy: 0.0017 - participant_output_1_accuracy: 0.1833 - val_loss: 0.8730 - val_participant_output_loss: 0.2113 - val_command_output_loss: 0.6616 - val_command_output_1_loss: 4.8505e-05 - val_participant_output_1_loss: 2.0345e-05 - val_participant_output_accuracy: 0.9687 - val_command_output_accuracy: 0.9613 - val_command_output_1_accuracy: 0.0110 - val_participant_output_1_accuracy: 0.2486\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 1s 144ms/step - loss: 0.6285 - participant_output_loss: 0.1044 - command_output_loss: 0.5241 - command_output_1_loss: 3.9010e-05 - participant_output_1_loss: 1.4471e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9983 - command_output_1_accuracy: 0.2783 - participant_output_1_accuracy: 0.1950 - val_loss: 0.8171 - val_participant_output_loss: 0.1977 - val_command_output_loss: 0.6193 - val_command_output_1_loss: 3.7141e-05 - val_participant_output_1_loss: 2.0304e-05 - val_participant_output_accuracy: 0.9705 - val_command_output_accuracy: 0.9503 - val_command_output_1_accuracy: 0.5359 - val_participant_output_1_accuracy: 0.2560\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 2s 196ms/step - loss: 0.5717 - participant_output_loss: 0.0948 - command_output_loss: 0.4768 - command_output_1_loss: 3.3563e-05 - participant_output_1_loss: 1.4010e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9983 - command_output_1_accuracy: 0.3667 - participant_output_1_accuracy: 0.2333 - val_loss: 0.7504 - val_participant_output_loss: 0.1819 - val_command_output_loss: 0.5685 - val_command_output_1_loss: 3.1403e-05 - val_participant_output_1_loss: 1.9990e-05 - val_participant_output_accuracy: 0.9761 - val_command_output_accuracy: 0.9576 - val_command_output_1_accuracy: 0.0147 - val_participant_output_1_accuracy: 0.1823\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 2s 190ms/step - loss: 0.5197 - participant_output_loss: 0.0867 - command_output_loss: 0.4329 - command_output_1_loss: 3.1807e-05 - participant_output_1_loss: 1.3482e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9983 - command_output_1_accuracy: 0.0000e+00 - participant_output_1_accuracy: 0.1717 - val_loss: 0.7094 - val_participant_output_loss: 0.1782 - val_command_output_loss: 0.5312 - val_command_output_1_loss: 3.2672e-05 - val_participant_output_1_loss: 1.9806e-05 - val_participant_output_accuracy: 0.9779 - val_command_output_accuracy: 0.9632 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.1842\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 2s 152ms/step - loss: 0.4755 - participant_output_loss: 0.0810 - command_output_loss: 0.3944 - command_output_1_loss: 2.6689e-05 - participant_output_1_loss: 1.3310e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9983 - command_output_1_accuracy: 0.0033 - participant_output_1_accuracy: 0.1867 - val_loss: 0.6664 - val_participant_output_loss: 0.1706 - val_command_output_loss: 0.4957 - val_command_output_1_loss: 2.2854e-05 - val_participant_output_1_loss: 2.0191e-05 - val_participant_output_accuracy: 0.9779 - val_command_output_accuracy: 0.9595 - val_command_output_1_accuracy: 0.0184 - val_participant_output_1_accuracy: 0.2818\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 4s 370ms/step - loss: 3.6556 - participant_output_loss: 1.3557 - command_output_loss: 2.2956 - command_output_1_loss: 6.5016e-04 - participant_output_1_loss: 0.0037 - participant_output_accuracy: 0.4967 - command_output_accuracy: 0.2417 - command_output_1_accuracy: 0.0883 - participant_output_1_accuracy: 0.3617 - val_loss: 3.2228 - val_participant_output_loss: 1.1290 - val_command_output_loss: 2.0929 - val_command_output_1_loss: 2.7808e-04 - val_participant_output_1_loss: 5.5878e-04 - val_participant_output_accuracy: 0.6280 - val_command_output_accuracy: 0.4457 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.1584\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 2s 192ms/step - loss: 2.8829 - participant_output_loss: 0.8731 - command_output_loss: 2.0092 - command_output_1_loss: 1.5907e-04 - participant_output_1_loss: 3.8331e-04 - participant_output_accuracy: 0.7683 - command_output_accuracy: 0.5567 - command_output_1_accuracy: 0.0117 - participant_output_1_accuracy: 0.0350 - val_loss: 2.7759 - val_participant_output_loss: 0.8332 - val_command_output_loss: 1.9423 - val_command_output_1_loss: 9.2053e-05 - val_participant_output_1_loss: 2.7624e-04 - val_participant_output_accuracy: 0.7514 - val_command_output_accuracy: 0.5820 - val_command_output_1_accuracy: 0.1400 - val_participant_output_1_accuracy: 0.1547\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 2s 185ms/step - loss: 2.4933 - participant_output_loss: 0.6212 - command_output_loss: 1.8719 - command_output_1_loss: 1.3173e-04 - participant_output_1_loss: 1.5348e-04 - participant_output_accuracy: 0.8667 - command_output_accuracy: 0.7533 - command_output_1_accuracy: 0.0967 - participant_output_1_accuracy: 0.1833 - val_loss: 2.4518 - val_participant_output_loss: 0.6214 - val_command_output_loss: 1.8302 - val_command_output_1_loss: 1.1691e-04 - val_participant_output_1_loss: 1.1550e-04 - val_participant_output_accuracy: 0.9006 - val_command_output_accuracy: 0.7090 - val_command_output_1_accuracy: 0.0552 - val_participant_output_1_accuracy: 0.0258\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 2s 202ms/step - loss: 2.2331 - participant_output_loss: 0.4666 - command_output_loss: 1.7663 - command_output_1_loss: 8.8377e-05 - participant_output_1_loss: 8.4131e-05 - participant_output_accuracy: 0.9433 - command_output_accuracy: 0.8000 - command_output_1_accuracy: 0.0850 - participant_output_1_accuracy: 0.1700 - val_loss: 2.2531 - val_participant_output_loss: 0.5214 - val_command_output_loss: 1.7316 - val_command_output_1_loss: 3.6091e-05 - val_participant_output_1_loss: 7.1580e-05 - val_participant_output_accuracy: 0.9190 - val_command_output_accuracy: 0.7716 - val_command_output_1_accuracy: 0.1934 - val_participant_output_1_accuracy: 0.3978\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 2s 206ms/step - loss: 2.0341 - participant_output_loss: 0.3648 - command_output_loss: 1.6691 - command_output_1_loss: 4.6002e-05 - participant_output_1_loss: 5.8602e-05 - participant_output_accuracy: 0.9667 - command_output_accuracy: 0.8717 - command_output_1_accuracy: 0.0583 - participant_output_1_accuracy: 0.2067 - val_loss: 2.0915 - val_participant_output_loss: 0.4408 - val_command_output_loss: 1.6506 - val_command_output_1_loss: 5.2822e-05 - val_participant_output_1_loss: 6.3850e-05 - val_participant_output_accuracy: 0.9429 - val_command_output_accuracy: 0.8471 - val_command_output_1_accuracy: 0.0055 - val_participant_output_1_accuracy: 0.0718\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10\n",
      "10/10 [==============================] - 2s 208ms/step - loss: 1.8655 - participant_output_loss: 0.2935 - command_output_loss: 1.5718 - command_output_1_loss: 8.0611e-05 - participant_output_1_loss: 5.0480e-05 - participant_output_accuracy: 0.9767 - command_output_accuracy: 0.9267 - command_output_1_accuracy: 0.0033 - participant_output_1_accuracy: 0.2167 - val_loss: 1.9449 - val_participant_output_loss: 0.3803 - val_command_output_loss: 1.5645 - val_command_output_1_loss: 8.7712e-05 - val_participant_output_1_loss: 6.0778e-05 - val_participant_output_accuracy: 0.9411 - val_command_output_accuracy: 0.8895 - val_command_output_1_accuracy: 0.0368 - val_participant_output_1_accuracy: 0.2265\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 2s 212ms/step - loss: 1.7050 - participant_output_loss: 0.2318 - command_output_loss: 1.4731 - command_output_1_loss: 7.4908e-05 - participant_output_1_loss: 4.7053e-05 - participant_output_accuracy: 0.9817 - command_output_accuracy: 0.9700 - command_output_1_accuracy: 0.0667 - participant_output_1_accuracy: 0.1567 - val_loss: 1.7884 - val_participant_output_loss: 0.3204 - val_command_output_loss: 1.4679 - val_command_output_1_loss: 7.8268e-05 - val_participant_output_1_loss: 5.8667e-05 - val_participant_output_accuracy: 0.9632 - val_command_output_accuracy: 0.8950 - val_command_output_1_accuracy: 0.0074 - val_participant_output_1_accuracy: 0.1473\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 2s 212ms/step - loss: 1.5725 - participant_output_loss: 0.1926 - command_output_loss: 1.3798 - command_output_1_loss: 9.6015e-05 - participant_output_1_loss: 4.4467e-05 - participant_output_accuracy: 0.9933 - command_output_accuracy: 0.9733 - command_output_1_accuracy: 0.0050 - participant_output_1_accuracy: 0.2333 - val_loss: 1.6611 - val_participant_output_loss: 0.2722 - val_command_output_loss: 1.3888 - val_command_output_1_loss: 6.7415e-05 - val_participant_output_1_loss: 5.8032e-05 - val_participant_output_accuracy: 0.9669 - val_command_output_accuracy: 0.9098 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.1602\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 2s 230ms/step - loss: 1.4423 - participant_output_loss: 0.1535 - command_output_loss: 1.2888 - command_output_1_loss: 4.8965e-05 - participant_output_1_loss: 4.3319e-05 - participant_output_accuracy: 0.9967 - command_output_accuracy: 0.9767 - command_output_1_accuracy: 0.0000e+00 - participant_output_1_accuracy: 0.1583 - val_loss: 1.5444 - val_participant_output_loss: 0.2427 - val_command_output_loss: 1.3016 - val_command_output_1_loss: 4.8700e-05 - val_participant_output_1_loss: 5.7970e-05 - val_participant_output_accuracy: 0.9669 - val_command_output_accuracy: 0.9263 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.2136\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 2s 211ms/step - loss: 1.3262 - participant_output_loss: 0.1314 - command_output_loss: 1.1948 - command_output_1_loss: 5.6410e-05 - participant_output_1_loss: 4.1890e-05 - participant_output_accuracy: 0.9967 - command_output_accuracy: 0.9817 - command_output_1_accuracy: 0.0633 - participant_output_1_accuracy: 0.2000 - val_loss: 1.4408 - val_participant_output_loss: 0.2187 - val_command_output_loss: 1.2221 - val_command_output_1_loss: 4.3376e-05 - val_participant_output_1_loss: 5.8291e-05 - val_participant_output_accuracy: 0.9687 - val_command_output_accuracy: 0.9411 - val_command_output_1_accuracy: 0.4401 - val_participant_output_1_accuracy: 0.1492\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 3s 269ms/step - loss: 1.2257 - participant_output_loss: 0.1160 - command_output_loss: 1.1096 - command_output_1_loss: 3.4693e-05 - participant_output_1_loss: 4.1048e-05 - participant_output_accuracy: 0.9983 - command_output_accuracy: 0.9950 - command_output_1_accuracy: 0.2700 - participant_output_1_accuracy: 0.2067 - val_loss: 1.3598 - val_participant_output_loss: 0.2173 - val_command_output_loss: 1.1425 - val_command_output_1_loss: 3.5337e-05 - val_participant_output_1_loss: 5.7783e-05 - val_participant_output_accuracy: 0.9632 - val_command_output_accuracy: 0.9429 - val_command_output_1_accuracy: 0.0203 - val_participant_output_1_accuracy: 0.1860\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 2s 211ms/step - loss: 1.1243 - participant_output_loss: 0.0999 - command_output_loss: 1.0243 - command_output_1_loss: 3.9827e-05 - participant_output_1_loss: 3.8998e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9950 - command_output_1_accuracy: 0.0100 - participant_output_1_accuracy: 0.1567 - val_loss: 1.2572 - val_participant_output_loss: 0.1921 - val_command_output_loss: 1.0650 - val_command_output_1_loss: 4.7897e-05 - val_participant_output_1_loss: 5.5944e-05 - val_participant_output_accuracy: 0.9687 - val_command_output_accuracy: 0.9411 - val_command_output_1_accuracy: 0.0018 - val_participant_output_1_accuracy: 0.1805\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 2s 204ms/step - loss: 1.0291 - participant_output_loss: 0.0870 - command_output_loss: 0.9420 - command_output_1_loss: 4.0047e-05 - participant_output_1_loss: 3.7579e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9950 - command_output_1_accuracy: 0.0017 - participant_output_1_accuracy: 0.1833 - val_loss: 1.1720 - val_participant_output_loss: 0.1755 - val_command_output_loss: 0.9964 - val_command_output_1_loss: 4.2572e-05 - val_participant_output_1_loss: 5.7996e-05 - val_participant_output_accuracy: 0.9779 - val_command_output_accuracy: 0.9558 - val_command_output_1_accuracy: 0.0129 - val_participant_output_1_accuracy: 0.1547\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 2s 197ms/step - loss: 0.9426 - participant_output_loss: 0.0773 - command_output_loss: 0.8652 - command_output_1_loss: 3.2056e-05 - participant_output_1_loss: 3.6639e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9950 - command_output_1_accuracy: 0.0317 - participant_output_1_accuracy: 0.1700 - val_loss: 1.0925 - val_participant_output_loss: 0.1689 - val_command_output_loss: 0.9235 - val_command_output_1_loss: 3.1339e-05 - val_participant_output_1_loss: 5.4580e-05 - val_participant_output_accuracy: 0.9816 - val_command_output_accuracy: 0.9576 - val_command_output_1_accuracy: 0.2210 - val_participant_output_1_accuracy: 0.2228\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 2s 173ms/step - loss: 0.8593 - participant_output_loss: 0.0693 - command_output_loss: 0.7900 - command_output_1_loss: 2.5855e-05 - participant_output_1_loss: 3.4476e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9983 - command_output_1_accuracy: 0.2550 - participant_output_1_accuracy: 0.1850 - val_loss: 1.0148 - val_participant_output_loss: 0.1527 - val_command_output_loss: 0.8621 - val_command_output_1_loss: 2.9503e-05 - val_participant_output_1_loss: 5.4209e-05 - val_participant_output_accuracy: 0.9761 - val_command_output_accuracy: 0.9521 - val_command_output_1_accuracy: 0.1123 - val_participant_output_1_accuracy: 0.1529\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 1s 147ms/step - loss: 0.7851 - participant_output_loss: 0.0606 - command_output_loss: 0.7245 - command_output_1_loss: 2.7287e-05 - participant_output_1_loss: 3.2453e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9983 - command_output_1_accuracy: 0.0533 - participant_output_1_accuracy: 0.2217 - val_loss: 0.9349 - val_participant_output_loss: 0.1403 - val_command_output_loss: 0.7945 - val_command_output_1_loss: 3.2425e-05 - val_participant_output_1_loss: 5.3285e-05 - val_participant_output_accuracy: 0.9797 - val_command_output_accuracy: 0.9595 - val_command_output_1_accuracy: 0.0129 - val_participant_output_1_accuracy: 0.1510\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 2s 209ms/step - loss: 0.7142 - participant_output_loss: 0.0554 - command_output_loss: 0.6587 - command_output_1_loss: 3.5347e-05 - participant_output_1_loss: 3.1237e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0050 - participant_output_1_accuracy: 0.1500 - val_loss: 0.8762 - val_participant_output_loss: 0.1393 - val_command_output_loss: 0.7368 - val_command_output_1_loss: 2.7594e-05 - val_participant_output_1_loss: 5.2913e-05 - val_participant_output_accuracy: 0.9761 - val_command_output_accuracy: 0.9650 - val_command_output_1_accuracy: 0.0018 - val_participant_output_1_accuracy: 0.2173\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10\n",
      "10/10 [==============================] - 2s 150ms/step - loss: 0.6473 - participant_output_loss: 0.0500 - command_output_loss: 0.5972 - command_output_1_loss: 3.3131e-05 - participant_output_1_loss: 3.0946e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0033 - participant_output_1_accuracy: 0.1783 - val_loss: 0.8131 - val_participant_output_loss: 0.1299 - val_command_output_loss: 0.6832 - val_command_output_1_loss: 3.5255e-05 - val_participant_output_1_loss: 5.3408e-05 - val_participant_output_accuracy: 0.9797 - val_command_output_accuracy: 0.9540 - val_command_output_1_accuracy: 0.0147 - val_participant_output_1_accuracy: 0.1842\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 2s 177ms/step - loss: 0.5863 - participant_output_loss: 0.0460 - command_output_loss: 0.5402 - command_output_1_loss: 3.2743e-05 - participant_output_1_loss: 2.8937e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0483 - participant_output_1_accuracy: 0.2017 - val_loss: 0.7636 - val_participant_output_loss: 0.1314 - val_command_output_loss: 0.6321 - val_command_output_1_loss: 3.0927e-05 - val_participant_output_1_loss: 5.1554e-05 - val_participant_output_accuracy: 0.9797 - val_command_output_accuracy: 0.9576 - val_command_output_1_accuracy: 0.3020 - val_participant_output_1_accuracy: 0.1584\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 2s 161ms/step - loss: 0.5315 - participant_output_loss: 0.0428 - command_output_loss: 0.4887 - command_output_1_loss: 2.6577e-05 - participant_output_1_loss: 2.7122e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.1700 - participant_output_1_accuracy: 0.1767 - val_loss: 0.7129 - val_participant_output_loss: 0.1267 - val_command_output_loss: 0.5861 - val_command_output_1_loss: 3.3251e-05 - val_participant_output_1_loss: 5.0548e-05 - val_participant_output_accuracy: 0.9724 - val_command_output_accuracy: 0.9613 - val_command_output_1_accuracy: 0.0258 - val_participant_output_1_accuracy: 0.1676\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 4s 355ms/step - loss: 3.6683 - participant_output_loss: 1.4271 - command_output_loss: 2.2386 - command_output_1_loss: 0.0012 - participant_output_1_loss: 0.0015 - participant_output_accuracy: 0.3950 - command_output_accuracy: 0.2317 - command_output_1_accuracy: 0.0800 - participant_output_1_accuracy: 0.2267 - val_loss: 3.3087 - val_participant_output_loss: 1.2403 - val_command_output_loss: 2.0678 - val_command_output_1_loss: 2.1464e-04 - val_participant_output_1_loss: 3.6980e-04 - val_participant_output_accuracy: 0.5691 - val_command_output_accuracy: 0.5175 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.1473\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 2s 189ms/step - loss: 3.0176 - participant_output_loss: 1.0295 - command_output_loss: 1.9877 - command_output_1_loss: 1.2428e-04 - participant_output_1_loss: 2.3729e-04 - participant_output_accuracy: 0.7283 - command_output_accuracy: 0.6917 - command_output_1_accuracy: 0.0000e+00 - participant_output_1_accuracy: 0.2300 - val_loss: 2.9457 - val_participant_output_loss: 1.0034 - val_command_output_loss: 1.9420 - val_command_output_1_loss: 1.5248e-04 - val_participant_output_1_loss: 1.7113e-04 - val_participant_output_accuracy: 0.6777 - val_command_output_accuracy: 0.6796 - val_command_output_1_accuracy: 0.0184 - val_participant_output_1_accuracy: 0.3738\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 2s 222ms/step - loss: 2.6954 - participant_output_loss: 0.8188 - command_output_loss: 1.8763 - command_output_1_loss: 1.3680e-04 - participant_output_1_loss: 1.2241e-04 - participant_output_accuracy: 0.8117 - command_output_accuracy: 0.7350 - command_output_1_accuracy: 0.2517 - participant_output_1_accuracy: 0.2583 - val_loss: 2.6560 - val_participant_output_loss: 0.8166 - val_command_output_loss: 1.8392 - val_command_output_1_loss: 7.8603e-05 - val_participant_output_1_loss: 1.0289e-04 - val_participant_output_accuracy: 0.8564 - val_command_output_accuracy: 0.7735 - val_command_output_1_accuracy: 0.3223 - val_participant_output_1_accuracy: 0.3039\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 2s 210ms/step - loss: 2.4381 - participant_output_loss: 0.6609 - command_output_loss: 1.7771 - command_output_1_loss: 4.3715e-05 - participant_output_1_loss: 8.2324e-05 - participant_output_accuracy: 0.8967 - command_output_accuracy: 0.8500 - command_output_1_accuracy: 0.1550 - participant_output_1_accuracy: 0.2417 - val_loss: 2.4341 - val_participant_output_loss: 0.6915 - val_command_output_loss: 1.7425 - val_command_output_1_loss: 6.1790e-05 - val_participant_output_1_loss: 8.6522e-05 - val_participant_output_accuracy: 0.8748 - val_command_output_accuracy: 0.8545 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.2523\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 2s 221ms/step - loss: 2.2076 - participant_output_loss: 0.5361 - command_output_loss: 1.6713 - command_output_1_loss: 7.8853e-05 - participant_output_1_loss: 6.7037e-05 - participant_output_accuracy: 0.9333 - command_output_accuracy: 0.8917 - command_output_1_accuracy: 0.0000e+00 - participant_output_1_accuracy: 0.2533 - val_loss: 2.2331 - val_participant_output_loss: 0.5801 - val_command_output_loss: 1.6528 - val_command_output_1_loss: 7.5048e-05 - val_participant_output_1_loss: 8.1223e-05 - val_participant_output_accuracy: 0.9208 - val_command_output_accuracy: 0.8674 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.2781\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 2s 220ms/step - loss: 2.0104 - participant_output_loss: 0.4366 - command_output_loss: 1.5736 - command_output_1_loss: 8.9314e-05 - participant_output_1_loss: 5.9947e-05 - participant_output_accuracy: 0.9533 - command_output_accuracy: 0.9267 - command_output_1_accuracy: 0.0000e+00 - participant_output_1_accuracy: 0.2750 - val_loss: 2.0480 - val_participant_output_loss: 0.4856 - val_command_output_loss: 1.5623 - val_command_output_1_loss: 6.9404e-05 - val_participant_output_1_loss: 7.5762e-05 - val_participant_output_accuracy: 0.9484 - val_command_output_accuracy: 0.8895 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.1750\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 2s 209ms/step - loss: 1.8272 - participant_output_loss: 0.3566 - command_output_loss: 1.4704 - command_output_1_loss: 6.5537e-05 - participant_output_1_loss: 5.1678e-05 - participant_output_accuracy: 0.9650 - command_output_accuracy: 0.9700 - command_output_1_accuracy: 0.0000e+00 - participant_output_1_accuracy: 0.2317 - val_loss: 1.8817 - val_participant_output_loss: 0.4135 - val_command_output_loss: 1.4680 - val_command_output_1_loss: 7.9989e-05 - val_participant_output_1_loss: 7.0289e-05 - val_participant_output_accuracy: 0.9669 - val_command_output_accuracy: 0.9263 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.2431\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 2s 222ms/step - loss: 1.6761 - participant_output_loss: 0.3003 - command_output_loss: 1.3758 - command_output_1_loss: 5.9547e-05 - participant_output_1_loss: 4.5887e-05 - participant_output_accuracy: 0.9850 - command_output_accuracy: 0.9767 - command_output_1_accuracy: 0.0167 - participant_output_1_accuracy: 0.2183 - val_loss: 1.7632 - val_participant_output_loss: 0.3815 - val_command_output_loss: 1.3816 - val_command_output_1_loss: 4.5306e-05 - val_participant_output_1_loss: 6.5560e-05 - val_participant_output_accuracy: 0.9650 - val_command_output_accuracy: 0.9282 - val_command_output_1_accuracy: 0.4217 - val_participant_output_1_accuracy: 0.2357\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 2s 219ms/step - loss: 1.5368 - participant_output_loss: 0.2560 - command_output_loss: 1.2807 - command_output_1_loss: 7.2108e-05 - participant_output_1_loss: 4.3255e-05 - participant_output_accuracy: 0.9917 - command_output_accuracy: 0.9850 - command_output_1_accuracy: 0.8450 - participant_output_1_accuracy: 0.2467 - val_loss: 1.6327 - val_participant_output_loss: 0.3371 - val_command_output_loss: 1.2955 - val_command_output_1_loss: 6.1265e-05 - val_participant_output_1_loss: 6.7474e-05 - val_participant_output_accuracy: 0.9724 - val_command_output_accuracy: 0.9227 - val_command_output_1_accuracy: 0.5764 - val_participant_output_1_accuracy: 0.2468\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10\n",
      "10/10 [==============================] - 2s 200ms/step - loss: 1.4079 - participant_output_loss: 0.2177 - command_output_loss: 1.1901 - command_output_1_loss: 4.6437e-05 - participant_output_1_loss: 4.1800e-05 - participant_output_accuracy: 0.9950 - command_output_accuracy: 0.9900 - command_output_1_accuracy: 0.2350 - participant_output_1_accuracy: 0.2200 - val_loss: 1.5184 - val_participant_output_loss: 0.3084 - val_command_output_loss: 1.2098 - val_command_output_1_loss: 5.9254e-05 - val_participant_output_1_loss: 6.8493e-05 - val_participant_output_accuracy: 0.9669 - val_command_output_accuracy: 0.9411 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.3444\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 3s 273ms/step - loss: 1.2895 - participant_output_loss: 0.1883 - command_output_loss: 1.1011 - command_output_1_loss: 6.9956e-05 - participant_output_1_loss: 3.9451e-05 - participant_output_accuracy: 0.9967 - command_output_accuracy: 0.9917 - command_output_1_accuracy: 0.0000e+00 - participant_output_1_accuracy: 0.2300 - val_loss: 1.4296 - val_participant_output_loss: 0.2946 - val_command_output_loss: 1.1349 - val_command_output_1_loss: 6.8258e-05 - val_participant_output_1_loss: 6.3481e-05 - val_participant_output_accuracy: 0.9613 - val_command_output_accuracy: 0.9521 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.3241\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 2s 166ms/step - loss: 1.1836 - participant_output_loss: 0.1668 - command_output_loss: 1.0167 - command_output_1_loss: 6.4470e-05 - participant_output_1_loss: 3.6272e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9933 - command_output_1_accuracy: 0.0000e+00 - participant_output_1_accuracy: 0.2400 - val_loss: 1.3396 - val_participant_output_loss: 0.2815 - val_command_output_loss: 1.0580 - val_command_output_1_loss: 5.3078e-05 - val_participant_output_1_loss: 6.0691e-05 - val_participant_output_accuracy: 0.9613 - val_command_output_accuracy: 0.9466 - val_command_output_1_accuracy: 0.0147 - val_participant_output_1_accuracy: 0.2136\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 2s 187ms/step - loss: 1.0792 - participant_output_loss: 0.1472 - command_output_loss: 0.9319 - command_output_1_loss: 5.3506e-05 - participant_output_1_loss: 3.4011e-05 - participant_output_accuracy: 0.9983 - command_output_accuracy: 0.9967 - command_output_1_accuracy: 0.0417 - participant_output_1_accuracy: 0.2150 - val_loss: 1.2384 - val_participant_output_loss: 0.2543 - val_command_output_loss: 0.9840 - val_command_output_1_loss: 4.5721e-05 - val_participant_output_1_loss: 6.0305e-05 - val_participant_output_accuracy: 0.9650 - val_command_output_accuracy: 0.9484 - val_command_output_1_accuracy: 0.0681 - val_participant_output_1_accuracy: 0.2449\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 2s 178ms/step - loss: 0.9864 - participant_output_loss: 0.1308 - command_output_loss: 0.8556 - command_output_1_loss: 4.2122e-05 - participant_output_1_loss: 3.2672e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9983 - command_output_1_accuracy: 0.0167 - participant_output_1_accuracy: 0.2067 - val_loss: 1.1527 - val_participant_output_loss: 0.2334 - val_command_output_loss: 0.9191 - val_command_output_1_loss: 4.5595e-05 - val_participant_output_1_loss: 5.9965e-05 - val_participant_output_accuracy: 0.9650 - val_command_output_accuracy: 0.9448 - val_command_output_1_accuracy: 0.0037 - val_participant_output_1_accuracy: 0.2468\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 2s 208ms/step - loss: 0.9037 - participant_output_loss: 0.1171 - command_output_loss: 0.7866 - command_output_1_loss: 5.3807e-05 - participant_output_1_loss: 3.2279e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9967 - command_output_1_accuracy: 0.0000e+00 - participant_output_1_accuracy: 0.2250 - val_loss: 1.0837 - val_participant_output_loss: 0.2275 - val_command_output_loss: 0.8561 - val_command_output_1_loss: 5.3018e-05 - val_participant_output_1_loss: 6.3189e-05 - val_participant_output_accuracy: 0.9650 - val_command_output_accuracy: 0.9558 - val_command_output_1_accuracy: 0.0018 - val_participant_output_1_accuracy: 0.3315\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 2s 214ms/step - loss: 0.8204 - participant_output_loss: 0.1041 - command_output_loss: 0.7162 - command_output_1_loss: 5.0414e-05 - participant_output_1_loss: 3.0994e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0383 - participant_output_1_accuracy: 0.2100 - val_loss: 0.9973 - val_participant_output_loss: 0.2012 - val_command_output_loss: 0.7960 - val_command_output_1_loss: 4.3462e-05 - val_participant_output_1_loss: 6.0809e-05 - val_participant_output_accuracy: 0.9742 - val_command_output_accuracy: 0.9558 - val_command_output_1_accuracy: 0.1602 - val_participant_output_1_accuracy: 0.2928\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 2s 184ms/step - loss: 0.7513 - participant_output_loss: 0.0975 - command_output_loss: 0.6537 - command_output_1_loss: 4.9831e-05 - participant_output_1_loss: 2.8950e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0317 - participant_output_1_accuracy: 0.1983 - val_loss: 0.9335 - val_participant_output_loss: 0.1934 - val_command_output_loss: 0.7400 - val_command_output_1_loss: 5.3158e-05 - val_participant_output_1_loss: 5.8770e-05 - val_participant_output_accuracy: 0.9742 - val_command_output_accuracy: 0.9521 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.2560\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 2s 167ms/step - loss: 0.6883 - participant_output_loss: 0.0896 - command_output_loss: 0.5987 - command_output_1_loss: 3.6764e-05 - participant_output_1_loss: 2.6852e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0067 - participant_output_1_accuracy: 0.2417 - val_loss: 0.8754 - val_participant_output_loss: 0.1849 - val_command_output_loss: 0.6904 - val_command_output_1_loss: 2.7802e-05 - val_participant_output_1_loss: 5.9200e-05 - val_participant_output_accuracy: 0.9724 - val_command_output_accuracy: 0.9540 - val_command_output_1_accuracy: 0.0203 - val_participant_output_1_accuracy: 0.2136\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 2s 180ms/step - loss: 0.6278 - participant_output_loss: 0.0820 - command_output_loss: 0.5458 - command_output_1_loss: 2.7056e-05 - participant_output_1_loss: 2.5265e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0067 - participant_output_1_accuracy: 0.2083 - val_loss: 0.8453 - val_participant_output_loss: 0.1950 - val_command_output_loss: 0.6502 - val_command_output_1_loss: 3.5056e-05 - val_participant_output_1_loss: 5.7655e-05 - val_participant_output_accuracy: 0.9632 - val_command_output_accuracy: 0.9521 - val_command_output_1_accuracy: 0.0037 - val_participant_output_1_accuracy: 0.2744\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 2s 153ms/step - loss: 0.5721 - participant_output_loss: 0.0749 - command_output_loss: 0.4971 - command_output_1_loss: 2.2854e-05 - participant_output_1_loss: 2.3652e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0083 - participant_output_1_accuracy: 0.2067 - val_loss: 0.7863 - val_participant_output_loss: 0.1855 - val_command_output_loss: 0.6007 - val_command_output_1_loss: 1.2651e-05 - val_participant_output_1_loss: 5.5048e-05 - val_participant_output_accuracy: 0.9669 - val_command_output_accuracy: 0.9558 - val_command_output_1_accuracy: 0.0829 - val_participant_output_1_accuracy: 0.2634\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 3s 349ms/step - loss: 3.8610 - participant_output_loss: 1.5532 - command_output_loss: 2.3018 - command_output_1_loss: 0.0022 - participant_output_1_loss: 0.0038 - participant_output_accuracy: 0.3667 - command_output_accuracy: 0.1900 - command_output_1_accuracy: 0.0683 - participant_output_1_accuracy: 0.2250 - val_loss: 3.5595 - val_participant_output_loss: 1.4158 - val_command_output_loss: 2.1429 - val_command_output_1_loss: 5.4887e-04 - val_participant_output_1_loss: 2.3003e-04 - val_participant_output_accuracy: 0.3425 - val_command_output_accuracy: 0.4144 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.1989\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10\n",
      "10/10 [==============================] - 2s 194ms/step - loss: 3.2694 - participant_output_loss: 1.2016 - command_output_loss: 2.0672 - command_output_1_loss: 4.3736e-04 - participant_output_1_loss: 1.9650e-04 - participant_output_accuracy: 0.5633 - command_output_accuracy: 0.5617 - command_output_1_accuracy: 0.0017 - participant_output_1_accuracy: 0.0950 - val_loss: 3.2145 - val_participant_output_loss: 1.1982 - val_command_output_loss: 2.0160 - val_command_output_1_loss: 2.4836e-04 - val_participant_output_1_loss: 9.8343e-05 - val_participant_output_accuracy: 0.5580 - val_command_output_accuracy: 0.6372 - val_command_output_1_accuracy: 0.0552 - val_participant_output_1_accuracy: 0.6280\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 2s 196ms/step - loss: 2.9771 - participant_output_loss: 0.9984 - command_output_loss: 1.9784 - command_output_1_loss: 2.2852e-04 - participant_output_1_loss: 7.8073e-05 - participant_output_accuracy: 0.6900 - command_output_accuracy: 0.6833 - command_output_1_accuracy: 0.2917 - participant_output_1_accuracy: 0.2550 - val_loss: 2.9543 - val_participant_output_loss: 1.0078 - val_command_output_loss: 1.9463 - val_command_output_1_loss: 1.5514e-04 - val_participant_output_1_loss: 5.7865e-05 - val_participant_output_accuracy: 0.6998 - val_command_output_accuracy: 0.6041 - val_command_output_1_accuracy: 0.0037 - val_participant_output_1_accuracy: 0.1473\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 2s 185ms/step - loss: 2.7104 - participant_output_loss: 0.8157 - command_output_loss: 1.8946 - command_output_1_loss: 7.3887e-05 - participant_output_1_loss: 4.5223e-05 - participant_output_accuracy: 0.8183 - command_output_accuracy: 0.7600 - command_output_1_accuracy: 0.0000e+00 - participant_output_1_accuracy: 0.3100 - val_loss: 2.7170 - val_participant_output_loss: 0.8493 - val_command_output_loss: 1.8676 - val_command_output_1_loss: 2.8069e-05 - val_participant_output_1_loss: 4.9385e-05 - val_participant_output_accuracy: 0.8361 - val_command_output_accuracy: 0.8158 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.0700\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 2s 195ms/step - loss: 2.5147 - participant_output_loss: 0.7017 - command_output_loss: 1.8129 - command_output_1_loss: 4.8256e-05 - participant_output_1_loss: 4.1965e-05 - participant_output_accuracy: 0.8900 - command_output_accuracy: 0.8867 - command_output_1_accuracy: 0.0000e+00 - participant_output_1_accuracy: 0.2067 - val_loss: 2.5568 - val_participant_output_loss: 0.7643 - val_command_output_loss: 1.7925 - val_command_output_1_loss: 5.5058e-05 - val_participant_output_1_loss: 3.5940e-05 - val_participant_output_accuracy: 0.8453 - val_command_output_accuracy: 0.8600 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.2781\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 2s 181ms/step - loss: 2.3304 - participant_output_loss: 0.5975 - command_output_loss: 1.7329 - command_output_1_loss: 5.1661e-05 - participant_output_1_loss: 2.9631e-05 - participant_output_accuracy: 0.9133 - command_output_accuracy: 0.9250 - command_output_1_accuracy: 0.0050 - participant_output_1_accuracy: 0.2150 - val_loss: 2.3972 - val_participant_output_loss: 0.6739 - val_command_output_loss: 1.7233 - val_command_output_1_loss: 4.2724e-05 - val_participant_output_1_loss: 3.2389e-05 - val_participant_output_accuracy: 0.9061 - val_command_output_accuracy: 0.8840 - val_command_output_1_accuracy: 0.1234 - val_participant_output_1_accuracy: 0.2891\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 2s 194ms/step - loss: 2.1820 - participant_output_loss: 0.5262 - command_output_loss: 1.6557 - command_output_1_loss: 4.7178e-05 - participant_output_1_loss: 2.9417e-05 - participant_output_accuracy: 0.9567 - command_output_accuracy: 0.9500 - command_output_1_accuracy: 0.0400 - participant_output_1_accuracy: 0.2167 - val_loss: 2.2562 - val_participant_output_loss: 0.6091 - val_command_output_loss: 1.6470 - val_command_output_1_loss: 3.7232e-05 - val_participant_output_1_loss: 3.4159e-05 - val_participant_output_accuracy: 0.9061 - val_command_output_accuracy: 0.8877 - val_command_output_1_accuracy: 0.0221 - val_participant_output_1_accuracy: 0.2063\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 2s 193ms/step - loss: 2.0423 - participant_output_loss: 0.4743 - command_output_loss: 1.5679 - command_output_1_loss: 4.2805e-05 - participant_output_1_loss: 3.1436e-05 - participant_output_accuracy: 0.9617 - command_output_accuracy: 0.9750 - command_output_1_accuracy: 0.0067 - participant_output_1_accuracy: 0.1783 - val_loss: 2.1053 - val_participant_output_loss: 0.5423 - val_command_output_loss: 1.5629 - val_command_output_1_loss: 5.1894e-05 - val_participant_output_1_loss: 3.5741e-05 - val_participant_output_accuracy: 0.9300 - val_command_output_accuracy: 0.9153 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.0866\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 2s 190ms/step - loss: 1.9125 - participant_output_loss: 0.4225 - command_output_loss: 1.4900 - command_output_1_loss: 5.4663e-05 - participant_output_1_loss: 3.0685e-05 - participant_output_accuracy: 0.9733 - command_output_accuracy: 0.9667 - command_output_1_accuracy: 0.0017 - participant_output_1_accuracy: 0.2300 - val_loss: 2.0111 - val_participant_output_loss: 0.5231 - val_command_output_loss: 1.4879 - val_command_output_1_loss: 2.4881e-05 - val_participant_output_1_loss: 3.3321e-05 - val_participant_output_accuracy: 0.9319 - val_command_output_accuracy: 0.9319 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.1436\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 2s 206ms/step - loss: 1.7759 - participant_output_loss: 0.3713 - command_output_loss: 1.4046 - command_output_1_loss: 2.8225e-05 - participant_output_1_loss: 2.9400e-05 - participant_output_accuracy: 0.9833 - command_output_accuracy: 0.9900 - command_output_1_accuracy: 0.0750 - participant_output_1_accuracy: 0.1550 - val_loss: 1.8649 - val_participant_output_loss: 0.4518 - val_command_output_loss: 1.4130 - val_command_output_1_loss: 5.9406e-05 - val_participant_output_1_loss: 3.2635e-05 - val_participant_output_accuracy: 0.9632 - val_command_output_accuracy: 0.9337 - val_command_output_1_accuracy: 0.1731 - val_participant_output_1_accuracy: 0.2910\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 3s 269ms/step - loss: 1.6616 - participant_output_loss: 0.3350 - command_output_loss: 1.3265 - command_output_1_loss: 6.7890e-05 - participant_output_1_loss: 2.6661e-05 - participant_output_accuracy: 0.9883 - command_output_accuracy: 0.9900 - command_output_1_accuracy: 0.1467 - participant_output_1_accuracy: 0.1367 - val_loss: 1.7769 - val_participant_output_loss: 0.4316 - val_command_output_loss: 1.3452 - val_command_output_1_loss: 5.2806e-05 - val_participant_output_1_loss: 3.1477e-05 - val_participant_output_accuracy: 0.9650 - val_command_output_accuracy: 0.9411 - val_command_output_1_accuracy: 0.0571 - val_participant_output_1_accuracy: 0.2818\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 2s 185ms/step - loss: 1.5544 - participant_output_loss: 0.3053 - command_output_loss: 1.2490 - command_output_1_loss: 4.5854e-05 - participant_output_1_loss: 2.5494e-05 - participant_output_accuracy: 0.9900 - command_output_accuracy: 0.9933 - command_output_1_accuracy: 0.0400 - participant_output_1_accuracy: 0.1800 - val_loss: 1.6736 - val_participant_output_loss: 0.3994 - val_command_output_loss: 1.2741 - val_command_output_1_loss: 5.3116e-05 - val_participant_output_1_loss: 2.9623e-05 - val_participant_output_accuracy: 0.9650 - val_command_output_accuracy: 0.9503 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.2228\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 2s 154ms/step - loss: 1.4475 - participant_output_loss: 0.2719 - command_output_loss: 1.1755 - command_output_1_loss: 5.4615e-05 - participant_output_1_loss: 2.4349e-05 - participant_output_accuracy: 0.9933 - command_output_accuracy: 0.9967 - command_output_1_accuracy: 0.0000e+00 - participant_output_1_accuracy: 0.1833 - val_loss: 1.5855 - val_participant_output_loss: 0.3830 - val_command_output_loss: 1.2025 - val_command_output_1_loss: 6.1694e-05 - val_participant_output_1_loss: 2.8554e-05 - val_participant_output_accuracy: 0.9632 - val_command_output_accuracy: 0.9503 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.2320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10\n",
      "10/10 [==============================] - 2s 191ms/step - loss: 1.3478 - participant_output_loss: 0.2467 - command_output_loss: 1.1010 - command_output_1_loss: 4.2683e-05 - participant_output_1_loss: 2.2823e-05 - participant_output_accuracy: 0.9950 - command_output_accuracy: 0.9950 - command_output_1_accuracy: 0.0000e+00 - participant_output_1_accuracy: 0.1900 - val_loss: 1.4922 - val_participant_output_loss: 0.3531 - val_command_output_loss: 1.1390 - val_command_output_1_loss: 3.2416e-05 - val_participant_output_1_loss: 2.7605e-05 - val_participant_output_accuracy: 0.9687 - val_command_output_accuracy: 0.9484 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.2044\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 2s 162ms/step - loss: 1.2597 - participant_output_loss: 0.2243 - command_output_loss: 1.0353 - command_output_1_loss: 2.9188e-05 - participant_output_1_loss: 2.2098e-05 - participant_output_accuracy: 0.9967 - command_output_accuracy: 0.9967 - command_output_1_accuracy: 0.0283 - participant_output_1_accuracy: 0.1800 - val_loss: 1.4105 - val_participant_output_loss: 0.3302 - val_command_output_loss: 1.0803 - val_command_output_1_loss: 2.9484e-05 - val_participant_output_1_loss: 2.7657e-05 - val_participant_output_accuracy: 0.9576 - val_command_output_accuracy: 0.9484 - val_command_output_1_accuracy: 0.3941 - val_participant_output_1_accuracy: 0.1768\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 2s 192ms/step - loss: 1.1711 - participant_output_loss: 0.2023 - command_output_loss: 0.9687 - command_output_1_loss: 5.3799e-05 - participant_output_1_loss: 2.1514e-05 - participant_output_accuracy: 0.9983 - command_output_accuracy: 0.9967 - command_output_1_accuracy: 0.3800 - participant_output_1_accuracy: 0.1833 - val_loss: 1.3341 - val_participant_output_loss: 0.3130 - val_command_output_loss: 1.0210 - val_command_output_1_loss: 4.8143e-05 - val_participant_output_1_loss: 2.6459e-05 - val_participant_output_accuracy: 0.9650 - val_command_output_accuracy: 0.9576 - val_command_output_1_accuracy: 0.0755 - val_participant_output_1_accuracy: 0.1842\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 2s 199ms/step - loss: 1.0915 - participant_output_loss: 0.1857 - command_output_loss: 0.9058 - command_output_1_loss: 3.9715e-05 - participant_output_1_loss: 2.0463e-05 - participant_output_accuracy: 0.9983 - command_output_accuracy: 0.9983 - command_output_1_accuracy: 0.0183 - participant_output_1_accuracy: 0.1950 - val_loss: 1.2580 - val_participant_output_loss: 0.2944 - val_command_output_loss: 0.9636 - val_command_output_1_loss: 2.8145e-05 - val_participant_output_1_loss: 2.6381e-05 - val_participant_output_accuracy: 0.9669 - val_command_output_accuracy: 0.9595 - val_command_output_1_accuracy: 0.0018 - val_participant_output_1_accuracy: 0.1639\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 1s 149ms/step - loss: 1.0152 - participant_output_loss: 0.1716 - command_output_loss: 0.8436 - command_output_1_loss: 2.4372e-05 - participant_output_1_loss: 1.9466e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9983 - command_output_1_accuracy: 0.0033 - participant_output_1_accuracy: 0.1833 - val_loss: 1.1879 - val_participant_output_loss: 0.2787 - val_command_output_loss: 0.9091 - val_command_output_1_loss: 2.6114e-05 - val_participant_output_1_loss: 2.5804e-05 - val_participant_output_accuracy: 0.9669 - val_command_output_accuracy: 0.9576 - val_command_output_1_accuracy: 0.0018 - val_participant_output_1_accuracy: 0.1436\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 2s 155ms/step - loss: 0.9429 - participant_output_loss: 0.1552 - command_output_loss: 0.7876 - command_output_1_loss: 2.7242e-05 - participant_output_1_loss: 1.8249e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9983 - command_output_1_accuracy: 0.0283 - participant_output_1_accuracy: 0.1683 - val_loss: 1.1298 - val_participant_output_loss: 0.2637 - val_command_output_loss: 0.8660 - val_command_output_1_loss: 2.6905e-05 - val_participant_output_1_loss: 2.4685e-05 - val_participant_output_accuracy: 0.9669 - val_command_output_accuracy: 0.9558 - val_command_output_1_accuracy: 0.0829 - val_participant_output_1_accuracy: 0.2284\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 1s 143ms/step - loss: 0.8736 - participant_output_loss: 0.1400 - command_output_loss: 0.7335 - command_output_1_loss: 3.2041e-05 - participant_output_1_loss: 1.7044e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9983 - command_output_1_accuracy: 0.2100 - participant_output_1_accuracy: 0.1533 - val_loss: 1.0619 - val_participant_output_loss: 0.2477 - val_command_output_loss: 0.8141 - val_command_output_1_loss: 4.1044e-05 - val_participant_output_1_loss: 2.4326e-05 - val_participant_output_accuracy: 0.9705 - val_command_output_accuracy: 0.9540 - val_command_output_1_accuracy: 0.1473 - val_participant_output_1_accuracy: 0.2615\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 4s 358ms/step - loss: 3.6830 - participant_output_loss: 1.4664 - command_output_loss: 2.2099 - command_output_1_loss: 7.6094e-04 - participant_output_1_loss: 0.0058 - participant_output_accuracy: 0.4400 - command_output_accuracy: 0.3533 - command_output_1_accuracy: 0.0417 - participant_output_1_accuracy: 0.1417 - val_loss: 3.1987 - val_participant_output_loss: 1.2118 - val_command_output_loss: 1.9866 - val_command_output_1_loss: 8.1844e-05 - val_participant_output_1_loss: 2.3479e-04 - val_participant_output_accuracy: 0.5875 - val_command_output_accuracy: 0.5138 - val_command_output_1_accuracy: 0.0018 - val_participant_output_1_accuracy: 0.0147\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 2s 199ms/step - loss: 2.9138 - participant_output_loss: 1.0027 - command_output_loss: 1.9108 - command_output_1_loss: 8.4379e-05 - participant_output_1_loss: 1.7523e-04 - participant_output_accuracy: 0.7167 - command_output_accuracy: 0.6500 - command_output_1_accuracy: 0.0000e+00 - participant_output_1_accuracy: 0.1350 - val_loss: 2.8339 - val_participant_output_loss: 0.9817 - val_command_output_loss: 1.8520 - val_command_output_1_loss: 7.6776e-05 - val_participant_output_1_loss: 1.1379e-04 - val_participant_output_accuracy: 0.7845 - val_command_output_accuracy: 0.7643 - val_command_output_1_accuracy: 0.0018 - val_participant_output_1_accuracy: 0.0829\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 2s 187ms/step - loss: 2.6121 - participant_output_loss: 0.8298 - command_output_loss: 1.7821 - command_output_1_loss: 8.4763e-05 - participant_output_1_loss: 8.9924e-05 - participant_output_accuracy: 0.8317 - command_output_accuracy: 0.8067 - command_output_1_accuracy: 0.0067 - participant_output_1_accuracy: 0.1017 - val_loss: 2.5691 - val_participant_output_loss: 0.8235 - val_command_output_loss: 1.7454 - val_command_output_1_loss: 6.9609e-05 - val_participant_output_1_loss: 7.1562e-05 - val_participant_output_accuracy: 0.8674 - val_command_output_accuracy: 0.8085 - val_command_output_1_accuracy: 0.2781 - val_participant_output_1_accuracy: 0.2007\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 2s 205ms/step - loss: 2.3582 - participant_output_loss: 0.6939 - command_output_loss: 1.6641 - command_output_1_loss: 4.8869e-05 - participant_output_1_loss: 6.1053e-05 - participant_output_accuracy: 0.8983 - command_output_accuracy: 0.8983 - command_output_1_accuracy: 0.2550 - participant_output_1_accuracy: 0.1567 - val_loss: 2.3579 - val_participant_output_loss: 0.7241 - val_command_output_loss: 1.6337 - val_command_output_1_loss: 4.4271e-05 - val_participant_output_1_loss: 5.3838e-05 - val_participant_output_accuracy: 0.9134 - val_command_output_accuracy: 0.8490 - val_command_output_1_accuracy: 0.0368 - val_participant_output_1_accuracy: 0.1676\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 2s 228ms/step - loss: 2.1365 - participant_output_loss: 0.5824 - command_output_loss: 1.5540 - command_output_1_loss: 6.9583e-05 - participant_output_1_loss: 4.6013e-05 - participant_output_accuracy: 0.9550 - command_output_accuracy: 0.9283 - command_output_1_accuracy: 0.0067 - participant_output_1_accuracy: 0.1617 - val_loss: 2.1565 - val_participant_output_loss: 0.6256 - val_command_output_loss: 1.5308 - val_command_output_1_loss: 7.3500e-05 - val_participant_output_1_loss: 4.9157e-05 - val_participant_output_accuracy: 0.9355 - val_command_output_accuracy: 0.8729 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.1510\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10\n",
      "10/10 [==============================] - 2s 198ms/step - loss: 1.9540 - participant_output_loss: 0.5047 - command_output_loss: 1.4491 - command_output_1_loss: 6.8819e-05 - participant_output_1_loss: 4.3230e-05 - participant_output_accuracy: 0.9650 - command_output_accuracy: 0.9417 - command_output_1_accuracy: 0.0033 - participant_output_1_accuracy: 0.2033 - val_loss: 2.0207 - val_participant_output_loss: 0.5781 - val_command_output_loss: 1.4425 - val_command_output_1_loss: 4.8650e-05 - val_participant_output_1_loss: 4.5903e-05 - val_participant_output_accuracy: 0.9392 - val_command_output_accuracy: 0.9134 - val_command_output_1_accuracy: 0.0368 - val_participant_output_1_accuracy: 0.1934\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 2s 194ms/step - loss: 1.8045 - participant_output_loss: 0.4545 - command_output_loss: 1.3499 - command_output_1_loss: 4.1949e-05 - participant_output_1_loss: 4.0141e-05 - participant_output_accuracy: 0.9750 - command_output_accuracy: 0.9683 - command_output_1_accuracy: 0.1683 - participant_output_1_accuracy: 0.1450 - val_loss: 1.8915 - val_participant_output_loss: 0.5420 - val_command_output_loss: 1.3494 - val_command_output_1_loss: 3.6569e-05 - val_participant_output_1_loss: 4.5210e-05 - val_participant_output_accuracy: 0.9300 - val_command_output_accuracy: 0.9319 - val_command_output_1_accuracy: 0.1105 - val_participant_output_1_accuracy: 0.2468\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 2s 203ms/step - loss: 1.6469 - participant_output_loss: 0.3975 - command_output_loss: 1.2493 - command_output_1_loss: 3.4953e-05 - participant_output_1_loss: 3.5929e-05 - participant_output_accuracy: 0.9817 - command_output_accuracy: 0.9750 - command_output_1_accuracy: 0.0717 - participant_output_1_accuracy: 0.2350 - val_loss: 1.7578 - val_participant_output_loss: 0.4976 - val_command_output_loss: 1.2601 - val_command_output_1_loss: 3.1888e-05 - val_participant_output_1_loss: 4.4942e-05 - val_participant_output_accuracy: 0.9411 - val_command_output_accuracy: 0.9337 - val_command_output_1_accuracy: 0.0479 - val_participant_output_1_accuracy: 0.1400\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 2s 188ms/step - loss: 1.5086 - participant_output_loss: 0.3548 - command_output_loss: 1.1538 - command_output_1_loss: 3.4030e-05 - participant_output_1_loss: 3.4885e-05 - participant_output_accuracy: 0.9850 - command_output_accuracy: 0.9867 - command_output_1_accuracy: 0.0033 - participant_output_1_accuracy: 0.1867 - val_loss: 1.6186 - val_participant_output_loss: 0.4413 - val_command_output_loss: 1.1771 - val_command_output_1_loss: 3.2734e-05 - val_participant_output_1_loss: 4.4430e-05 - val_participant_output_accuracy: 0.9595 - val_command_output_accuracy: 0.9540 - val_command_output_1_accuracy: 0.0589 - val_participant_output_1_accuracy: 0.2339\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 2s 211ms/step - loss: 1.3753 - participant_output_loss: 0.3139 - command_output_loss: 1.0614 - command_output_1_loss: 3.4483e-05 - participant_output_1_loss: 3.3535e-05 - participant_output_accuracy: 0.9917 - command_output_accuracy: 0.9900 - command_output_1_accuracy: 0.2050 - participant_output_1_accuracy: 0.1717 - val_loss: 1.4991 - val_participant_output_loss: 0.4068 - val_command_output_loss: 1.0923 - val_command_output_1_loss: 4.4078e-05 - val_participant_output_1_loss: 4.3566e-05 - val_participant_output_accuracy: 0.9669 - val_command_output_accuracy: 0.9521 - val_command_output_1_accuracy: 0.3959 - val_participant_output_1_accuracy: 0.1621\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 3s 266ms/step - loss: 1.2631 - participant_output_loss: 0.2929 - command_output_loss: 0.9702 - command_output_1_loss: 4.7476e-05 - participant_output_1_loss: 3.2024e-05 - participant_output_accuracy: 0.9900 - command_output_accuracy: 0.9917 - command_output_1_accuracy: 0.3017 - participant_output_1_accuracy: 0.1850 - val_loss: 1.4102 - val_participant_output_loss: 0.3961 - val_command_output_loss: 1.0141 - val_command_output_1_loss: 4.4381e-05 - val_participant_output_1_loss: 4.3185e-05 - val_participant_output_accuracy: 0.9650 - val_command_output_accuracy: 0.9558 - val_command_output_1_accuracy: 0.1823 - val_participant_output_1_accuracy: 0.1713\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 1s 144ms/step - loss: 1.1491 - participant_output_loss: 0.2635 - command_output_loss: 0.8856 - command_output_1_loss: 3.8432e-05 - participant_output_1_loss: 3.0534e-05 - participant_output_accuracy: 0.9983 - command_output_accuracy: 0.9933 - command_output_1_accuracy: 0.0933 - participant_output_1_accuracy: 0.1850 - val_loss: 1.2949 - val_participant_output_loss: 0.3607 - val_command_output_loss: 0.9341 - val_command_output_1_loss: 3.8936e-05 - val_participant_output_1_loss: 4.1987e-05 - val_participant_output_accuracy: 0.9650 - val_command_output_accuracy: 0.9540 - val_command_output_1_accuracy: 0.0129 - val_participant_output_1_accuracy: 0.2136\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 2s 201ms/step - loss: 1.0420 - participant_output_loss: 0.2322 - command_output_loss: 0.8097 - command_output_1_loss: 3.6964e-05 - participant_output_1_loss: 2.9488e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9967 - command_output_1_accuracy: 0.0750 - participant_output_1_accuracy: 0.1933 - val_loss: 1.2055 - val_participant_output_loss: 0.3347 - val_command_output_loss: 0.8706 - val_command_output_1_loss: 3.4556e-05 - val_participant_output_1_loss: 4.3368e-05 - val_participant_output_accuracy: 0.9687 - val_command_output_accuracy: 0.9576 - val_command_output_1_accuracy: 0.0129 - val_participant_output_1_accuracy: 0.1105\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 1s 142ms/step - loss: 0.9472 - participant_output_loss: 0.2108 - command_output_loss: 0.7363 - command_output_1_loss: 4.3074e-05 - participant_output_1_loss: 2.8833e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9983 - command_output_1_accuracy: 0.0017 - participant_output_1_accuracy: 0.1800 - val_loss: 1.1261 - val_participant_output_loss: 0.3106 - val_command_output_loss: 0.8155 - val_command_output_1_loss: 3.5862e-05 - val_participant_output_1_loss: 4.1338e-05 - val_participant_output_accuracy: 0.9650 - val_command_output_accuracy: 0.9576 - val_command_output_1_accuracy: 0.0092 - val_participant_output_1_accuracy: 0.1584\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 2s 160ms/step - loss: 0.8673 - participant_output_loss: 0.1912 - command_output_loss: 0.6760 - command_output_1_loss: 3.4436e-05 - participant_output_1_loss: 2.7448e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.1250 - participant_output_1_accuracy: 0.1683 - val_loss: 1.0359 - val_participant_output_loss: 0.2858 - val_command_output_loss: 0.7500 - val_command_output_1_loss: 3.8977e-05 - val_participant_output_1_loss: 4.0966e-05 - val_participant_output_accuracy: 0.9669 - val_command_output_accuracy: 0.9576 - val_command_output_1_accuracy: 0.5359 - val_participant_output_1_accuracy: 0.1750\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 1s 143ms/step - loss: 0.7830 - participant_output_loss: 0.1696 - command_output_loss: 0.6133 - command_output_1_loss: 3.7468e-05 - participant_output_1_loss: 2.6874e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9983 - command_output_1_accuracy: 0.3883 - participant_output_1_accuracy: 0.1817 - val_loss: 0.9751 - val_participant_output_loss: 0.2811 - val_command_output_loss: 0.6939 - val_command_output_1_loss: 3.9578e-05 - val_participant_output_1_loss: 4.1276e-05 - val_participant_output_accuracy: 0.9669 - val_command_output_accuracy: 0.9595 - val_command_output_1_accuracy: 0.0516 - val_participant_output_1_accuracy: 0.1473\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 2s 199ms/step - loss: 0.7146 - participant_output_loss: 0.1567 - command_output_loss: 0.5579 - command_output_1_loss: 5.4649e-05 - participant_output_1_loss: 2.6738e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.1067 - participant_output_1_accuracy: 0.1567 - val_loss: 0.9215 - val_participant_output_loss: 0.2748 - val_command_output_loss: 0.6466 - val_command_output_1_loss: 6.5679e-05 - val_participant_output_1_loss: 4.0673e-05 - val_participant_output_accuracy: 0.9669 - val_command_output_accuracy: 0.9613 - val_command_output_1_accuracy: 0.0939 - val_participant_output_1_accuracy: 0.2173\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10\n",
      "10/10 [==============================] - 1s 144ms/step - loss: 0.6542 - participant_output_loss: 0.1460 - command_output_loss: 0.5082 - command_output_1_loss: 4.9830e-05 - participant_output_1_loss: 2.5902e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0333 - participant_output_1_accuracy: 0.1633 - val_loss: 0.8530 - val_participant_output_loss: 0.2492 - val_command_output_loss: 0.6038 - val_command_output_1_loss: 3.0696e-05 - val_participant_output_1_loss: 4.0736e-05 - val_participant_output_accuracy: 0.9687 - val_command_output_accuracy: 0.9576 - val_command_output_1_accuracy: 0.0092 - val_participant_output_1_accuracy: 0.1934\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 2s 197ms/step - loss: 0.5949 - participant_output_loss: 0.1344 - command_output_loss: 0.4604 - command_output_1_loss: 2.8165e-05 - participant_output_1_loss: 2.5142e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0067 - participant_output_1_accuracy: 0.1783 - val_loss: 0.7912 - val_participant_output_loss: 0.2369 - val_command_output_loss: 0.5542 - val_command_output_1_loss: 3.0580e-05 - val_participant_output_1_loss: 4.0306e-05 - val_participant_output_accuracy: 0.9705 - val_command_output_accuracy: 0.9650 - val_command_output_1_accuracy: 0.0221 - val_participant_output_1_accuracy: 0.1786\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 1s 144ms/step - loss: 0.5437 - participant_output_loss: 0.1250 - command_output_loss: 0.4187 - command_output_1_loss: 3.0775e-05 - participant_output_1_loss: 2.3968e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.2483 - participant_output_1_accuracy: 0.1733 - val_loss: 0.7494 - val_participant_output_loss: 0.2342 - val_command_output_loss: 0.5151 - val_command_output_1_loss: 4.0595e-05 - val_participant_output_1_loss: 3.9240e-05 - val_participant_output_accuracy: 0.9669 - val_command_output_accuracy: 0.9669 - val_command_output_1_accuracy: 0.7348 - val_participant_output_1_accuracy: 0.1768\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 3s 339ms/step - loss: 3.6709 - participant_output_loss: 1.4694 - command_output_loss: 2.1963 - command_output_1_loss: 4.2019e-04 - participant_output_1_loss: 0.0048 - participant_output_accuracy: 0.3917 - command_output_accuracy: 0.2650 - command_output_1_accuracy: 0.0583 - participant_output_1_accuracy: 0.1833 - val_loss: 3.2276 - val_participant_output_loss: 1.2614 - val_command_output_loss: 1.9655 - val_command_output_1_loss: 6.2365e-05 - val_participant_output_1_loss: 5.8312e-04 - val_participant_output_accuracy: 0.4604 - val_command_output_accuracy: 0.5930 - val_command_output_1_accuracy: 0.7403 - val_participant_output_1_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 2s 187ms/step - loss: 2.9296 - participant_output_loss: 1.0571 - command_output_loss: 1.8720 - command_output_1_loss: 8.5815e-05 - participant_output_1_loss: 4.1397e-04 - participant_output_accuracy: 0.6483 - command_output_accuracy: 0.7367 - command_output_1_accuracy: 0.4017 - participant_output_1_accuracy: 0.0950 - val_loss: 2.8312 - val_participant_output_loss: 1.0175 - val_command_output_loss: 1.8133 - val_command_output_1_loss: 7.5801e-05 - val_participant_output_1_loss: 2.9327e-04 - val_participant_output_accuracy: 0.6593 - val_command_output_accuracy: 0.6906 - val_command_output_1_accuracy: 0.0239 - val_participant_output_1_accuracy: 0.9374\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 2s 196ms/step - loss: 2.5725 - participant_output_loss: 0.8335 - command_output_loss: 1.7387 - command_output_1_loss: 7.2079e-05 - participant_output_1_loss: 1.6501e-04 - participant_output_accuracy: 0.7900 - command_output_accuracy: 0.7767 - command_output_1_accuracy: 0.0050 - participant_output_1_accuracy: 0.3767 - val_loss: 2.5118 - val_participant_output_loss: 0.8063 - val_command_output_loss: 1.7052 - val_command_output_1_loss: 4.5893e-05 - val_participant_output_1_loss: 1.2515e-04 - val_participant_output_accuracy: 0.7993 - val_command_output_accuracy: 0.7937 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.0221\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 2s 205ms/step - loss: 2.2659 - participant_output_loss: 0.6382 - command_output_loss: 1.6276 - command_output_1_loss: 4.9586e-05 - participant_output_1_loss: 9.0405e-05 - participant_output_accuracy: 0.8650 - command_output_accuracy: 0.8783 - command_output_1_accuracy: 0.0000e+00 - participant_output_1_accuracy: 0.0733 - val_loss: 2.2311 - val_participant_output_loss: 0.6365 - val_command_output_loss: 1.5944 - val_command_output_1_loss: 7.4779e-05 - val_participant_output_1_loss: 9.5554e-05 - val_participant_output_accuracy: 0.8748 - val_command_output_accuracy: 0.8987 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.6501\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 2s 200ms/step - loss: 1.9978 - participant_output_loss: 0.4880 - command_output_loss: 1.5096 - command_output_1_loss: 9.2738e-05 - participant_output_1_loss: 6.7114e-05 - participant_output_accuracy: 0.9317 - command_output_accuracy: 0.9400 - command_output_1_accuracy: 0.0067 - participant_output_1_accuracy: 0.3850 - val_loss: 2.0182 - val_participant_output_loss: 0.5260 - val_command_output_loss: 1.4919 - val_command_output_1_loss: 1.1373e-04 - val_participant_output_1_loss: 6.0430e-05 - val_participant_output_accuracy: 0.9134 - val_command_output_accuracy: 0.9024 - val_command_output_1_accuracy: 0.0405 - val_participant_output_1_accuracy: 0.1436\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 2s 204ms/step - loss: 1.7794 - participant_output_loss: 0.3748 - command_output_loss: 1.4045 - command_output_1_loss: 1.2368e-04 - participant_output_1_loss: 5.2600e-05 - participant_output_accuracy: 0.9600 - command_output_accuracy: 0.9500 - command_output_1_accuracy: 0.0117 - participant_output_1_accuracy: 0.1150 - val_loss: 1.8344 - val_participant_output_loss: 0.4414 - val_command_output_loss: 1.3929 - val_command_output_1_loss: 9.2259e-05 - val_participant_output_1_loss: 5.5997e-05 - val_participant_output_accuracy: 0.9374 - val_command_output_accuracy: 0.9190 - val_command_output_1_accuracy: 0.0055 - val_participant_output_1_accuracy: 0.2781\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 2s 205ms/step - loss: 1.5908 - participant_output_loss: 0.2979 - command_output_loss: 1.2929 - command_output_1_loss: 7.6677e-05 - participant_output_1_loss: 4.5625e-05 - participant_output_accuracy: 0.9750 - command_output_accuracy: 0.9717 - command_output_1_accuracy: 0.0817 - participant_output_1_accuracy: 0.2533 - val_loss: 1.6583 - val_participant_output_loss: 0.3652 - val_command_output_loss: 1.2929 - val_command_output_1_loss: 7.1225e-05 - val_participant_output_1_loss: 4.9600e-05 - val_participant_output_accuracy: 0.9521 - val_command_output_accuracy: 0.9282 - val_command_output_1_accuracy: 0.0663 - val_participant_output_1_accuracy: 0.2026\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 2s 211ms/step - loss: 1.4210 - participant_output_loss: 0.2361 - command_output_loss: 1.1848 - command_output_1_loss: 7.2599e-05 - participant_output_1_loss: 4.0419e-05 - participant_output_accuracy: 0.9850 - command_output_accuracy: 0.9783 - command_output_1_accuracy: 0.0317 - participant_output_1_accuracy: 0.1567 - val_loss: 1.5443 - val_participant_output_loss: 0.3444 - val_command_output_loss: 1.1998 - val_command_output_1_loss: 6.7971e-05 - val_participant_output_1_loss: 4.8770e-05 - val_participant_output_accuracy: 0.9576 - val_command_output_accuracy: 0.9521 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.2376\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 2s 202ms/step - loss: 1.2719 - participant_output_loss: 0.1878 - command_output_loss: 1.0839 - command_output_1_loss: 4.9596e-05 - participant_output_1_loss: 3.8523e-05 - participant_output_accuracy: 0.9917 - command_output_accuracy: 0.9883 - command_output_1_accuracy: 0.0650 - participant_output_1_accuracy: 0.2567 - val_loss: 1.3939 - val_participant_output_loss: 0.2913 - val_command_output_loss: 1.1024 - val_command_output_1_loss: 5.3857e-05 - val_participant_output_1_loss: 4.7567e-05 - val_participant_output_accuracy: 0.9613 - val_command_output_accuracy: 0.9558 - val_command_output_1_accuracy: 0.1087 - val_participant_output_1_accuracy: 0.1860\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10\n",
      "10/10 [==============================] - 2s 166ms/step - loss: 1.1324 - participant_output_loss: 0.1489 - command_output_loss: 0.9834 - command_output_1_loss: 6.4873e-05 - participant_output_1_loss: 3.6436e-05 - participant_output_accuracy: 0.9967 - command_output_accuracy: 0.9950 - command_output_1_accuracy: 0.0300 - participant_output_1_accuracy: 0.1817 - val_loss: 1.2673 - val_participant_output_loss: 0.2523 - val_command_output_loss: 1.0149 - val_command_output_1_loss: 5.7295e-05 - val_participant_output_1_loss: 4.7370e-05 - val_participant_output_accuracy: 0.9613 - val_command_output_accuracy: 0.9558 - val_command_output_1_accuracy: 0.0147 - val_participant_output_1_accuracy: 0.2173\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 3s 268ms/step - loss: 1.0174 - participant_output_loss: 0.1254 - command_output_loss: 0.8919 - command_output_1_loss: 5.8770e-05 - participant_output_1_loss: 3.5358e-05 - participant_output_accuracy: 0.9967 - command_output_accuracy: 0.9917 - command_output_1_accuracy: 0.0150 - participant_output_1_accuracy: 0.2217 - val_loss: 1.1582 - val_participant_output_loss: 0.2253 - val_command_output_loss: 0.9328 - val_command_output_1_loss: 4.8576e-05 - val_participant_output_1_loss: 4.6937e-05 - val_participant_output_accuracy: 0.9705 - val_command_output_accuracy: 0.9521 - val_command_output_1_accuracy: 0.1234 - val_participant_output_1_accuracy: 0.1731\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 2s 186ms/step - loss: 0.9114 - participant_output_loss: 0.1088 - command_output_loss: 0.8025 - command_output_1_loss: 4.7047e-05 - participant_output_1_loss: 3.3791e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9967 - command_output_1_accuracy: 0.2767 - participant_output_1_accuracy: 0.2267 - val_loss: 1.0597 - val_participant_output_loss: 0.2038 - val_command_output_loss: 0.8558 - val_command_output_1_loss: 3.9342e-05 - val_participant_output_1_loss: 4.6139e-05 - val_participant_output_accuracy: 0.9705 - val_command_output_accuracy: 0.9576 - val_command_output_1_accuracy: 0.2670 - val_participant_output_1_accuracy: 0.1750\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 2s 199ms/step - loss: 0.8135 - participant_output_loss: 0.0927 - command_output_loss: 0.7207 - command_output_1_loss: 3.9417e-05 - participant_output_1_loss: 3.2333e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9967 - command_output_1_accuracy: 0.0900 - participant_output_1_accuracy: 0.1900 - val_loss: 0.9816 - val_participant_output_loss: 0.1950 - val_command_output_loss: 0.7865 - val_command_output_1_loss: 3.5855e-05 - val_participant_output_1_loss: 4.6047e-05 - val_participant_output_accuracy: 0.9724 - val_command_output_accuracy: 0.9669 - val_command_output_1_accuracy: 0.0368 - val_participant_output_1_accuracy: 0.1989\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 1s 147ms/step - loss: 0.7277 - participant_output_loss: 0.0781 - command_output_loss: 0.6495 - command_output_1_loss: 3.1854e-05 - participant_output_1_loss: 3.1575e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9983 - command_output_1_accuracy: 0.0200 - participant_output_1_accuracy: 0.1933 - val_loss: 0.9005 - val_participant_output_loss: 0.1841 - val_command_output_loss: 0.7163 - val_command_output_1_loss: 3.5516e-05 - val_participant_output_1_loss: 4.4675e-05 - val_participant_output_accuracy: 0.9705 - val_command_output_accuracy: 0.9650 - val_command_output_1_accuracy: 0.0166 - val_participant_output_1_accuracy: 0.2265\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 2s 152ms/step - loss: 0.6508 - participant_output_loss: 0.0707 - command_output_loss: 0.5801 - command_output_1_loss: 3.3734e-05 - participant_output_1_loss: 2.9818e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0300 - participant_output_1_accuracy: 0.2117 - val_loss: 0.8328 - val_participant_output_loss: 0.1701 - val_command_output_loss: 0.6626 - val_command_output_1_loss: 3.8721e-05 - val_participant_output_1_loss: 4.3873e-05 - val_participant_output_accuracy: 0.9705 - val_command_output_accuracy: 0.9632 - val_command_output_1_accuracy: 0.1381 - val_participant_output_1_accuracy: 0.2081\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 1s 143ms/step - loss: 0.5813 - participant_output_loss: 0.0629 - command_output_loss: 0.5183 - command_output_1_loss: 3.3044e-05 - participant_output_1_loss: 2.8202e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9983 - command_output_1_accuracy: 0.1533 - participant_output_1_accuracy: 0.1950 - val_loss: 0.7785 - val_participant_output_loss: 0.1691 - val_command_output_loss: 0.6094 - val_command_output_1_loss: 2.8523e-05 - val_participant_output_1_loss: 4.2438e-05 - val_participant_output_accuracy: 0.9705 - val_command_output_accuracy: 0.9595 - val_command_output_1_accuracy: 0.1842 - val_participant_output_1_accuracy: 0.2007\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 2s 153ms/step - loss: 0.5189 - participant_output_loss: 0.0562 - command_output_loss: 0.4627 - command_output_1_loss: 2.9703e-05 - participant_output_1_loss: 2.6740e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.1883 - participant_output_1_accuracy: 0.2050 - val_loss: 0.7164 - val_participant_output_loss: 0.1540 - val_command_output_loss: 0.5623 - val_command_output_1_loss: 2.8971e-05 - val_participant_output_1_loss: 4.1483e-05 - val_participant_output_accuracy: 0.9724 - val_command_output_accuracy: 0.9613 - val_command_output_1_accuracy: 0.1179 - val_participant_output_1_accuracy: 0.1952\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 2s 183ms/step - loss: 0.4653 - participant_output_loss: 0.0507 - command_output_loss: 0.4145 - command_output_1_loss: 2.5340e-05 - participant_output_1_loss: 2.5666e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 1.0000 - command_output_1_accuracy: 0.0183 - participant_output_1_accuracy: 0.2000 - val_loss: 0.6684 - val_participant_output_loss: 0.1487 - val_command_output_loss: 0.5196 - val_command_output_1_loss: 2.7612e-05 - val_participant_output_1_loss: 4.1062e-05 - val_participant_output_accuracy: 0.9724 - val_command_output_accuracy: 0.9558 - val_command_output_1_accuracy: 0.0055 - val_participant_output_1_accuracy: 0.2376\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 4s 354ms/step - loss: 3.7131 - participant_output_loss: 1.4917 - command_output_loss: 2.2193 - command_output_1_loss: 6.5915e-04 - participant_output_1_loss: 0.0014 - participant_output_accuracy: 0.3867 - command_output_accuracy: 0.3050 - command_output_1_accuracy: 0.1800 - participant_output_1_accuracy: 0.2183 - val_loss: 3.2946 - val_participant_output_loss: 1.2911 - val_command_output_loss: 2.0030 - val_command_output_1_loss: 2.1583e-04 - val_participant_output_1_loss: 2.6212e-04 - val_participant_output_accuracy: 0.6169 - val_command_output_accuracy: 0.6519 - val_command_output_1_accuracy: 0.6703 - val_participant_output_1_accuracy: 0.0018\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 2s 189ms/step - loss: 2.9918 - participant_output_loss: 1.0913 - command_output_loss: 1.9002 - command_output_1_loss: 1.4384e-04 - participant_output_1_loss: 1.5993e-04 - participant_output_accuracy: 0.6500 - command_output_accuracy: 0.7367 - command_output_1_accuracy: 0.3183 - participant_output_1_accuracy: 0.2317 - val_loss: 2.8642 - val_participant_output_loss: 1.0313 - val_command_output_loss: 1.8327 - val_command_output_1_loss: 1.2824e-04 - val_participant_output_1_loss: 7.2209e-05 - val_participant_output_accuracy: 0.7569 - val_command_output_accuracy: 0.6832 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.3260\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 2s 185ms/step - loss: 2.6121 - participant_output_loss: 0.8549 - command_output_loss: 1.7570 - command_output_1_loss: 1.1452e-04 - participant_output_1_loss: 7.3237e-05 - participant_output_accuracy: 0.8000 - command_output_accuracy: 0.7967 - command_output_1_accuracy: 0.0000e+00 - participant_output_1_accuracy: 0.0650 - val_loss: 2.5811 - val_participant_output_loss: 0.8631 - val_command_output_loss: 1.7179 - val_command_output_1_loss: 5.7659e-05 - val_participant_output_1_loss: 4.7660e-05 - val_participant_output_accuracy: 0.8250 - val_command_output_accuracy: 0.7956 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.1621\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10\n",
      "10/10 [==============================] - 2s 184ms/step - loss: 2.3154 - participant_output_loss: 0.6805 - command_output_loss: 1.6349 - command_output_1_loss: 5.6716e-05 - participant_output_1_loss: 4.6857e-05 - participant_output_accuracy: 0.8900 - command_output_accuracy: 0.8717 - command_output_1_accuracy: 0.0017 - participant_output_1_accuracy: 0.3033 - val_loss: 2.3073 - val_participant_output_loss: 0.7046 - val_command_output_loss: 1.6026 - val_command_output_1_loss: 6.6265e-05 - val_participant_output_1_loss: 4.4636e-05 - val_participant_output_accuracy: 0.8858 - val_command_output_accuracy: 0.8766 - val_command_output_1_accuracy: 0.0037 - val_participant_output_1_accuracy: 0.2376\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 2s 192ms/step - loss: 2.0707 - participant_output_loss: 0.5479 - command_output_loss: 1.5227 - command_output_1_loss: 7.4972e-05 - participant_output_1_loss: 3.6658e-05 - participant_output_accuracy: 0.9300 - command_output_accuracy: 0.9100 - command_output_1_accuracy: 0.0033 - participant_output_1_accuracy: 0.2183 - val_loss: 2.1033 - val_participant_output_loss: 0.5989 - val_command_output_loss: 1.5042 - val_command_output_1_loss: 9.0889e-05 - val_participant_output_1_loss: 3.5639e-05 - val_participant_output_accuracy: 0.9061 - val_command_output_accuracy: 0.8877 - val_command_output_1_accuracy: 0.0018 - val_participant_output_1_accuracy: 0.1934\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 2s 191ms/step - loss: 1.8661 - participant_output_loss: 0.4455 - command_output_loss: 1.4205 - command_output_1_loss: 9.6297e-05 - participant_output_1_loss: 3.0416e-05 - participant_output_accuracy: 0.9600 - command_output_accuracy: 0.9333 - command_output_1_accuracy: 0.0000e+00 - participant_output_1_accuracy: 0.1600 - val_loss: 1.9290 - val_participant_output_loss: 0.5216 - val_command_output_loss: 1.4073 - val_command_output_1_loss: 6.2366e-05 - val_participant_output_1_loss: 3.2419e-05 - val_participant_output_accuracy: 0.9411 - val_command_output_accuracy: 0.9282 - val_command_output_1_accuracy: 0.0018 - val_participant_output_1_accuracy: 0.3039\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 2s 200ms/step - loss: 1.6944 - participant_output_loss: 0.3801 - command_output_loss: 1.3142 - command_output_1_loss: 5.9773e-05 - participant_output_1_loss: 2.8744e-05 - participant_output_accuracy: 0.9717 - command_output_accuracy: 0.9517 - command_output_1_accuracy: 0.4417 - participant_output_1_accuracy: 0.2683 - val_loss: 1.7812 - val_participant_output_loss: 0.4692 - val_command_output_loss: 1.3120 - val_command_output_1_loss: 5.7879e-05 - val_participant_output_1_loss: 3.0152e-05 - val_participant_output_accuracy: 0.9466 - val_command_output_accuracy: 0.9355 - val_command_output_1_accuracy: 0.7624 - val_participant_output_1_accuracy: 0.2173\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 2s 184ms/step - loss: 1.5353 - participant_output_loss: 0.3215 - command_output_loss: 1.2137 - command_output_1_loss: 4.8475e-05 - participant_output_1_loss: 2.5900e-05 - participant_output_accuracy: 0.9817 - command_output_accuracy: 0.9650 - command_output_1_accuracy: 0.1817 - participant_output_1_accuracy: 0.2183 - val_loss: 1.6238 - val_participant_output_loss: 0.4111 - val_command_output_loss: 1.2126 - val_command_output_1_loss: 5.3927e-05 - val_participant_output_1_loss: 2.8462e-05 - val_participant_output_accuracy: 0.9613 - val_command_output_accuracy: 0.9300 - val_command_output_1_accuracy: 0.0000e+00 - val_participant_output_1_accuracy: 0.1455\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 2s 188ms/step - loss: 1.3932 - participant_output_loss: 0.2745 - command_output_loss: 1.1186 - command_output_1_loss: 4.8958e-05 - participant_output_1_loss: 2.4488e-05 - participant_output_accuracy: 0.9850 - command_output_accuracy: 0.9717 - command_output_1_accuracy: 0.0000e+00 - participant_output_1_accuracy: 0.1867 - val_loss: 1.5030 - val_participant_output_loss: 0.3685 - val_command_output_loss: 1.1344 - val_command_output_1_loss: 3.9055e-05 - val_participant_output_1_loss: 2.7732e-05 - val_participant_output_accuracy: 0.9687 - val_command_output_accuracy: 0.9613 - val_command_output_1_accuracy: 0.0976 - val_participant_output_1_accuracy: 0.2136\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 1s 142ms/step - loss: 1.2637 - participant_output_loss: 0.2413 - command_output_loss: 1.0223 - command_output_1_loss: 5.0775e-05 - participant_output_1_loss: 2.3505e-05 - participant_output_accuracy: 0.9933 - command_output_accuracy: 0.9867 - command_output_1_accuracy: 0.1150 - participant_output_1_accuracy: 0.1567 - val_loss: 1.3810 - val_participant_output_loss: 0.3327 - val_command_output_loss: 1.0483 - val_command_output_1_loss: 5.7607e-05 - val_participant_output_1_loss: 2.7639e-05 - val_participant_output_accuracy: 0.9687 - val_command_output_accuracy: 0.9503 - val_command_output_1_accuracy: 0.1436 - val_participant_output_1_accuracy: 0.1934\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 3s 263ms/step - loss: 1.1406 - participant_output_loss: 0.2116 - command_output_loss: 0.9290 - command_output_1_loss: 4.3409e-05 - participant_output_1_loss: 2.2445e-05 - participant_output_accuracy: 0.9933 - command_output_accuracy: 0.9900 - command_output_1_accuracy: 0.0567 - participant_output_1_accuracy: 0.2217 - val_loss: 1.2829 - val_participant_output_loss: 0.3039 - val_command_output_loss: 0.9789 - val_command_output_1_loss: 3.3418e-05 - val_participant_output_1_loss: 2.8165e-05 - val_participant_output_accuracy: 0.9705 - val_command_output_accuracy: 0.9503 - val_command_output_1_accuracy: 0.0258 - val_participant_output_1_accuracy: 0.1105\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 2s 190ms/step - loss: 1.0333 - participant_output_loss: 0.1839 - command_output_loss: 0.8493 - command_output_1_loss: 5.1309e-05 - participant_output_1_loss: 2.1544e-05 - participant_output_accuracy: 0.9983 - command_output_accuracy: 0.9900 - command_output_1_accuracy: 0.0350 - participant_output_1_accuracy: 0.1717 - val_loss: 1.1875 - val_participant_output_loss: 0.2829 - val_command_output_loss: 0.9045 - val_command_output_1_loss: 5.3917e-05 - val_participant_output_1_loss: 2.7404e-05 - val_participant_output_accuracy: 0.9742 - val_command_output_accuracy: 0.9558 - val_command_output_1_accuracy: 0.1657 - val_participant_output_1_accuracy: 0.1473\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 2s 178ms/step - loss: 0.9374 - participant_output_loss: 0.1659 - command_output_loss: 0.7714 - command_output_1_loss: 4.5829e-05 - participant_output_1_loss: 2.0682e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9950 - command_output_1_accuracy: 0.0867 - participant_output_1_accuracy: 0.2067 - val_loss: 1.0914 - val_participant_output_loss: 0.2672 - val_command_output_loss: 0.8241 - val_command_output_1_loss: 4.4357e-05 - val_participant_output_1_loss: 2.6048e-05 - val_participant_output_accuracy: 0.9761 - val_command_output_accuracy: 0.9613 - val_command_output_1_accuracy: 0.0037 - val_participant_output_1_accuracy: 0.1326\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 2s 152ms/step - loss: 0.8469 - participant_output_loss: 0.1491 - command_output_loss: 0.6978 - command_output_1_loss: 4.7741e-05 - participant_output_1_loss: 1.9422e-05 - participant_output_accuracy: 0.9983 - command_output_accuracy: 0.9950 - command_output_1_accuracy: 0.0067 - participant_output_1_accuracy: 0.1667 - val_loss: 1.0035 - val_participant_output_loss: 0.2479 - val_command_output_loss: 0.7555 - val_command_output_1_loss: 3.2425e-05 - val_participant_output_1_loss: 2.5816e-05 - val_participant_output_accuracy: 0.9742 - val_command_output_accuracy: 0.9632 - val_command_output_1_accuracy: 0.0258 - val_participant_output_1_accuracy: 0.1436\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 1s 142ms/step - loss: 0.7592 - participant_output_loss: 0.1327 - command_output_loss: 0.6264 - command_output_1_loss: 3.5803e-05 - participant_output_1_loss: 1.8766e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9983 - command_output_1_accuracy: 0.0400 - participant_output_1_accuracy: 0.1567 - val_loss: 0.9406 - val_participant_output_loss: 0.2393 - val_command_output_loss: 0.7012 - val_command_output_1_loss: 2.9949e-05 - val_participant_output_1_loss: 2.5735e-05 - val_participant_output_accuracy: 0.9669 - val_command_output_accuracy: 0.9558 - val_command_output_1_accuracy: 0.2063 - val_participant_output_1_accuracy: 0.1676\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10\n",
      "10/10 [==============================] - 2s 191ms/step - loss: 0.6869 - participant_output_loss: 0.1215 - command_output_loss: 0.5653 - command_output_1_loss: 3.8572e-05 - participant_output_1_loss: 1.8447e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9983 - command_output_1_accuracy: 0.1400 - participant_output_1_accuracy: 0.2033 - val_loss: 0.8678 - val_participant_output_loss: 0.2266 - val_command_output_loss: 0.6412 - val_command_output_1_loss: 5.3211e-05 - val_participant_output_1_loss: 2.5913e-05 - val_participant_output_accuracy: 0.9705 - val_command_output_accuracy: 0.9687 - val_command_output_1_accuracy: 0.3094 - val_participant_output_1_accuracy: 0.1252\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.6211 - participant_output_loss: 0.1115 - command_output_loss: 0.5095 - command_output_1_loss: 4.7410e-05 - participant_output_1_loss: 1.8056e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9983 - command_output_1_accuracy: 0.1367 - participant_output_1_accuracy: 0.1600 - val_loss: 0.8114 - val_participant_output_loss: 0.2142 - val_command_output_loss: 0.5971 - val_command_output_1_loss: 3.4152e-05 - val_participant_output_1_loss: 2.4762e-05 - val_participant_output_accuracy: 0.9724 - val_command_output_accuracy: 0.9650 - val_command_output_1_accuracy: 0.0442 - val_participant_output_1_accuracy: 0.1142\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 2s 150ms/step - loss: 0.5643 - participant_output_loss: 0.1037 - command_output_loss: 0.4605 - command_output_1_loss: 2.0983e-05 - participant_output_1_loss: 1.6247e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9983 - command_output_1_accuracy: 0.0800 - participant_output_1_accuracy: 0.1717 - val_loss: 0.7663 - val_participant_output_loss: 0.2101 - val_command_output_loss: 0.5561 - val_command_output_1_loss: 2.0016e-05 - val_participant_output_1_loss: 2.4094e-05 - val_participant_output_accuracy: 0.9687 - val_command_output_accuracy: 0.9595 - val_command_output_1_accuracy: 0.0516 - val_participant_output_1_accuracy: 0.1657\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 1s 143ms/step - loss: 0.5128 - participant_output_loss: 0.0963 - command_output_loss: 0.4165 - command_output_1_loss: 2.9714e-05 - participant_output_1_loss: 1.5373e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9983 - command_output_1_accuracy: 0.0117 - participant_output_1_accuracy: 0.1467 - val_loss: 0.7106 - val_participant_output_loss: 0.1989 - val_command_output_loss: 0.5116 - val_command_output_1_loss: 2.2679e-05 - val_participant_output_1_loss: 2.3148e-05 - val_participant_output_accuracy: 0.9724 - val_command_output_accuracy: 0.9613 - val_command_output_1_accuracy: 0.0166 - val_participant_output_1_accuracy: 0.1436\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 2s 166ms/step - loss: 0.4665 - participant_output_loss: 0.0884 - command_output_loss: 0.3781 - command_output_1_loss: 2.0208e-05 - participant_output_1_loss: 1.4576e-05 - participant_output_accuracy: 1.0000 - command_output_accuracy: 0.9983 - command_output_1_accuracy: 0.0117 - participant_output_1_accuracy: 0.2050 - val_loss: 0.6663 - val_participant_output_loss: 0.1880 - val_command_output_loss: 0.4783 - val_command_output_1_loss: 2.7438e-05 - val_participant_output_1_loss: 2.2824e-05 - val_participant_output_accuracy: 0.9724 - val_command_output_accuracy: 0.9632 - val_command_output_1_accuracy: 0.0092 - val_participant_output_1_accuracy: 0.1271\n"
     ]
    }
   ],
   "source": [
    "high_acc = 0\n",
    "for run in range(0,10):\n",
    "    # feature extraction layers\n",
    "    resnet_model = ResNet50(input_shape=(224, 224,3), include_top=False, weights=\"imagenet\")\n",
    "    for layer in resnet_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    d = resnet_model.output.shape[-1] # dimension of last layer\n",
    "\n",
    "    ###################### model 1 ###################### \n",
    "    layer_1_0 = tf.keras.layers.Dense(d,name=\"weight_1\")(resnet_model.output) #times weight before flatten\n",
    "    layer_1_1 = tf.keras.layers.Flatten(name='flatten_1')(layer_1_0)\n",
    "\n",
    "    Dense_1_1 = tf.keras.layers.Dense(shape_1_1, activation=actv_fun_1_1,name='fc1_1')\n",
    "    layer_1_2 = Dense_1_1(layer_1_1)\n",
    "    Dense_1_2 = tf.keras.layers.Dense(shape_1_2, activation=actv_fun_1_2,name='fc1_2')\n",
    "    layer_1_3 = Dense_1_2(layer_1_2)\n",
    "\n",
    "    Dense_1_3 = tf.keras.layers.Dense(train_number, activation='softmax' ,name='participant_output')\n",
    "    out_layer_1 = Dense_1_3(layer_1_3)\n",
    "\n",
    "    ###################### model 2 ###################### \n",
    "    layer_2_0 = tf.keras.layers.Dense(d,name=\"weight_2\")(resnet_model.output) #times weight before flatten\n",
    "    layer_2_1 = tf.keras.layers.Flatten(name='flatten_2')(layer_2_0)\n",
    "\n",
    "    Dense_2_1 = tf.keras.layers.Dense(shape_2_1, activation=actv_fun_2_1,name='fc2_1')\n",
    "    layer_2_2  = Dense_2_1(layer_2_1)\n",
    "    Dense_2_2 = tf.keras.layers.Dense(shape_2_2, activation=actv_fun_2_2,name='fc2_2')\n",
    "    layer_2_3  = Dense_2_2(layer_2_2)\n",
    "\n",
    "    Dense_2_3 = tf.keras.layers.Dense(10, activation='softmax',name='command_output')\n",
    "    out_layer_2 = Dense_2_3(layer_2_3)\n",
    "\n",
    "    ###################### model 1' ###################### \n",
    "    layer_1_2_  = Dense_2_1(layer_1_1)\n",
    "    layer_1_3_  = Dense_2_2(layer_1_2_)\n",
    "    out_layer_1_ = Dense_2_3(layer_1_3_)\n",
    "\n",
    "    ###################### model 1' ###################### \n",
    "    layer_2_2_  = Dense_1_1(layer_2_1)\n",
    "    layer_2_3_  = Dense_1_2(layer_2_2_)\n",
    "    out_layer_2_ = Dense_1_3(layer_2_3_)\n",
    "\n",
    "    resnet_model = tf.keras.Model(resnet_model.input, [out_layer_1,out_layer_2,out_layer_1_,out_layer_2_])\n",
    "\n",
    "\n",
    "    # resnet_model.summary() \n",
    "\n",
    "    w_1, w_2, w_1_, w_2_ = 1,1,1,1\n",
    "    ##################### training ############################\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "    callbacks = [MyEarlyStopping(monitor1 = 'val_' + resnet_model.layers[-1].name+'_accuracy',\n",
    "                                  monitor2 = 'val_' + resnet_model.layers[-2].name+'_accuracy',\n",
    "                                  patience=5,restore_best_weights=True)]\n",
    "    resnet_model.compile(optimizer=opt, loss=[\"categorical_crossentropy\",\"categorical_crossentropy\",\"mse\",\"mse\"],\n",
    "                         loss_weights=[w_1, w_2, w_1_, w_2_], metrics=['accuracy'])\n",
    "\n",
    "    \n",
    "    start = timeit.default_timer()\n",
    "       \n",
    "    history1 = resnet_model.fit(Train_Inputs, \n",
    "                           {resnet_model.layers[-2].name:Train_participant_class, \n",
    "                            resnet_model.layers[-1].name:Train_command_class,\n",
    "                            resnet_model.layers[-1].name+\"_1\":Train_command_uniform, \n",
    "                            resnet_model.layers[-2].name+\"_1\":Train_participant_uniform}, \n",
    "                            validation_data=(Val_Inputs,\n",
    "                                             {resnet_model.layers[-2].name:Val_participant_class,\n",
    "                                              resnet_model.layers[-1].name:Val_command_class,\n",
    "                                              resnet_model.layers[-1].name+\"_1\":Val_command_uniform,\n",
    "                                              resnet_model.layers[-2].name+\"_1\":Val_participant_uniform}), \n",
    "                           callbacks=callbacks,\n",
    "                           batch_size=64,\n",
    "                           epochs=10)\n",
    "    \n",
    "    for layer in resnet_model.layers[0:175]:\n",
    "        layer.trainable = True\n",
    "        \n",
    "    history2 = resnet_model.fit(Train_Inputs, \n",
    "                               {resnet_model.layers[-2].name:Train_participant_class, \n",
    "                                resnet_model.layers[-1].name:Train_command_class,\n",
    "                                resnet_model.layers[-1].name+\"_1\":Train_command_uniform, \n",
    "                                resnet_model.layers[-2].name+\"_1\":Train_participant_uniform}, \n",
    "                                validation_data=(Val_Inputs,\n",
    "                                                 {resnet_model.layers[-2].name:Val_participant_class,\n",
    "                                                  resnet_model.layers[-1].name:Val_command_class,\n",
    "                                                  resnet_model.layers[-1].name+\"_1\":Val_command_uniform,\n",
    "                                                  resnet_model.layers[-2].name+\"_1\":Val_participant_uniform}), \n",
    "                               callbacks=callbacks,\n",
    "                               batch_size=64,\n",
    "                               epochs=10)\n",
    "\n",
    "    stop = timeit.default_timer()\n",
    "    run_time = stop - start\n",
    "    \n",
    "    ##################### test performance ############################\n",
    "    predictions = resnet_model.predict(Test_Inputs)[0]\n",
    "    predicted_classes = np.argmax(predictions, axis=1)+1\n",
    "    true_classes = test_unit_participant_class\n",
    "    acc_p15_s = metrics.accuracy_score(true_classes, predicted_classes).round(4)\n",
    "\n",
    "    predictions = resnet_model.predict(Test_Inputs)[1]\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    true_classes = test_unit_command_class\n",
    "    acc_p15_c = metrics.accuracy_score(true_classes, predicted_classes).round(4)\n",
    "\n",
    "\n",
    "    # test on p1\n",
    "    ## speaker classification\n",
    "    predictions = resnet_model.predict(Test_Inputs_1)[0]\n",
    "    predicted_classes = np.argmax(predictions, axis=1)+1\n",
    "    true_classes = np.array([1]*len(predicted_classes))\n",
    "    acc_p1_s = metrics.accuracy_score(true_classes, predicted_classes).round(4)   \n",
    "    ## command classification\n",
    "    predictions = resnet_model.predict(Test_Inputs_1)[1]\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    true_classes = np.argmax(Test_command_class_1, axis=-1)\n",
    "    acc_p1_c = metrics.accuracy_score(true_classes, predicted_classes).round(4)   \n",
    "\n",
    "    # test on p2\n",
    "    ## speaker classification\n",
    "    predictions = resnet_model.predict(Test_Inputs_2)[0]\n",
    "    predicted_classes = np.argmax(predictions, axis=1)+1\n",
    "    true_classes = np.array([2]*len(predicted_classes))\n",
    "    acc_p2_s = metrics.accuracy_score(true_classes, predicted_classes).round(4)   \n",
    "    ## command classification\n",
    "    predictions = resnet_model.predict(Test_Inputs_2)[1]\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    true_classes = np.argmax(Test_command_class_2, axis=-1)\n",
    "    acc_p2_c = metrics.accuracy_score(true_classes, predicted_classes).round(4)   \n",
    "\n",
    "    # test on p3\n",
    "    ## speaker classification\n",
    "    predictions = resnet_model.predict(Test_Inputs_3)[0]\n",
    "    predicted_classes = np.argmax(predictions, axis=1)+1\n",
    "    true_classes = np.array([3]*len(predicted_classes))\n",
    "    acc_p3_s = metrics.accuracy_score(true_classes, predicted_classes).round(4)   \n",
    "    ## command classification\n",
    "    predictions = resnet_model.predict(Test_Inputs_3)[1]\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    true_classes = np.argmax(Test_command_class_3, axis=-1)\n",
    "    acc_p3_c = metrics.accuracy_score(true_classes, predicted_classes).round(4)   \n",
    "\n",
    "    # test on p4\n",
    "    ## speaker classification\n",
    "    predictions = resnet_model.predict(Test_Inputs_4)[0]\n",
    "    predicted_classes = np.argmax(predictions, axis=1)+1\n",
    "    true_classes = np.array([4]*len(predicted_classes))\n",
    "    acc_p4_s = metrics.accuracy_score(true_classes, predicted_classes).round(4)   \n",
    "    ## command classification\n",
    "    predictions = resnet_model.predict(Test_Inputs_4)[1]\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    true_classes = np.argmax(Test_command_class_4, axis=-1)\n",
    "    acc_p4_c = metrics.accuracy_score(true_classes, predicted_classes).round(4)   \n",
    "\n",
    "    # test on p5\n",
    "    ## speaker classification\n",
    "    predictions = resnet_model.predict(Test_Inputs_5)[0]\n",
    "    predicted_classes = np.argmax(predictions, axis=1)+1\n",
    "    true_classes = np.array([5]*len(predicted_classes))\n",
    "    acc_p5_s = metrics.accuracy_score(true_classes, predicted_classes).round(4)   \n",
    "    ## command classification\n",
    "    predictions = resnet_model.predict(Test_Inputs_5)[1]\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    true_classes = np.argmax(Test_command_class_5, axis=-1)\n",
    "    acc_p5_c = metrics.accuracy_score(true_classes, predicted_classes).round(4)   \n",
    "\n",
    "    # test on p6 \n",
    "    ## command classification\n",
    "    predictions = resnet_model.predict(Test_Inputs_6)[1]\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    true_classes = test_unit_command_class_6\n",
    "    acc_p6 = metrics.accuracy_score(true_classes, predicted_classes).round(4)                \n",
    "\n",
    "    # test on p7 \n",
    "    ## command classification\n",
    "    predictions = resnet_model.predict(Test_Inputs_7)[1]\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    true_classes = test_unit_command_class_7\n",
    "    acc_p7 = metrics.accuracy_score(true_classes, predicted_classes).round(4)    \n",
    "\n",
    "    # test on p8 \n",
    "    ## command classification\n",
    "    predictions = resnet_model.predict(Test_Inputs_8)[1]\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    true_classes = test_unit_command_class_8\n",
    "    acc_p8 = metrics.accuracy_score(true_classes, predicted_classes).round(4)    \n",
    "\n",
    "    Perfomance = Perfomance.append({'Model': \"Group\",'Size':'mix_20%&s2_40%','Time':run_time,\n",
    "                                    'Partcp_Acc_p15':acc_p15_s,'Command_Acc_p15':acc_p15_c,'Partcp_Acc_p1':acc_p1_s,\n",
    "                                    'Command_Acc_p1':acc_p1_c,'Partcp_Acc_p2':acc_p2_s,'Command_Acc_p2':acc_p2_c,\n",
    "                                    'Partcp_Acc_p3':acc_p3_s,'Command_Acc_p3':acc_p3_c,'Partcp_Acc_p4':acc_p4_s,\n",
    "                                    'Command_Acc_p4':acc_p4_c,'Partcp_Acc_p5':acc_p5_s,'Command_Acc_p5':acc_p5_c,\n",
    "                                    'Acc_p6':acc_p6,'Acc_p7':acc_p7,'Acc_p8':acc_p8}, ignore_index=True)\n",
    "\n",
    "\n",
    "    if high_acc < acc_p15_c + acc_p15_s:\n",
    "        resnet_model.save('Initial_group_model_mix_20p_40p_0608.h5')\n",
    "        high_acc = acc_p15_c + acc_p15_s\n",
    "        best_index = run\n",
    "        pd.DataFrame.from_dict(history1.history).to_csv('mix_20p_40p_history1_0608.csv',index=False)\n",
    "        pd.DataFrame.from_dict(history2.history).to_csv('mix_20p_40p_history2_0608.csv',index=False)\n",
    "        \n",
    "    del resnet_model\n",
    "    run = run + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "0.9945 0.965\n"
     ]
    }
   ],
   "source": [
    "resnet_model = tf.keras.models.load_model('Initial_group_model_mix_20p_40p_0608.h5')\n",
    "predictions = resnet_model.predict(Test_Inputs)[0]\n",
    "predicted_classes = np.argmax(predictions, axis=1)+1\n",
    "acc_c = round(sum(x == y for x, y in zip(test_unit_participant_class, predicted_classes)) / len(test_unit_participant_class),4)\n",
    "\n",
    "predictions = resnet_model.predict(Test_Inputs)[1]\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "acc_s = round(sum(x == y for x, y in zip(test_unit_command_class, predicted_classes)) / len(test_unit_command_class),4)\n",
    "overall_acc = acc_c + acc_s\n",
    "print(acc_c,acc_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Size</th>\n",
       "      <th>Time</th>\n",
       "      <th>Partcp_Acc_p15</th>\n",
       "      <th>Command_Acc_p15</th>\n",
       "      <th>Partcp_Acc_p1</th>\n",
       "      <th>Command_Acc_p1</th>\n",
       "      <th>Partcp_Acc_p2</th>\n",
       "      <th>Command_Acc_p2</th>\n",
       "      <th>Partcp_Acc_p3</th>\n",
       "      <th>Command_Acc_p3</th>\n",
       "      <th>Partcp_Acc_p4</th>\n",
       "      <th>Command_Acc_p4</th>\n",
       "      <th>Partcp_Acc_p5</th>\n",
       "      <th>Command_Acc_p5</th>\n",
       "      <th>Acc_p6</th>\n",
       "      <th>Acc_p7</th>\n",
       "      <th>Acc_p8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Group</td>\n",
       "      <td>20%</td>\n",
       "      <td>47.540156</td>\n",
       "      <td>0.9724</td>\n",
       "      <td>0.9484</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.9550</td>\n",
       "      <td>0.9259</td>\n",
       "      <td>0.8796</td>\n",
       "      <td>0.9652</td>\n",
       "      <td>0.9565</td>\n",
       "      <td>0.9817</td>\n",
       "      <td>0.9633</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.528</td>\n",
       "      <td>0.3366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Group</td>\n",
       "      <td>20%</td>\n",
       "      <td>48.307249</td>\n",
       "      <td>0.9779</td>\n",
       "      <td>0.9521</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.9369</td>\n",
       "      <td>0.9352</td>\n",
       "      <td>0.8796</td>\n",
       "      <td>0.9739</td>\n",
       "      <td>0.9652</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.528</td>\n",
       "      <td>0.2970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Group</td>\n",
       "      <td>20%</td>\n",
       "      <td>46.201615</td>\n",
       "      <td>0.9613</td>\n",
       "      <td>0.9448</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.9369</td>\n",
       "      <td>0.9074</td>\n",
       "      <td>0.8611</td>\n",
       "      <td>0.9826</td>\n",
       "      <td>0.9652</td>\n",
       "      <td>0.9358</td>\n",
       "      <td>0.9725</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.432</td>\n",
       "      <td>0.2673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Group</td>\n",
       "      <td>20%</td>\n",
       "      <td>43.692362</td>\n",
       "      <td>0.9650</td>\n",
       "      <td>0.9521</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.9459</td>\n",
       "      <td>0.9074</td>\n",
       "      <td>0.8704</td>\n",
       "      <td>0.9826</td>\n",
       "      <td>0.9652</td>\n",
       "      <td>0.9358</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.504</td>\n",
       "      <td>0.2673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Group</td>\n",
       "      <td>20%</td>\n",
       "      <td>44.504580</td>\n",
       "      <td>0.9687</td>\n",
       "      <td>0.9484</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.9550</td>\n",
       "      <td>0.9259</td>\n",
       "      <td>0.8796</td>\n",
       "      <td>0.9739</td>\n",
       "      <td>0.9652</td>\n",
       "      <td>0.9541</td>\n",
       "      <td>0.9541</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.472</td>\n",
       "      <td>0.3267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Group</td>\n",
       "      <td>20%</td>\n",
       "      <td>44.229166</td>\n",
       "      <td>0.9705</td>\n",
       "      <td>0.9521</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.9550</td>\n",
       "      <td>0.9074</td>\n",
       "      <td>0.8796</td>\n",
       "      <td>0.9826</td>\n",
       "      <td>0.9739</td>\n",
       "      <td>0.9633</td>\n",
       "      <td>0.9633</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.456</td>\n",
       "      <td>0.3069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Group</td>\n",
       "      <td>20%</td>\n",
       "      <td>44.535541</td>\n",
       "      <td>0.9632</td>\n",
       "      <td>0.9540</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.9369</td>\n",
       "      <td>0.9259</td>\n",
       "      <td>0.8981</td>\n",
       "      <td>0.9565</td>\n",
       "      <td>0.9652</td>\n",
       "      <td>0.9541</td>\n",
       "      <td>0.9817</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.496</td>\n",
       "      <td>0.3267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Group</td>\n",
       "      <td>20%</td>\n",
       "      <td>42.948731</td>\n",
       "      <td>0.9724</td>\n",
       "      <td>0.9595</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.9550</td>\n",
       "      <td>0.9074</td>\n",
       "      <td>0.8889</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9739</td>\n",
       "      <td>0.9633</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.496</td>\n",
       "      <td>0.2574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Group</td>\n",
       "      <td>20%</td>\n",
       "      <td>45.444911</td>\n",
       "      <td>0.9724</td>\n",
       "      <td>0.9503</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.9459</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>0.8796</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9652</td>\n",
       "      <td>0.9633</td>\n",
       "      <td>0.9725</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.552</td>\n",
       "      <td>0.2673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Group</td>\n",
       "      <td>20%</td>\n",
       "      <td>42.707019</td>\n",
       "      <td>0.9669</td>\n",
       "      <td>0.9540</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.9459</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>0.8704</td>\n",
       "      <td>0.9739</td>\n",
       "      <td>0.9652</td>\n",
       "      <td>0.9541</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.480</td>\n",
       "      <td>0.4059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Group</td>\n",
       "      <td>40%</td>\n",
       "      <td>67.289367</td>\n",
       "      <td>0.9945</td>\n",
       "      <td>0.9761</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.9640</td>\n",
       "      <td>0.9907</td>\n",
       "      <td>0.9352</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.472</td>\n",
       "      <td>0.2772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Group</td>\n",
       "      <td>40%</td>\n",
       "      <td>64.328163</td>\n",
       "      <td>0.9890</td>\n",
       "      <td>0.9761</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.9730</td>\n",
       "      <td>0.9815</td>\n",
       "      <td>0.9259</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.480</td>\n",
       "      <td>0.2871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Group</td>\n",
       "      <td>40%</td>\n",
       "      <td>61.978212</td>\n",
       "      <td>0.9926</td>\n",
       "      <td>0.9797</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.9730</td>\n",
       "      <td>0.9907</td>\n",
       "      <td>0.9444</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.3168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Group</td>\n",
       "      <td>40%</td>\n",
       "      <td>60.036626</td>\n",
       "      <td>0.9926</td>\n",
       "      <td>0.9779</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.9730</td>\n",
       "      <td>0.9907</td>\n",
       "      <td>0.9352</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.456</td>\n",
       "      <td>0.3267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Group</td>\n",
       "      <td>40%</td>\n",
       "      <td>58.215136</td>\n",
       "      <td>0.9890</td>\n",
       "      <td>0.9761</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.9730</td>\n",
       "      <td>0.9815</td>\n",
       "      <td>0.9352</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9826</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.448</td>\n",
       "      <td>0.2871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Group</td>\n",
       "      <td>40%</td>\n",
       "      <td>49.347837</td>\n",
       "      <td>0.9871</td>\n",
       "      <td>0.9761</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.9730</td>\n",
       "      <td>0.9815</td>\n",
       "      <td>0.9352</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9817</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.472</td>\n",
       "      <td>0.2772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Group</td>\n",
       "      <td>40%</td>\n",
       "      <td>59.879732</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.9779</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.9730</td>\n",
       "      <td>0.9815</td>\n",
       "      <td>0.9444</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9826</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.3366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Group</td>\n",
       "      <td>40%</td>\n",
       "      <td>57.413757</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.9761</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.9640</td>\n",
       "      <td>0.9815</td>\n",
       "      <td>0.9444</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9826</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.3168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Group</td>\n",
       "      <td>40%</td>\n",
       "      <td>50.219540</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.9761</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.9730</td>\n",
       "      <td>0.9815</td>\n",
       "      <td>0.9352</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.456</td>\n",
       "      <td>0.2772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Group</td>\n",
       "      <td>40%</td>\n",
       "      <td>53.871787</td>\n",
       "      <td>0.9945</td>\n",
       "      <td>0.9742</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.9730</td>\n",
       "      <td>0.9907</td>\n",
       "      <td>0.9259</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.9817</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.424</td>\n",
       "      <td>0.2673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Group</td>\n",
       "      <td>60%</td>\n",
       "      <td>80.966223</td>\n",
       "      <td>0.9926</td>\n",
       "      <td>0.9871</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.9820</td>\n",
       "      <td>0.9815</td>\n",
       "      <td>0.9722</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.2772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Group</td>\n",
       "      <td>60%</td>\n",
       "      <td>77.376384</td>\n",
       "      <td>0.9926</td>\n",
       "      <td>0.9797</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.9820</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9537</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9826</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.9817</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.456</td>\n",
       "      <td>0.2178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Group</td>\n",
       "      <td>60%</td>\n",
       "      <td>79.340686</td>\n",
       "      <td>0.9945</td>\n",
       "      <td>0.9816</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.9820</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9444</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.2970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Group</td>\n",
       "      <td>60%</td>\n",
       "      <td>63.791425</td>\n",
       "      <td>0.9890</td>\n",
       "      <td>0.9871</td>\n",
       "      <td>0.973</td>\n",
       "      <td>0.9910</td>\n",
       "      <td>0.9815</td>\n",
       "      <td>0.9630</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.424</td>\n",
       "      <td>0.3069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Group</td>\n",
       "      <td>60%</td>\n",
       "      <td>78.678261</td>\n",
       "      <td>0.9926</td>\n",
       "      <td>0.9797</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.9820</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9537</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9826</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.9817</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.424</td>\n",
       "      <td>0.2376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Group</td>\n",
       "      <td>60%</td>\n",
       "      <td>71.382334</td>\n",
       "      <td>0.9945</td>\n",
       "      <td>0.9834</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.9820</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9537</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.408</td>\n",
       "      <td>0.2475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Group</td>\n",
       "      <td>60%</td>\n",
       "      <td>76.130331</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.9853</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.9910</td>\n",
       "      <td>0.9907</td>\n",
       "      <td>0.9537</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.416</td>\n",
       "      <td>0.2673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Group</td>\n",
       "      <td>60%</td>\n",
       "      <td>70.832085</td>\n",
       "      <td>0.9945</td>\n",
       "      <td>0.9871</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.9820</td>\n",
       "      <td>0.9907</td>\n",
       "      <td>0.9722</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.2673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Group</td>\n",
       "      <td>60%</td>\n",
       "      <td>73.439023</td>\n",
       "      <td>0.9945</td>\n",
       "      <td>0.9890</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.9910</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9722</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.424</td>\n",
       "      <td>0.2277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Group</td>\n",
       "      <td>60%</td>\n",
       "      <td>72.148432</td>\n",
       "      <td>0.9945</td>\n",
       "      <td>0.9834</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.9910</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9444</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.416</td>\n",
       "      <td>0.2772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Group</td>\n",
       "      <td>mix_20%&amp;s2_40%</td>\n",
       "      <td>47.769887</td>\n",
       "      <td>0.9834</td>\n",
       "      <td>0.9669</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.9459</td>\n",
       "      <td>0.9815</td>\n",
       "      <td>0.9352</td>\n",
       "      <td>0.9739</td>\n",
       "      <td>0.9826</td>\n",
       "      <td>0.9725</td>\n",
       "      <td>0.9817</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.552</td>\n",
       "      <td>0.3267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Group</td>\n",
       "      <td>mix_20%&amp;s2_40%</td>\n",
       "      <td>49.705597</td>\n",
       "      <td>0.9816</td>\n",
       "      <td>0.9576</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.9369</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9259</td>\n",
       "      <td>0.9739</td>\n",
       "      <td>0.9652</td>\n",
       "      <td>0.9450</td>\n",
       "      <td>0.9817</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.512</td>\n",
       "      <td>0.3168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Group</td>\n",
       "      <td>mix_20%&amp;s2_40%</td>\n",
       "      <td>44.363904</td>\n",
       "      <td>0.9797</td>\n",
       "      <td>0.9576</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.9550</td>\n",
       "      <td>0.9815</td>\n",
       "      <td>0.9259</td>\n",
       "      <td>0.9652</td>\n",
       "      <td>0.9478</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.9725</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.536</td>\n",
       "      <td>0.2376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Group</td>\n",
       "      <td>mix_20%&amp;s2_40%</td>\n",
       "      <td>46.206470</td>\n",
       "      <td>0.9945</td>\n",
       "      <td>0.9650</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.9550</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9259</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9652</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.480</td>\n",
       "      <td>0.2673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Group</td>\n",
       "      <td>mix_20%&amp;s2_40%</td>\n",
       "      <td>47.192904</td>\n",
       "      <td>0.9797</td>\n",
       "      <td>0.9632</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.9369</td>\n",
       "      <td>0.9907</td>\n",
       "      <td>0.9444</td>\n",
       "      <td>0.9739</td>\n",
       "      <td>0.9652</td>\n",
       "      <td>0.9541</td>\n",
       "      <td>0.9817</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.504</td>\n",
       "      <td>0.2871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Group</td>\n",
       "      <td>mix_20%&amp;s2_40%</td>\n",
       "      <td>47.685570</td>\n",
       "      <td>0.9761</td>\n",
       "      <td>0.9558</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.9279</td>\n",
       "      <td>0.9907</td>\n",
       "      <td>0.9352</td>\n",
       "      <td>0.9565</td>\n",
       "      <td>0.9565</td>\n",
       "      <td>0.9633</td>\n",
       "      <td>0.9817</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.472</td>\n",
       "      <td>0.2871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Group</td>\n",
       "      <td>mix_20%&amp;s2_40%</td>\n",
       "      <td>44.867667</td>\n",
       "      <td>0.9816</td>\n",
       "      <td>0.9687</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.9550</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9537</td>\n",
       "      <td>0.9652</td>\n",
       "      <td>0.9652</td>\n",
       "      <td>0.9541</td>\n",
       "      <td>0.9817</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.496</td>\n",
       "      <td>0.2673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Group</td>\n",
       "      <td>mix_20%&amp;s2_40%</td>\n",
       "      <td>44.795298</td>\n",
       "      <td>0.9853</td>\n",
       "      <td>0.9724</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.9550</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9630</td>\n",
       "      <td>0.9652</td>\n",
       "      <td>0.9739</td>\n",
       "      <td>0.9633</td>\n",
       "      <td>0.9817</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.544</td>\n",
       "      <td>0.3069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Group</td>\n",
       "      <td>mix_20%&amp;s2_40%</td>\n",
       "      <td>40.871670</td>\n",
       "      <td>0.9742</td>\n",
       "      <td>0.9558</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.9459</td>\n",
       "      <td>0.9815</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>0.9391</td>\n",
       "      <td>0.9565</td>\n",
       "      <td>0.9541</td>\n",
       "      <td>0.9725</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.480</td>\n",
       "      <td>0.2970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Group</td>\n",
       "      <td>mix_20%&amp;s2_40%</td>\n",
       "      <td>42.479896</td>\n",
       "      <td>0.9834</td>\n",
       "      <td>0.9687</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.9550</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9352</td>\n",
       "      <td>0.9739</td>\n",
       "      <td>0.9826</td>\n",
       "      <td>0.9633</td>\n",
       "      <td>0.9817</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.536</td>\n",
       "      <td>0.2673</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Model            Size       Time  Partcp_Acc_p15  Command_Acc_p15  \\\n",
       "0   Group             20%  47.540156          0.9724           0.9484   \n",
       "1   Group             20%  48.307249          0.9779           0.9521   \n",
       "2   Group             20%  46.201615          0.9613           0.9448   \n",
       "3   Group             20%  43.692362          0.9650           0.9521   \n",
       "4   Group             20%  44.504580          0.9687           0.9484   \n",
       "5   Group             20%  44.229166          0.9705           0.9521   \n",
       "6   Group             20%  44.535541          0.9632           0.9540   \n",
       "7   Group             20%  42.948731          0.9724           0.9595   \n",
       "8   Group             20%  45.444911          0.9724           0.9503   \n",
       "9   Group             20%  42.707019          0.9669           0.9540   \n",
       "10  Group             40%  67.289367          0.9945           0.9761   \n",
       "11  Group             40%  64.328163          0.9890           0.9761   \n",
       "12  Group             40%  61.978212          0.9926           0.9797   \n",
       "13  Group             40%  60.036626          0.9926           0.9779   \n",
       "14  Group             40%  58.215136          0.9890           0.9761   \n",
       "15  Group             40%  49.347837          0.9871           0.9761   \n",
       "16  Group             40%  59.879732          0.9908           0.9779   \n",
       "17  Group             40%  57.413757          0.9908           0.9761   \n",
       "18  Group             40%  50.219540          0.9908           0.9761   \n",
       "19  Group             40%  53.871787          0.9945           0.9742   \n",
       "20  Group             60%  80.966223          0.9926           0.9871   \n",
       "21  Group             60%  77.376384          0.9926           0.9797   \n",
       "22  Group             60%  79.340686          0.9945           0.9816   \n",
       "23  Group             60%  63.791425          0.9890           0.9871   \n",
       "24  Group             60%  78.678261          0.9926           0.9797   \n",
       "25  Group             60%  71.382334          0.9945           0.9834   \n",
       "26  Group             60%  76.130331          0.9908           0.9853   \n",
       "27  Group             60%  70.832085          0.9945           0.9871   \n",
       "28  Group             60%  73.439023          0.9945           0.9890   \n",
       "29  Group             60%  72.148432          0.9945           0.9834   \n",
       "30  Group  mix_20%&s2_40%  47.769887          0.9834           0.9669   \n",
       "31  Group  mix_20%&s2_40%  49.705597          0.9816           0.9576   \n",
       "32  Group  mix_20%&s2_40%  44.363904          0.9797           0.9576   \n",
       "33  Group  mix_20%&s2_40%  46.206470          0.9945           0.9650   \n",
       "34  Group  mix_20%&s2_40%  47.192904          0.9797           0.9632   \n",
       "35  Group  mix_20%&s2_40%  47.685570          0.9761           0.9558   \n",
       "36  Group  mix_20%&s2_40%  44.867667          0.9816           0.9687   \n",
       "37  Group  mix_20%&s2_40%  44.795298          0.9853           0.9724   \n",
       "38  Group  mix_20%&s2_40%  40.871670          0.9742           0.9558   \n",
       "39  Group  mix_20%&s2_40%  42.479896          0.9834           0.9687   \n",
       "\n",
       "    Partcp_Acc_p1  Command_Acc_p1  Partcp_Acc_p2  Command_Acc_p2  \\\n",
       "0           0.991          0.9550         0.9259          0.8796   \n",
       "1           1.000          0.9369         0.9352          0.8796   \n",
       "2           0.991          0.9369         0.9074          0.8611   \n",
       "3           1.000          0.9459         0.9074          0.8704   \n",
       "4           0.991          0.9550         0.9259          0.8796   \n",
       "5           1.000          0.9550         0.9074          0.8796   \n",
       "6           0.991          0.9369         0.9259          0.8981   \n",
       "7           1.000          0.9550         0.9074          0.8889   \n",
       "8           0.991          0.9459         0.9167          0.8796   \n",
       "9           0.991          0.9459         0.9167          0.8704   \n",
       "10          0.991          0.9640         0.9907          0.9352   \n",
       "11          0.982          0.9730         0.9815          0.9259   \n",
       "12          0.991          0.9730         0.9907          0.9444   \n",
       "13          0.991          0.9730         0.9907          0.9352   \n",
       "14          0.982          0.9730         0.9815          0.9352   \n",
       "15          0.982          0.9730         0.9815          0.9352   \n",
       "16          0.991          0.9730         0.9815          0.9444   \n",
       "17          0.991          0.9640         0.9815          0.9444   \n",
       "18          0.991          0.9730         0.9815          0.9352   \n",
       "19          1.000          0.9730         0.9907          0.9259   \n",
       "20          0.991          0.9820         0.9815          0.9722   \n",
       "21          0.982          0.9820         1.0000          0.9537   \n",
       "22          0.982          0.9820         1.0000          0.9444   \n",
       "23          0.973          0.9910         0.9815          0.9630   \n",
       "24          0.982          0.9820         1.0000          0.9537   \n",
       "25          0.982          0.9820         1.0000          0.9537   \n",
       "26          0.982          0.9910         0.9907          0.9537   \n",
       "27          0.991          0.9820         0.9907          0.9722   \n",
       "28          0.982          0.9910         1.0000          0.9722   \n",
       "29          0.982          0.9910         1.0000          0.9444   \n",
       "30          0.991          0.9459         0.9815          0.9352   \n",
       "31          0.991          0.9369         1.0000          0.9259   \n",
       "32          0.991          0.9550         0.9815          0.9259   \n",
       "33          0.991          0.9550         1.0000          0.9259   \n",
       "34          0.982          0.9369         0.9907          0.9444   \n",
       "35          0.991          0.9279         0.9907          0.9352   \n",
       "36          0.991          0.9550         1.0000          0.9537   \n",
       "37          1.000          0.9550         1.0000          0.9630   \n",
       "38          1.000          0.9459         0.9815          0.9167   \n",
       "39          0.982          0.9550         1.0000          0.9352   \n",
       "\n",
       "    Partcp_Acc_p3  Command_Acc_p3  Partcp_Acc_p4  Command_Acc_p4  \\\n",
       "0          0.9652          0.9565         0.9817          0.9633   \n",
       "1          0.9739          0.9652         0.9908          0.9908   \n",
       "2          0.9826          0.9652         0.9358          0.9725   \n",
       "3          0.9826          0.9652         0.9358          0.9908   \n",
       "4          0.9739          0.9652         0.9541          0.9541   \n",
       "5          0.9826          0.9739         0.9633          0.9633   \n",
       "6          0.9565          0.9652         0.9541          0.9817   \n",
       "7          0.9913          0.9739         0.9633          0.9908   \n",
       "8          0.9913          0.9652         0.9633          0.9725   \n",
       "9          0.9739          0.9652         0.9541          0.9908   \n",
       "10         1.0000          0.9913         0.9908          0.9908   \n",
       "11         0.9913          0.9913         0.9908          0.9908   \n",
       "12         0.9913          0.9913         0.9908          0.9908   \n",
       "13         0.9913          0.9913         0.9908          0.9908   \n",
       "14         0.9913          0.9826         0.9908          0.9908   \n",
       "15         0.9913          0.9913         0.9817          0.9908   \n",
       "16         0.9913          0.9826         0.9908          0.9908   \n",
       "17         0.9913          0.9826         0.9908          0.9908   \n",
       "18         0.9913          0.9913         0.9908          0.9908   \n",
       "19         0.9913          0.9913         0.9908          0.9817   \n",
       "20         1.0000          0.9913         0.9908          0.9908   \n",
       "21         0.9913          0.9826         0.9908          0.9817   \n",
       "22         1.0000          0.9913         0.9908          0.9908   \n",
       "23         1.0000          0.9913         0.9908          0.9908   \n",
       "24         0.9913          0.9826         0.9908          0.9817   \n",
       "25         1.0000          0.9913         0.9908          0.9908   \n",
       "26         0.9913          0.9913         0.9908          0.9908   \n",
       "27         1.0000          0.9913         0.9908          0.9908   \n",
       "28         1.0000          0.9913         0.9908          0.9908   \n",
       "29         1.0000          0.9913         0.9908          0.9908   \n",
       "30         0.9739          0.9826         0.9725          0.9817   \n",
       "31         0.9739          0.9652         0.9450          0.9817   \n",
       "32         0.9652          0.9478         0.9908          0.9725   \n",
       "33         0.9913          0.9652         0.9908          0.9908   \n",
       "34         0.9739          0.9652         0.9541          0.9817   \n",
       "35         0.9565          0.9565         0.9633          0.9817   \n",
       "36         0.9652          0.9652         0.9541          0.9817   \n",
       "37         0.9652          0.9739         0.9633          0.9817   \n",
       "38         0.9391          0.9565         0.9541          0.9725   \n",
       "39         0.9739          0.9826         0.9633          0.9817   \n",
       "\n",
       "    Partcp_Acc_p5  Command_Acc_p5  Acc_p6  Acc_p7  Acc_p8  \n",
       "0            1.00            0.99    0.67   0.528  0.3366  \n",
       "1            0.99            0.99    0.59   0.528  0.2970  \n",
       "2            0.99            0.99    0.67   0.432  0.2673  \n",
       "3            1.00            0.99    0.62   0.504  0.2673  \n",
       "4            1.00            0.99    0.59   0.472  0.3267  \n",
       "5            1.00            0.99    0.62   0.456  0.3069  \n",
       "6            0.99            0.99    0.67   0.496  0.3267  \n",
       "7            1.00            0.99    0.67   0.496  0.2574  \n",
       "8            1.00            0.99    0.60   0.552  0.2673  \n",
       "9            1.00            1.00    0.66   0.480  0.4059  \n",
       "10           1.00            1.00    0.65   0.472  0.2772  \n",
       "11           1.00            1.00    0.63   0.480  0.2871  \n",
       "12           1.00            1.00    0.69   0.400  0.3168  \n",
       "13           1.00            1.00    0.70   0.456  0.3267  \n",
       "14           1.00            1.00    0.70   0.448  0.2871  \n",
       "15           1.00            0.99    0.70   0.472  0.2772  \n",
       "16           1.00            1.00    0.70   0.440  0.3366  \n",
       "17           1.00            1.00    0.67   0.440  0.3168  \n",
       "18           1.00            0.99    0.63   0.456  0.2772  \n",
       "19           1.00            1.00    0.65   0.424  0.2673  \n",
       "20           1.00            1.00    0.69   0.440  0.2772  \n",
       "21           1.00            1.00    0.72   0.456  0.2178  \n",
       "22           1.00            1.00    0.68   0.440  0.2970  \n",
       "23           1.00            1.00    0.68   0.424  0.3069  \n",
       "24           1.00            1.00    0.68   0.424  0.2376  \n",
       "25           1.00            1.00    0.66   0.408  0.2475  \n",
       "26           1.00            1.00    0.73   0.416  0.2673  \n",
       "27           1.00            1.00    0.70   0.440  0.2673  \n",
       "28           1.00            1.00    0.70   0.424  0.2277  \n",
       "29           1.00            1.00    0.70   0.416  0.2772  \n",
       "30           1.00            0.99    0.69   0.552  0.3267  \n",
       "31           1.00            0.98    0.69   0.512  0.3168  \n",
       "32           0.97            0.99    0.72   0.536  0.2376  \n",
       "33           1.00            0.99    0.70   0.480  0.2673  \n",
       "34           1.00            0.99    0.69   0.504  0.2871  \n",
       "35           0.98            0.98    0.72   0.472  0.2871  \n",
       "36           1.00            0.99    0.66   0.496  0.2673  \n",
       "37           1.00            0.99    0.68   0.544  0.3069  \n",
       "38           1.00            0.99    0.71   0.480  0.2970  \n",
       "39           1.00            0.99    0.73   0.536  0.2673  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Perfomance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "Perfomance.to_csv('Performance_0608_training_Data_Size.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
